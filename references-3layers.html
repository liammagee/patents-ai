<html>
<head>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/vis/4.16.1/vis.css" type="text/css" />
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/vis/4.16.1/vis-network.min.js"> </script>
<center>
<h1></h1>
</center>

<!-- <link rel="stylesheet" href="../node_modules/vis/dist/vis.min.css" type="text/css" />
<script type="text/javascript" src="../node_modules/vis/dist/vis.js"> </script>-->

<style type="text/css">

        #mynetwork {
            width: 100%;
            height: 750px;
            background-color: #222222;
            border: 1px solid lightgray;
            position: relative;
            float: left;
        }

        
        #loadingBar {
            position:absolute;
            top:0px;
            left:0px;
            width: 100%;
            height: 750px;
            background-color:rgba(200,200,200,0.8);
            -webkit-transition: all 0.5s ease;
            -moz-transition: all 0.5s ease;
            -ms-transition: all 0.5s ease;
            -o-transition: all 0.5s ease;
            transition: all 0.5s ease;
            opacity:1;
        }

        #bar {
            position:absolute;
            top:0px;
            left:0px;
            width:20px;
            height:20px;
            margin:auto auto auto auto;
            border-radius:11px;
            border:2px solid rgba(30,30,30,0.05);
            background: rgb(0, 173, 246); /* Old browsers */
            box-shadow: 2px 0px 4px rgba(0,0,0,0.4);
        }

        #border {
            position:absolute;
            top:10px;
            left:10px;
            width:500px;
            height:23px;
            margin:auto auto auto auto;
            box-shadow: 0px 0px 4px rgba(0,0,0,0.2);
            border-radius:10px;
        }

        #text {
            position:absolute;
            top:8px;
            left:530px;
            width:30px;
            height:50px;
            margin:auto auto auto auto;
            font-size:22px;
            color: #000000;
        }

        div.outerBorder {
            position:relative;
            top:400px;
            width:600px;
            height:44px;
            margin:auto auto auto auto;
            border:8px solid rgba(0,0,0,0.1);
            background: rgb(252,252,252); /* Old browsers */
            background: -moz-linear-gradient(top,  rgba(252,252,252,1) 0%, rgba(237,237,237,1) 100%); /* FF3.6+ */
            background: -webkit-gradient(linear, left top, left bottom, color-stop(0%,rgba(252,252,252,1)), color-stop(100%,rgba(237,237,237,1))); /* Chrome,Safari4+ */
            background: -webkit-linear-gradient(top,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* Chrome10+,Safari5.1+ */
            background: -o-linear-gradient(top,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* Opera 11.10+ */
            background: -ms-linear-gradient(top,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* IE10+ */
            background: linear-gradient(to bottom,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* W3C */
            filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#fcfcfc', endColorstr='#ededed',GradientType=0 ); /* IE6-9 */
            border-radius:72px;
            box-shadow: 0px 0px 10px rgba(0,0,0,0.2);
        }
        

        

        
</style>

</head>

<body>
<div id = "mynetwork"></div>

<div id="loadingBar">
    <div class="outerBorder">
        <div id="text">0%</div>
        <div id="border">
            <div id="bar"></div>
        </div>
    </div>
</div>


<script type="text/javascript">

    // initialize global variables.
    var edges;
    var nodes;
    var network; 
    var container;
    var options, data;

    
    // This method is responsible for drawing the graph, returns the drawn network
    function drawGraph() {
        var container = document.getElementById('mynetwork');
        
        

        // parsing and collecting nodes and edges from the python
        nodes = new vis.DataSet([{"font": {"color": "white"}, "id": "", "label": "", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database", "label": "PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep learning for visual understanding: A review", "label": "Deep learning for visual understanding: A review", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep convolutional neural networks for image classification: A comprehensive review", "label": "Deep convolutional neural networks for image classification: A comprehensive review", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deepfashion: Powering robust clothes recognition and retrieval with rich annotations", "label": "Deepfashion: Powering robust clothes recognition and retrieval with rich annotations", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "3d shapenets: A deep representation for volumetric shapes", "label": "3d shapenets: A deep representation for volumetric shapes", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Seeing 3d chairs: exemplar part-based 2d-3d alignment using a large dataset of cad models", "label": "Seeing 3d chairs: exemplar part-based 2d-3d alignment using a large dataset of cad models", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Benchmark Datasets for Fault Detection and Classification in Sensor Data", "label": "Benchmark Datasets for Fault Detection and Classification in Sensor Data", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A style-based generator architecture for generative adversarial networks", "label": "A style-based generator architecture for generative adversarial networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A compact embedding for facial expression similarity", "label": "A compact embedding for facial expression similarity", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding", "label": "Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "3d object representations for fine-grained categorization", "label": "3d object representations for fine-grained categorization", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fashionista: A fashion-aware graphical system for exploring visually similar items", "label": "Fashionista: A fashion-aware graphical system for exploring visually similar items", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fashionai: A hierarchical dataset for fashion understanding", "label": "Fashionai: A hierarchical dataset for fashion understanding", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms", "label": "Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fashion-gen: The generative fashion dataset and challenge", "label": "Fashion-gen: The generative fashion dataset and challenge", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Very deep convolutional networks for large-scale image recognition", "label": "Very deep convolutional networks for large-scale image recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Going deeper with convolutions", "label": "Going deeper with convolutions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep residual learning for image recognition", "label": "Deep residual learning for image recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Densely connected convolutional networks", "label": "Densely connected convolutional networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Efficientnet: Rethinking model scaling for convolutional neural networks", "label": "Efficientnet: Rethinking model scaling for convolutional neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Central similarity quantization for efficient image and video retrieval", "label": "Central similarity quantization for efficient image and video retrieval", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Hashnet: Deep learning to hash by continuation", "label": "Hashnet: Deep learning to hash by continuation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Incomplete multi-modal visual data grouping", "label": "Incomplete multi-modal visual data grouping", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Doubly Aligned Incomplete Multi-view Clustering", "label": "Doubly Aligned Incomplete Multi-view Clustering", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Incomplete Multiview Spectral Clustering With Adaptive Graph Learning", "label": "Incomplete Multiview Spectral Clustering With Adaptive Graph Learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Anchors bring ease: An embarrassingly simple approach to partial multi-view clustering", "label": "Anchors bring ease: An embarrassingly simple approach to partial multi-view clustering", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A comparison of extrinsic clustering evaluation metrics based on formal constraints", "label": "A comparison of extrinsic clustering evaluation metrics based on formal constraints", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Adaptive structure discovery for multimedia analysis using multiple features", "label": "Adaptive structure discovery for multimedia analysis using multiple features", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Emotionet: An accurate", "label": "Emotionet: An accurate", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Large scale online learning of image similarity through ranking", "label": "Large scale online learning of image similarity through ranking", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep struc-ture inference network for facial action unit recognition", "label": "Deep struc-ture inference network for facial action unit recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Self-report captures 27 dis-tinct categories of emotion bridged by continuous gradi-ents", "label": "Self-report captures 27 dis-tinct categories of emotion bridged by continuous gradi-ents", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Clarifying the conceptualiza-tion", "label": "Clarifying the conceptualiza-tion", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "From individual to group-level emotion recog-nition: Emotiw 5", "label": "From individual to group-level emotion recog-nition: Emotiw 5", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "R", "label": "R", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "O", "label": "O", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Facial Action Coding System -Manual", "label": "Facial Action Coding System -Manual", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Candid portrait ACM Transactions on Graphics", "label": "Candid portrait ACM Transactions on Graphics", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep metric learning with hierarchical triplet loss", "label": "Deep metric learning with hierarchical triplet loss", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Understanding the dif\ufb01culty of In AISTATS", "label": "Understanding the dif\ufb01culty of In AISTATS", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Challenges in representation learning: A report on three machine learning contests", "label": "Challenges in representation learning: A report on three machine learning contests", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "I", "label": "I", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "MS-Celeb-1M: A dataset and benchmark for large scale face recognition", "label": "MS-Celeb-1M: A dataset and benchmark for large scale face recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Triplet-center loss for multi-view 3D object retrieval", "label": "Triplet-center loss for multi-view 3D object retrieval", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "In defense of the triplet loss for person re-identi\ufb01cation", "label": "In defense of the triplet loss for person re-identi\ufb01cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "label": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The MegaFace benchmark: 1 million faces for recognition at scale", "label": "The MegaFace benchmark: 1 million faces for recognition at scale", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Adam: A method for stochastic optimization", "label": "Adam: A method for stochastic optimization", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "DEAP: A database for emotion analysis using physiological sig-nals", "label": "DEAP: A database for emotion analysis using physiological sig-nals", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Self-supervised In learning of a facial attribute embedding from video", "label": "Self-supervised In learning of a facial attribute embedding from video", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep af-fect prediction in-the-wild: Aff-wild database and challenge", "label": "Deep af-fect prediction in-the-wild: Aff-wild database and challenge", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "AFEW-VA database for valence and arousal estimation in-the-wild", "label": "AFEW-VA database for valence and arousal estimation in-the-wild", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Convolutional deep belief networks on CIFAR-10", "label": "Convolutional deep belief networks on CIFAR-10", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep facial expression recognition: A survey", "label": "Deep facial expression recognition: A survey", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Reliable crowdsourcing and deep locality-preserving learning for unconstrained facial expres-sion recognition", "label": "Reliable crowdsourcing and deep locality-preserving learning for unconstrained facial expres-sion recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep relative distance learning: Tell the difference between similar vehicles", "label": "Deep relative distance learning: Tell the difference between similar vehicles", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep learning face attributes in the wild", "label": "Deep learning face attributes in the wild", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The extended Cohn-Kanade dataset (CK+): A complete dataset for action unit and emotion-speci\ufb01ed expression", "label": "The extended Cohn-Kanade dataset (CK+): A complete dataset for action unit and emotion-speci\ufb01ed expression", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Auto-matic analysis of facial actions: A survey", "label": "Auto-matic analysis of facial actions: A survey", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Facial expression recognition from near-infrared videos", "label": "Facial expression recognition from near-infrared videos", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fast training of triplet-based deep binary embedding networks", "label": "Fast training of triplet-based deep binary embedding networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Affectiva-MIT facial expression dataset (AM-FED): Naturalistic and spontaneous facial expressions collected in-the-wild", "label": "Affectiva-MIT facial expression dataset (AM-FED): Naturalistic and spontaneous facial expressions collected in-the-wild", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Basic dimensions for a general psychological theory: Implications for personality", "label": "Basic dimensions for a general psychological theory: Implications for personality", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "LSTM-based facial performance capture using embedding between expressions", "label": "LSTM-based facial performance capture using embedding between expressions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Affect-Net: A database for facial expression", "label": "Affect-Net: A database for facial expression", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Facial expression recognition from world wild web", "label": "Facial expression recognition from world wild web", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Level playing \ufb01eld for million scale face recognition", "label": "Level playing \ufb01eld for million scale face recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Web-In ICME", "label": "Web-In ICME", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Introducing the RECOLA multimodal corpus of remote col-laborative and affective interactions", "label": "Introducing the RECOLA multimodal corpus of remote col-laborative and affective interactions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A circumplex model of affect", "label": "A circumplex model of affect", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "FaceNet: A In uni\ufb01ed embedding for face recognition and clustering", "label": "FaceNet: A In uni\ufb01ed embedding for face recognition and clustering", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep adaptive attention for joint facial action unit detection and face alignment", "label": "Deep adaptive attention for joint facial action unit detection and face alignment", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep metric learning via lifted structured feature embedding", "label": "Deep metric learning via lifted structured feature embedding", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "DeepFace: Closing the gap to human-level performance in face veri\ufb01ca-tion", "label": "DeepFace: Closing the gap to human-level performance in face veri\ufb01ca-tion", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning \ufb01ne-grained im-age similarity with deep ranking", "label": "Learning \ufb01ne-grained im-age similarity with deep ranking", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep metric learning with angular loss", "label": "Deep metric learning with angular loss", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Distance metric learning for large margin nearest neighbor classi\ufb01cation", "label": "Distance metric learning for large margin nearest neighbor classi\ufb01cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "From facial expression recognition to interpersonal relation prediction", "label": "From facial expression recognition to interpersonal relation prediction", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Mesh segmentation-a comparative study", "label": "Mesh segmentation-a comparative study", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A framework for the objective evaluation of segmentation algorithms using a ground-truth of human segmented 3D-models", "label": "A framework for the objective evaluation of segmentation algorithms using a ground-truth of human segmented 3D-models", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "T", "label": "T", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Linking WordNet to 3D shapes", "label": "Linking WordNet to 3D shapes", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A benchmark for 3D mesh segmentation", "label": "A benchmark for 3D mesh segmentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "3D se-mantic segmentation with submanifold sparse convolutional networks", "label": "3D se-mantic segmentation with submanifold sparse convolutional networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Parts of recognition", "label": "Parts of recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Co-segmentation of 3D shapes via subspace clustering", "label": "Co-segmentation of 3D shapes via subspace clustering", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning to predict part mobility from a sin-gle static snapshot", "label": "Learning to predict part mobility from a sin-gle static snapshot", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning how objects function via co-analysis of interactions", "label": "Learning how objects function via co-analysis of interactions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Predictive and generative neural networks for object functionality", "label": "Predictive and generative neural networks for object functionality", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Robust watertight mani-fold surface generation method for shapenet models", "label": "Robust watertight mani-fold surface generation method for shapenet models", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Explor-ing shape variations by 3d-model decomposition and part-In Computer Graphics Forum", "label": "Explor-ing shape variations by 3d-model decomposition and part-In Computer Graphics Forum", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning 3D mesh segmentation and labeling", "label": "Learning 3D mesh segmentation and labeling", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Shape2pose: Human-centric shape analysis", "label": "Shape2pose: Human-centric shape analysis", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Escape from cells: Deep kd-networks for the recognition of 3D point cloud models", "label": "Escape from cells: Deep kd-networks for the recognition of 3D point cloud models", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Ai2-thor: An interactive 3d environment for vi-sual ai", "label": "Ai2-thor: An interactive 3d environment for vi-sual ai", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Parameter learning and con-vergent inference for dense random \ufb01elds", "label": "Parameter learning and con-vergent inference for dense random \ufb01elds", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The hungarian method for the assignment prob-lem", "label": "The hungarian method for the assignment prob-lem", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "PointGrid: A deep network for 3D shape understanding", "label": "PointGrid: A deep network for 3D shape understanding", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "SO-Net: Self-organizing network for point cloud analysis", "label": "SO-Net: Self-organizing network for point cloud analysis", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Grass: Generative recursive autoencoders for shape structures", "label": "Grass: Generative recursive autoencoders for shape structures", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "PointCNN: Convolution on X -transformed points", "label": "PointCNN: Convolution on X -transformed points", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Physical primitive decomposition", "label": "Physical primitive decomposition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Explo-ration of continuous variability in collections of 3d shapes", "label": "Explo-ration of continuous variability in collections of 3d shapes", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Virtualhome: Simulating household activities via programs", "label": "Virtualhome: Simulating household activities via programs", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "PointNet: Deep learning on point sets for 3D classi\ufb01cation and segmentation", "label": "PointNet: Deep learning on point sets for 3D classi\ufb01cation and segmentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "PointNet++: Deep hierarchical feature learning on point sets in a metric space", "label": "PointNet++: Deep hierarchical feature learning on point sets in a metric space", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Con-point cloud processing", "label": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Con-point cloud processing", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions", "label": "Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "SGPN: Sim-ilarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation", "label": "SGPN: Sim-ilarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning to group and label \ufb01ne-grained shape components", "label": "Learning to group and label \ufb01ne-grained shape components", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Active co-analysis of a set of shapes", "label": "Active co-analysis of a set of shapes", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Dynamic graph cnn for learning on point clouds", "label": "Dynamic graph cnn for learning on point clouds", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "VoxSegNet: Volumetric CNNs for semantic part segmentation of 3D shapes", "label": "VoxSegNet: Volumetric CNNs for semantic part segmentation of 3D shapes", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Structure-aware generative network for 3d-shape modeling", "label": "Structure-aware generative network for 3d-shape modeling", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Spider-CNN: Deep learning on point sets with parameterized con-volutional \ufb01lters", "label": "Spider-CNN: Deep learning on point sets with parameterized con-volutional \ufb01lters", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Chalet: Cornell house agent learning environment", "label": "Chalet: Cornell house agent learning environment", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning hierarchical shape segmentation and labeling from online repositories", "label": "Learning hierarchical shape segmentation and labeling from online repositories", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "V", "label": "V", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "SyncSpecCNN: Syn-chronized spectral CNN for 3D shape segmentation", "label": "SyncSpecCNN: Syn-chronized spectral CNN for 3D shape segmentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Visual semantic plan-ning using deep successor representations", "label": "Visual semantic plan-ning using deep successor representations", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Image-based recommendations on styles and substitutes", "label": "Image-based recommendations on styles and substitutes", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative \ufb01ltering", "label": "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative \ufb01ltering", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "VBPR: visual bayesian personalized ranking from implicit feedback", "label": "VBPR: visual bayesian personalized ranking from implicit feedback", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Lotusx: a position-aware xml graphical search system with auto-completion", "label": "Lotusx: a position-aware xml graphical search system with auto-completion", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Imagenet classi\ufb01cation with deep convolutional neural networks", "label": "Imagenet classi\ufb01cation with deep convolutional neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "One-class collaborative \ufb01ltering", "label": "One-class collaborative \ufb01ltering", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Accelerating t-SNE using tree-based algorithms", "label": "Accelerating t-SNE using tree-based algorithms", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A note on the inception score", "label": "A note on the inception score", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Viton: An image-based virtual try-on network", "label": "Viton: An image-based virtual try-on network", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Stacked generative adversarial networks", "label": "Stacked generative adversarial networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Image-to-image translation with conditional adversarial networks", "label": "Image-to-image translation with conditional adversarial networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Getting the look: clothing recognition and segmentation for automatic prod-uct suggestions in everyday photos", "label": "Getting the look: clothing recognition and segmentation for automatic prod-uct suggestions in everyday photos", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Progres-sive growing of gans for improved quality, stability, and variation", "label": "Progres-sive growing of gans for improved quality, stability, and variation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Where to buy it: Matching street clothing photos in online shops", "label": "Where to buy it: Matching street clothing photos in online shops", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Hierar-chical adversarially learned inference", "label": "Hierar-chical adversarially learned inference", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": ", et al", "label": ", et al", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Apparel classi\ufb01cation with style", "label": "Apparel classi\ufb01cation with style", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Clothes co-parsing via joint image segmentation and la-beling with application to clothing retrieval", "label": "Clothes co-parsing via joint image segmentation and la-beling with application to clothing retrieval", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Describing cloth-ing by semantic attributes", "label": "Describing cloth-ing by semantic attributes", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep domain adaptation for describing people based on \ufb01ne-grained clothing attributes", "label": "Deep domain adaptation for describing people based on \ufb01ne-grained clothing attributes", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Stochastic video generation with a learned prior", "label": "Stochastic video generation with a learned prior", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "et al", "label": "et al", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Microsoft coco: Common objects in context", "label": "Microsoft coco: Common objects in context", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Street-to-shop: Cross-scenario clothing retrieval via parts In Computer Vision and alignment and auxiliary set", "label": "Street-to-shop: Cross-scenario clothing retrieval via parts In Computer Vision and alignment and auxiliary set", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": ", and Tang, X", "label": ", and Tang, X", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "label": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Unpaired image-to-image translation using cycle-consistent adver-sarial networks", "label": "Unpaired image-to-image translation using cycle-consistent adver-sarial networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Generative adversarial text to image synthesis", "label": "Generative adversarial text to image synthesis", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Improved techniques for training In Advances in Neural Information Processing gans", "label": "Improved techniques for training In Advances in Neural Information Processing gans", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Bidirectional recurrent neural networks", "label": "Bidirectional recurrent neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Neuroaesthetics in fashion: Modeling the perception of fashionability", "label": "Neuroaesthetics in fashion: Modeling the perception of fashionability", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Amortised map inference for image super-resolution", "label": "Amortised map inference for image super-resolution", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Unsuper-vised cross-domain image generation", "label": "Unsuper-vised cross-domain image generation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Visualizing data us-ing t-SNE", "label": "Visualizing data us-ing t-SNE", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Attention is all you need", "label": "Attention is all you need", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning visual clothing style with heteroge-neous dyadic co-occurrences", "label": "Learning visual clothing style with heteroge-neous dyadic co-occurrences", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Birdsnap: Large-scale \ufb01ne-grained visual categorization of birds", "label": "Birdsnap: Large-scale \ufb01ne-grained visual categorization of birds", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Food-101\u2013 mining discriminative components with random forests", "label": "Food-101\u2013 mining discriminative components with random forests", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Proxylessnas: Direct neural architecture search on target task and hardware", "label": "Proxylessnas: Direct neural architecture search on target task and hardware", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Xception: Deep learning with depthwise separa-ble convolutions", "label": "Xception: Deep learning with depthwise separa-ble convolutions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Autoaugment: Learning augmentation policies from data", "label": "Autoaugment: Learning augmentation policies from data", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Sigmoid-weighted linear units for neural network function approximation in reinforcement learning", "label": "Sigmoid-weighted linear units for neural network function approximation in reinforcement learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Squeezenext: Hardware-aware neural network design", "label": "Squeezenext: Hardware-aware neural network design", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding", "label": "Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Mask r-cnn", "label": "Mask r-cnn", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Amc: Automl for model compression and acceleration on mobile devices", "label": "Amc: Automl for model compression and acceleration on mobile devices", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Gaussian error linear units (gelus)", "label": "Gaussian error linear units (gelus)", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Mobilenets: Ef\ufb01cient convolutional neural networks for mobile vision applications", "label": "Mobilenets: Ef\ufb01cient convolutional neural networks for mobile vision applications", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Squeeze-and-excitation net-works", "label": "Squeeze-and-excitation net-works", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep networks with stochastic depth", "label": "Deep networks with stochastic depth", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Gpipe: Ef\ufb01cient training of giant neural networks using pipeline parallelism", "label": "Gpipe: Ef\ufb01cient training of giant neural networks using pipeline parallelism", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": ", and Keutzer, K", "label": ", and Keutzer, K", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "On the expressive power of deep neural networks", "label": "On the expressive power of deep neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Collecting a large-scale dataset of \ufb01ne-grained cars", "label": "Collecting a large-scale dataset of \ufb01ne-grained cars", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning multiple layers of features from tiny images", "label": "Learning multiple layers of features from tiny images", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Searching for activation functions", "label": "Searching for activation functions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Regu-larized evolution for image classi\ufb01er architecture search", "label": "Regu-larized evolution for image classi\ufb01er architecture search", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Resnet with one-neuron hidden layers is a universal approximator", "label": "Resnet with one-neuron hidden layers is a universal approximator", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Mobilenetv2: Inverted residuals and linear bottlenecks", "label": "Mobilenetv2: Inverted residuals and linear bottlenecks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Feature pyramid networks for object detection", "label": "Feature pyramid networks for object detection", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Progressive neural architecture search", "label": "Progressive neural architecture search", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The expres-sive power of neural networks: A view from the width", "label": "The expres-sive power of neural networks: A view from the width", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Shuf\ufb02enet v2: Practical guidelines for ef\ufb01cient cnn architecture design", "label": "Shuf\ufb02enet v2: Practical guidelines for ef\ufb01cient cnn architecture design", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Explor-ing the limits of weakly supervised pretraining", "label": "Explor-ing the limits of weakly supervised pretraining", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "On the expressive power of overlapping architectures of deep learning", "label": "On the expressive power of overlapping architectures of deep learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Dropout: a simple way to prevent neural networks from over\ufb01tting", "label": "Dropout: a simple way to prevent neural networks from over\ufb01tting", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Rethinking the inception architecture for computer vision", "label": "Rethinking the inception architecture for computer vision", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Inception-v4, inception-resnet and the impact of residual connections on learning", "label": "Inception-v4, inception-resnet and the impact of residual connections on learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fine-grained visual classi\ufb01cation of aircraft", "label": "Fine-grained visual classi\ufb01cation of aircraft", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "MnasNet: Platform-aware neural architecture search for mobile", "label": "MnasNet: Platform-aware neural architecture search for mobile", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Domain adaptive transfer learning with spe-cialist models", "label": "Domain adaptive transfer learning with spe-cialist models", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Aggre-gated residual transformations for deep neural networks", "label": "Aggre-gated residual transformations for deep neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Automated \ufb02ower clas-si\ufb01cation over a large number of classes", "label": "Automated \ufb02ower clas-si\ufb01cation over a large number of classes", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Netadapt: Platform-aware neural net-work adaptation for mobile applications", "label": "Netadapt: Platform-aware neural net-work adaptation for mobile applications", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Cats and dogs", "label": "Cats and dogs", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Wide residual networks", "label": "Wide residual networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Polynet: A pursuit of structural diversity in very deep networks", "label": "Polynet: A pursuit of structural diversity in very deep networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Shuf\ufb02enet: An ex-tremely ef\ufb01cient convolutional neural network for mobile devices", "label": "Shuf\ufb02enet: An ex-tremely ef\ufb01cient convolutional neural network for mobile devices", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning deep features for discriminative localization", "label": "Learning deep features for discriminative localization", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Neural architecture search with reinforcement learning", "label": "Neural architecture search with reinforcement learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning transferable architectures for scalable image recognition", "label": "Learning transferable architectures for scalable image recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Instance-based learning algorithms", "label": "Instance-based learning algorithms", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The bellkor solution to the net\ufb02ix prize", "label": "The bellkor solution to the net\ufb02ix prize", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "On the approximation of curves by line segments using dynamic programming", "label": "On the approximation of curves by line segments using dynamic programming", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The net\ufb02ix prize", "label": "The net\ufb02ix prize", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Gbpr: Group preference based bayesian personalized ranking for one-class collaborative \ufb01ltering", "label": "Gbpr: Group preference based bayesian personalized ranking for one-class collaborative \ufb01ltering", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "One-class collaborative \ufb01ltering with random graphs", "label": "One-class collaborative \ufb01ltering with random graphs", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Bpr: Bayesian personalized ranking from implicit feedback", "label": "Bpr: Bayesian personalized ranking from implicit feedback", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Imagenet large scale visual recognition challenge", "label": "Imagenet large scale visual recognition challenge", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Matchbox: large scale online bayesian recommendations", "label": "Matchbox: large scale online bayesian recommendations", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The problem of concept drift: de\ufb01nitions and related work", "label": "The problem of concept drift: de\ufb01nitions and related work", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Accelerating t-sne using tree-based algorithms", "label": "Accelerating t-sne using tree-based algorithms", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning visual clothing style with heterogeneous dyadic co-occurrences", "label": "Learning visual clothing style with heterogeneous dyadic co-occurrences", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Mining concept-drifting data streams using ensemble classi\ufb01ers", "label": "Mining concept-drifting data streams using ensemble classi\ufb01ers", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Beyond clicks: dwell time for personalization", "label": "Beyond clicks: dwell time for personalization", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Daily-aware personalized recommendation based on feature-level time series analysis", "label": "Daily-aware personalized recommendation based on feature-level time series analysis", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Leveraging social connections to improve personalized ranking for collaborative \ufb01ltering", "label": "Leveraging social connections to improve personalized ranking for collaborative \ufb01ltering", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Music recommendations with temporal context awareness", "label": "Music recommendations with temporal context awareness", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Is a picture really worth a thousand words?-on the role of images in e-commerce", "label": "Is a picture really worth a thousand words?-on the role of images in e-commerce", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Time weight collaborative \ufb01ltering", "label": "Time weight collaborative \ufb01ltering", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Decaf: A deep convolutional activation feature for generic visual recognition", "label": "Decaf: A deep convolutional activation feature for generic visual recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Mymedialite: A free recommender system library", "label": "Mymedialite: A free recommender system library", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Determinants of internet auction success and closing price: An exploratory study", "label": "Determinants of internet auction success and closing price: An exploratory study", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A study on the impact of product images on user clicks for online shopping", "label": "A study on the impact of product images on user clicks for online shopping", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Vbpr: Visual bayesian personalized ranking from implicit feedback", "label": "Vbpr: Visual bayesian personalized ranking from implicit feedback", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Collaborative \ufb01ltering for implicit feedback datasets", "label": "Collaborative \ufb01ltering for implicit feedback datasets", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Large scale visual recommendations from street fashion images", "label": "Large scale visual recommendations from street fashion images", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Caffe: Convolutional architecture for fast feature embedding", "label": "Caffe: Convolutional architecture for fast feature embedding", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Getting the look: clothing recognition and segmentation for automatic product suggestions in everyday photos", "label": "Getting the look: clothing recognition and segmentation for automatic product suggestions in everyday photos", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Recognizing image style", "label": "Recognizing image style", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning drifting concepts: Example selection vs", "label": "Learning drifting concepts: Example selection vs", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Collaborative \ufb01ltering with temporal dynamics", "label": "Collaborative \ufb01ltering with temporal dynamics", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Advances in collaborative \ufb01ltering", "label": "Advances in collaborative \ufb01ltering", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multi-relational matrix factorization using bayesian personalized ranking for social network data", "label": "Multi-relational matrix factorization using bayesian personalized ranking for social network data", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Temporal diversity in recommender systems", "label": "Temporal diversity in recommender systems", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "RAPID: rating pictorial aesthetics using deep learning", "label": "RAPID: rating pictorial aesthetics using deep learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews", "label": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "HoME: a arXiv preprint Household Multimodal Environment", "label": "HoME: a arXiv preprint Household Multimodal Environment", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fostering mathematical thinking through playful learning", "label": "Fostering mathematical thinking through playful learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Object perception and object naming in early development", "label": "Object perception and object naming in early development", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Infants rapidly learn word-referent mappings via cross-situational statistics", "label": "Infants rapidly learn word-referent mappings via cross-situational statistics", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Zero-shot task generalization with multi-task deep reinforcement learning", "label": "Zero-shot task generalization with multi-task deep reinforcement learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Guesswhat?! visual object discovery through multi-modal dialogue", "label": "Guesswhat?! visual object discovery through multi-modal dialogue", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Virtual embodiment: A scalable long-term strategy for arti\ufb01cial intelligence research", "label": "Virtual embodiment: A scalable long-term strategy for arti\ufb01cial intelligence research", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Distributed representations of words and phrases and their compositionality", "label": "Distributed representations of words and phrases and their compositionality", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Vqa: Visual question answering", "label": "Vqa: Visual question answering", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The arcade learning environment: An evaluation platform for general agents", "label": "The arcade learning environment: An evaluation platform for general agents", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Gated-attention architectures for task-oriented language grounding", "label": "Gated-attention architectures for task-oriented language grounding", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Word and object", "label": "Word and object", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Reinforcement learning with unsupervised auxiliary tasks", "label": "Reinforcement learning with unsupervised auxiliary tasks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "ImageNet Large Scale Visual Recognition Challenge", "label": "ImageNet Large Scale Visual Recognition Challenge", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Domain randomization for transferring deep neural networks from simulation to the real world", "label": "Domain randomization for transferring deep neural networks from simulation to the real world", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Semantic scene completion from a single depth image", "label": "Semantic scene completion from a single depth image", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Accelerated beam tracing algorithm", "label": "Accelerated beam tracing algorithm", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Openai gym", "label": "Openai gym", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The malmo platform for arti\ufb01cial intelligence experimentation", "label": "The malmo platform for arti\ufb01cial intelligence experimentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "ViZDoom: A Doom-based AI research platform for visual reinforcement learning", "label": "ViZDoom: A Doom-based AI research platform for visual reinforcement learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Target-driven Visual Navigation in Indoor Scenes using Deep Reinforcement Learning", "label": "Target-driven Visual Navigation in Indoor Scenes using Deep Reinforcement Learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Vision-and-language navigation: Interpreting visually-grounded navigation instructions in real environments", "label": "Vision-and-language navigation: Interpreting visually-grounded navigation instructions in real environments", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Example-based synthesis of 3d object arrangements", "label": "Example-based synthesis of 3d object arrangements", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Matterport3d: Learning from rgb-d data in indoor environments", "label": "Matterport3d: Learning from rgb-d data in indoor environments", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Scenenet: An annotated model generator for indoor scene understanding", "label": "Scenenet: An annotated model generator for indoor scene understanding", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The panda3d graphics engine", "label": "The panda3d graphics engine", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Seeing 3D chairs: exemplar part-based 2D-3D alignment us-ing a large dataset of CAD models", "label": "Seeing 3D chairs: exemplar part-based 2D-3D alignment us-ing a large dataset of CAD models", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Domain Separation Networks", "label": "Domain Separation Networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "ShapeNet: An Information-Rich 3D Model Repository", "label": "ShapeNet: An Information-Rich 3D Model Repository", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Procedural Generation of Videos to Train Deep Ac-tion Recognition Networks", "label": "Procedural Generation of Videos to Train Deep Ac-tion Recognition Networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Semantic Scene Completion from a Single Depth Image", "label": "Semantic Scene Completion from a Single Depth Image", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Align-In ing 3D models to RGB-D images of cluttered scenes", "label": "Align-In ing 3D models to RGB-D images of cluttered scenes", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Real-Time Camera Tracking: When is High Frame-Rate Best? In ECCV", "label": "Real-Time Camera Tracking: When is High Frame-Rate Best? In ECCV", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A Benchmark for RGB-D Visual Odometry", "label": "A Benchmark for RGB-D Visual Odometry", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Flownet 2", "label": "Flownet 2", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A practical guide to global illumination using photon maps", "label": "A practical guide to global illumination using photon maps", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Imagenet clas-si\ufb01cation with deep convolutional neural networks", "label": "Imagenet clas-si\ufb01cation with deep convolutional neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "SemanticFusion: Dense 3D Semantic Mapping with Convo-lutional Neural Networks", "label": "SemanticFusion: Dense 3D Semantic Mapping with Convo-lutional Neural Networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Progressive photon mapping on gpus", "label": "Progressive photon mapping on gpus", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning Deep Object Detectors from 3D Models", "label": "Learning Deep Object Detectors from 3D Models", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "UnrealCV: Connecting computer vi-sion to unreal engine", "label": "UnrealCV: Connecting computer vi-sion to unreal engine", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Playing for data: Ground truth from computer games", "label": "Playing for data: Ground truth from computer games", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The SYNTHIA Dataset: A large collection of synthetic images for semantic segmentation of urban scenes", "label": "The SYNTHIA Dataset: A large collection of synthetic images for semantic segmentation of urban scenes", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "On being the right scale: Sizing large collec-tions of 3D models", "label": "On being the right scale: Sizing large collec-tions of 3D models", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Indoor segmentation and support inference from RGBD images", "label": "Indoor segmentation and support inference from RGBD images", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "SUN RGB-D: A In CVPR", "label": "SUN RGB-D: A In CVPR", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Towards principled methods for training 1 generative adversarial networks", "label": "Towards principled methods for training 1 generative adversarial networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Wasserstein GAN", "label": "Wasserstein GAN", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Neural photo editing with introspective adversarial networks", "label": "Neural photo editing with introspective adversarial networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Mode regularized generative adversarial networks", "label": "Mode regularized generative adversarial networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Maximum-likelihood augmented discrete generative adversarial networks", "label": "Maximum-likelihood augmented discrete generative adversarial networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "InfoGAN: Interpretable representation learning by informa-tion maximizing generative adversarial nets", "label": "InfoGAN: Interpretable representation learning by informa-tion maximizing generative adversarial nets", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep generative In image models using a laplacian pyramid of adversarial networks", "label": "Deep generative In image models using a laplacian pyramid of adversarial networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Tutorial on variational autoencoders", "label": "Tutorial on variational autoencoders", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Generative multi-adversarial networks", "label": "Generative multi-adversarial networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Conditional generative adversarial networks for convolu-tional face generation", "label": "Conditional generative adversarial networks for convolu-tional face generation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Generative adversarial nets", "label": "Generative adversarial nets", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Improved training of wasserstein gans", "label": "Improved training of wasserstein gans", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Gans trained by a two time-scale update rule converge to a local nash equilibrium", "label": "Gans trained by a two time-scale update rule converge to a local nash equilibrium", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Progressive growing of gans for improved quality", "label": "Progressive growing of gans for improved quality", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Autoencoding beyond pixels using a learned similarity metric", "label": "Autoencoding beyond pixels using a learned similarity metric", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Photo-realistic single image super-resolution using a generative adversarial network", "label": "Photo-realistic single image super-resolution using a generative adversarial network", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Generating images from captions with attention", "label": "Generating images from captions with attention", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Least squares generative adversarial networks", "label": "Least squares generative adversarial networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Unrolled generative adversarial networks", "label": "Unrolled generative adversarial networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Conditional generative adversarial nets", "label": "Conditional generative adversarial nets", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Plug \u0026 play generative networks: Conditional iterative generation of images in latent space", "label": "Plug \u0026 play generative networks: Conditional iterative generation of images in latent space", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Conditional image synthesis with auxiliary classi\ufb01er GANs", "label": "Conditional image synthesis with auxiliary classi\ufb01er GANs", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Unsupervised representation In learning with deep convolutional generative adversarial networks", "label": "Unsupervised representation In learning with deep convolutional generative adversarial networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning what and where to draw", "label": "Learning what and where to draw", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning deep representations of \ufb01ne-grained visual descriptions", "label": "Learning deep representations of \ufb01ne-grained visual descriptions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Generative adversarial text-to-image synthesis", "label": "Generative adversarial text-to-image synthesis", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Generating interpretable images with controllable structure", "label": "Generating interpretable images with controllable structure", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Stochastic backpropaga-In ICML", "label": "Stochastic backpropaga-In ICML", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The statistics of natural images", "label": "The statistics of natural images", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Improved techniques for training GANs", "label": "Improved techniques for training GANs", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Unsupervised cross-domain image generation", "label": "Unsupervised cross-domain image generation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Pixel recurrent neural networks", "label": "Pixel recurrent neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "N", "label": "N", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Visualizing high-dimensional data using t-sne", "label": "Visualizing high-dimensional data using t-sne", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Matching networks for one shot learning", "label": "Matching networks for one shot learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Generating videos with scene dynamics", "label": "Generating videos with scene dynamics", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The Caltech-UCSD Birds-200-2011 Dataset", "label": "The Caltech-UCSD Birds-200-2011 Dataset", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Generative image modeling using style and structure adversarial networks", "label": "Generative image modeling using style and structure adversarial networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multi-scale structural In Signals", "label": "Multi-scale structural In Signals", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Attribute2image: Conditional image generation from visual attributes", "label": "Attribute2image: Conditional image generation from visual attributes", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "LR-GAN: layered recursive generative adversarial networks for image generation", "label": "LR-GAN: layered recursive generative adversarial networks for image generation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "LSUN: Construction of a large-scale image dataset using deep learning with humans in the loop", "label": "LSUN: Construction of a large-scale image dataset using deep learning with humans in the loop", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "StackGAN: Text to photo-realistic image synthesis with stacked gener-ative adversarial networks", "label": "StackGAN: Text to photo-realistic image synthesis with stacked gener-ative adversarial networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Energy-based generative adversarial network", "label": "Energy-based generative adversarial network", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Generative visual manipulation on the natural image manifold", "label": "Generative visual manipulation on the natural image manifold", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Xception: Deep learning with depthwise separable convolutions", "label": "Xception: Deep learning with depthwise separable convolutions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Tensor-Flow: Large-scale machine learning on heterogeneous sys-tems", "label": "Tensor-Flow: Large-scale machine learning on heterogeneous sys-tems", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Keras", "label": "Keras", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning visual representations at scale", "label": "Learning visual representations at scale", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Factorized convolutional neural networks", "label": "Factorized convolutional neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Visualizing and understanding convolutional networks", "label": "Visualizing and understanding convolutional networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Distilling the knowledge in a neural network", "label": "Distilling the knowledge in a neural network", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Mobilenets: Ef\ufb01cient convolutional neural net-works for mobile vision applications", "label": "Mobilenets: Ef\ufb01cient convolutional neural net-works for mobile vision applications", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Flattened convolutional neural networks for feedforward acceleration", "label": "Flattened convolutional neural networks for feedforward acceleration", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "L", "label": "L", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Network in network", "label": "Network in network", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Simplifying ConvNets for Fast Learning", "label": "Simplifying ConvNets for Fast Learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Acceleration of stochas-tic approximation by averaging", "label": "Acceleration of stochas-tic approximation by averaging", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "J", "label": "J", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Rigid-motion scattering for image classi\ufb01cation", "label": "Rigid-motion scattering for image classi\ufb01cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Rotation", "label": "Rotation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Tf-slim", "label": "Tf-slim", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Inception-v4", "label": "Inception-v4", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "M", "label": "M", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": ", and Hoffman, T", "label": ", and Hoffman, T", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning separable \ufb01lters", "label": "Learning separable \ufb01lters", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Training deep nets with sublinear memory cost", "label": "Training deep nets with sublinear memory cost", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "An introduction to computational networks and the computational network toolkit", "label": "An introduction to computational networks and the computational network toolkit", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Theano: a CPU and GPU math expression compiler", "label": "Theano: a CPU and GPU math expression compiler", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "MXNet: A \ufb02exible and ef\ufb01cient machine learning library for heterogeneous distributed systems", "label": "MXNet: A \ufb02exible and ef\ufb01cient machine learning library for heterogeneous distributed systems", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Large scale distributed deep networks", "label": "Large scale distributed deep networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep learning", "label": "Deep learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Algorithm 799: Revolve: An implementation of checkpointing for the reverse or adjoint mode of computational differentiation", "label": "Algorithm 799: Revolve: An implementation of checkpointing for the reverse or adjoint mode of computational differentiation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Identity mappings in deep residual networks", "label": "Identity mappings in deep residual networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Long short-term memory", "label": "Long short-term memory", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Virtualizing deep neural networks for memory-ef\ufb01cient neural network design", "label": "Virtualizing deep neural networks for memory-ef\ufb01cient neural network design", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Training very deep networks", "label": "Training very deep networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "arXiv preprint Highway long short-term memory rnns for distant speech recognition", "label": "arXiv preprint Highway long short-term memory rnns for distant speech recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Faster r-cnn: Towards real-time object detection with region proposal networks", "label": "Faster r-cnn: Towards real-time object detection with region proposal networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Functional correspondence by matrix completion", "label": "Functional correspondence by matrix completion", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "23(2):1214\u20131236", "label": "23(2):1214\u20131236", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Playing atari with deep reinforcement learning", "label": "Playing atari with deep reinforcement learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Speech recognition with deep recurrent neural networks", "label": "Speech recognition with deep recurrent neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Actor-critic reinforcement learning with energy-based policies", "label": "Actor-critic reinforcement learning with energy-based policies", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Prioritized sweeping: Reinforcement learning with less data and less real time", "label": "Prioritized sweeping: Reinforcement learning with less data and less real time", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Why did td-gammon work", "label": "Why did td-gammon work", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Reinforcement learning with factored states and actions", "label": "Reinforcement learning with factored states and actions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Reinforcement Learning: An Introduction", "label": "Reinforcement Learning: An Introduction", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Q-learning", "label": "Q-learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Scenenet RGB-D: 5m photorealistic images of synthetic indoor trajectories with ground truth", "label": "Scenenet RGB-D: 5m photorealistic images of synthetic indoor trajectories with ground truth", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "On the optimization of deep networks: Implicit acceleration by overparameterization", "label": "On the optimization of deep networks: Implicit acceleration by overparameterization", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Universal approximation bounds for superpositions of a sigmoidal function", "label": "Universal approximation bounds for superpositions of a sigmoidal function", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "On decision regions of narrow deep neural networks", "label": "On decision regions of narrow deep neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Sgd learns over-parameterized networks In The International Conference on Learning that provably generalize on linearly separable data", "label": "Sgd learns over-parameterized networks In The International Conference on Learning that provably generalize on linearly separable data", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The loss surfaces of multilayer networks", "label": "The loss surfaces of multilayer networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "On the expressive power of deep learning: A tensor analysis", "label": "On the expressive power of deep learning: A tensor analysis", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Approximation by superpositions of a sigmoidal function", "label": "Approximation by superpositions of a sigmoidal function", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Gradient descent learns one-hidden-layer cnn: Don\u2019t be afraid of spurious local minima", "label": "Gradient descent learns one-hidden-layer cnn: Don\u2019t be afraid of spurious local minima", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The power of depth for feedforward neural networks", "label": "The power of depth for feedforward neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "On the approximate realization of continuous mappings by neural networks", "label": "On the approximate realization of continuous mappings by neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Approximating continuous functions by relu nets of minimal width", "label": "Approximating continuous functions by relu nets of minimal width", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Identity matters in deep learning", "label": "Identity matters in deep learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multilayer feedforward networks are universal approximators", "label": "Multilayer feedforward networks are universal approximators", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep learning without poor local minima", "label": "Deep learning without poor local minima", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Kolmogorov\u2019s theorem and multilayer neural networks", "label": "Kolmogorov\u2019s theorem and multilayer neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Gradient-based learning applied to document recognition", "label": "Gradient-based learning applied to document recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Why deep neural networks for function approximation? In The International Conference on Learning Representations (ICLR)", "label": "Why deep neural networks for function approximation? In The International Conference on Learning Representations (ICLR)", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The expressive power of neural networks: A view from the width", "label": "The expressive power of neural networks: A view from the width", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Neural networks for optimal approximation of smooth and analytic functions", "label": "Neural networks for optimal approximation of smooth and analytic functions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep vs", "label": "Deep vs", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The loss surface of deep and wide neural networks", "label": "The loss surface of deep and wide neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The power of deeper networks for expressing natural functions", "label": "The power of deeper networks for expressing natural functions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Weight sharing is crucial to succesful optimization", "label": "Weight sharing is crucial to succesful optimization", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Are resnets provably better than linear predictors? arXiv:1804", "label": "Are resnets provably better than linear predictors? arXiv:1804", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Dropout: A simple way to prevent neural networks from over\ufb01tting", "label": "Dropout: A simple way to prevent neural networks from over\ufb01tting", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "W", "label": "W", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep networks are e\ufb00ective encoders of periodicity", "label": "Deep networks are e\ufb00ective encoders of periodicity", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Bene\ufb01ts of depth in neural networks", "label": "Bene\ufb01ts of depth in neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Error bounds for approximations with deep relu networks", "label": "Error bounds for approximations with deep relu networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Optimal approximation of continuous functions by very deep relu networks", "label": "Optimal approximation of continuous functions by very deep relu networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Global optimality conditions for deep neural networks", "label": "Global optimality conditions for deep neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Understanding deep learning requires rethinking generalization", "label": "Understanding deep learning requires rethinking generalization", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Finding approximate local minima faster than gradient descent", "label": "Finding approximate local minima faster than gradient descent", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Understanding deep neural networks with recti\ufb01ed linear units", "label": "Understanding deep neural networks with recti\ufb01ed linear units", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Neural networks and principal component analysis: Learning from examples without local minima", "label": "Neural networks and principal component analysis: Learning from examples without local minima", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Elementary differential equations and boundary value problems, volume 9", "label": "Elementary differential equations and boundary value problems, volume 9", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Advanced calculus", "label": "Advanced calculus", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Accel-erated methods for non-convex optimization", "label": "Accel-erated methods for non-convex optimization", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Analysis and design of convolutional net-works via hierarchical tensor decompositions", "label": "Analysis and design of convolutional net-works via hierarchical tensor decompositions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Depth separation for neural networks", "label": "Depth separation for neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "On the ability of neural nets to express distributions", "label": "On the ability of neural nets to express distributions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "On the compu-tational ef\ufb01ciency of training neural networks", "label": "On the compu-tational ef\ufb01ciency of training neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Adaptive subgradient methods for online learning and stochastic optimization", "label": "Adaptive subgradient methods for online learning and stochastic optimization", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A method of solving a convex programming problem with convergence rate o (1/k2)", "label": "A method of solving a convex programming problem with convergence rate o (1/k2)", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Updating quasi-newton matrices with limited storage", "label": "Updating quasi-newton matrices with limited storage", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Effect of batch learning in multilayer neural net-works", "label": "Effect of batch learning in multilayer neural net-works", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Escaping from saddle points\u2014online stochastic gradient for tensor decomposition", "label": "Escaping from saddle points\u2014online stochastic gradient for tensor decomposition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Why momentum really works", "label": "Why momentum really works", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep learning, volume 1", "label": "Deep learning, volume 1", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Qualitatively characterizing neural network optimization problems", "label": "Qualitatively characterizing neural network optimization problems", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Optimization and dynamical systems", "label": "Optimization and dynamical systems", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Beating the Perils of Non-Convexity: Guaranteed Training of Neural Networks using Tensor Methods", "label": "Beating the Perils of Non-Convexity: Guaranteed Training of Neural Networks using Tensor Methods", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Adam: A method for stochastic optimiza-tion", "label": "Adam: A method for stochastic optimiza-tion", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "On the calibration of sensor arrays for pattern recog-nition using the minimal number of experiments", "label": "On the calibration of sensor arrays for pattern recog-nition using the minimal number of experiments", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "On the quality of the initial basin in overspeci\ufb01ed neural networks", "label": "On the quality of the initial basin in overspeci\ufb01ed neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Spurious local minima are com-arXiv preprint mon in two-layer relu neural networks", "label": "Spurious local minima are com-arXiv preprint mon in two-layer relu neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Exact solutions to the nonlinear dynamics of learning in deep linear neural networks", "label": "Exact solutions to the nonlinear dynamics of learning in deep linear neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "No bad local minima: Data independent training error guarantees for multilayer neural networks", "label": "No bad local minima: Data independent training error guarantees for multilayer neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Dropout: a simple way to prevent neural net-works from over\ufb01tting", "label": "Dropout: a simple way to prevent neural net-works from over\ufb01tting", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A differential equation for modeling nesterovs accelerated gradient method: Theory and insights", "label": "A differential equation for modeling nesterovs accelerated gradient method: Theory and insights", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "and Hinton, G", "label": "and Hinton, G", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Chemical gas sensor drift compensation using classi\ufb01er ensembles", "label": "Chemical gas sensor drift compensation using classi\ufb01er ensembles", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A variational per-spective on accelerated methods in optimization", "label": "A variational per-spective on accelerated methods in optimization", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Adadelta: an adaptive learning rate method", "label": "Adadelta: an adaptive learning rate method", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep residual learn-ing for image recognition", "label": "Deep residual learn-ing for image recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Extensions of lipschitz mappings into a hilbert space", "label": "Extensions of lipschitz mappings into a hilbert space", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Shallow vs", "label": "Shallow vs", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Provable bounds for learning some deep representations", "label": "Provable bounds for learning some deep representations", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Globally optimal gradient descent for a convnet with gaussian inputs", "label": "Globally optimal gradient descent for a convnet with gaussian inputs", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Global optimality in tensor factorization, deep learning, and beyond", "label": "Global optimality in tensor factorization, deep learning, and beyond", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Beating the perils of non-convexity: Guaran-teed training of neural networks using tensor methods", "label": "Beating the perils of non-convexity: Guaran-teed training of neural networks using tensor methods", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "E\ufb03cient learning of generalized linear and single index models with isotonic regression", "label": "E\ufb03cient learning of generalized linear and single index models with isotonic regression", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The isotron algorithm: High-dimensional isotonic regression", "label": "The isotron algorithm: High-dimensional isotonic regression", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "On the computational e\ufb03ciency of training neural networks", "label": "On the computational e\ufb03ciency of training neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The landscape of empirical risk for non-convex losses", "label": "The landscape of empirical risk for non-convex losses", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Understanding machine learning: From theory to algorithms", "label": "Understanding machine learning: From theory to algorithms", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Failures of deep learning", "label": "Failures of deep learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "l1-regularized neural networks are improperly learnable in polynomial time", "label": "l1-regularized neural networks are improperly learnable in polynomial time", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Im-agenet large scale visual recognition challenge", "label": "Im-agenet large scale visual recognition challenge", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The pascal visual object classes challenge a retrospective", "label": "The pascal visual object classes challenge a retrospective", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Random search for hyper-parameter optimization", "label": "Random search for hyper-parameter optimization", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Mobilenets: Ef\ufb01cient convolutional neural net-CoRR, works for mobile vision applications", "label": "Mobilenets: Ef\ufb01cient convolutional neural net-CoRR, works for mobile vision applications", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "CoRR, residual networks", "label": "CoRR, residual networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Caffe: Convolutional architecture for fast feature embed-ding", "label": "Caffe: Convolutional architecture for fast feature embed-ding", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Ssd: Single shot multibox detector", "label": "Ssd: Single shot multibox detector", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Better, stronger", "label": "Better, stronger", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Faster r-cnn: Towards real-time object In Ad-detection with region proposal networks", "label": "Faster r-cnn: Towards real-time object In Ad-detection with region proposal networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "R-fcn: Object detection via region-based fully con-volutional networks", "label": "R-fcn: Object detection via region-based fully con-volutional networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Overfeat: Integrated recognition, localiza-tion and detection using convolutional networks", "label": "Overfeat: Integrated recognition, localiza-tion and detection using convolutional networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Modeling local and global defor-mations in deep learning: Epitomic convolution, multiple instance learning, and sliding window de-tection", "label": "Modeling local and global defor-mations in deep learning: Epitomic convolution, multiple instance learning, and sliding window de-tection", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs", "label": "Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Se-mantic contours from inverse detectors", "label": "Se-mantic contours from inverse detectors", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Bayesian locality sensitive hashing for fast similarity search", "label": "Bayesian locality sensitive hashing for fast similarity search", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Building rome in a day", "label": "Building rome in a day", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Near-optimal hashing algorithms for approximate nearest neighbor in high dimensions", "label": "Near-optimal hashing algorithms for approximate nearest neighbor in high dimensions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Scaling up all pairs similarity search", "label": "Scaling up all pairs similarity search", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Min-wise independent permutations (extended abstract)", "label": "Min-wise independent permutations (extended abstract)", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Syntactic clustering of the web", "label": "Syntactic clustering of the web", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Similarity estimation techniques from rounding algorithms", "label": "Similarity estimation techniques from rounding algorithms", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Locality-sensitive hashing scheme based on p-stable distributions", "label": "Locality-sensitive hashing scheme based on p-stable distributions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "When close enough is good enough: Approximate positional indexes for e\ufb03cient ranked retrieval", "label": "When close enough is good enough: Approximate positional indexes for e\ufb03cient ranked retrieval", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Similarity search in high dimensions via hashing", "label": "Similarity search in high dimensions via hashing", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Finding near-duplicate web pages: a large-scale evaluation of algorithms", "label": "Finding near-duplicate web pages: a large-scale evaluation of algorithms", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Approximate nearest neighbors: towards removing the curse of dimensionality", "label": "Approximate nearest neighbors: towards removing the curse of dimensionality", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fast image search for learned metrics", "label": "Fast image search for learned metrics", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "What is Twitter", "label": "What is Twitter", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Rcv1: A new benchmark collection for text categorization research", "label": "Rcv1: A new benchmark collection for text categorization research", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "b-bit minwise hashing", "label": "b-bit minwise hashing", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The link-prediction problem for social networks", "label": "The link-prediction problem for social networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multi-probe lsh: e\ufb03cient indexing for high-dimensional similarity search", "label": "Multi-probe lsh: e\ufb03cient indexing for high-dimensional similarity search", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Detecting near-duplicates for web crawling", "label": "Detecting near-duplicates for web crawling", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Measurement and Analysis of Online Social Networks", "label": "Measurement and Analysis of Online Social Networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Randomized algorithms and nlp: using locality sensitive hash function for high speed noun clustering", "label": "Randomized algorithms and nlp: using locality sensitive hash function for high speed noun clustering", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Symmetrizations for clustering directed graphs", "label": "Symmetrizations for clustering directed graphs", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Local graph sparsi\ufb01cation for scalable clustering", "label": "Local graph sparsi\ufb01cation for scalable clustering", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Quality and e\ufb03ciency in high dimensional nearest neighbor search", "label": "Quality and e\ufb03ciency in high dimensional nearest neighbor search", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "E\ufb03cient similarity joins for near duplicate detection", "label": "E\ufb03cient similarity joins for near duplicate detection", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Atlas: a probabilistic algorithm for high dimensional similarity search", "label": "Atlas: a probabilistic algorithm for high dimensional similarity search", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Introduction to semi-supervised learning", "label": "Introduction to semi-supervised learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The megaface benchmark: 1 million faces for recognition at scale", "label": "The megaface benchmark: 1 million faces for recognition at scale", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Face description with local binary patterns: Application to face recognition", "label": "Face description with local binary patterns: Application to face recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Unconstrained face recognition: Identifying a person of in-terest from a media collection", "label": "Unconstrained face recognition: Identifying a person of in-terest from a media collection", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "P", "label": "P", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Bayesian face revisited: A joint formulation", "label": "Bayesian face revisited: A joint formulation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The fg-net aging database", "label": "The fg-net aging database", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Can a poor veri\ufb01cation system be a good identi\ufb01cation system? a preliminary study", "label": "Can a poor veri\ufb01cation system be a good identi\ufb01cation system? a preliminary study", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Yale face database", "label": "Yale face database", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Image and Vision Computing", "label": "Image and Vision Computing", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Models of large population In Computer Vision and Pattern recognition performance", "label": "Models of large population In Computer Vision and Pattern recognition performance", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Report on the evaluation of 2d still-image face recognition algorithms", "label": "Report on the evaluation of 2d still-image face recognition algorithms", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "When face recognition meets with deep learning: an evaluation of convolutional neural networks for face recognition", "label": "When face recognition meets with deep learning: an evaluation of convolutional neural networks for face recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Labeled faces in the wild: A database for studying face recognition in unconstrained environments", "label": "Labeled faces in the wild: A database for studying face recognition in unconstrained environments", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Illumination-aware age progression", "label": "Illumination-aware age progression", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Face recognition in uncon-strained videos with matched background similarity", "label": "Face recognition in uncon-strained videos with matched background similarity", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Supervised descent method and its applications to face alignment", "label": "Supervised descent method and its applications to face alignment", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning face represen-tation from scratch", "label": "Learning face represen-tation from scratch", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Face recognition: A literature survey", "label": "Face recognition: A literature survey", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A case study on unconstrained facial recognition using the boston marathon bombings sus-pects", "label": "A case study on unconstrained facial recognition using the boston marathon bombings sus-pects", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Attribute and simile classi\ufb01ers for face veri\ufb01cation", "label": "Attribute and simile classi\ufb01ers for face veri\ufb01cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Describable visual attributes for face veri\ufb01cation and image search", "label": "Describable visual attributes for face veri\ufb01cation and image search", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A discriminative model for Information Forensics and age invariant face recognition", "label": "A discriminative model for Information Forensics and age invariant face recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Face detection without bells and whistles", "label": "Face detection without bells and whistles", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Face recognition for web-scale datasets", "label": "Face recognition for web-scale datasets", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A", "label": "A", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Facenet: A uni-\ufb01ed embedding for face recognition and clustering", "label": "Facenet: A uni-\ufb01ed embedding for face recognition and clustering", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Autotagging face-book: Social network context improves photo annotation", "label": "Autotagging face-book: Social network context improves photo annotation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deepid3: Face recognition with very deep neural networks", "label": "Deepid3: Face recognition with very deep neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deeply learned face repre-sentations are sparse", "label": "Deeply learned face repre-sentations are sparse", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deepface: Closing the gap to human-level performance in face veri\ufb01ca-tion", "label": "Deepface: Closing the gap to human-level performance in face veri\ufb01ca-tion", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Web-arXiv preprint face identi\ufb01cation", "label": "Web-arXiv preprint face identi\ufb01cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The new data and new challenges in multimedia research", "label": "The new data and new challenges in multimedia research", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Robust real-time face detection", "label": "Robust real-time face detection", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Face search at scale: 80 million gallery", "label": "Face search at scale: 80 million gallery", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Face recognition In Computer vision-eccv 2004", "label": "Face recognition In Computer vision-eccv 2004", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Recog-nition of blurred faces using local phase quantization", "label": "Recog-nition of blurred faces using local phase quantization", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Mul-tiscale local phase quantization for robust component-based face recognition using kernel fusion of multiple descriptors", "label": "Mul-tiscale local phase quantization for robust component-based face recognition using kernel fusion of multiple descriptors", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Return of the devil in the details: Delving deep into convo-lutional nets", "label": "Return of the devil in the details: Delving deep into convo-lutional nets", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Blessing of dimension-ality: High-dimensional feature and its ef\ufb01cient compression for face veri\ufb01cation", "label": "Blessing of dimension-ality: High-dimensional feature and its ef\ufb01cient compression for face veri\ufb01cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Is that you? met-ric learning approaches for face identi\ufb01cation", "label": "Is that you? met-ric learning approaches for face identi\ufb01cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Delving deep into recti\ufb01ers: Surpassing human-level performance on imagenet classi\ufb01cation", "label": "Delving deep into recti\ufb01ers: Surpassing human-level performance on imagenet classi\ufb01cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Improving neural networks by pre-venting co-adaptation of feature detectors", "label": "Improving neural networks by pre-venting co-adaptation of feature detectors", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning to align from scratch", "label": "Learning to align from scratch", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Probabilistic models for inference about identity", "label": "Probabilistic models for inference about identity", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning multi-scale block local binary patterns for face recognition", "label": "Learning multi-scale block local binary patterns for face recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fisher Vector Faces in the Wild", "label": "Fisher Vector Faces in the Wild", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep learning face representation by joint identi\ufb01cation-veri\ufb01cation", "label": "Deep learning face representation by joint identi\ufb01cation-veri\ufb01cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Hybrid deep learning for In Computer Vision (ICCV)", "label": "Hybrid deep learning for In Computer Vision (ICCV)", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep learning face represen-In Computer Vision tation from predicting 10", "label": "Deep learning face represen-In Computer Vision tation from predicting 10", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Face recognition using eigen-In Computer Vision and Pattern Recognition", "label": "Face recognition using eigen-In Computer Vision and Pattern Recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Matconvnet \u2013 convolutional neural networks for matlab", "label": "Matconvnet \u2013 convolutional neural networks for matlab", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Z", "label": "Z", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Unconstrained face recognition: Identifying a person of interest from a media collection", "label": "Unconstrained face recognition: Identifying a person of interest from a media collection", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A practical transfer learning algorithm for face veri\ufb01cation", "label": "A practical transfer learning algorithm for face veri\ufb01cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Blessing of dimensionality: High-dimensional feature and its ef\ufb01cient compression for face veri\ufb01cation", "label": "Blessing of dimensionality: High-dimensional feature and its ef\ufb01cient compression for face veri\ufb01cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Improving neural networks by preventing co-adaptation of feature detectors", "label": "Improving neural networks by preventing co-adaptation of feature detectors", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Labeled Faces in the Wild: A database for studying face recognition in unconstrained environments", "label": "Labeled Faces in the Wild: A database for studying face recognition in unconstrained environments", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Surpassing human-level face veri\ufb01cation performance on LFW with GaussianFace", "label": "Surpassing human-level face veri\ufb01cation performance on LFW with GaussianFace", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Surpassing human-level face veri\ufb01cation In Proc", "label": "Surpassing human-level face veri\ufb01cation In Proc", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Recti\ufb01ed linear units improve restricted Boltzmann machines", "label": "Recti\ufb01ed linear units improve restricted Boltzmann machines", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep learning face In Proc", "label": "Deep learning face In Proc", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Hybrid deep learning for face veri\ufb01cation", "label": "Hybrid deep learning for face veri\ufb01cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deeply learned face representations are sparse", "label": "Deeply learned face representations are sparse", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Web-Technical report", "label": "Web-Technical report", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning face repre-sentation from scratch", "label": "Learning face repre-sentation from scratch", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep learning identity-preserving face space", "label": "Deep learning identity-preserving face space", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep learning and disentangling face representation by multi-view perceptron", "label": "Deep learning and disentangling face representation by multi-view perceptron", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Recover canonical-view faces in the wild with deep neural networks", "label": "Recover canonical-view faces in the wild with deep neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Scalable face image retrieval using attribute-enhanced sparse codewords", "label": "Scalable face image retrieval using attribute-enhanced sparse codewords", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Scalable face image retrieval with identity-based quantization and multi-reference re-ranking", "label": "Scalable face image retrieval with identity-based quantization and multi-reference re-ranking", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Face retriever: Pre-\ufb01ltering the gallery via deep neural net", "label": "Face retriever: Pre-\ufb01ltering the gallery via deep neural net", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning face representation from scratch", "label": "Learning face representation from scratch", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Product quantization for nearest neighbor search", "label": "Product quantization for nearest neighbor search", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Face recognition vendor (frvt): Performance of face identi\ufb01cation algorithms", "label": "Face recognition vendor (frvt): Performance of face identi\ufb01cation algorithms", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Pushing the frontiers of unconstrained face detection and recognition: Iarpa janus benchmark", "label": "Pushing the frontiers of unconstrained face detection and recognition: Iarpa janus benchmark", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Megaface: A million faces for recognition at scale", "label": "Megaface: A million faces for recognition at scale", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A data-driven approach to cleaning large face datasets", "label": "A data-driven approach to cleaning large face datasets", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fast matching by 2 lines of code for large scale face recognition systems", "label": "Fast matching by 2 lines of code for large scale face recognition systems", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The feret evaluation methodology for face-recognition algorithms", "label": "The feret evaluation methodology for face-recognition algorithms", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Towards incremental and large scale face recognition", "label": "Towards incremental and large scale face recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Overview of the face recognition grand challenge", "label": "Overview of the face recognition grand challenge", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Ef\ufb01cient face retrieval using synecdoches", "label": "Ef\ufb01cient face retrieval using synecdoches", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A benchmark study of large-scale unconstrained face recognition", "label": "A benchmark study of large-scale unconstrained face recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Facenet: A uni\ufb01ed embedding for face recognition and clustering", "label": "Facenet: A uni\ufb01ed embedding for face recognition and clustering", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A survey of content-based image retrieval with high-level semantics", "label": "A survey of content-based image retrieval with high-level semantics", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Retrieval-based face annotation by weak label regularized local coordinate coding", "label": "Retrieval-based face annotation by weak label regularized local coordinate coding", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Modeling LSH for performance tuning", "label": "Modeling LSH for performance tuning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Discrimination of characters by a multi-stage recognition process", "label": "Discrimination of characters by a multi-stage recognition process", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep learning for content-based image retrieval: A comprehensive study", "label": "Deep learning for content-based image retrieval: A comprehensive study", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "One millisecond face alignment with an ensemble of regression trees", "label": "One millisecond face alignment with an ensemble of regression trees", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Locally optimized product quantization for approximate nearest neighbor search", "label": "Locally optimized product quantization for approximate nearest neighbor search", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "On combining classi\ufb01ers", "label": "On combining classi\ufb01ers", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Score normalization in multimodal biometric systems", "label": "Score normalization in multimodal biometric systems", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "On the link between error correlation and error reduction in decision tree ensembles", "label": "On the link between error correlation and error reduction in decision tree ensembles", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deepface: Closing the gap to human-level performance in face veri\ufb01cation", "label": "Deepface: Closing the gap to human-level performance in face veri\ufb01cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Naive-deep face recognition: Touching the limit of LFW benchmark or not?", "label": "Naive-deep face recognition: Touching the limit of LFW benchmark or not?", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Unsupervised joint alignment of complex images", "label": "Unsupervised joint alignment of complex images", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A case study of automated face recognition: The boston marathon bombings suspects", "label": "A case study of automated face recognition: The boston marathon bombings suspects", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep functional maps: Structured prediction for dense shape correspondence", "label": "Deep functional maps: Structured prediction for dense shape correspondence", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "8(2):1141\u20131160", "label": "8(2):1141\u20131160", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "editors, Proceedings of the 32nd International Conference on Machine Learning (ICML-15), pages 448\u2013456", "label": "editors, Proceedings of the 32nd International Conference on Machine Learning (ICML-15), pages 448\u2013456", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "ebear: An expressive bear-like robot", "label": "ebear: An expressive bear-like robot", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A \u201csomatic alphabet\u201d approach to \u201csensitive skin\u201d", "label": "A \u201csomatic alphabet\u201d approach to \u201csensitive skin\u201d", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Emotions and robot artists: State-of-the-art and research challenges", "label": "Emotions and robot artists: State-of-the-art and research challenges", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The expression of the emotions in man and animals", "label": "The expression of the emotions in man and animals", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Facial Action Coding System: A Technique Palo Alto: Consulting for the Measurement of Facial Movement", "label": "Facial Action Coding System: A Technique Palo Alto: Consulting for the Measurement of Facial Movement", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Tutelage and collab-oration for humanoid robots", "label": "Tutelage and collab-oration for humanoid robots", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The shape of simon: creative design of a humanoid robot shell", "label": "The shape of simon: creative design of a humanoid robot shell", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "icat: Experimenting with animabotics", "label": "icat: Experimenting with animabotics", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Design and testing of a hybrid expressive face for a humanoid robot", "label": "Design and testing of a hybrid expressive face for a humanoid robot", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Animating visible speech and facial expressions", "label": "Animating visible speech and facial expressions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Handbook of the International Phonetic Association: A guide to the use of the International Phonetic Alphabet", "label": "Handbook of the International Phonetic Association: A guide to the use of the International Phonetic Alphabet", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Nonparametric regression and spline smoothing", "label": "Nonparametric regression and spline smoothing", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A design methodology for expressing emotion on robot faces", "label": "A design methodology for expressing emotion on robot faces", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Facial expression recognition using hessianmkl based multiclass-svm", "label": "Facial expression recognition using hessianmkl based multiclass-svm", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The extended cohn-kanade dataset (ck+): A complete dataset for action unit and emotion-speci\ufb01ed expression", "label": "The extended cohn-kanade dataset (ck+): A complete dataset for action unit and emotion-speci\ufb01ed expression", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Induced disgust", "label": "Induced disgust", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Histograms of oriented gradients for human detection", "label": "Histograms of oriented gradients for human detection", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Face recognition with local binary patterns", "label": "Face recognition with local binary patterns", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Facial expression recognition using game theory", "label": "Facial expression recognition using game theory", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Local directional number pattern for face analysis: Face and expression recognition", "label": "Local directional number pattern for face analysis: Face and expression recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Facial expression recognition based on local binary patterns: A comprehensive study", "label": "Facial expression recognition based on local binary patterns: A comprehensive study", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Vizdoom: A doom-based ai research platform In IEEE Conference on for visual reinforcement learning", "label": "Vizdoom: A doom-based ai research platform In IEEE Conference on for visual reinforcement learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A vision-based reinforcement learning for coordination of soccer playing behaviors", "label": "A vision-based reinforcement learning for coordination of soccer playing behaviors", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "pages 276\u2013282", "label": "pages 276\u2013282", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Reinforcement In Intelligent Robots and learning for a vision based mobile robot", "label": "Reinforcement In Intelligent Robots and learning for a vision based mobile robot", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "editors, Proceedings of the Fourteenth International Conference on Ar-ti\ufb01cial Intelligence and Statistics (AISTATS-11), volume 15, pages 315\u2013 323", "label": "editors, Proceedings of the Fourteenth International Conference on Ar-ti\ufb01cial Intelligence and Statistics (AISTATS-11), volume 15, pages 315\u2013 323", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Believable Bot Navigation via Playback of Human Traces, pages 151\u2013170", "label": "Believable Bot Navigation via Playback of Human Traces, pages 151\u2013170", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep auto-encoder neural net-works in reinforcement learning", "label": "Deep auto-encoder neural net-works in reinforcement learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Recti\ufb01er nonlinearities improve neural network acoustic models", "label": "Recti\ufb01er nonlinearities improve neural network acoustic models", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "RE-TALIATE: learning winning policies in \ufb01rst-person shooter games", "label": "RE-TALIATE: learning winning policies in \ufb01rst-person shooter games", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Continuous and Reinforcement Learning Methods for First-Person Shooter Games", "label": "Continuous and Reinforcement Learning Methods for First-Person Shooter Games", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Computer game engines for developing \ufb01rst-person virtual environments", "label": "Computer game engines for developing \ufb01rst-person virtual environments", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Visual semantic planning using deep successor representations", "label": "Visual semantic planning using deep successor representations", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The devil is in the details: an evaluation of recent feature encoding methods", "label": "The devil is in the details: an evaluation of recent feature encoding methods", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "PatchMatch: A Randomized Correspon-dence Algorithm for Structural Image Editing", "label": "PatchMatch: A Randomized Correspon-dence Algorithm for Structural Image Editing", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Random Sample Consensus: A Paradigm for Model Fitting with Applications to Image Analysis and Automated Cartography", "label": "Random Sample Consensus: A Paradigm for Model Fitting with Applications to Image Analysis and Automated Cartography", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "ImageNet Classi\ufb01cation with Deep Convolutional Neural Networks", "label": "ImageNet Classi\ufb01cation with Deep Convolutional Neural Networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A Benchmark Dataset and Evaluation Methodology for Video Object Segmentation", "label": "A Benchmark Dataset and Evaluation Methodology for Video Object Segmentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "FaceForen-sics: A Large-Scale Video Dataset for Forgery Detection in Human Faces", "label": "FaceForen-sics: A Large-Scale Video Dataset for Forgery Detection in Human Faces", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Going Deeper With Convolutions", "label": "Going Deeper With Convolutions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Attention is All You Need", "label": "Attention is All You Need", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Space-Time Completion of Video", "label": "Space-Time Completion of Video", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The Unreasonable Effectiveness of Deep In IEEE Conference on Features as a Perceptual Metric", "label": "The Unreasonable Effectiveness of Deep In IEEE Conference on Features as a Perceptual Metric", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "3D semantic segmentation with submanifold sparse convolutional networks", "label": "3D semantic segmentation with submanifold sparse convolutional networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Video propagation networks", "label": "Video propagation networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A novel locally linear knn model for visual recognition", "label": "A novel locally linear knn model for visual recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Recognizing imprecisely localized", "label": "Recognizing imprecisely localized", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Computational models of face perception", "label": "Computational models of face perception", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A neural basis of facial action recognition in humans", "label": "A neural basis of facial action recognition in humans", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Lifting from the deep: Convolutional 3d pose estimation from a single image", "label": "Lifting from the deep: Convolutional 3d pose estimation from a single image", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Facial action unit recognition by exploiting their dynamic and semantic relationships", "label": "Facial action unit recognition by exploiting their dynamic and semantic relationships", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Transferring face veri\ufb01-cation nets to pain and expression regression", "label": "Transferring face veri\ufb01-cation nets to pain and expression regression", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multiob-jective optimization for model selection in kernel methods in regression", "label": "Multiob-jective optimization for model selection in kernel methods in regression", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Kernel op-IEEE Transactions on timization in discriminant analysis", "label": "Kernel op-IEEE Transactions on timization in discriminant analysis", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Facial affect \u201cin the wild\u201d", "label": "Facial affect \u201cin the wild\u201d", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Joint patch and multi-label learning for facial action unit and holistic expression recognition", "label": "Joint patch and multi-label learning for facial action unit and holistic expression recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A simple", "label": "A simple", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Survey on rgb", "label": "Survey on rgb", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Emotion recognition in the wild", "label": "Emotion recognition in the wild", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Compound facial expres-sions of emotion", "label": "Compound facial expres-sions of emotion", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "What the Face Reveals: Ba-sic and applied studies of spontaneous expression using the Facial Action Coding System (FACS)", "label": "What the Face Reveals: Ba-sic and applied studies of spontaneous expression using the Facial Action Coding System (FACS)", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The pascal visual object classes (voc) chal-lenge", "label": "The pascal visual object classes (voc) chal-lenge", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The \ufb01rst 3d face alignment in the wild (3dfaw) challenge", "label": "The \ufb01rst 3d face alignment in the wild (3dfaw) challenge", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Support vector machines in face recognition with occlusions", "label": "Support vector machines in face recognition with occlusions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "An analysis of facial expres-sion recognition under partial facial image occlusion", "label": "An analysis of facial expres-sion recognition under partial facial image occlusion", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Torch7: A MATLAB-like environment for machine learning", "label": "Torch7: A MATLAB-like environment for machine learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Rich feature hierarchies for accurate object detection and semantic segmentation", "label": "Rich feature hierarchies for accurate object detection and semantic segmentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Pylearn2: a machine learning research library", "label": "Pylearn2: a machine learning research library", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Open-vocabulary object retrieval", "label": "Open-vocabulary object retrieval", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "cuda-convnet", "label": "cuda-convnet", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "ImageNet classi\ufb01cation with deep convolutional neural networks", "label": "ImageNet classi\ufb01cation with deep convolutional neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Overfeat: Integrated recognition", "label": "Overfeat: Integrated recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Selective search for object recognition", "label": "Selective search for object recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Panda: Pose aligned networks for deep attribute modeling", "label": "Panda: Pose aligned networks for deep attribute modeling", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A framework for learning predictive structures from multiple tasks and unlabeled data", "label": "A framework for learning predictive structures from multiple tasks and unlabeled data", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Van", "label": "Van", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "POOF: Part-based one-vs-one features for \ufb01ne-grained categorization, face veri\ufb01cation, and attribute estimation", "label": "POOF: Part-based one-vs-one features for \ufb01ne-grained categorization, face veri\ufb01cation, and attribute estimation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Kernel descriptors for visual recog-nition", "label": "Kernel descriptors for visual recog-nition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multitask learning", "label": "Multitask learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Dlid: Deep learn-ing for domain adaptation by interpolating between domains", "label": "Dlid: Deep learn-ing for domain adaptation by interpolating between domains", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "In ImageNet: A Large-Scale Hierarchical Image Database", "label": "In ImageNet: A Large-Scale Hierarchical Image Database", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning generative visual models from few training examples: an incremental Bayesian approach tested on 101 object categories", "label": "Learning generative visual models from few training examples: an incremental Bayesian approach tested on 101 object categories", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Object detection with discriminatively trained part-based mod-els", "label": "Object detection with discriminatively trained part-based mod-els", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Geodesic \ufb02ow kernel for unsupervised domain adaptation", "label": "Geodesic \ufb02ow kernel for unsupervised domain adaptation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Reducing the dimensionality of data with neural networks", "label": "Reducing the dimensionality of data with neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": ", Sutskever, and Salakhutdinov, R", "label": ", Sutskever, and Salakhutdinov, R", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Ef\ufb01cient learning of domain-invariant image representations", "label": "Ef\ufb01cient learning of domain-invariant image representations", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multi-arXiv preprint label prediction via compressed sensing", "label": "Multi-arXiv preprint label prediction via compressed sensing", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": ", and LeCun, Y", "label": ", and LeCun, Y", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "ImageNet clas-si\ufb01cation with deep convolutional neural networks", "label": "ImageNet clas-si\ufb01cation with deep convolutional neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "What you saw is not what you get: Domain adaptation using asymmetric kernel trans-forms", "label": "What you saw is not what you get: Domain adaptation using asymmetric kernel trans-forms", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning hierarchical invariant spatio-temporal features for action recognition with independent subspace analysis", "label": "Learning hierarchical invariant spatio-temporal features for action recognition with independent subspace analysis", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Building high-level features using large scale unsupervised learning", "label": "Building high-level features using large scale unsupervised learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Backpropagation applied to hand-written zip code recognition", "label": "Backpropagation applied to hand-written zip code recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Object bank: A high-level image representation for scene classi\ufb01cation \u0026 semantic feature sparsi\ufb01cation", "label": "Object bank: A high-level image representation for scene classi\ufb01cation \u0026 semantic feature sparsi\ufb01cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Unsupervised and transfer learning challenge: a deep learning approach", "label": "Unsupervised and transfer learning challenge: a deep learning approach", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Modeling the shape of the scene: A holistic representation of the spatial envelope", "label": "Modeling the shape of the scene: A holistic representation of the spatial envelope", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Transfer learning for In image classication with sparse prototype representations", "label": "Transfer learning for In image classication with sparse prototype representations", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Self-In taught learning: Transfer learning from unlabeled data", "label": "Self-In taught learning: Transfer learning from unlabeled data", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Histograms of sparse codes for object detection", "label": "Histograms of sparse codes for object detection", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Adapting visual category models to new domains", "label": "Adapting visual category models to new domains", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Unsupervised discovery of mid-level discriminative patches", "label": "Unsupervised discovery of mid-level discriminative patches", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Unbiased look at dataset bias", "label": "Unbiased look at dataset bias", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Visualizing data using t-sne", "label": "Visualizing data using t-sne", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Locality-constrained linear coding for image classi\ufb01cation", "label": "Locality-constrained linear coding for image classi\ufb01cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Sun database: Large-scale scene recognition from abbey to zoo", "label": "Sun database: Large-scale scene recognition from abbey to zoo", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deformable part descriptors for \ufb01ne-grained recognition and attribute pre-diction", "label": "Deformable part descriptors for \ufb01ne-grained recognition and attribute pre-diction", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Mask-cnn: Localizing parts and selecting descriptors for \ufb01ne-grained bird species categorization", "label": "Mask-cnn: Localizing parts and selecting descriptors for \ufb01ne-grained bird species categorization", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Object detection using strongly-supervised deformable part models", "label": "Object detection using strongly-supervised deformable part models", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Bird species categorization using pose normalized deep convolutional nets", "label": "Bird species categorization using pose normalized deep convolutional nets", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Visual recognition using embedded feature selection for curvature self-similarity", "label": "Visual recognition using embedded feature selection for curvature self-similarity", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Local alignments for \ufb01ne-grained categorization", "label": "Local alignments for \ufb01ne-grained categorization", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Part-stacked CNN for \ufb01ne-grained visual categorization", "label": "Part-stacked CNN for \ufb01ne-grained visual categorization", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Spatial transformer networks", "label": "Spatial transformer networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fine-grained recognition without part annotations", "label": "Fine-grained recognition without part annotations", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep LAC: Deep localization", "label": "Deep LAC: Deep localization", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fully convolutional networks for semantic segmentation", "label": "Fully convolutional networks for semantic segmentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "GrabCut: Interactive foreground extraction using iterated graph cuts", "label": "GrabCut: Interactive foreground extraction using iterated graph cuts", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Neural activation constellations: Unsupervised part model discovery with convolutional networks", "label": "Neural activation constellations: Unsupervised part model discovery with convolutional networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "MatConvNet: Convolutional neural networks for MATLAB", "label": "MatConvNet: Convolutional neural networks for MATLAB", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The Caltech-UCSD birds-200-2011 dataset", "label": "The Caltech-UCSD birds-200-2011 dataset", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The application of two-level attention models in deep convolutional neural network for \ufb01ne-grained image classi\ufb01cation", "label": "The application of two-level attention models in deep convolutional neural network for \ufb01ne-grained image classi\ufb01cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Adaptive deconvolutional networks for mid and high level feature learning", "label": "Adaptive deconvolutional networks for mid and high level feature learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Part-based R-CNNs for \ufb01ne-grained category detection", "label": "Part-based R-CNNs for \ufb01ne-grained category detection", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Compact representation for image classi\ufb01cation: To choose or to compress? In CVPR", "label": "Compact representation for image classi\ufb01cation: To choose or to compress? In CVPR", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Picking deep \ufb01lter resonses for \ufb01ne-grained image recognition", "label": "Picking deep \ufb01lter resonses for \ufb01ne-grained image recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Weakly supervised \ufb01ne-grained categorization with part-based image representation", "label": "Weakly supervised \ufb01ne-grained categorization with part-based image representation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Origami: A 803-gop/s/w IEEE Transac-convolutional network accelerator", "label": "Origami: A 803-gop/s/w IEEE Transac-convolutional network accelerator", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Neu\ufb02ow: A runtime recon-\ufb01gurable data\ufb02ow processor for vision", "label": "Neu\ufb02ow: A runtime recon-\ufb01gurable data\ufb02ow processor for vision", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Cnp: An fpga-based processor for convolutional networks", "label": "Cnp: An fpga-based processor for convolutional networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Integrated model", "label": "Integrated model", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A 240 g-ops/s mobile coprocessor for deep In Proceedings of the IEEE Con-neural networks", "label": "A 240 g-ops/s mobile coprocessor for deep In Proceedings of the IEEE Con-neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep compres-sion: Compressing deep neural networks with prun-In-ing", "label": "Deep compres-sion: Compressing deep neural networks with prun-In-ing", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning both weights and connections for ef\ufb01cient neural network", "label": "Learning both weights and connections for ef\ufb01cient neural network", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep resid-ual learning for image recognition", "label": "Deep resid-ual learning for image recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Shuf\ufb02e net: An ap-plication of generalized perfect shuf\ufb02es to multihop lightwave networks", "label": "Shuf\ufb02e net: An ap-plication of generalized perfect shuf\ufb02es to multihop lightwave networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Mobilenets: Ef\ufb01cient convolutional neural networks arXiv preprint for mobile vision applications", "label": "Mobilenets: Ef\ufb01cient convolutional neural networks arXiv preprint for mobile vision applications", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Condensenet: An ef\ufb01cient densenet using learned group convolutions", "label": "Condensenet: An ef\ufb01cient densenet using learned group convolutions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Quantized neural networks: Training neural networks with low precision weights and acti-vations", "label": "Quantized neural networks: Training neural networks with low precision weights and acti-vations", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and\u003c 0", "label": "SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and\u003c 0", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Batch normalization: Accel-erating deep network training by reducing internal co-variate shift", "label": "Batch normalization: Accel-erating deep network training by reducing internal co-variate shift", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Speed-ing up convolutional neural networks with low rank expansions", "label": "Speed-ing up convolutional neural networks with low rank expansions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "C", "label": "C", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Im-agenet classi\ufb01cation with deep convolutional neural networks", "label": "Im-agenet classi\ufb01cation with deep convolutional neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Weighted-entropy-based quantization for deep neural networks", "label": "Weighted-entropy-based quantization for deep neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Xnor-net: Imagenet classi\ufb01cation using binary convo-lutional neural networks", "label": "Xnor-net: Imagenet classi\ufb01cation using binary convo-lutional neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Darknet: Open source neural networks in c", "label": "Darknet: Open source neural networks in c", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Roo\ufb02ine: an insightful visual performance model for multicore architectures", "label": "Roo\ufb02ine: an insightful visual performance model for multicore architectures", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Squeezedet: Uni\ufb01ed", "label": "Squeezedet: Uni\ufb01ed", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Squeeze-seg: Convolutional neural nets with recurrent crf for real-time road-object segmentation from 3d lidar point cloud", "label": "Squeeze-seg: Convolutional neural nets with recurrent crf for real-time road-object segmentation from 3d lidar point cloud", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep layer aggrega-tion", "label": "Deep layer aggrega-tion", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "S", "label": "S", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning the number of neurons in deep networks", "label": "Learning the number of neurons in deep networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Adaptive neural networks for fast test-time prediction", "label": "Adaptive neural networks for fast test-time prediction", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Model compression", "label": "Model compression", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "In Compressing neural networks with the hashing trick", "label": "In Compressing neural networks with the hashing trick", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Xception: Deep learning with depthwise sepa-rable convolutions", "label": "Xception: Deep learning with depthwise sepa-rable convolutions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Imagenet: A large-scale hierarchical image database", "label": "Imagenet: A large-scale hierarchical image database", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Adaptive computation time for recurrent neural networks", "label": "Adaptive computation time for recurrent neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep compres-sion: Compressing deep neural networks with pruning", "label": "Deep compres-sion: Compressing deep neural networks with pruning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Optimal brain sur-geon and general network pruning", "label": "Optimal brain sur-geon and general network pruning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Channel pruning for accelerat-ing very deep neural networks", "label": "Channel pruning for accelerat-ing very deep neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Distilling the knowl-edge in a neural network", "label": "Distilling the knowl-edge in a neural network", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Mobilenets: Ef\ufb01-cient convolutional neural networks for mobile vision appli-cations", "label": "Mobilenets: Ef\ufb01-cient convolutional neural networks for mobile vision appli-cations", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multi-scale dense networks for resource ef\ufb01cient image classi\ufb01cation", "label": "Multi-scale dense networks for resource ef\ufb01cient image classi\ufb01cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Snapshot ensembles: Train 1", "label": "Snapshot ensembles: Train 1", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Binarized neural networks", "label": "Binarized neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Squeezenet: Alexnet-level accuracy with 50x fewer parameters and 0", "label": "Squeezenet: Alexnet-level accuracy with 50x fewer parameters and 0", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "classi\ufb01cation with deep convolutional neural networks", "label": "classi\ufb01cation with deep convolutional neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fractalnet: Ultra-deep neural networks without residuals", "label": "Fractalnet: Ultra-deep neural networks without residuals", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "volume 2", "label": "volume 2", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Pruning \ufb01lters for ef\ufb01cient convnets", "label": "Pruning \ufb01lters for ef\ufb01cient convnets", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning ef\ufb01cient convolutional networks through network slimming", "label": "Learning ef\ufb01cient convolutional networks through network slimming", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "SGDR: stochastic gradient de-scent with restarts", "label": "SGDR: stochastic gradient de-scent with restarts", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Recti\ufb01ed linear units improve re-stricted boltzmann machines", "label": "Recti\ufb01ed linear units improve re-stricted boltzmann machines", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Xnor-net: Imagenet classi\ufb01cation using binary convolutional neu-ral networks", "label": "Xnor-net: Imagenet classi\ufb01cation using binary convolutional neu-ral networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fitnets: Hints for thin deep nets", "label": "Fitnets: Hints for thin deep nets", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Striving for simplicity: The all convolutional net", "label": "Striving for simplicity: The all convolutional net", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Dropout: a simple way to prevent neu-ral networks from over\ufb01tting", "label": "Dropout: a simple way to prevent neu-ral networks from over\ufb01tting", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Aggregated residual transformations for deep neural networks", "label": "Aggregated residual transformations for deep neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Model selection and estimation in re-gression with grouped variables", "label": "Model selection and estimation in re-gression with grouped variables", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Interleaved group convolutions for deep neural networks", "label": "Interleaved group convolutions for deep neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Shuf\ufb02enet: An extremely ef\ufb01cient convolutional neural network for mobile devices", "label": "Shuf\ufb02enet: An extremely ef\ufb01cient convolutional neural network for mobile devices", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep convolu-tional neural networks with merge-and-run mappings", "label": "Deep convolu-tional neural networks with merge-and-run mappings", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learn-ing transferable architectures for scalable image recognition", "label": "Learn-ing transferable architectures for scalable image recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Octnet: Learning Deep 3D Representations at High Resolutions", "label": "Octnet: Learning Deep 3D Representations at High Resolutions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Orientation-boosted voxel nets for 3d object recognition", "label": "Orientation-boosted voxel nets for 3d object recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Segnet: A deep convolutional encoder-decoder architecture for image segmentation", "label": "Segnet: A deep convolutional encoder-decoder architecture for image segmentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning 6d object pose estimation using In Proc", "label": "Learning 6d object pose estimation using In Proc", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Uncertainty-driven 6d pose estimation of ob-In Proc", "label": "Uncertainty-driven 6d pose estimation of ob-In Proc", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Generative and discriminative voxel modeling with convolutional neural networks", "label": "Generative and discriminative voxel modeling with convolutional neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Shapenet: An information-rich 3d model repository", "label": "Shapenet: An information-rich 3d model repository", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A large dataset of object scans", "label": "A large dataset of object scans", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "3d-r2n2: A uni\ufb01ed approach for single and multi-view 3d object reconstruction", "label": "3d-r2n2: A uni\ufb01ed approach for single and multi-view 3d object reconstruction", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Vote3deep: Fast object detection in 3d point clouds using ef-\ufb01cient convolutional neural networks", "label": "Vote3deep: Fast object detection in 3d point clouds using ef-\ufb01cient convolutional neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Real time head pose In Proc", "label": "Real time head pose In Proc", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep-stereo: Learning to predict new views from the world\u2019s im-agery", "label": "Deep-stereo: Learning to predict new views from the world\u2019s im-agery", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Ef-\ufb01cient 2d and 3d facade segmentation using auto-context", "label": "Ef-\ufb01cient 2d and 3d facade segmentation using auto-context", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Laplacian pyramid reconstruc-tion and re\ufb01nement for semantic segmentation", "label": "Laplacian pyramid reconstruc-tion and re\ufb01nement for semantic segmentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning a predictable and generative vector representation In Proc", "label": "Learning a predictable and generative vector representation In Proc", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Spatially-sparse convolutional neural networks", "label": "Spatially-sparse convolutional neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Sparse 3d convolutional neural networks", "label": "Sparse 3d convolutional neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep residual learning In Proc", "label": "Deep residual learning In Proc", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fusionnet: 3d object classi\ufb01cation using multiple data representations", "label": "Fusionnet: 3d object classi\ufb01cation using multiple data representations", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Point cloud labeling using 3d convolu-tional neural network", "label": "Point cloud labeling using 3d convolu-tional neural network", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Single-view reconstruc-In tion via joint analysis of image and shape collections", "label": "Single-view reconstruc-In tion via joint analysis of image and shape collections", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning sparse high dimensional \ufb01lters: Image \ufb01ltering", "label": "Learning sparse high dimensional \ufb01lters: Image \ufb01ltering", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "An octree-based approach towards ef\ufb01cient variational range data fusion", "label": "An octree-based approach towards ef\ufb01cient variational range data fusion", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Ef\ufb01cient sparse voxel octrees", "label": "Ef\ufb01cient sparse voxel octrees", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "FPNN: \ufb01eld probing neural networks for 3d data", "label": "FPNN: \ufb01eld probing neural networks for 3d data", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "3d all the way: Semantic segmentation of urban scenes from start to end in 3d", "label": "3d all the way: Semantic segmentation of urban scenes from start to end in 3d", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Voxnet: A 3d convolutional In Proc", "label": "Voxnet: A 3d convolutional In Proc", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Geometric modeling using octree encod-ing", "label": "Geometric modeling using octree encod-ing", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Real-time rendering In Proc", "label": "Real-time rendering In Proc", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "V-net: Fully convo-lutional neural networks for volumetric medical image seg-mentation", "label": "V-net: Fully convo-lutional neural networks for volumetric medical image seg-mentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep3d: Fully au-tomatic 2d-to-3d video conversion with deep convolutional In Proc", "label": "Deep3d: Fully au-tomatic 2d-to-3d video conversion with deep convolutional In Proc", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Generic 3d representation via pose estimation and matching", "label": "Generic 3d representation via pose estimation and matching", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Adaptive decon-volutional networks for mid and high level feature learning", "label": "Adaptive decon-volutional networks for mid and high level feature learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deepcon-text: Context-encoding neural pathways for 3d holistic scene understanding", "label": "Deepcon-text: Context-encoding neural pathways for 3d holistic scene understanding", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Kinectfusion: Real-time dense surface map-ping and tracking", "label": "Kinectfusion: Real-time dense surface map-ping and tracking", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Volumetric and multi-view cnns for object classi\ufb01cation on 3d data", "label": "Volumetric and multi-view cnns for object classi\ufb01cation on 3d data", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Faster R-CNN: towards real-time object detection with region proposal net-works", "label": "Faster R-CNN: towards real-time object detection with region proposal net-works", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Unsupervised learning of 3d structure from images", "label": "Unsupervised learning of 3d structure from images", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning where to classify in multi-view semantic segmentation", "label": "Learning where to classify in multi-view semantic segmentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Discriminatively trained templates for 3d object detection: A real-time scalable ap-proach", "label": "Discriminatively trained templates for 3d object detection: A real-time scalable ap-proach", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Vconv-dae: Deep vol-arXiv", "label": "Vconv-dae: Deep vol-arXiv", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep sliding shapes for amodal 3d object detection in RGB-D images", "label": "Deep sliding shapes for amodal 3d object detection in RGB-D images", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multi-view convolutional neural networks for 3d shape In Proc", "label": "Multi-view convolutional neural networks for 3d shape In Proc", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multi-view 3d models from single images with a convolutional network", "label": "Multi-view 3d models from single images with a convolutional network", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Latent-class hough forests for 3d object detection and pose estima-In Proc", "label": "Latent-class hough forests for 3d object detection and pose estima-In Proc", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Towards prob-abilistic volumetric reconstruction using ray potentials", "label": "Towards prob-abilistic volumetric reconstruction using ray potentials", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning descriptors for object recognition and 3d pose estimation", "label": "Learning descriptors for object recognition and 3d pose estimation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Single image 3d interpreter net-work", "label": "Single image 3d interpreter net-work", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The protein data bank", "label": "The protein data bank", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Schelling points on 3D surface meshes", "label": "Schelling points on 3D surface meshes", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "ImageNet: A large-scale hierarchical image database", "label": "ImageNet: A large-scale hierarchical image database", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Example-based synthesis of 3D object arrangements", "label": "Example-based synthesis of 3D object arrangements", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fine-grained semi-supervised labeling of large shape collections", "label": "Fine-grained semi-supervised labeling of large shape collections", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Developing an engineering shape benchmark for CAD models", "label": "Developing an engineering shape benchmark for CAD models", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A probabilistic model for component-based shape synthesis", "label": "A probabilistic model for component-based shape synthesis", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Mobius transformations for global intrinsic symmetry analysis", "label": "Mobius transformations for global intrinsic symmetry analysis", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning part-based templates from large collections of 3D shapes", "label": "Learning part-based templates from large collections of 3D shapes", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Exploring collections of 3D models using fuzzy correspondences", "label": "Exploring collections of 3D models using fuzzy correspondences", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "PDBsum: A web-based database of summaries and analyses of all PDB structures", "label": "PDBsum: A web-based database of summaries and analyses of all PDB structures", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Cre-ating consistent scene graphs using a probabilistic grammar", "label": "Cre-ating consistent scene graphs using a probabilistic grammar", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Building a large annotated corpus of english: The Penn Treebank", "label": "Building a large annotated corpus of english: The Penn Treebank", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Simpli\ufb01cation and repair of polygonal models using volumetric techniques", "label": "Simpli\ufb01cation and repair of polygonal models using volumetric techniques", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Building a database of 3D scenes from user annotations", "label": "Building a database of 3D scenes from user annotations", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The Princeton shape benchmark", "label": "The Princeton shape benchmark", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Sliding shapes for 3D ob-ject detection in depth images", "label": "Sliding shapes for 3D ob-ject detection in depth images", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A large-scale shape benchmark for 3D object retrieval: Toy-ohashi shape benchmark", "label": "A large-scale shape benchmark for 3D object retrieval: Toy-ohashi shape benchmark", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "La-belMe: Online image annotation and applications", "label": "La-belMe: Online image annotation and applications", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "3D ShapeNets: A Deep Representation for Volumetric Shapes", "label": "3D ShapeNets: A Deep Representation for Volumetric Shapes", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Beyond PASCAL: A benchmark for 3D object detection in the wild", "label": "Beyond PASCAL: A benchmark for 3D object detection in the wild", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Retrieving articulated 3-D mod-els using medial surfaces and their graph spectra", "label": "Retrieving articulated 3-D mod-els using medial surfaces and their graph spectra", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Expressionbot: An emotive lifelike robotic face for face-to-face communication", "label": "Expressionbot: An emotive lifelike robotic face for face-to-face communication", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Action recognition in video using sparse coding and relative features", "label": "Action recognition in video using sparse coding and relative features", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "FAUST: Dataset and evaluation for 3D mesh registration", "label": "FAUST: Dataset and evaluation for 3D mesh registration", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fast convolutional sparse coding", "label": "Fast convolutional sparse coding", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Spectral networks and locally connected networks on graphs", "label": "Spectral networks and locally connected networks on graphs", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Atomic decomposition by basis pursuit", "label": "Atomic decomposition by basis pursuit", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Indexing by latent semantic analysis", "label": "Indexing by latent semantic analysis", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Coupled func-tional maps", "label": "Coupled func-tional maps", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Recurrent slice networks for 3d segmen-tation on point clouds", "label": "Recurrent slice networks for 3d segmen-tation on point clouds", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Joint shape segmentation with linear programming", "label": "Joint shape segmentation with linear programming", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Functional map networks for analyzing and exploring large shape collections", "label": "Functional map networks for analyzing and exploring large shape collections", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "3D shape segmentation with projective convolutional networks", "label": "3D shape segmentation with projective convolutional networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Escape from cells: Deep kd-networks for the recogni-tion of 3d point cloud models", "label": "Escape from cells: Deep kd-networks for the recogni-tion of 3d point cloud models", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Ef\ufb01cient sparse coding algorithms", "label": "Ef\ufb01cient sparse coding algorithms", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning overcomplete representations", "label": "Learning overcomplete representations", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Informative descriptor preservation via commutativity for shape matching", "label": "Informative descriptor preservation via commutativity for shape matching", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Emergence of simple-cell receptive \ufb01eld properties by learning a sparse code for natural images", "label": "Emergence of simple-cell receptive \ufb01eld properties by learning a sparse code for natural images", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Sparse coding of sensory inputs", "label": "Sparse coding of sensory inputs", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Functional maps: a \ufb02exible representation of maps between shapes", "label": "Functional maps: a \ufb02exible representation of maps between shapes", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Sparse modeling of intrinsic correspondences", "label": "Sparse modeling of intrinsic correspondences", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Frustum pointnets for 3d object detection from rgb-d data", "label": "Frustum pointnets for 3d object detection from rgb-d data", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Pointnet: Deep learning on point sets for 3d classi\ufb01cation and segmentation", "label": "Pointnet: Deep learning on point sets for 3d classi\ufb01cation and segmentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Pointnet++: Deep hierarchical feature learning on point sets in a metric space", "label": "Pointnet++: Deep hierarchical feature learning on point sets in a metric space", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Partial functional correspondence", "label": "Partial functional correspondence", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A concise and provably informative multi-scale signature based on heat diffusion", "label": "A concise and provably informative multi-scale signature based on heat diffusion", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Image co-segmentation via consistent functional maps", "label": "Image co-segmentation via consistent functional maps", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Sgpn: Similarity group proposal network for 3d point cloud instance segmentation", "label": "Sgpn: Similarity group proposal network for 3d point cloud instance segmentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A scalable active framework for region annotation in 3d shape collections", "label": "A scalable active framework for region annotation in 3d shape collections", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Syncspeccnn: Synchronized spectral cnn for 3d shape segmentation", "label": "Syncspeccnn: Synchronized spectral cnn for 3d shape segmentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deconvolutional networks", "label": "Deconvolutional networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Human activity analysis", "label": "Human activity analysis", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "K-SVD: An al-gorithm for designing overcomplete dictionaries for sparse representation", "label": "K-SVD: An al-gorithm for designing overcomplete dictionaries for sparse representation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Human action recogni-In tion from inter-temporal dictionaries of key-sequences", "label": "Human action recogni-In tion from inter-temporal dictionaries of key-sequences", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Action synopsis: Pose selection and illustration", "label": "Action synopsis: Pose selection and illustration", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Trajectory-based \ufb01sher kernel representation for action recognition in videos", "label": "Trajectory-based \ufb01sher kernel representation for action recognition in videos", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Representing shape with a spatial pyramid kernel", "label": "Representing shape with a spatial pyramid kernel", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Detecting people using mutually consistent poselet activations", "label": "Detecting people using mutually consistent poselet activations", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Sparse modeling of human ac-tions from motion imagery", "label": "Sparse modeling of human ac-tions from motion imagery", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Behavior recognition via sparse spatio-temporal features", "label": "Behavior recognition via sparse spatio-temporal features", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Optimally sparse representation in general (non orthogonal) dictionaries via l1 minimization", "label": "Optimally sparse representation in general (non orthogonal) dictionaries via l1 minimization", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "See all by looking at a few: Sparse modeling for \ufb01nding representative objects", "label": "See all by looking at a few: Sparse modeling for \ufb01nding representative objects", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Object detection with discriminatively trained part based models", "label": "Object detection with discriminatively trained part based models", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A dual algorithm for the solu-tion of nonlinear variational problems via \ufb01nite-element ap-proximations", "label": "A dual algorithm for the solu-tion of nonlinear variational problems via \ufb01nite-element ap-proximations", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Actom sequence models for ef\ufb01cient action detection", "label": "Actom sequence models for ef\ufb01cient action detection", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Activity represen-tation with motion hierarchies", "label": "Activity represen-tation with motion hierarchies", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning sparse representations for human action recognition", "label": "Learning sparse representations for human action recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Action recognition in video by sparse representation on covariance manifolds of silhou-ette tunnels", "label": "Action recognition in video by sparse representation on covariance manifolds of silhou-ette tunnels", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Trajectory-based modeling of human actions with motion reference points", "label": "Trajectory-based modeling of human actions with motion reference points", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Creating ef\ufb01cient codebooks for vi-In IEEE Int", "label": "Creating ef\ufb01cient codebooks for vi-In IEEE Int", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A spatio-temporal descriptor based on 3D-gradients", "label": "A spatio-temporal descriptor based on 3D-gradients", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Space-time interest points", "label": "Space-time interest points", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "In IEEE Learning realistic human actions from movies", "label": "In IEEE Learning realistic human actions from movies", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Recognizing human actions using multiple features", "label": "Recognizing human actions using multiple features", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Recognizing human ac-tions by attributes", "label": "Recognizing human ac-tions by attributes", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Boosted key-frame selec-tion and correlated pyramidal feature representation for hu-man action recognition", "label": "Boosted key-frame selec-tion and correlated pyramidal feature representation for hu-man action recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Modeling temporal structure of decomposable motion segments for activity clas-si\ufb01cation", "label": "Modeling temporal structure of decomposable motion segments for activity clas-si\ufb01cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Action and event recognition with \ufb01sher vectors on a compact feature set", "label": "Action and event recognition with \ufb01sher vectors on a compact feature set", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Relative attributes", "label": "Relative attributes", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Discovering discrim-inative action parts from mid-level video representations", "label": "Discovering discrim-inative action parts from mid-level video representations", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Poselet key-framing: A model for human activity recognition", "label": "Poselet key-framing: A model for human activity recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Action Bank: A high-level rep-resentation of activity in video", "label": "Action Bank: A high-level rep-resentation of activity in video", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Action Snippets: How many In IEEE frames does human action recognition require? Conf", "label": "Action Snippets: How many In IEEE frames does human action recognition require? Conf", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Recognizing human In Int", "label": "Recognizing human In Int", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Modeling motion of body parts for action recognition", "label": "Modeling motion of body parts for action recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Improved object categorization and detection using comparative object simi-larity", "label": "Improved object categorization and detection using comparative object simi-larity", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Dense trajecto-ries and motion boundary descriptors for action recognition", "label": "Dense trajecto-ries and motion boundary descriptors for action recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Evaluation of local spatio-temporal features for action recog-nition", "label": "Evaluation of local spatio-temporal features for action recog-nition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Hidden part models for human action recognition: Probabilistic versus max margin", "label": "Hidden part models for human action recognition: Probabilistic versus max margin", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Action recognition using exemplar-based embedding", "label": "Action recognition using exemplar-based embedding", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Action recognition in videos acquired by a moving camera using motion decomposition of lagragian particle trajectories", "label": "Action recognition in videos acquired by a moving camera using motion decomposition of lagragian particle trajectories", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The power of comparative reasoning", "label": "The power of comparative reasoning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A Hough transform-based voting framework for action recognition", "label": "A Hough transform-based voting framework for action recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Real-time action recognition by spatiotemporal semantic and structural forest", "label": "Real-time action recognition by spatiotemporal semantic and structural forest", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Information theoretic key frame selection for action recognition", "label": "Information theoretic key frame selection for action recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning spatial and temporal extents of human actions for action detection", "label": "Learning spatial and temporal extents of human actions for action detection", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Capturing long-tail distributions of object subcategories", "label": "Capturing long-tail distributions of object subcategories", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A learned feature descriptor for object recognition in RGB-D data", "label": "A learned feature descriptor for object recognition in RGB-D data", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Unsupervised feature learning for RGB-D based object recognition", "label": "Unsupervised feature learning for RGB-D based object recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "AttribIt: Content creation with semantic at-tributes", "label": "AttribIt: Content creation with semantic at-tributes", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Probabilistic reasoning for assembly-based 3D modeling", "label": "Probabilistic reasoning for assembly-based 3D modeling", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep \ufb01lter banks for texture recognition and segmentation", "label": "Deep \ufb01lter banks for texture recognition and segmentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "3D object detec-tion and viewpoint estimation with a deformable 3D cuboid model", "label": "3D object detec-tion and viewpoint estimation with a deformable 3D cuboid model", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Upright ori-entation of man-made objects", "label": "Upright ori-entation of man-made objects", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "3D mesh labeling via deep convolutional neural networks", "label": "3D mesh labeling via deep convolutional neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Perceptual organization In and recognition of indoor scenes from RGB-D images", "label": "Perceptual organization In and recognition of indoor scenes from RGB-D images", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning rich features from RGB-D images for object detection and segmentation", "label": "Learning rich features from RGB-D images for object detection and segmentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Simul-taneous detection and segmentation", "label": "Simul-taneous detection and segmentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Hyper-columns for object segmentation and \ufb01ne-grained localiza-tion", "label": "Hyper-columns for object segmentation and \ufb01ne-grained localiza-tion", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fusenet: Incorporating depth into semantic segmentation via fusion-based CNN architecture", "label": "Fusenet: Incorporating depth into semantic segmentation via fusion-based CNN architecture", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Analysis and syn-thesis of 3D shape families via deep-learned generative mod-els of surfaces", "label": "Analysis and syn-thesis of 3D shape families via deep-learned generative mod-els of surfaces", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Shape synthesis from sketches via procedural models and convolu-tional networks", "label": "Shape synthesis from sketches via procedural models and convolu-tional networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Joint shape segmenta-tion with linear programming", "label": "Joint shape segmenta-tion with linear programming", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Single-view reconstruc-tion via joint analysis of image and shape collections", "label": "Single-view reconstruc-tion via joint analysis of image and shape collections", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learn-ing 3D mesh segmentation and labeling", "label": "Learn-ing 3D mesh segmentation and labeling", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Probabilistic Graphical Models: Principles and Techniques", "label": "Probabilistic Graphical Models: Principles and Techniques", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A large-scale hierarchi-cal multi-view RGB-D object dataset", "label": "A large-scale hierarchi-cal multi-view RGB-D object dataset", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "FPM: Fine pose parts-In Proc", "label": "FPM: Fine pose parts-In Proc", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Function-ality preserving shape style transfer", "label": "Function-ality preserving shape style transfer", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Feed-forward semantic segmentation with zoom-out features", "label": "Feed-forward semantic segmentation with zoom-out features", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning deconvolution net-work for semantic segmentation", "label": "Learning deconvolution net-work for semantic segmentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multi-view and 3D deformable part models", "label": "Multi-view and 3D deformable part models", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Illumination for computer generated pictures", "label": "Illumination for computer generated pictures", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Volumetric and multi-view CNNs for object classi-\ufb01cation on 3D data", "label": "Volumetric and multi-view CNNs for object classi-\ufb01cation on 3D data", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Unsupervised learning of 3D structure from images", "label": "Unsupervised learning of 3D structure from images", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Semantic 3D Object Maps for Everyday Robot Manipulation", "label": "Semantic 3D Object Maps for Everyday Robot Manipulation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Contextual part analogies in 3D objects", "label": "Contextual part analogies in 3D objects", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Real-time human pose recog-nition in parts from a single depth image", "label": "Real-time human pose recog-nition in parts from a single depth image", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Unsupervised co-segmentation of a set of shapes Trans", "label": "Unsupervised co-segmentation of a set of shapes Trans", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "SUN RGB-D: In Proc", "label": "SUN RGB-D: In Proc", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep sliding shapes for amodal arXiv preprint 3D object detection in RGB-D images", "label": "Deep sliding shapes for amodal arXiv preprint 3D object detection in RGB-D images", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multi-view convolutional neural networks for 3D shape recogni-tion", "label": "Multi-view convolutional neural networks for 3D shape recogni-tion", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Prior knowledge for part correspondence", "label": "Prior knowledge for part correspondence", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Reg-ularization of neural networks using DropConnect", "label": "Reg-ularization of neural networks using DropConnect", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Projective analysis for 3D shape segmentation", "label": "Projective analysis for 3D shape segmentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Pro-jective feature learning for 3D shapes with multi-view depth images", "label": "Pro-jective feature learning for 3D shapes with multi-view depth images", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Data-driven shape analysis and processing", "label": "Data-driven shape analysis and processing", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Example-based 3D object re-construction from line drawings", "label": "Example-based 3D object re-construction from line drawings", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Perspec-tive transformer nets: Learning single-view 3D object recon-struction without 3D supervision", "label": "Perspec-tive transformer nets: Learning single-view 3D object recon-struction without 3D supervision", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A scalable ac-tive framework for region annotation in 3D shape collections", "label": "A scalable ac-tive framework for region annotation in 3D shape collections", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multi-scale context aggregation by di-lated convolutions", "label": "Multi-scale context aggregation by di-lated convolutions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Co-segmentation of textured 3D shapes with sparse annotations", "label": "Co-segmentation of textured 3D shapes with sparse annotations", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Conditional random \ufb01elds as recurrent neural networks", "label": "Conditional random \ufb01elds as recurrent neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning dense correspondence via 3D-guided cycle consistency", "label": "Learning dense correspondence via 3D-guided cycle consistency", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The wave kernel signature: A quantum mechanical approach to shape analysis", "label": "The wave kernel signature: A quantum mechanical approach to shape analysis", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Classi\ufb01cation and segmentation of terrestrial laser scanner point clouds using local variance information", "label": "Classi\ufb01cation and segmentation of terrestrial laser scanner point clouds using local variance information", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Scannet: Richly-annotated 3d reconstructions of indoor scenes", "label": "Scannet: Richly-annotated 3d reconstructions of indoor scenes", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Dimensionality based scale selection in 3d lidar point clouds", "label": "Dimensionality based scale selection in 3d lidar point clouds", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Towards 3d lidar point cloud registration improvement using optimal neighborhood knowledge", "label": "Towards 3d lidar point cloud registration improvement using optimal neighborhood knowledge", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Non-rigid 3D Shape Retrieval", "label": "Non-rigid 3D Shape Retrieval", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep learning with geodesic moments for 3d shape classi\ufb01cation", "label": "Deep learning with geodesic moments for 3d shape classi\ufb01cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Geodesic convolutional neural networks on riemannian manifolds", "label": "Geodesic convolutional neural networks on riemannian manifolds", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Estimating surface normals in noisy point cloud data", "label": "Estimating surface normals in noisy point cloud data", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Structure sensor-3d scanning", "label": "Structure sensor-3d scanning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Point-based multiscale surface representation", "label": "Point-based multiscale surface representation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Octnet: Learning deep 3d representations at high resolutions", "label": "Octnet: Learning deep 3d representations at high resolutions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Interior distance using barycentric coordinates", "label": "Interior distance using barycentric coordinates", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Best practices for convolutional neural networks applied to visual document analysis", "label": "Best practices for convolutional neural networks applied to visual document analysis", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multi-view convolutional neural networks for 3d shape recognition", "label": "Multi-view convolutional neural networks for 3d shape recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Order matters: Sequence to sequence for sets", "label": "Order matters: Sequence to sequence for sets", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Semantic point cloud interpretation based on optimal neighborhoods", "label": "Semantic point cloud interpretation based on optimal neighborhoods", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Geometric deep learning: Going beyond euclidean data", "label": "Geometric deep learning: Going beyond euclidean data", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups", "label": "Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Sequence to sequence learning with neural networks", "label": "Sequence to sequence learning with neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Convolutional networks and applications in vision", "label": "Convolutional networks and applications in vision", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A committee of neural networks for traf\ufb01c sign classi\ufb01cation", "label": "A committee of neural networks for traf\ufb01c sign classi\ufb01cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning hierar-chical features for scene labeling", "label": "Learning hierar-chical features for scene labeling", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep learning: methods and applications", "label": "Deep learning: methods and applications", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Natural image statistics and neural representation", "label": "Natural image statistics and neural representation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "An exact mapping between the variational renormalization group and deep learning", "label": "An exact mapping between the variational renormalization group and deep learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Invariant scattering convolution networks", "label": "Invariant scattering convolution networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A mathematical motivation for complex-valued convolutional net-works", "label": "A mathematical motivation for complex-valued convolutional net-works", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Backpropagation applied to handwritten ZIP code recognition", "label": "Backpropagation applied to handwritten ZIP code recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Maxout networks", "label": "Maxout networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The multiscale structure of non-differentiable image manifolds", "label": "The multiscale structure of non-differentiable image manifolds", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Which spatial partition trees are adaptive to intrinsic dimension?\u201d in Proc", "label": "Which spatial partition trees are adaptive to intrinsic dimension?\u201d in Proc", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A global geometric framework for nonlinear dimensionality reduction", "label": "A global geometric framework for nonlinear dimensionality reduction", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Nonlinear dimensionality reduction by locally linear embedding", "label": "Nonlinear dimensionality reduction by locally linear embedding", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Visualizing data using t-SNE", "label": "Visualizing data using t-SNE", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Laplacian eigenmaps for dimensionality reduction and data representation", "label": "Laplacian eigenmaps for dimensionality reduction and data representation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Diffusion maps", "label": "Diffusion maps", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Dimensionality reduction by learning an invariant mapping", "label": "Dimensionality reduction by learning an invariant mapping", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "DeepWalk: Online learning of social representations", "label": "DeepWalk: Online learning of social representations", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "LINE: Large-scale information network embedding", "label": "LINE: Large-scale information network embedding", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "GraRep: Learning graph representations with global structural information", "label": "GraRep: Learning graph representations with global structural information", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Ef\ufb01cient estimation of word representations in vector space", "label": "Ef\ufb01cient estimation of word representations in vector space", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Network motifs: simple building blocks of complex net-works", "label": "Network motifs: simple building blocks of complex net-works", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning spectral descriptors for deformable shape correspondence", "label": "Learning spectral descriptors for deformable shape correspondence", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Friendship and mobility: user movement in location-based social networks", "label": "Friendship and mobility: user movement in location-based social networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The emerging \ufb01eld of signal processing on graphs: Ex-tending high-dimensional data analysis to networks and other irregular domains", "label": "The emerging \ufb01eld of signal processing on graphs: Ex-tending high-dimensional data analysis to networks and other irregular domains", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep convolutional networks on graph-structured data", "label": "Deep convolutional networks on graph-structured data", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Convolutional neural networks on graphs with fast localized spectral \ufb01ltering", "label": "Convolutional neural networks on graphs with fast localized spectral \ufb01ltering", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Diffusion-convolutional neural networks", "label": "Diffusion-convolutional neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Geodesic convolutional neural networks on Riemannian manifolds", "label": "Geodesic convolutional neural networks on Riemannian manifolds", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A new model for learning in graph domains", "label": "A new model for learning in graph domains", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Gated graph sequence neural networks", "label": "Gated graph sequence neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning multiagent com-munication with backpropagation", "label": "Learning multiagent com-munication with backpropagation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "D", "label": "D", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Convolutional networks on graphs for learning molecular \ufb01ngerprints", "label": "Convolutional networks on graphs for learning molecular \ufb01ngerprints", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Geometric matrix com-pletion with recurrent multi-graph neural networks", "label": "Geometric matrix com-pletion with recurrent multi-graph neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Object detection with discriminatively trained part-based models", "label": "Object detection with discriminatively trained part-based models", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A wavelet tour of signal processing", "label": "A wavelet tour of signal processing", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Net2net: Accelerating learning via knowledge transfer", "label": "Net2net: Accelerating learning via knowledge transfer", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Topology and geometry of half-recti\ufb01ed network optimization", "label": "Topology and geometry of half-recti\ufb01ed network optimization", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Discrete laplace operators: no free lunch", "label": "Discrete laplace operators: no free lunch", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Computing discrete minimal surfaces and their conjugates", "label": "Computing discrete minimal surfaces and their conjugates", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The Laplacian on a Riemannian manifold: an introduc-tion to analysis on manifolds", "label": "The Laplacian on a Riemannian manifold: an introduc-tion to analysis on manifolds", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A tutorial on spectral clustering", "label": "A tutorial on spectral clustering", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multimodal manifold analysis by simultaneous diagonal-ization of Laplacians", "label": "Multimodal manifold analysis by simultaneous diagonal-ization of Laplacians", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning the 2-d topology of images", "label": "Learning the 2-d topology of images", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Semi-supervised classi\ufb01cation with graph convolutional networks", "label": "Semi-supervised classi\ufb01cation with graph convolutional networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The graph neural network model", "label": "The graph neural network model", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A compositional object-based approach to learning physical dynamics", "label": "A compositional object-based approach to learning physical dynamics", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Interaction networks for learning about objects", "label": "Interaction networks for learning about objects", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Selecting receptive \ufb01elds in deep networks", "label": "Selecting receptive \ufb01elds in deep networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "E", "label": "E", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Vertex-frequency analysis on graphs", "label": "Vertex-frequency analysis on graphs", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Diffusion wavelets", "label": "Diffusion wavelets", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Diffusion-driven multiscale analysis on manifolds and graphs: top-down and bottom-up constructions", "label": "Diffusion-driven multiscale analysis on manifolds and graphs: top-down and bottom-up constructions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multiscale wavelets on trees", "label": "Multiscale wavelets on trees", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Wavelets on graphs via deep learning", "label": "Wavelets on graphs via deep learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep Haar scattering networks", "label": "Deep Haar scattering networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation", "label": "SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learn-ing to generate chairs", "label": "Learn-ing to generate chairs", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Wavenet: A generative model for raw audio", "label": "Wavenet: A generative model for raw audio", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Collective classi\ufb01cation in network data", "label": "Collective classi\ufb01cation in network data", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning fast approximations of sparse coding", "label": "Learning fast approximations of sparse coding", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Exact matrix completion via convex opti-mization", "label": "Exact matrix completion via convex opti-mization", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Matrix factorization techniques for recommender systems", "label": "Matrix factorization techniques for recommender systems", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Recommender systems with social regularization", "label": "Recommender systems with social regularization", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Matrix completion on graphs", "label": "Matrix completion on graphs", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Collaborative \ufb01ltering with graph information: Consistency and scalable methods", "label": "Collaborative \ufb01ltering with graph information: Consistency and scalable methods", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A harmonic extension approach for collaborative ranking", "label": "A harmonic extension approach for collaborative ranking", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multi-view convolutional neural networks for 3D shape recognition", "label": "Multi-view convolutional neural networks for 3D shape recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Dense human body correspondences using convolutional networks", "label": "Dense human body correspondences using convolutional networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "3D shapenets: A deep representation for volumetric shapes", "label": "3D shapenets: A deep representation for volumetric shapes", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Volumetric and multi-view CNNs for object classi\ufb01cation on 3D data", "label": "Volumetric and multi-view CNNs for object classi\ufb01cation on 3D data", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Generalized multidimensional scaling: a framework for isometry-invariant partial surface matching", "label": "Generalized multidimensional scaling: a framework for isometry-invariant partial surface matching", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Scale-invariant heat kernel signa-tures for non-rigid shape recognition", "label": "Scale-invariant heat kernel signa-tures for non-rigid shape recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Blended intrinsic maps", "label": "Blended intrinsic maps", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "ShapeGoogle: Geometric words and expressions for invariant shape retrieval", "label": "ShapeGoogle: Geometric words and expressions for invariant shape retrieval", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Recent trends", "label": "Recent trends", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Unique signatures of his-tograms for local surface description", "label": "Unique signatures of his-tograms for local surface description", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The generation of a unique machine description for chemical structure", "label": "The generation of a unique machine description for chemical structure", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Extended-connectivity \ufb01ngerprints", "label": "Extended-connectivity \ufb01ngerprints", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The dynamic functional connectome: State-of-the-art and perspectives", "label": "The dynamic functional connectome: State-of-the-art and perspectives", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Distance metric learning using graph convolutional net-works: Application to functional brain networks", "label": "Distance metric learning using graph convolutional net-works: Application to functional brain networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": ": Imagenet: A large-scale hierarchical image database", "label": ": Imagenet: A large-scale hierarchical image database", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep contextualized word representations", "label": "Deep contextualized word representations", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Bert: Pre-training of deep bidirectional transformers for language understanding", "label": "Bert: Pre-training of deep bidirectional transformers for language understanding", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Squeeze-and-excitation networks", "label": "Squeeze-and-excitation networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Regularized evolution for image classi\ufb01er architecture search", "label": "Regularized evolution for image classi\ufb01er architecture search", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Algorithm 799: revolve: an implementation of check-pointing for the reverse or adjoint mode of computational differentiation", "label": "Algorithm 799: revolve: an implementation of check-pointing for the reverse or adjoint mode of computational differentiation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Mxnet: A \ufb02exible and ef\ufb01cient machine learning library for heterogeneous distributed systems", "label": "Mxnet: A \ufb02exible and ef\ufb01cient machine learning library for heterogeneous distributed systems", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Megdet: A large mini-batch object detector", "label": "Megdet: A large mini-batch object detector", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Cnn features off-the-shelf: An astounding baseline for recognition", "label": "Cnn features off-the-shelf: An astounding baseline for recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Improved regularization of convolutional neural networks with cutout", "label": "Improved regularization of convolutional neural networks with cutout", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Exploring the limits of weakly supervised pretraining", "label": "Exploring the limits of weakly supervised pretraining", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Object-part attention model for \ufb01ne-grained image classi\ufb01cation", "label": "Object-part attention model for \ufb01ne-grained image classi\ufb01cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Large scale \ufb01ne-grained categorization and domain-speci\ufb01c transfer learning", "label": "Large scale \ufb01ne-grained categorization and domain-speci\ufb01c transfer learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep layer aggregation", "label": "Deep layer aggregation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fixup initialization: Residual learning without normalization", "label": "Fixup initialization: Residual learning without normalization", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Device placement opti-mization with reinforcement learning", "label": "Device placement opti-mization with reinforcement learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Pipedream: Fast and ef\ufb01cient pipeline parallel dnn training", "label": "Pipedream: Fast and ef\ufb01cient pipeline parallel dnn training", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Naik, and R", "label": "Naik, and R", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Wei, and M", "label": "Wei, and M", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Metzen, and F", "label": "Metzen, and F", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Zhao, and K", "label": "Zhao, and K", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Yang, and E", "label": "Yang, and E", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Jia, and K", "label": "Jia, and K", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Ren, and J", "label": "Ren, and J", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Li, and S", "label": "Li, and S", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Andreetto, and H", "label": "Andreetto, and H", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Chen, W", "label": "Chen, W", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Shen, and G", "label": "Shen, and G", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "van der Maaten, and K", "label": "van der Maaten, and K", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Dally, and K", "label": "Dally, and K", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Adam, and D", "label": "Adam, and D", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Poczos, and E", "label": "Poczos, and E", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Doll\u00b4ar, and C", "label": "Doll\u00b4ar, and C", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Huang, and K", "label": "Huang, and K", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fernando, and K", "label": "Fernando, and K", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Simonyan, and Y", "label": "Simonyan, and Y", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Zheng, and J", "label": "Zheng, and J", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Le, and J", "label": "Le, and J", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Huang, and Q", "label": "Huang, and Q", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Bernstein, et al", "label": "Bernstein, et al", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Radford, and O", "label": "Radford, and O", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Vanhoucke, and A", "label": "Vanhoucke, and A", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Sze, and H", "label": "Sze, and H", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Lin, and J", "label": "Lin, and J", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "\u00a8O", "label": "\u00a8O", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Shlens, and Q", "label": "Shlens, and Q", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": ": A 3d facial expression database for facial behavior research", "label": ": A 3d facial expression database for facial behavior research", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning visual similarity for product design with convolutional neural networks", "label": "Learning visual similarity for product design with convolutional neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Out-of-sample ex-tensions for lle", "label": "Out-of-sample ex-tensions for lle", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Signature veri\ufb01cation using a \u201csiamese\u201d time delay neural network", "label": "Signature veri\ufb01cation using a \u201csiamese\u201d time delay neural network", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning a similarity metric discriminatively", "label": "Learning a similarity metric discriminatively", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Extreme multi class classi\ufb01cation", "label": "Extreme multi class classi\ufb01cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multidimensional scaling", "label": "Multidimensional scaling", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "https://sites", "label": "https://sites", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Zero-shot learning through cross-modal transfer", "label": "Zero-shot learning through cross-modal transfer", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "In Pose-sensitive embedding by nonlinear nca regression", "label": "In Pose-sensitive embedding by nonlinear nca regression", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Support vector machine learning for interdependent and structured output spaces", "label": "Support vector machine learning for interdependent and structured output spaces", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Accelerating t-sne using tree-based algo-rithms", "label": "Accelerating t-sne using tree-based algo-rithms", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The caltech-ucsd birds-200-2011 dataset", "label": "The caltech-ucsd birds-200-2011 dataset", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Wsabi: Scaling up to large vocabulary image annotation", "label": "Wsabi: Scaling up to large vocabulary image annotation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "http:// www", "label": "http:// www", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Clustering by passing messages between data points", "label": "Clustering by passing messages between data points", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Devise: A deep visual-semantic embedding model", "label": "Devise: A deep visual-semantic embedding model", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Neighbourhood component analysis", "label": "Neighbourhood component analysis", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Dimensionality reduc-tion by learning an invariant mapping", "label": "Dimensionality reduc-tion by learning an invariant mapping", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Caffe: Convolu-tional architecture for fast feature embedding", "label": "Caffe: Convolu-tional architecture for fast feature embedding", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Cutting-plane training of structural svms", "label": "Cutting-plane training of structural svms", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Principal component analysis", "label": "Principal component analysis", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "3d object repre-ICCV 3dRR-13", "label": "3d object repre-ICCV 3dRR-13", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Attribute-based classi\ufb01cation for zero-shot visual object categoriza-tion", "label": "Attribute-based classi\ufb01cation for zero-shot visual object categoriza-tion", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Joint embeddings of shapes and images via cnn image pu-ri\ufb01cation", "label": "Joint embeddings of shapes and images via cnn image pu-ri\ufb01cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Introduction to Information Retrieval", "label": "Introduction to Information Retrieval", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Metric learning for large scale image classi\ufb01cation: Generalizaing to new classes at near-zero cost", "label": "Metric learning for large scale image classi\ufb01cation: Generalizaing to new classes at near-zero cost", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Zero-shot learning with semantic output codes", "label": "Zero-shot learning with semantic output codes", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fastxml: A fast", "label": "Fastxml: A fast", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fine-grained visual cat-egorization via multi-stage metric learning", "label": "Fine-grained visual cat-egorization via multi-stage metric learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Evaluating knowl-edge transfer and zero-shot learn-ing in a large-scale setting", "label": "Evaluating knowl-edge transfer and zero-shot learn-ing in a large-scale setting", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": ": Visualizing data using t-sne", "label": ": Visualizing data using t-sne", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "David W", "label": "David W", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Support vector networks", "label": "Support vector networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Local learn-ing to improve bag of visual words model for facial expression recognition", "label": "Local learn-ing to improve bag of visual words model for facial expression recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Constructing hierarchical image-tags bimodal representations for word tags alternative choice", "label": "Constructing hierarchical image-tags bimodal representations for word tags alternative choice", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Gift: A real-time and scalable 3d shape search engine", "label": "Gift: A real-time and scalable 3d shape search engine", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Gift: Towards scalable 3d shape retrieval", "label": "Gift: Towards scalable 3d shape retrieval", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Ensemble diffusion for retrieval", "label": "Ensemble diffusion for retrieval", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep correlated metric learning for sketch-based 3d shape retrieval", "label": "Deep correlated metric learning for sketch-based 3d shape retrieval", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Ranking on cross-domain man-In Cyberworlds ifold for sketch-based 3d model retrieval", "label": "Ranking on cross-domain man-In Cyberworlds ifold for sketch-based 3d model retrieval", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep aggregation of local 3d geometric features for 3d model retrieval", "label": "Deep aggregation of local 3d geometric features for 3d model retrieval", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep learning advances in computer vision with 3d data: A survey", "label": "Deep learning advances in computer vision with 3d data: A survey", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Pairwise de-composition of image sequences for active multi-view recog-nition", "label": "Pairwise de-composition of image sequences for active multi-view recog-nition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Escape from cells: Deep kd-networks for the recognition of 3d point cloud models", "label": "Escape from cells: Deep kd-networks for the recognition of 3d point cloud models", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Shrec\u201913 track: Large scale sketch-based 3d shape retrieval", "label": "Shrec\u201913 track: Large scale sketch-based 3d shape retrieval", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fpnn: Field probing neural networks for 3d data", "label": "Fpnn: Field probing neural networks for 3d data", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep rel-ative distance learning: Tell the difference between similar vehicles", "label": "Deep rel-ative distance learning: Tell the difference between similar vehicles", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Voxnet: A 3d convolutional In IROS", "label": "Voxnet: A 3d convolutional In IROS", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Sparse 3d convolutional neural networks for large-scale shape retrieval", "label": "Sparse 3d convolutional neural networks for large-scale shape retrieval", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Volumetric and multi-view cnns for object classi-\ufb01cation on 3d data", "label": "Volumetric and multi-view cnns for object classi-\ufb01cation on 3d data", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "F", "label": "F", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Orientation-In BMVC", "label": "Orientation-In BMVC", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deeppano: Deep IEEE panoramic representation for 3-d shape recognition", "label": "Deeppano: Deep IEEE panoramic representation for 3-d shape recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Very deep con-large-scale image recognition", "label": "Very deep con-large-scale image recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A survey of content based 3d shape retrieval methods", "label": "A survey of content based 3d shape retrieval methods", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Sketch-based 3d shape retrieval using convolutional neural networks", "label": "Sketch-based 3d shape retrieval using convolutional neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Normface: L 2 hypersphere embedding for face veri\ufb01cation", "label": "Normface: L 2 hypersphere embedding for face veri\ufb01cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A discriminative fea-ture learning approach for deep face recognition", "label": "A discriminative fea-ture learning approach for deep face recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning barycentric rep-resentations of 3d shapes for sketch-based 3d shape retrieval", "label": "Learning barycentric rep-resentations of 3d shapes for sketch-based 3d shape retrieval", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deepshape: Deep-learned shape descriptor for 3d shape retrieval", "label": "Deepshape: Deep-learned shape descriptor for 3d shape retrieval", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning cross-domain neural networks for sketch-based 3d shape retrieval", "label": "Learning cross-domain neural networks for sketch-based 3d shape retrieval", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Theano: new features and speed improvements", "label": "Theano: new features and speed improvements", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Hashing with binary autoencoders", "label": "Hashing with binary autoencoders", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Bayesian face In Proc", "label": "Bayesian face In Proc", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep hashing for compact binary codes learning", "label": "Deep hashing for compact binary codes learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Itera-tive quantization: A procrustean approach to learning binary IEEE Trans", "label": "Itera-tive quantization: A procrustean approach to learning binary IEEE Trans", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Revisiting kernelized locality-sensitive hashing for improved large-scale image re-trieval", "label": "Revisiting kernelized locality-sensitive hashing for improved large-scale image re-trieval", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Pushing the frontiers of unconstrained face detection and recognition: Iarpa janus benchmark a", "label": "Pushing the frontiers of unconstrained face detection and recognition: Iarpa janus benchmark a", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning to hash with binary re-constructive embeddings", "label": "Learning to hash with binary re-constructive embeddings", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Kernelized locality-sensitive In Proc", "label": "Kernelized locality-sensitive In Proc", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Simultaneous feature learning and hash coding with deep neural networks", "label": "Simultaneous feature learning and hash coding with deep neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning hash functions using column generation", "label": "Learning hash functions using column generation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fast supervised hashing with decision trees for high-In Proc", "label": "Fast supervised hashing with decision trees for high-In Proc", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Bit-scalable deep hashing with regularized similarity learning for image retrieval", "label": "Bit-scalable deep hashing with regularized similarity learning for image retrieval", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep semantic ranking based hashing for multi-label image retrieval", "label": "Deep semantic ranking based hashing for multi-label image retrieval", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A general two-step approach to learning-based hashing", "label": "A general two-step approach to learning-based hashing", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Super-vised hashing with kernels", "label": "Super-vised hashing with kernels", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Hashing with graphs", "label": "Hashing with graphs", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Hamming distance metric learning", "label": "Hamming distance metric learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Recognizing indoor scenes", "label": "Recognizing indoor scenes", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Imagenet large scale visual recog-nition challenge", "label": "Imagenet large scale visual recog-nition challenge", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "FaceNet: A uni\ufb01ed embedding for face recognition and clustering", "label": "FaceNet: A uni\ufb01ed embedding for face recognition and clustering", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Supervised dis-crete hashing", "label": "Supervised dis-crete hashing", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Inductive hashing on manifolds", "label": "Inductive hashing on manifolds", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning \ufb01ne-grained image similarity with deep ranking", "label": "Learning \ufb01ne-grained image similarity with deep ranking", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multidimensional spectral hashing", "label": "Multidimensional spectral hashing", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Spectral hashing", "label": "Spectral hashing", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Static fa-cial expression analysis in tough conditions: Data", "label": "Static fa-cial expression analysis in tough conditions: Data", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Why is this canadian hacker better http: than facebook at detecting gun photos? //www", "label": "Why is this canadian hacker better http: than facebook at detecting gun photos? //www", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Why is facial expression anal-In Proceedings of the 2013 ysis in the wild challenging? on Emotion recognition in the wild challenge and workshop", "label": "Why is facial expression anal-In Proceedings of the 2013 ysis in the wild challenging? on Emotion recognition in the wild challenge and workshop", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Automatically recognizing facial expression: Predicting engagement and frustration", "label": "Automatically recognizing facial expression: Predicting engagement and frustration", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Local features based facial expression recognition with face reg-istration errors", "label": "Local features based facial expression recognition with face reg-istration errors", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Facial interaction between ani-In Systems", "label": "Facial interaction between ani-In Systems", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Gabor feature based classi\ufb01ca-tion using the enhanced \ufb01sher linear discriminant model for face recognition", "label": "Gabor feature based classi\ufb01ca-tion using the enhanced \ufb01sher linear discriminant model for face recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Au-aware deep In Automatic networks for facial expression recognition", "label": "Au-aware deep In Automatic networks for facial expression recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Coding facial expressions with gabor wavelets", "label": "Coding facial expressions with gabor wavelets", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Disfa: A spontaneous facial action intensity database", "label": "Disfa: A spontaneous facial action intensity database", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Affectiva-mit facial expression dataset (am-fed): Naturalistic and spontaneous facial expressions collected", "label": "Affectiva-mit facial expression dataset (am-fed): Naturalistic and spontaneous facial expressions collected", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Pca-based dictionary building for accurate facial expression Journal of Visual recognition via sparse representation", "label": "Pca-based dictionary building for accurate facial expression Journal of Visual recognition via sparse representation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "In-tensity estimation of spontaneous facial action units based on their sparsity properties", "label": "In-tensity estimation of spontaneous facial action units based on their sparsity properties", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Going deeper in facial expression recognition using deep neural networks", "label": "Going deeper in facial expression recognition using deep neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Expressionbot: An emo-tive lifelike robotic face for face-to-face communication", "label": "Expressionbot: An emo-tive lifelike robotic face for face-to-face communication", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Bidirectional warping of active appearance model", "label": "Bidirectional warping of active appearance model", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning and transferring mid-level image representations using convolu-In Proceedings of the IEEE Con-tional neural networks", "label": "Learning and transferring mid-level image representations using convolu-In Proceedings of the IEEE Con-tional neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Web-based database for facial expression analysis", "label": "Web-based database for facial expression analysis", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Face alignment at 3000 fps via regressing local binary features", "label": "Face alignment at 3000 fps via regressing local binary features", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Impact of face registration errors on recognition", "label": "Impact of face registration errors on recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "300 faces in-the-wild challenge: Database and results", "label": "300 faces in-the-wild challenge: Database and results", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Emotion recognition in the wild via sparse transductive transfer linear discriminant analysis", "label": "Emotion recognition in the wild via sparse transductive transfer linear discriminant analysis", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "300 faces in-the-wild challenge: The \ufb01rst facial landmark In Proceedings of the IEEE Inter-localization challenge", "label": "300 faces in-the-wild challenge: The \ufb01rst facial landmark In Proceedings of the IEEE Inter-localization challenge", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A semi-automatic methodology for facial landmark annota-tion", "label": "A semi-automatic methodology for facial landmark annota-tion", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning from noisy labels with deep neural networks", "label": "Learning from noisy labels with deep neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep learning using linear support vector machines", "label": "Deep learning using linear support vector machines", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deeppose: Human pose estima-tion via deep neural networks", "label": "Deeppose: Human pose estima-tion via deep neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep learn-In Neural Networks: ing via semi-supervised embedding", "label": "Deep learn-In Neural Networks: ing via semi-supervised embedding", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learn-ing from massive noisy labeled data for image classi\ufb01cation", "label": "Learn-ing from massive noisy labeled data for image classi\ufb01cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "face-alignment-in-3000fps", "label": "face-alignment-in-3000fps", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Image based static facial expression In Pro-recognition with multiple deep network learning", "label": "Image based static facial expression In Pro-recognition with multiple deep network learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "ebear: An expres-sive bear-like robot", "label": "ebear: An expres-sive bear-like robot", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Facial expression recognition based on local phase quantization and sparse representation", "label": "Facial expression recognition based on local phase quantization and sparse representation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Expertise identi\ufb01cation and visualization from CVS", "label": "Expertise identi\ufb01cation and visualization from CVS", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Scalable collaborative \ufb01ltering with jointly derived neighborhood interpolation weights", "label": "Scalable collaborative \ufb01ltering with jointly derived neighborhood interpolation weights", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The Net\ufb02ix prize", "label": "The Net\ufb02ix prize", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A survey of longest common subsequence algorithms", "label": "A survey of longest common subsequence algorithms", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The Development of Expertise in Pedagogy", "label": "The Development of Expertise in Pedagogy", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning to recognize reliable users and content in social media with coupled mutual reinforcement", "label": "Learning to recognize reliable users and content in social media with coupled mutual reinforcement", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "P@noptic expert: Searching for experts not just for documents", "label": "P@noptic expert: Searching for experts not just for documents", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Writing expertise and second-language pro\ufb01ciency", "label": "Writing expertise and second-language pro\ufb01ciency", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "No country for old members: User lifecycle and linguistic change in online communities", "label": "No country for old members: User lifecycle and linguistic change in online communities", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Churn prediction in new users of Yahoo! Answers", "label": "Churn prediction in new users of Yahoo! Answers", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Expert judgment: Some necessary conditions and an example", "label": "Expert judgment: Some necessary conditions and an example", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Sequential and temporal dynamics of online opinion", "label": "Sequential and temporal dynamics of online opinion", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Effects of search experience and subject knowledge on the search tactics of novice and experienced searchers", "label": "Effects of search experience and subject knowledge on the search tactics of novice and experienced searchers", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Opinion spam and analysis", "label": "Opinion spam and analysis", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Discovering authorities in question answer communities by using link analysis", "label": "Discovering authorities in question answer communities by using link analysis", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Enhancing expert \ufb01nding using organizational hierarchies", "label": "Enhancing expert \ufb01nding using organizational hierarchies", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Amazon", "label": "Amazon", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Information Theory", "label": "Information Theory", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning attitudes and attributes from multi-aspect reviews", "label": "Learning attitudes and attributes from multi-aspect reviews", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Online product opinions: Incidence", "label": "Online product opinions: Incidence", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Language use as a re\ufb02ection of socialization in online communities", "label": "Language use as a re\ufb02ection of socialization in online communities", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Early detection of potential experts in question answering communities", "label": "Early detection of potential experts in question answering communities", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "editors", "label": "editors", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The language of children and adolescents: The acquisition of communicative competence", "label": "The language of children and adolescents: The acquisition of communicative competence", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Adaptive web search based on user pro\ufb01le constructed without any effort from users", "label": "Adaptive web search based on user pro\ufb01le constructed without any effort from users", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Second language use", "label": "Second language use", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The problem of concept drift: De\ufb01nitions and related work", "label": "The problem of concept drift: De\ufb01nitions and related work", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Characterizing the in\ufb02uence of domain expertise on web search behavior", "label": "Characterizing the in\ufb02uence of domain expertise on web search behavior", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning in the presence of concept drift and hidden contexts", "label": "Learning in the presence of concept drift and hidden contexts", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Temporal recommendation on graphs via long-and short-term preference fusion", "label": "Temporal recommendation on graphs via long-and short-term preference fusion", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Temporal collaborative \ufb01ltering with bayesian probabilistic tensor factorization", "label": "Temporal collaborative \ufb01ltering with bayesian probabilistic tensor factorization", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Churn in social networks", "label": "Churn in social networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Dynamic weighted majority: An ensemble method for drifting concepts", "label": "Dynamic weighted majority: An ensemble method for drifting concepts", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Classi\ufb01er ensembles for changing environments", "label": "Classi\ufb01er ensembles for changing environments", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Temporal collaborative \ufb01ltering with adaptive neighbourhoods", "label": "Temporal collaborative \ufb01ltering with adaptive neighbourhoods", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multidimensional binary search trees used for associative searching", "label": "Multidimensional binary search trees used for associative searching", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning class-speci\ufb01c descrip-tors for deformable shapes using localized spectral convolu-tional networks", "label": "Learning class-speci\ufb01c descrip-tors for deformable shapes using localized spectral convolu-tional networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Signature veri\ufb01ca-Interna-tion using a siamese time delay neural network", "label": "Signature veri\ufb01ca-Interna-tion using a siamese time delay neural network", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "volume 55", "label": "volume 55", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "R-trees: A Dynamic Index Structure for Spatial Searching", "label": "R-trees: A Dynamic Index Structure for Spatial Searching", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fusionnet: 3d object classi\ufb01-cation using multiple data representations", "label": "Fusionnet: 3d object classi\ufb01-cation using multiple data representations", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "K", "label": "K", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "TI-POOLING: transformation-invariant pooling for feature learning in convolutional neural networks", "label": "TI-POOLING: transformation-invariant pooling for feature learning in convolutional neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Octree encoding: A new technique for the representation", "label": "Octree encoding: A new technique for the representation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Volumetric and multi-view cnns for object classi\ufb01-cation on 3d data", "label": "Volumetric and multi-view cnns for object classi\ufb01-cation on 3d data", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "H", "label": "H", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Octnet: Learn-ing deep 3d representations at high resolutions", "label": "Octnet: Learn-ing deep 3d representations at high resolutions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "U-net: Convolu-tional networks for biomedical image segmentation", "label": "U-net: Convolu-tional networks for biomedical image segmentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The design and analysis of spatial data structures", "label": "The design and analysis of spatial data structures", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning a distance metric from relative comparisons", "label": "Learning a distance metric from relative comparisons", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Study for applying computer-generated images to vi-sual simulation", "label": "Study for applying computer-generated images to vi-sual simulation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Dynamic edge-conditioned \ufb01lters in convolutional neural networks on graphs", "label": "Dynamic edge-conditioned \ufb01lters in convolutional neural networks on graphs", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Parsing nat-ural scenes and natural language with recursive neural net-works", "label": "Parsing nat-ural scenes and natural language with recursive neural net-works", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning deep embeddings with histogram loss", "label": "Learning deep embeddings with histogram loss", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Voting for voting in online point cloud object detection", "label": "Voting for voting in online point cloud object detection", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning a probabilistic latent space of object shapes via 3d generative-adversarial modeling", "label": "Learning a probabilistic latent space of object shapes via 3d generative-adversarial modeling", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Anisotropic diffusion descriptors", "label": "Anisotropic diffusion descriptors", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Shape google: Geometric words and expressions for invariant shape retrieval", "label": "Shape google: Geometric words and expressions for invariant shape retrieval", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "On visual similarity based 3d model retrieval", "label": "On visual similarity based 3d model retrieval", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Understanding the dif\ufb01culty of training deep feedforward neural networks", "label": "Understanding the dif\ufb01culty of training deep feedforward neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Using spin images for ef\ufb01cient object recognition in cluttered 3d scenes", "label": "Using spin images for ef\ufb01cient object recognition in cluttered 3d scenes", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Voxnet: A 3d convolutional neural network for real-In IEEE/RSJ International Conference on Intelligent Robots and time object recognition", "label": "Voxnet: A 3d convolutional neural network for real-In IEEE/RSJ International Conference on Intelligent Robots and time object recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Recti\ufb01ed linear units improve restricted boltzmann machines", "label": "Recti\ufb01ed linear units improve restricted boltzmann machines", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Real-time 3d reconstruction at scale using voxel hashing", "label": "Real-time 3d reconstruction at scale using voxel hashing", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Shape distributions", "label": "Shape distributions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deeppano: Deep panoramic repre-sentation for 3-d shape recognition", "label": "Deeppano: Deep panoramic repre-sentation for 3-d shape recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Convolutional-recursive deep learning for 3d object classi\ufb01cation", "label": "Convolutional-recursive deep learning for 3d object classi\ufb01cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning representations by back-propagating errors", "label": "Learning representations by back-propagating errors", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "CNN features off-the-shelf: an astounding baseline In Computer Vision and Pattern Recognifor recognition", "label": "CNN features off-the-shelf: an astounding baseline In Computer Vision and Pattern Recognifor recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "AffectNet: A database for facial expression", "label": "AffectNet: A database for facial expression", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Gift: A realtime and scalable 3d shape search engine", "label": "Gift: A realtime and scalable 3d shape search engine", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "label": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Menpo: A comprehensive platform for para-metric image alignment and visual deformable models", "label": "Menpo: A comprehensive platform for para-metric image alignment and visual deformable models", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A uni\ufb01ed frame-work for compositional \ufb01tting of active appearance mod-els", "label": "A uni\ufb01ed frame-work for compositional \ufb01tting of active appearance mod-els", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A 3D Dynamic Database for Unconstrained Face Recognition", "label": "A 3D Dynamic Database for Unconstrained Face Recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A Grassmannian Framework for Face Recognition of 3D Dy-namic Sequences with Challenging Conditions", "label": "A Grassmannian Framework for Face Recognition of 3D Dy-namic Sequences with Challenging Conditions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A grassmann framework for 4d facial shape analysis", "label": "A grassmann framework for 4d facial shape analysis", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Vt-kfer: A kinect-based rgbd+time dataset for spontaneous and non-spontaneous facial expression recognition", "label": "Vt-kfer: A kinect-based rgbd+time dataset for spontaneous and non-spontaneous facial expression recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Optimal step non-rigid icp algorithms for surface registration", "label": "Optimal step non-rigid icp algorithms for surface registration", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "From pixels to response maps: Discrimina-tive image \ufb01ltering for face alignment in the wild", "label": "From pixels to response maps: Discrimina-tive image \ufb01ltering for face alignment in the wild", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A New Approach to Linear Filtering and Prediction Problems", "label": "A New Approach to Linear Filtering and Prediction Problems", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Assess-ing the uniqueness and permanence of facial actions for use in biometric applications", "label": "Assess-ing the uniqueness and permanence of facial actions for use in biometric applications", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Face veri\ufb01cation from 3d and grey level clues", "label": "Face veri\ufb01cation from 3d and grey level clues", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A morphable model for the synthesis of 3d faces", "label": "A morphable model for the synthesis of 3d faces", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "3d face morphable models \"in-the-wild\"", "label": "3d face morphable models \"in-the-wild\"", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Large scale 3d morphable models", "label": "Large scale 3d morphable models", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Optimal uv spaces for facial mor-phable model construction", "label": "Optimal uv spaces for facial mor-phable model construction", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "High res-olution passive facial performance capture", "label": "High res-olution passive facial performance capture", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "3d face sketch modeling and assessment for component based face recognition", "label": "3d face sketch modeling and assessment for component based face recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Faceware-house: A 3d facial expression database for visual comput-ing", "label": "Faceware-house: A 3d facial expression database for visual comput-ing", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Automatic 3d facial expression analysis in videos", "label": "Automatic 3d facial expression analysis in videos", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Statistical non-rigid icp algorithm and its application to 3d face align-ment", "label": "Statistical non-rigid icp algorithm and its application to 3d face align-ment", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "In the pursuit of effective af-fective computing: The relationship between features and registration", "label": "In the pursuit of effective af-fective computing: The relationship between features and registration", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A facs valid 3d dynamic action unit database with applications to 3d dy-namic morphable facial modeling", "label": "A facs valid 3d dynamic action unit database with applications to 3d dy-namic morphable facial modeling", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Facial Action Coding System", "label": "Facial Action Coding System", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A 3-d audio-visual corpus of affective communication", "label": "A 3-d audio-visual corpus of affective communication", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Anthropometric 3d face recognition", "label": "Anthropometric 3d face recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fully au-In ICPR", "label": "Fully au-In ICPR", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Three-dimensional face recognition using combinations of surface feature map subspace components", "label": "Three-dimensional face recognition using combinations of surface feature map subspace components", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Long short-term mem-ory", "label": "Long short-term mem-ory", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Adam: A method for stochastic op-timization", "label": "Adam: A method for stochastic op-timization", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "3d In ACII", "label": "3d In ACII", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Facial behaviometrics: The case In of facial deformation in spontaneous smile/laughter", "label": "Facial behaviometrics: The case In of facial deformation in spontaneous smile/laughter", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The discriminant elastic graph matching algorithm applied to frontal face veri\ufb01ca-tion", "label": "The discriminant elastic graph matching algorithm applied to frontal face veri\ufb01ca-tion", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Bp4d-spontaneous: a high-resolution spontaneous 3d dynamic facial expression database", "label": "Bp4d-spontaneous: a high-resolution spontaneous 3d dynamic facial expression database", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multimodal spontaneous emotion corpus for human behavior analysis", "label": "Multimodal spontaneous emotion corpus for human behavior analysis", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Robust 3d face recognition using learned visual codebook", "label": "Robust 3d face recognition using learned visual codebook", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Hi4d-adsip 3-d dynamic facial articulation database", "label": "Hi4d-adsip 3-d dynamic facial articulation database", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "GavabDB: a 3D Face Database", "label": "GavabDB: a 3D Face Database", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Sparse localized deformation com-ponents", "label": "Sparse localized deformation com-ponents", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "3d morphable face models re-visited", "label": "3d morphable face models re-visited", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A 3d face model for pose and illumination invariant face recognition", "label": "A 3d face model for pose and illumination invariant face recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multimodal biometric database dmcsv1 of 3d face and hand scans", "label": "Multimodal biometric database dmcsv1 of 3d face and hand scans", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Ef-fect of illumination on automatic expression recognition: A novel 3d relightable facial database", "label": "Ef-fect of illumination on automatic expression recognition: A novel 3d relightable facial database", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Tracking vertex \ufb02ow and model adaptation for three-dimensional spatiotempo-ral face analysis", "label": "Tracking vertex \ufb02ow and model adaptation for three-dimensional spatiotempo-ral face analysis", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Synthesizing obama: Learning lip sync from audio", "label": "Synthesizing obama: Learning lip sync from audio", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Demo of face2face: Real-time face capture and reenactment of rgb videos", "label": "Demo of face2face: Real-time face capture and reenactment of rgb videos", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A high-resolution 3d dynamic facial expression database", "label": "A high-resolution 3d dynamic facial expression database", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A 3d fa-cial expression database for facial behavior research", "label": "A 3d fa-cial expression database for facial behavior research", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The photoface database", "label": "The photoface database", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "label": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fast high-dimensional \ufb01ltering using the permutohedral lattice", "label": "Fast high-dimensional \ufb01ltering using the permutohedral lattice", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Non-linear Gaussian \ufb01lters perform-In DAGM", "label": "Non-linear Gaussian \ufb01lters perform-In DAGM", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "GIFT: In Proc", "label": "GIFT: In Proc", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Geometric deep learning: Going beyond eu-clidean data", "label": "Geometric deep learning: Going beyond eu-clidean data", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "3D object classi\ufb01cation via spherical projections", "label": "3D object classi\ufb01cation via spherical projections", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Convolu-tional neural networks on graphs with fast localized spectral \ufb01ltering", "label": "Convolu-tional neural networks on graphs with fast localized spectral \ufb01ltering", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The Pascal Visual Ob-ject Classes Challenge: A retrospective", "label": "The Pascal Visual Ob-ject Classes Challenge: A retrospective", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "GWCNN: A metric alignment layer for deep shape analysis", "label": "GWCNN: A metric alignment layer for deep shape analysis", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Ef\ufb01cient 2D and 3D facade segmentation using auto-context", "label": "Ef\ufb01cient 2D and 3D facade segmentation using auto-context", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "PointNet: A 3D convo-lutional neural network for real-time object class recognition", "label": "PointNet: A 3D convo-lutional neural network for real-time object class recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Submanifold sparse con-volutional networks", "label": "Submanifold sparse con-volutional networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "FusionNet: 3D object classi\ufb01ca-tion using multiple data representations", "label": "FusionNet: 3D object classi\ufb01ca-tion using multiple data representations", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep convolutional net-works on graph-structured data", "label": "Deep convolutional net-works on graph-structured data", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning local shape descriptors with view-based convolutional neural networks", "label": "Learning local shape descriptors with view-based convolutional neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Permutohedral lat-tice CNNs", "label": "Permutohedral lat-tice CNNs", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Adam: A method for stochastic opti-mization", "label": "Adam: A method for stochastic opti-mization", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Escape from cells: Deep Kd-Networks for the recognition of 3D point cloud models", "label": "Escape from cells: Deep Kd-Networks for the recognition of 3D point cloud models", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Convolutional neural networks on surfaces via seamless toric covers", "label": "Convolutional neural networks on surfaces via seamless toric covers", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "3D convolutional neural net-In Proc", "label": "3D convolutional neural net-In Proc", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Geometric deep learning on graphs and manifolds using mixture model CNNs", "label": "Geometric deep learning on graphs and manifolds using mixture model CNNs", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Oct-NetFusion: Learning depth fusion from data", "label": "Oct-NetFusion: Learning depth fusion from data", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Octnet: Learning deep 3D representations at high resolutions", "label": "Octnet: Learning deep 3D representations at high resolutions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Orientation-boosted voxel nets for 3D object recognition", "label": "Orientation-boosted voxel nets for 3D object recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep learning 3D shape surfaces using geometry images", "label": "Deep learning 3D shape surfaces using geometry images", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Octree gen-erating networks: Ef\ufb01cient convolutional architectures for high-resolution 3D outputs", "label": "Octree gen-erating networks: Ef\ufb01cient convolutional architectures for high-resolution 3D outputs", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Bilateral \ufb01ltering for gray and color images", "label": "Bilateral \ufb01ltering for gray and color images", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep sets", "label": "Deep sets", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "10(4):740\u2013756", "label": "10(4):740\u2013756", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Aligning Books and Movies: Towards Story-like Visual Explanations by Watching Movies and Reading Books", "label": "Aligning Books and Movies: Towards Story-like Visual Explanations by Watching Movies and Reading Books", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Domain adaptive transfer learning with specialist models", "label": "Domain adaptive transfer learning with specialist models", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Analyzing the per-formance of multilayer neural networks for object recogni-tion", "label": "Analyzing the per-formance of multilayer neural networks for object recogni-tion", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "How HBOs Silicon Valley built Not Hotdog with mobile TensorFlow", "label": "How HBOs Silicon Valley built Not Hotdog with mobile TensorFlow", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Factors of transferability for a generic con-vnet representation", "label": "Factors of transferability for a generic con-vnet representation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Food-101 -mining discriminative components with random forests", "label": "Food-101 -mining discriminative components with random forests", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deeplab: Semantic image segmentation with deep convolutional nets", "label": "Deeplab: Semantic image segmentation with deep convolutional nets", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Large scale \ufb01ne-grained categorization and domain-speci\ufb01c trans-fer learning", "label": "Large scale \ufb01ne-grained categorization and domain-speci\ufb01c trans-fer learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Decaf: A deep convolutional acti-vation feature for generic visual recognition", "label": "Decaf: A deep convolutional acti-vation feature for generic visual recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Borrowing treasures from the wealthy: Deep transfer learning through selective joint \ufb01ne-tuning", "label": "Borrowing treasures from the wealthy: Deep transfer learning through selective joint \ufb01ne-tuning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fast r-cnn", "label": "Fast r-cnn", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Speed/accuracy trade-offs for modern convolutional ob-ject detectors", "label": "Speed/accuracy trade-offs for modern convolutional ob-ject detectors", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Gpipe: Ef\ufb01cient training of giant neural net-works using pipeline parallelism", "label": "Gpipe: Ef\ufb01cient training of giant neural net-works using pipeline parallelism", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Do better imagenet models transfer better? CoRR", "label": "Do better imagenet models transfer better? CoRR", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The unreasonable effec-tiveness of noisy data for \ufb01ne-grained recognition", "label": "The unreasonable effec-tiveness of noisy data for \ufb01ne-grained recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Ex-ploring the limits of weakly supervised pretraining", "label": "Ex-ploring the limits of weakly supervised pretraining", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Cnn features off-the-shelf: An astounding baseline for recog-nition", "label": "Cnn features off-the-shelf: An astounding baseline for recog-nition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Regular-ized evolution for image classi\ufb01er architecture search", "label": "Regular-ized evolution for image classi\ufb01er architecture search", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Faster r-cnn: Towards real-time object detection with region proposal net-works", "label": "Faster r-cnn: Towards real-time object detection with region proposal net-works", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Imagenet large scale visual recog-Int", "label": "Imagenet large scale visual recog-Int", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Adjusting the outputs of a classi\ufb01er to new a priori probabilities: A simple procedure", "label": "Adjusting the outputs of a classi\ufb01er to new a priori probabilities: A simple procedure", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fully convolutional IEEE Trans", "label": "Fully convolutional IEEE Trans", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Improving predictive inference under covari-ate shift by weighting the log-likelihood function", "label": "Improving predictive inference under covari-ate shift by weighting the log-likelihood function", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "When training and test sets are different: Characterising learning transfer", "label": "When training and test sets are different: Characterising learning transfer", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Revisiting Unreasonable Effectiveness of Data in Deep Learning Era", "label": "Revisiting Unreasonable Effectiveness of Data in Deep Learning Era", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Yfcc100m: The new data in multimedia research", "label": "Yfcc100m: The new data in multimedia research", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "How trans-ferable are features in deep neural networks? In Advances in Neural Information Processing Systems", "label": "How trans-ferable are features in deep neural networks? In Advances in Neural Information Processing Systems", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Taskonomy: Disentangling task transfer learn-In IEEE Conference on Computer Vision and Pattern ing", "label": "Taskonomy: Disentangling task transfer learn-In IEEE Conference on Computer Vision and Pattern ing", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Do-main adaptation under target and conditional shift", "label": "Do-main adaptation under target and conditional shift", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "From generic to speci\ufb01c deep representations In Proceedings of the IEEE Con-for visual recognition", "label": "From generic to speci\ufb01c deep representations In Proceedings of the IEEE Con-for visual recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multipath sparse coding using hierarchical matching pursuit", "label": "Multipath sparse coding using hierarchical matching pursuit", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep \ufb01l-ter banks for texture recognition", "label": "Deep \ufb01l-ter banks for texture recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Visual event IEEE recognition in videos by learning from web data", "label": "Visual event IEEE recognition in videos by learning from web data", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Predicting depth", "label": "Predicting depth", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multi-task feature learning", "label": "Multi-task feature learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Local alignments for \ufb01ne-grained categoriza-tion", "label": "Local alignments for \ufb01ne-grained categoriza-tion", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Rich fea-ture hierarchies for accurate object detection and semantic In Proceedings of the IEEE conference on segmentation", "label": "Rich fea-ture hierarchies for accurate object detection and semantic In Proceedings of the IEEE conference on segmentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Caltech-256 object cat-egory dataset", "label": "Caltech-256 object cat-egory dataset", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Scene recognition with cnns: objects", "label": "Scene recognition with cnns: objects", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning transferrable knowledge for semantic segmentation with deep convolu-In IEEE Conference on Computer tional neural network", "label": "Learning transferrable knowledge for semantic segmentation with deep convolu-In IEEE Conference on Computer tional neural network", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Correcting sample selection bias by unlabeled data", "label": "Correcting sample selection bias by unlabeled data", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Very deep convolutional net-arXiv preprint works for large-scale image recognition", "label": "Very deep convolutional net-arXiv preprint works for large-scale image recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Novel dataset for \ufb01ne-grained image categorization: Stanford dogs", "label": "Novel dataset for \ufb01ne-grained image categorization: Stanford dogs", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The unreasonable ef-fectiveness of noisy data for \ufb01ne-grained recognition", "label": "The unreasonable ef-fectiveness of noisy data for \ufb01ne-grained recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning transferable features with deep adaptation networks", "label": "Learning transferable features with deep adaptation networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Understanding deep image representations by inverting them", "label": "Understanding deep image representations by inverting them", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Texture features for brows-IEEE Transactions on ing and retrieval of image data", "label": "Texture features for brows-IEEE Transactions on ing and retrieval of image data", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A survey on transfer learning", "label": "A survey on transfer learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multi-task learning for classi\ufb01cation with dirichlet process priors", "label": "Multi-task learning for classi\ufb01cation with dirichlet process priors", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Hd-cnn: Hierarchical deep convolutional neural networks for large scale visual recognition", "label": "Hd-cnn: Hierarchical deep convolutional neural networks for large scale visual recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multi-scale In pyramid pooling for deep convolutional representation", "label": "Multi-scale In pyramid pooling for deep convolutional representation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "How trans-ferable are features in deep neural networks? In Advances in neural information processing systems", "label": "How trans-ferable are features in deep neural networks? In Advances in neural information processing systems", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning deep features for scene recognition using places database", "label": "Learning deep features for scene recognition using places database", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Transformation pursuit for image classi\ufb01cation", "label": "Transformation pursuit for image classi\ufb01cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fine-grained visual categorization via multi-stage metric learning", "label": "Fine-grained visual categorization via multi-stage metric learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Metric learn-ing with adaptive density discrimination", "label": "Metric learn-ing with adaptive density discrimination", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Cnn features off-the-shelf: an astounding baseline for recognition", "label": "Cnn features off-the-shelf: an astounding baseline for recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Neural activation constellations: Unsupervised part model discovery with convolutional net-works", "label": "Neural activation constellations: Unsupervised part model discovery with convolutional net-works", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "In IEEE Conference on Going deeper with convolutions", "label": "In IEEE Conference on Going deeper with convolutions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Simultane-ous deep transfer across domains and tasks", "label": "Simultane-ous deep transfer across domains and tasks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Harvesting discrimi-native meta objects with deep cnn features for scene classi\ufb01-cation", "label": "Harvesting discrimi-native meta objects with deep cnn features for scene classi\ufb01-cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Hyper-class aug-mented and regularized deep learning for \ufb01ne-grained im-In Proceedings of the IEEE Conference age classi\ufb01cation", "label": "Hyper-class aug-mented and regularized deep learning for \ufb01ne-grained im-In Proceedings of the IEEE Conference age classi\ufb01cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "OverFeat: Integrated Recognition", "label": "OverFeat: Integrated Recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Rapid object detection using a boosted cascade of simple features", "label": "Rapid object detection using a boosted cascade of simple features", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Restructuring of deep neural network acoustic models with singular value decomposition", "label": "Restructuring of deep neural network acoustic models with singular value decomposition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Do we need more training data or better models for object detec-tion? In BMVC", "label": "Do we need more training data or better models for object detec-tion? In BMVC", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "segDeepM: Exploiting segmentation and context in deep In CVPR", "label": "segDeepM: Exploiting segmentation and context in deep In CVPR", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Se-mantic segmentation with second-order pooling", "label": "Se-mantic segmentation with second-order pooling", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Exploiting linear structure within convolutional networks for ef\ufb01cient evaluation", "label": "Exploiting linear structure within convolutional networks for ef\ufb01cient evaluation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Scalable object detection using deep neural networks", "label": "Scalable object detection using deep neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The PASCAL Visual Object Classes (VOC) Challenge", "label": "The PASCAL Visual Object Classes (VOC) Challenge", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Rich fea-ture hierarchies for accurate object detection and semantic segmentation", "label": "Rich fea-ture hierarchies for accurate object detection and semantic segmentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Region-based convolutional networks for accurate object detection and segmentation", "label": "Region-based convolutional networks for accurate object detection and segmentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Spatial pyramid pooling In in deep convolutional networks for visual recognition", "label": "Spatial pyramid pooling In in deep convolutional networks for visual recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories", "label": "Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Backpropagation applied to handwritten zip code recognition", "label": "Backpropagation applied to handwritten zip code recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Microsoft COCO: common objects in context", "label": "Microsoft COCO: common objects in context", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "SyncSpecCNN: Synchronized Spectral CNN for 3D Shape Segmentation", "label": "SyncSpecCNN: Synchronized Spectral CNN for 3D Shape Segmentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "3d mesh labeling via deep convolutional neural networks", "label": "3d mesh labeling via deep convolutional neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep convolu-tional networks on graph-structured data", "label": "Deep convolu-tional networks on graph-structured data", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning 3d mesh segmentation and labeling", "label": "Learning 3d mesh segmentation and labeling", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Shape2pose: human-centric shape analysis", "label": "Shape2pose: human-centric shape analysis", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning part-based templates from large collections of 3d shapes", "label": "Learning part-based templates from large collections of 3d shapes", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Segmentation of 3d meshes through spectral clustering", "label": "Segmentation of 3d meshes through spectral clustering", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Mesh segmentation via spectral In Computer Graphics embedding and contour analysis", "label": "Mesh segmentation via spectral In Computer Graphics embedding and contour analysis", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fully convolutional In Proceedings of networks for semantic segmentation", "label": "Fully convolutional In Proceedings of networks for semantic segmentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning 3d part detection In 2014 2nd International from sparsely labeled data", "label": "Learning 3d part detection In 2014 2nd International from sparsely labeled data", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Geodesic convolutional neural networks on riemannian man-ifolds", "label": "Geodesic convolutional neural networks on riemannian man-ifolds", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning class-speci\ufb01c de-scriptors for deformable shapes using localized spectral In Computer Graphics Forum", "label": "Learning class-speci\ufb01c de-scriptors for deformable shapes using localized spectral In Computer Graphics Forum", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Angular synchronization by eigenvectors and Applied and computational semide\ufb01nite programming", "label": "Angular synchronization by eigenvectors and Applied and computational semide\ufb01nite programming", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Unsupervised multi-class joint In 2014 IEEE Conference on Computer Vision and Pattern Recognition", "label": "Unsupervised multi-class joint In 2014 IEEE Conference on Computer Vision and Pattern Recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Interactive shape co-segmentation via label propagation", "label": "Interactive shape co-segmentation via label propagation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "3d shape segmentation In Computer and labeling via extreme learning machine", "label": "3d shape segmentation In Computer and labeling via extreme learning machine", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multi-scale context aggregation by arXiv preprint arXiv:1511", "label": "Multi-scale context aggregation by arXiv preprint arXiv:1511", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Yolo9000: Better", "label": "Yolo9000: Better", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Inside-outside net: Detecting objects in context with skip arXiv preprint pooling and recurrent neural networks", "label": "Inside-outside net: Detecting objects in context with skip arXiv preprint pooling and recurrent neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fast R-CNN", "label": "Fast R-CNN", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "SSD: single shot multibox detector", "label": "SSD: single shot multibox detector", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Introduction to wordnet: An on-line lexical database", "label": "Introduction to wordnet: An on-line lexical database", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "You only look once: Uni\ufb01ed", "label": "You only look once: Uni\ufb01ed", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Faster r-cnn: To-wards real-time object detection with region proposal net-works", "label": "Faster r-cnn: To-wards real-time object detection with region proposal net-works", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Vizdoom: A doom-based AI research platform for visual reinforcement learning", "label": "Vizdoom: A doom-based AI research platform for visual reinforcement learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Lucas-kanade 20 years on: A uni-fying framework", "label": "Lucas-kanade 20 years on: A uni-fying framework", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Active appearance models", "label": "Active appearance models", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Generic vs", "label": "Generic vs", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "In Automatic Face Gesture Recognition", "label": "In Automatic Face Gesture Recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fast motion estimation using Image Processing", "label": "Fast motion estimation using Image Processing", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A framework for automated measurement of the intensity of non-posed facial action units", "label": "A framework for automated measurement of the intensity of non-posed facial action units", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Active appearance models revis-ited", "label": "Active appearance models revis-ited", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Bidirec-tional Composition on Lie Groups for Gradient-Based Im-Image Processing", "label": "Bidirec-tional Composition on Lie Groups for Gradient-Based Im-Image Processing", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Vision-and-language navigation: Interpreting visually-grounded nav-igation instructions in real environments", "label": "Vision-and-language navigation: Interpreting visually-grounded nav-igation instructions in real environments", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Embodied Question Answering", "label": "Embodied Question Answering", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "IQA: Visual Question Answering in Interactive Environ-ments", "label": "IQA: Visual Question Answering in Interactive Environ-ments", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "arXiv preprint Learning in a Simulated 3D World", "label": "arXiv preprint Learning in a Simulated 3D World", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Vizdoom: A doom-based AI research platform for visual reinforce-ment learning", "label": "Vizdoom: A doom-based AI research platform for visual reinforce-ment learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Playing atari with deep rein-forcement learning", "label": "Playing atari with deep rein-forcement learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Control of memory, active perception, and action in minecraft", "label": "Control of memory, active perception, and action in minecraft", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Evolution strategies as a scalable alternative to reinforce-ment learning", "label": "Evolution strategies as a scalable alternative to reinforce-ment learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "MINOS: Multimodal Indoor Simulator for Navigation in Complex Environments", "label": "MINOS: Multimodal Indoor Simulator for Navigation in Complex Environments", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A corpus of natural language for visual reasoning", "label": "A corpus of natural language for visual reasoning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Building Generalizable Agents with a Realistic and Rich 3D Environment", "label": "Building Generalizable Agents with a Realistic and Rich 3D Environment", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Extending the openai gym for robotics: a toolkit for reinforce-arXiv preprint ment learning using ros and gazebo", "label": "Extending the openai gym for robotics: a toolkit for reinforce-arXiv preprint ment learning using ros and gazebo", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Target-driven visual navigation in indoor scenes using deep re-inforcement learning", "label": "Target-driven visual navigation in indoor scenes using deep re-inforcement learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multi-residual networks", "label": "Multi-residual networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The power of sparsity in convolutional neural networks", "label": "The power of sparsity in convolutional neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Mxnet: A \ufb02exible and ef\ufb01-cient machine learning library for heterogeneous distributed systems", "label": "Mxnet: A \ufb02exible and ef\ufb01-cient machine learning library for heterogeneous distributed systems", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Ima-genet: A large-scale hierarchical image database", "label": "Ima-genet: A large-scale hierarchical image database", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Exploiting linear structure within convolutional net-works for ef\ufb01cient evaluation", "label": "Exploiting linear structure within convolutional net-works for ef\ufb01cient evaluation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep compression: Com-pressing deep neural network with pruning", "label": "Deep compression: Com-pressing deep neural network with pruning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning both In weights and connections for ef\ufb01cient neural network", "label": "Learning both In weights and connections for ef\ufb01cient neural network", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep roots: Improving CNN ef\ufb01ciency with hierarchical \ufb01l-ter groups", "label": "Deep roots: Improving CNN ef\ufb01ciency with hierarchical \ufb01l-ter groups", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Training cnns with low-rank \ufb01lters for ef\ufb01-cient image classi\ufb01cation", "label": "Training cnns with low-rank \ufb01lters for ef\ufb01-cient image classi\ufb01cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Speeding up convolutional neural networks with low rank expansions", "label": "Speeding up convolutional neural networks with low rank expansions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Flattened convolu-tional neural networks for feedforward acceleration", "label": "Flattened convolu-tional neural networks for feedforward acceleration", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Compression of deep convolutional neural networks for fast and low power mobile applications", "label": "Compression of deep convolutional neural networks for fast and low power mobile applications", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fractal-net: Ultra-deep neural networks without residuals", "label": "Fractal-net: Ultra-deep neural networks without residuals", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deeply-supervised nets", "label": "Deeply-supervised nets", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Simplifying convnets for fast learning", "label": "Simplifying convnets for fast learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Rigid-motion scattering for texture classi\ufb01cation", "label": "Rigid-motion scattering for texture classi\ufb01cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Very deep convolu-tional networks for large-scale image recognition", "label": "Very deep convolu-tional networks for large-scale image recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Swapout: Learning In NIPS", "label": "Swapout: Learning In NIPS", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Resnet in resnet: Gener-alizing residual architectures", "label": "Resnet in resnet: Gener-alizing residual architectures", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "80 million tiny images: A large data set for nonparametric object and scene recognition", "label": "80 million tiny images: A large data set for nonparametric object and scene recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deeply-fused nets", "label": "Deeply-fused nets", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning structured sparsity in deep neural networks", "label": "Learning structured sparsity in deep neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Ag-gregated residual transformations for deep neural networks", "label": "Ag-gregated residual transformations for deep neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "On the connec-tion of deep fusion to ensembling", "label": "On the connec-tion of deep fusion to ensembling", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "End-to-End Text Recognition with Hybrid HMM Maxout Models", "label": "End-to-End Text Recognition with Hybrid HMM Maxout Models", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "PhotoOCR: Reading text in un-controlled conditions", "label": "PhotoOCR: Reading text in un-controlled conditions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Character recognition in natural images", "label": "Character recognition in natural images", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Predicting parameters in deep learning", "label": "Predicting parameters in deep learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Large-scale fpga-based convolutional networks", "label": "Large-scale fpga-based convolutional networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Scene parsing with multiscale feature learning", "label": "Scene parsing with multiscale feature learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multi-digit number In recognition from street view imagery using deep convolutional neural networks", "label": "Multi-digit number In recognition from street view imagery using deep convolutional neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "arXiv preprint Implementing ef\ufb01cient convnet descriptor pyramids", "label": "arXiv preprint Implementing ef\ufb01cient convnet descriptor pyramids", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Caffe: An open source convolutional architecture for fast feature embedding", "label": "Caffe: An open source convolutional architecture for fast feature embedding", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning convolutional feature hierarchies for visual recognition", "label": "Learning convolutional feature hierarchies for visual recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "ImageNet classi\ufb01cation with deep con-volutional neural networks", "label": "ImageNet classi\ufb01cation with deep con-volutional neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations", "label": "Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "ICDAR 2005 text locating competition results", "label": "ICDAR 2005 text locating competition results", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fast training of convolutional networks through ffts", "label": "Fast training of convolutional networks through ffts", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A method for text localization and recognition in real-world images", "label": "A method for text localization and recognition in real-world images", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Text localization in real-world images using ef\ufb01ciently pruned exhaustive search", "label": "Text localization in real-world images using ef\ufb01ciently pruned exhaustive search", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Real-time scene text localization and recognition", "label": "Real-time scene text localization and recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Scene text localization and recognition with oriented stroke detection", "label": "Scene text localization and recognition with oriented stroke detection", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning and transferring mid-level image representations using convolutional neural networks", "label": "Learning and transferring mid-level image representations using convolutional neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Using text-spotting to query the world", "label": "Using text-spotting to query the world", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Large scale mining and retrieval of visual data in a multimodal context", "label": "Large scale mining and retrieval of visual data in a multimodal context", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Are sparse representations really relevant for image classi\ufb01cation? In Computer Vision and Pattern Recognition (CVPR)", "label": "Are sparse representations really relevant for image classi\ufb01cation? In Computer Vision and Pattern Recognition (CVPR)", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "ICDAR 2011 robust reading competition chal-lenge 2: Reading text in scene images", "label": "ICDAR 2011 robust reading competition chal-lenge 2: Reading text in scene images", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Sparselet models for ef\ufb01cient multiclass object detection", "label": "Sparselet models for ef\ufb01cient multiclass object detection", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Discriminatively activated sparselets", "label": "Discriminatively activated sparselets", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep-Face: Closing the gap to human-level performance in face veri\ufb01cation", "label": "Deep-Face: Closing the gap to human-level performance in face veri\ufb01cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "DeepPose: Human pose estimation via deep neural net-works", "label": "DeepPose: Human pose estimation via deep neural net-works", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Segmentation as selective In Computer Vision (ICCV)", "label": "Segmentation as selective In Computer Vision (ICCV)", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Improving the speed of neural networks on In Proc", "label": "Improving the speed of neural networks on In Proc", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "End-to-end scene text recognition", "label": "End-to-end scene text recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "End-to-end text recognition with con-In Pattern Recognition (ICPR)", "label": "End-to-end text recognition with con-In Pattern Recognition (ICPR)", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A framework for improved video text detection and recognition", "label": "A framework for improved video text detection and recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "OctNetFusion: Learning depth fusion from data", "label": "OctNetFusion: Learning depth fusion from data", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deeppose: Human pose estimation via deep neural networks", "label": "Deeppose: Human pose estimation via deep neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "SpiderCNN: Deep learning on point sets with parameterized convolutional \ufb01lters", "label": "SpiderCNN: Deep learning on point sets with parameterized convolutional \ufb01lters", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Dominant set clustering and pooling for multi-view 3d object recognition", "label": "Dominant set clustering and pooling for multi-view 3d object recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Gift: A real-time and scalable 3D shape search engine", "label": "Gift: A real-time and scalable 3D shape search engine", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Generative and In Advances in discriminative voxel modeling with convolutional neural networks", "label": "Generative and In Advances in discriminative voxel modeling with convolutional neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Dominant-set clustering: A review", "label": "Dominant-set clustering: A review", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Return of the devil in the details: Delving deep into convolutional nets", "label": "Return of the devil in the details: Delving deep into convolutional nets", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Pairwise Decomposition of Image Sequences for Active Multi-View Recognition", "label": "Pairwise Decomposition of Image Sequences for Active Multi-View Recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Rotation invari-ant spherical harmonic representation of 3D shape descriptors", "label": "Rotation invari-ant spherical harmonic representation of 3D shape descriptors", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Hough transform and 3D SURF for robust three dimensional classi\ufb01cation", "label": "Hough transform and 3D SURF for robust three dimensional classi\ufb01cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "View-based 3-D object recognition using shock graphs", "label": "View-based 3-D object recognition using shock graphs", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Voxnet: A 3D convolutional neural network for real-time object recognition", "label": "Voxnet: A 3D convolutional neural network for real-time object recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Visual learning and recognition of 3-D objects from appearance", "label": "Visual learning and recognition of 3-D objects from appearance", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A new graph-theoretic approach to clustering and segmentation", "label": "A new graph-theoretic approach to clustering and segmentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Dominant sets and pairwise clustering", "label": "Dominant sets and pairwise clustering", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Volumetric and Multi-View CNNs for Object Classi\ufb01cation on 3D Data", "label": "Volumetric and Multi-View CNNs for Object Classi\ufb01cation on 3D Data", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep learning 3D shape surfaces using In Proceedings of the European Conference on Computer Vision geometry images", "label": "Deep learning 3D shape surfaces using In Proceedings of the European Conference on Computer Vision geometry images", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learn-ing a probabilistic latent space of object shapes via 3D generative-adversarial modeling", "label": "Learn-ing a probabilistic latent space of object shapes via 3D generative-adversarial modeling", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Octree generating networks: Ef\ufb01cient convolutional architectures for high-resolution 3D outputs", "label": "Octree generating networks: Ef\ufb01cient convolutional architectures for high-resolution 3D outputs", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "SSD: Smooth Signed Distance Surface Reconstruction", "label": "SSD: Smooth Signed Distance Surface Reconstruction", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Voxresnet: Deep vox-elwise residual networks for volumetric brain segmentation", "label": "Voxresnet: Deep vox-elwise residual networks for volumetric brain segmentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Cumulative generation of octree models from range data", "label": "Cumulative generation of octree models from range data", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep shape from a low number of silhouettes", "label": "Deep shape from a low number of silhouettes", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning to generate chairs", "label": "Learning to generate chairs", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A point set generation network for 3d object reconstruction from a single image", "label": "A point set generation network for 3d object reconstruction from a single image", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fusion of depth maps with multiple scales", "label": "Fusion of depth maps with multiple scales", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "3d shape induction from 2d views of multiple objects", "label": "3d shape induction from 2d views of multiple objects", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Linear octtrees for fast processing of three-dimensional objects", "label": "Linear octtrees for fast processing of three-dimensional objects", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learn-ing a predictable and generative vector representation for ob-jects", "label": "Learn-ing a predictable and generative vector representation for ob-jects", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep disentan-gled representations for volumetric reconstruction", "label": "Deep disentan-gled representations for volumetric reconstruction", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Caffe: Con-volutional architecture for fast feature embedding", "label": "Caffe: Con-volutional architecture for fast feature embedding", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Perceptual losses for real-time style transfer and super-resolution", "label": "Perceptual losses for real-time style transfer and super-resolution", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Poisson surface reconstruction", "label": "Poisson surface reconstruction", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Geodesic convolutional neural networks on rie-mannian manifolds", "label": "Geodesic convolutional neural networks on rie-mannian manifolds", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Octree encoding: A new technique for the rep-resentation", "label": "Octree encoding: A new technique for the rep-resentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Unsupervised repre-sentation learning with deep convolutional generative adver-sarial networks", "label": "Unsupervised repre-sentation learning with deep convolutional generative adver-sarial networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Vconv-dae: Deep volu-metric shape learning without object labels", "label": "Vconv-dae: Deep volu-metric shape learning without object labels", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep learning 3d shape surfaces using geometry images", "label": "Deep learning 3d shape surfaces using geometry images", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Volumetric 3d mapping in real-time on a cpu", "label": "Volumetric 3d mapping in real-time on a cpu", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning shape abstractions by assembling volumetric prim-itives", "label": "Learning shape abstractions by assembling volumetric prim-itives", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Global", "label": "Global", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Perspective transformer nets: Learning single-view 3d object reconstruc-tion without 3d supervision", "label": "Perspective transformer nets: Learning single-view 3d object reconstruc-tion without 3d supervision", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Syncspeccnn: Syn-chronized spectral CNN for 3d shape segmentation", "label": "Syncspeccnn: Syn-chronized spectral CNN for 3d shape segmentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning semantic deformation \ufb02ows with 3d convolutional networks", "label": "Learning semantic deformation \ufb02ows with 3d convolutional networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deepmind lab", "label": "Deepmind lab", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "ImageNet: A Large-Scale Hierarchical Image Database", "label": "ImageNet: A Large-Scale Hierarchical Image Database", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "WordNet: An Electronic Lexical Database", "label": "WordNet: An Electronic Lexical Database", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Introduction to MPEG-7: Multimedia New York", "label": "Introduction to MPEG-7: Multimedia New York", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Color and texture descriptors", "label": "Color and texture descriptors", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Mpeg-7 visual motion descriptors", "label": "Mpeg-7 visual motion descriptors", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Ef\ufb01cient use of mpeg-7 edge histogram descriptor", "label": "Ef\ufb01cient use of mpeg-7 edge histogram descriptor", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep attribute In Deep Learning and Unsupervised Feature networks", "label": "Deep attribute In Deep Learning and Unsupervised Feature networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Robust classi\ufb01cation using structured sparse representation", "label": "Robust classi\ufb01cation using structured sparse representation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Describing objects by their attributes", "label": "Describing objects by their attributes", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Is that you? Metric learning approaches for face identi\ufb01cation", "label": "Is that you? Metric learning approaches for face identi\ufb01cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Discriminative deep metric In Proc", "label": "Discriminative deep metric In Proc", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Large margin multi-metric learning for face and kinship veri\ufb01cation in the wild", "label": "Large margin multi-metric learning for face and kinship veri\ufb01cation in the wild", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Large scale strongly supervised ensemble metric learning", "label": "Large scale strongly supervised ensemble metric learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning hierarchical representations for face veri\ufb01cation with convo-lutional deep belief networks", "label": "Learning hierarchical representations for face veri\ufb01cation with convo-lutional deep belief networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Robust and practical face recognition via structured sparsity", "label": "Robust and practical face recognition via structured sparsity", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Eigen-pep for video face recognition", "label": "Eigen-pep for video face recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Sparse representation using nonnegative curds and whey", "label": "Sparse representation using nonnegative curds and whey", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A deep sum-product In Proc", "label": "A deep sum-product In Proc", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Tom-vs-Pete classi\ufb01ers and identity-preserving alignment for face veri\ufb01cation", "label": "Tom-vs-Pete classi\ufb01ers and identity-preserving alignment for face veri\ufb01cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Automatic attribute discovery and characterization from noisy web data", "label": "Automatic attribute discovery and characterization from noisy web data", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Describing people: Poselet-based attribute classi\ufb01cation", "label": "Describing people: Poselet-based attribute classi\ufb01cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fisher vector faces in the wild", "label": "Fisher vector faces in the wild", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multiple one-shots for utilizing class label information", "label": "Multiple one-shots for utilizing class label information", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Robust boltzmann In Proc", "label": "Robust boltzmann In Proc", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Neural mechanisms for face perception", "label": "Neural mechanisms for face perception", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Face recognition in unconstrained videos with matched background similarity", "label": "Face recognition in unconstrained videos with matched background similarity", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Robust face recognition via sparse representation", "label": "Robust face recognition via sparse representation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Gabor feature based sparse represen-tation for face recognition with gabor occlusion dictionary", "label": "Gabor feature based sparse represen-tation for face recognition with gabor occlusion dictionary", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "An associate-predict model for face recognition", "label": "An associate-predict model for face recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Sparse representation or collaborative representation: Which helps face recognition? In Proc", "label": "Sparse representation or collaborative representation: Which helps face recognition? In Proc", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "PANDA: Pose aligned networks for deep attribute modeling", "label": "PANDA: Pose aligned networks for deep attribute modeling", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Eigenfaces vs", "label": "Eigenfaces vs", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning deep architectures for AI\u201d", "label": "Learning deep architectures for AI\u201d", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Bayesian In Computer Vision\u2013 face revisited: A joint formulation\u201d", "label": "Bayesian In Computer Vision\u2013 face revisited: A joint formulation\u201d", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Blessing of dimen-sionality: High-dimensional feature and its ef\ufb01cient com-pression for face veri\ufb01cation\u201d", "label": "Blessing of dimen-sionality: High-dimensional feature and its ef\ufb01cient com-pression for face veri\ufb01cation\u201d", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Improving neural networks by pre-venting co-adaptation of feature detectors\u201d", "label": "Improving neural networks by pre-venting co-adaptation of feature detectors\u201d", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Labeled faces in the wild: A database for studying face recognition in unconstrained environments\u201d", "label": "Labeled faces in the wild: A database for studying face recognition in unconstrained environments\u201d", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Imagenet classi\ufb01cation with deep convolutional neural networks\u201d", "label": "Imagenet classi\ufb01cation with deep convolutional neural networks\u201d", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Gradient-based learning applied to document recognition\u201d", "label": "Gradient-based learning applied to document recognition\u201d", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Face recog-nition by exploring information jointly in space", "label": "Face recog-nition by exploring information jointly in space", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning discriminant face descriptor\u201d", "label": "Learning discriminant face descriptor\u201d", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Illumination in-variant face recognition using near-infrared images\u201d", "label": "Illumination in-variant face recognition using near-infrared images\u201d", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Benchmark of large-scale unconstrained face recognition\u201d", "label": "Benchmark of large-scale unconstrained face recognition\u201d", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Gabor feature based classi\ufb01ca-tion using the enhanced \ufb01sher linear discriminant model for face recognition\u201d", "label": "Gabor feature based classi\ufb01ca-tion using the enhanced \ufb01sher linear discriminant model for face recognition\u201d", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Face recognition with decision tree-based local binary patterns\u201d", "label": "Face recognition with decision tree-based local binary patterns\u201d", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Recti\ufb01ed linear units improve restricted boltzmann machines\u201d", "label": "Recti\ufb01ed linear units improve restricted boltzmann machines\u201d", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The FERET evaluation methodology for face-recognition algo-IEEE Transactions on Pattern Analysis and Ma-rithms\u201d", "label": "The FERET evaluation methodology for face-recognition algo-IEEE Transactions on Pattern Analysis and Ma-rithms\u201d", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The cmu pose", "label": "The cmu pose", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Very deep convolutional networks for large-scale image recognition\u201d", "label": "Very deep convolutional networks for large-scale image recognition\u201d", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep learning face repre-sentation by joint identi\ufb01cation-veri\ufb01cation\u201d", "label": "Deep learning face repre-sentation by joint identi\ufb01cation-veri\ufb01cation\u201d", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Going deeper with convolutions\u201d", "label": "Going deeper with convolutions\u201d", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deepface: Closing the gap to human-level performance in face veri\ufb01ca-tion\u201d", "label": "Deepface: Closing the gap to human-level performance in face veri\ufb01ca-tion\u201d", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Eigenfaces for recognition\u201d", "label": "Eigenfaces for recognition\u201d", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Face recognition in unconstrained videos with matched background similarity\u201d", "label": "Face recognition in unconstrained videos with matched background similarity\u201d", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Towards pose robust face recognition\u201d", "label": "Towards pose robust face recognition\u201d", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning representations and generative models for 3d point clouds", "label": "Learning representations and generative models for 3d point clouds", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Joint 2D-3D-Semantic Data for Indoor Scene Understanding", "label": "Joint 2D-3D-Semantic Data for Indoor Scene Understanding", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Locality-sensitive deconvolution networks with gated fusion for rgb-d indoor semantic segmentation", "label": "Locality-sensitive deconvolution networks with gated fusion for rgb-d indoor semantic segmentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multi-column deep neural networks for image classi\ufb01cation", "label": "Multi-column deep neural networks for image classi\ufb01cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Why does unsupervised pre-training help deep learning? Journal of Machine Learning Research", "label": "Why does unsupervised pre-training help deep learning? Journal of Machine Learning Research", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Unsupervised cnn for In single view depth estimation: Geometry to the rescue", "label": "Unsupervised cnn for In single view depth estimation: Geometry to the rescue", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Unsuper-vised monocular depth estimation with left-right consistency", "label": "Unsuper-vised monocular depth estimation with left-right consistency", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Billion-scale similarity search with gpus", "label": "Billion-scale similarity search with gpus", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The self-organizing map", "label": "The self-organizing map", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Voxnet: A 3d convolutional neural network for real-time object recognition", "label": "Voxnet: A 3d convolutional neural network for real-time object recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep learning with sets and point clouds", "label": "Deep learning with sets and point clouds", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Voting for voting in online point In Robotics: Science and Systems", "label": "Voting for voting in online point In Robotics: Science and Systems", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": ": Web-based database for facial expression analysis", "label": ": Web-based database for facial expression analysis", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Human computing and machine understanding of human behavior: A survey", "label": "Human computing and machine understanding of human behavior: A survey", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Machine analysis of facial behaviour: naturalistic and dynamic behaviour", "label": "Machine analysis of facial behaviour: naturalistic and dynamic behaviour", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Universals and cultural di\ufb00erences in facial expressions of emo-tion", "label": "Universals and cultural di\ufb00erences in facial expressions of emo-tion", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Di\ufb00erentiating between posed and sponta-neous expressions with latent regression bayesian network", "label": "Di\ufb00erentiating between posed and sponta-neous expressions with latent regression bayesian network", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Convolutional networks and ap-plications in vision", "label": "Convolutional networks and ap-plications in vision", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Pictures of facial a\ufb00ect", "label": "Pictures of facial a\ufb00ect", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A spontaneous micro-expression database: Inducement", "label": "A spontaneous micro-expression database: Inducement", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Exploring human visual system: study to aid the development of automatic facial expression recog-nition framework", "label": "Exploring human visual system: study to aid the development of automatic facial expression recog-nition framework", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Automatic a\ufb00ect analysis: From chil-dren to adults", "label": "Automatic a\ufb00ect analysis: From chil-dren to adults", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Face expression recognition with a 2-channel convolutional neural network", "label": "Face expression recognition with a 2-channel convolutional neural network", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Visualizing and understanding convolutional neural networks", "label": "Visualizing and understanding convolutional neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Distortion Invariant Object Recognition in the Dynamic Link Architecture", "label": "Distortion Invariant Object Recognition in the Dynamic Link Architecture", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Coding Facial Expressions with Gabor Wavelets", "label": "Coding Facial Expressions with Gabor Wavelets", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Recognition of facial expression from optical \ufb02ow", "label": "Recognition of facial expression from optical \ufb02ow", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A circumplex model of a\ufb00ect", "label": "A circumplex model of a\ufb00ect", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Recognizing Human Facial Expressions from Long Image Sequences using Optical Flow", "label": "Recognizing Human Facial Expressions from Long Image Sequences using Optical Flow", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Comparison between Geometry-based and Gabor-wavelets-based Facial Expression Recognition using Multi-layer Perceptron", "label": "Comparison between Geometry-based and Gabor-wavelets-based Facial Expression Recognition using Multi-layer Perceptron", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "High-performance neural networks for visual object classi\ufb01cation", "label": "High-performance neural networks for visual object classi\ufb01cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Large-scale learning with SVM and convolutional for generic object categorization", "label": "Large-scale learning with SVM and convolutional for generic object categorization", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "What is the best multi-stage architecture for object recognition? In Proc", "label": "What is the best multi-stage architecture for object recognition? In Proc", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Convo-lutional deep belief networks for scalable unsupervised learning of hierarchical representations", "label": "Convo-lutional deep belief networks for scalable unsupervised learning of hierarchical representations", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Ssvm: A smooth support vector machine for classi\ufb01cation", "label": "Ssvm: A smooth support vector machine for classi\ufb01cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep belief networks for phone recognition", "label": "Deep belief networks for phone recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": ", Di Caro, G", "label": ", Di Caro, G", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation", "label": "SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Murphy, , and A", "label": "Murphy, , and A", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Nouri, and E", "label": "Nouri, and E", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Kr\u00e4henb\u00fchl, and T", "label": "Kr\u00e4henb\u00fchl, and T", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Pouget-Abadie, Jean, M", "label": "Pouget-Abadie, Jean, M", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Weinberger, and L", "label": "Weinberger, and L", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Rezende, and M", "label": "Rezende, and M", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Dumoulin, and A", "label": "Dumoulin, and A", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "S\u00f8nderby, and O", "label": "S\u00f8nderby, and O", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Wang, and X", "label": "Wang, and X", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Metz, and S", "label": "Metz, and S", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Castillo, and R", "label": "Castillo, and R", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "McClelland, and S", "label": "McClelland, and S", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Goroshin, and Y", "label": "Goroshin, and Y", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Shechtman, and A", "label": "Shechtman, and A", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "FusionNet: 3D object classi\ufb01cation using multiple data representations", "label": "FusionNet: 3D object classi\ufb01cation using multiple data representations", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Netadapt: Platform-aware neural network adaptation for mobile applications", "label": "Netadapt: Platform-aware neural network adaptation for mobile applications", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Compressing neural networks with the hashing trick", "label": "Compressing neural networks with the hashing trick", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "precision storage for deep learning", "label": "precision storage for deep learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "SeGAN: Segment ing and generating the invisible", "label": "SeGAN: Segment ing and generating the invisible", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Escape from Cells: Deep KdNetworks for The Recognition of 3D Point Cloud Models", "label": "Escape from Cells: Deep KdNetworks for The Recognition of 3D Point Cloud Models", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Invariant scattering convolution net-works", "label": "Invariant scattering convolution net-works", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "An integrated micro-and macroarchitectural analysis of the drosophila brain by computer-assisted serial section electron mi-croscopy", "label": "An integrated micro-and macroarchitectural analysis of the drosophila brain by computer-assisted serial section electron mi-croscopy", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Backpropagation: theory", "label": "Backpropagation: theory", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep neural networks segment neuronal membranes in electron microscopy images", "label": "Deep neural networks segment neuronal membranes in electron microscopy images", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Torch7: A matlab-like environment for machine learning", "label": "Torch7: A matlab-like environment for machine learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Transformation-invariant convolutional jungles", "label": "Transformation-invariant convolutional jungles", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "An empirical evaluation of deep architectures on problems with many factors of variation", "label": "An empirical evaluation of deep architectures on problems with many factors of variation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Convolutional networks for images", "label": "Convolutional networks for images", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multi-layer feedforward networks with a nonpolynomial activation function can approximate any function", "label": "Multi-layer feedforward networks with a nonpolynomial activation function can approximate any function", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Object recognition from local scale-invariant features", "label": "Object recognition from local scale-invariant features", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Lost in quantization: Improving particular object retrieval in large scale image databases", "label": "Lost in quantization: Improving particular object retrieval in large scale image databases", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Hierarchical models of ob-ject recognition in cortex", "label": "Hierarchical models of ob-ject recognition in cortex", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Segmentation of thin structures in electron micrographs using orientation \ufb01elds", "label": "Segmentation of thin structures in electron micrographs using orientation \ufb01elds", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Computational tma analysis and cell nucleus classi\ufb01-cation of renal cell carcinoma", "label": "Computational tma analysis and cell nucleus classi\ufb01-cation of renal cell carcinoma", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning invariant representations with In Proceedings of the 29th Interna-local transformations", "label": "Learning invariant representations with In Proceedings of the 29th Interna-local transformations", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multi-view convolutional neural networks for 3d shape recogni-tion", "label": "Multi-view convolutional neural networks for 3d shape recogni-tion", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The art of data augmen-tation", "label": "The art of data augmen-tation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep multiple instance learning for image classi\ufb01cation and auto-annotation", "label": "Deep multiple instance learning for image classi\ufb01cation and auto-annotation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Bag-of-visual-words and spatial In Proceedings of extensions for land-use classi\ufb01cation", "label": "Bag-of-visual-words and spatial In Proceedings of extensions for land-use classi\ufb01cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Adadelta: An adaptive learning rate method", "label": "Adadelta: An adaptive learning rate method", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Rethinking atrous convolution for semantic image segmentation", "label": "Rethinking atrous convolution for semantic image segmentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multi-level adaptive solutions to boundary-value problems", "label": "Multi-level adaptive solutions to boundary-value problems", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A multigrid tutorial", "label": "A multigrid tutorial", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Scene labeling with lstm recurrent neural networks", "label": "Scene labeling with lstm recurrent neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "COCO-Stuff: Thing and stuff classes in context", "label": "COCO-Stuff: Thing and stuff classes in context", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fast", "label": "Fast", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The cityscapes dataset for semantic urban scene understanding", "label": "The cityscapes dataset for semantic urban scene understanding", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Convolutional feature masking for joint object and stuff segmentation", "label": "Convolutional feature masking for joint object and stuff segmentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Boxsup: Exploiting bounding boxes to supervise convolutional networks for semantic segmenta-tion", "label": "Boxsup: Exploiting bounding boxes to supervise convolutional networks for semantic segmenta-tion", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "R-fcn: Object detection via region-based fully convolutional networks", "label": "R-fcn: Object detection via region-based fully convolutional networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multi-level contextual rnns with attention model for scene labeling", "label": "Multi-level contextual rnns with attention model for scene labeling", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning hierarchical features for scene labeling", "label": "Learning hierarchical features for scene labeling", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Stacked deconvolutional network for semantic segmentation", "label": "Stacked deconvolutional network for semantic segmentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Semantic video cnns through representation warping", "label": "Semantic video cnns through representation warping", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Laplacian reconstruction and re\ufb01nement for semantic segmentation", "label": "Laplacian reconstruction and re\ufb01nement for semantic segmentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fast image scanning with deep max-pooling convolutional neural networks", "label": "Fast image scanning with deep max-pooling convolutional neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Decomposing a scene into geometric and semantically consistent regions", "label": "Decomposing a scene into geometric and semantically consistent regions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The pyramid match kernel: Dis-criminative classi\ufb01cation with sets of image features", "label": "The pyramid match kernel: Dis-criminative classi\ufb01cation with sets of image features", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Semantic contours from inverse detectors", "label": "Semantic contours from inverse detectors", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Hyper-columns for object segmentation and \ufb01ne-grained localization", "label": "Hyper-columns for object segmentation and \ufb01ne-grained localization", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Spatial pyramid pooling in deep convolutional networks for visual recognition", "label": "Spatial pyramid pooling in deep convolutional networks for visual recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multiscale conditional random \ufb01elds for image labeling", "label": "Multiscale conditional random \ufb01elds for image labeling", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A real-time algorithm for signal analysis with the help of the wavelet transform", "label": "A real-time algorithm for signal analysis with the help of the wavelet transform", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Speed/accuracy trade-offs for modern convolutional object detectors", "label": "Speed/accuracy trade-offs for modern convolutional object detectors", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Gated feedback re\ufb01nement network for dense image labeling", "label": "Gated feedback re\ufb01nement network for dense image labeling", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fusionseg: Learn-ing to combine motion and appearance for fully automatic segmention of generic objects in videos", "label": "Fusionseg: Learn-ing to combine motion and appearance for fully automatic segmention of generic objects in videos", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Video scene parsing with predictive feature learning", "label": "Video scene parsing with predictive feature learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Recurrent scene parsing with per-spective understanding in the loop", "label": "Recurrent scene parsing with per-spective understanding in the loop", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Ef\ufb01cient inference in fully connected crfs with gaussian edge potentials", "label": "Ef\ufb01cient inference in fully connected crfs with gaussian edge potentials", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Associative In hierarchical crfs for object class image segmentation", "label": "Associative In hierarchical crfs for object class image segmentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Beyond bags of fea-tures: Spatial pyramid matching for recognizing natural scene categories", "label": "Beyond bags of fea-tures: Spatial pyramid matching for recognizing natural scene categories", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Foveanet: Perspective-aware urban scene parsing", "label": "Foveanet: Perspective-aware urban scene parsing", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Not all pixels are equal: Dif\ufb01culty-aware semantic segmentation via deep layer cascade", "label": "Not all pixels are equal: Dif\ufb01culty-aware semantic segmentation via deep layer cascade", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Semantic object parsing with local-global long short-term memory", "label": "Semantic object parsing with local-global long short-term memory", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Re\ufb01nenet: Multi-path re\ufb01nement networks with identity mappings for high-resolution semantic segmentation", "label": "Re\ufb01nenet: Multi-path re\ufb01nement networks with identity mappings for high-resolution semantic segmentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Parsenet: Looking wider to see better", "label": "Parsenet: Looking wider to see better", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Semantic image segmentation via deep parsing network", "label": "Semantic image segmentation via deep parsing network", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep dual learning for semantic image segmentation", "label": "Deep dual learning for semantic image segmentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The role of context for object detection and semantic segmentation in the wild", "label": "The role of context for object detection and semantic segmentation in the wild", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Weakly-and semi-supervised learning of a dcnn for semantic image segmentation", "label": "Weakly-and semi-supervised learning of a dcnn for semantic image segmentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Modeling local and global deformations in deep learning: Epitomic convolution", "label": "Modeling local and global deformations in deep learning: Epitomic convolution", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multigrid geometric active contour models", "label": "Multigrid geometric active contour models", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Large kernel matters\u2013improve semantic segmentation by global convolu-tional network", "label": "Large kernel matters\u2013improve semantic segmentation by global convolu-tional network", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Recurrent convolutional neural networks for scene labeling", "label": "Recurrent convolutional neural networks for scene labeling", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Full-resolution residual networks for semantic segmentation in street scenes", "label": "Full-resolution residual networks for semantic segmentation in street scenes", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "U-net: Convolutional networks for biomedical image segmentation", "label": "U-net: Convolutional networks for biomedical image segmentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fully connected deep struc-tured networks", "label": "Fully connected deep struc-tured networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Semantic segmentation via structured patch prediction", "label": "Semantic segmentation via structured patch prediction", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Textonboost for image understanding: Multi-class object recognition and segmentation by jointly modeling texture", "label": "Textonboost for image understanding: Multi-class object recognition and segmentation by jointly modeling texture", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Be-yond skip connections: Top-down modulation for object de-tection", "label": "Be-yond skip connections: Top-down modulation for object de-tection", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Revisiting unreasonable effectiveness of data in deep learning era", "label": "Revisiting unreasonable effectiveness of data in deep learning era", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Mixed context networks for semantic segmentation", "label": "Mixed context networks for semantic segmentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Image analysis using multigrid relaxation methods", "label": "Image analysis using multigrid relaxation methods", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Gaus-sian conditional random \ufb01eld network for semantic segmenta-tion", "label": "Gaus-sian conditional random \ufb01eld network for semantic segmenta-tion", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning object inter-actions and descriptions for semantic image segmentation", "label": "Learning object inter-actions and descriptions for semantic image segmentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Understanding convolution for semantic segmen-tation", "label": "Understanding convolution for semantic segmen-tation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Bridging category-level and instance-level semantic image segmen-tation", "label": "Bridging category-level and instance-level semantic image segmen-tation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Wider or deeper: Revisiting the resnet model for visual recognition", "label": "Wider or deeper: Revisiting the resnet model for visual recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Zoom better to see clearer: Huamn part segmentation with auto zoom net", "label": "Zoom better to see clearer: Huamn part segmentation with auto zoom net", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Combining the best of convolutional layers and recurrent layers: A hybrid network for semantic segmentation", "label": "Combining the best of convolutional layers and recurrent layers: A hybrid network for semantic segmentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Describing the scene as a whole: Joint object detection", "label": "Describing the scene as a whole: Joint object detection", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multi-scale context aggregation by dilated convolutions", "label": "Multi-scale context aggregation by dilated convolutions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Adaptive deconvo-lutional networks for mid and high level feature learning", "label": "Adaptive deconvo-lutional networks for mid and high level feature learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Global-residual and local-boundary re\ufb01nement networks for rectifying scene parsing predictions", "label": "Global-residual and local-boundary re\ufb01nement networks for rectifying scene parsing predictions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Scale-adaptive convolutions for scene parsing", "label": "Scale-adaptive convolutions for scene parsing", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Pyramid scene parsing network", "label": "Pyramid scene parsing network", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Scene parsing through ade20k dataset", "label": "Scene parsing through ade20k dataset", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Xception: Deep learning with depthwise separa ble convolutions", "label": "Xception: Deep learning with depthwise separa ble convolutions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Structure inference machines: Recurrent neural networks for analyzing relations in group activity recognition", "label": "Structure inference machines: Recurrent neural networks for analyzing relations in group activity recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": ": Fast point feature histograms (fpfh) for 3d registration", "label": ": Fast point feature histograms (fpfh) for 3d registration", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Ai2-thor: An interactive 3d environment for visual ai", "label": "Ai2-thor: An interactive 3d environment for visual ai", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Home: a household multimodal environment", "label": "Home: a household multimodal environment", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "G", "label": "G", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "SeGAN: Segment-ing and generating the invisible", "label": "SeGAN: Segment-ing and generating the invisible", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Virtual worlds as proxy for multi-object tracking analysis", "label": "Virtual worlds as proxy for multi-object tracking analysis", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "IQA: Visual question answering in interac-tive environments", "label": "IQA: Visual question answering in interac-tive environments", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Scenenet: An annotated model generator for indoor scene understand-ing", "label": "Scenenet: An annotated model generator for indoor scene understand-ing", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning physical intu-ition of block towers by example", "label": "Learning physical intu-ition of block towers by example", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Scenenet RGB-D: 5m photorealistic images of synthetic in-door trajectories with ground truth", "label": "Scenenet RGB-D: 5m photorealistic images of synthetic in-door trajectories with ground truth", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "MINOS: Multimodal indoor simulator for navi-gation in complex environments", "label": "MINOS: Multimodal indoor simulator for navi-gation in complex environments", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Habitat: A platform for embodied ai research", "label": "Habitat: A platform for embodied ai research", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Torchcraft: a library for machine learning research on real-time strategy games", "label": "Torchcraft: a library for machine learning research on real-time strategy games", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "ELF: an extensive", "label": "ELF: an extensive", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning to learn how to learn: Self-adaptive visual navigation using meta-learning", "label": "Learning to learn how to learn: Self-adaptive visual navigation using meta-learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "TORCS", "label": "TORCS", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "In ICLR", "label": "In ICLR", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Target-driven visual navigation in in-In ICRA", "label": "Target-driven visual navigation in in-In ICRA", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Evaluating Multi-ple Object Tracking Performance: The CLEAR MOT Met-rics", "label": "Evaluating Multi-ple Object Tracking Performance: The CLEAR MOT Met-rics", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Teaching 3d geometry to deformable part models", "label": "Teaching 3d geometry to deformable part models", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Data-driven scene understanding from 3d models", "label": "Data-driven scene understanding from 3d models", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Motion capture of hands in action using discriminative salient points", "label": "Motion capture of hands in action using discriminative salient points", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Simulation as an engine of physical scene understand-ing", "label": "Simulation as an engine of physical scene understand-ing", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Back to the future: Learning shape models from 3d cad data", "label": "Back to the future: Learning shape models from 3d cad data", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning scene-speci\ufb01c pedestrian detectors with-out real data", "label": "Learning scene-speci\ufb01c pedestrian detectors with-out real data", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Ovvv: Using virtual worlds to design and evaluate surveil-lance systems", "label": "Ovvv: Using virtual worlds to design and evaluate surveil-lance systems", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A naturalistic open source movie for opti-cal \ufb02ow evaluation", "label": "A naturalistic open source movie for opti-cal \ufb02ow evaluation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Global data as-sociation for multi-object tracking using network \ufb02ows", "label": "Global data as-sociation for multi-object tracking using network \ufb02ows", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A dataset for developing and benchmarking active vision", "label": "A dataset for developing and benchmarking active vision", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "On evaluation of embodied naviga-tion agents", "label": "On evaluation of embodied naviga-tion agents", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Vision-and-language navigation: In-terpreting visually-grounded navigation instructions in real environments", "label": "Vision-and-language navigation: In-terpreting visually-grounded navigation instructions in real environments", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "VQA: Visual Question Answering", "label": "VQA: Visual Question Answering", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "3D semantic parsing of large-scale indoor spaces", "label": "3D semantic parsing of large-scale indoor spaces", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning to drive from simulation without real world labels", "label": "Learning to drive from simulation without real world labels", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "HoME: A household multimodal environment", "label": "HoME: A household multimodal environment", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Matterport3D: Learning from RGB-D data in indoor environments", "label": "Matterport3D: Learning from RGB-D data in indoor environments", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Embodied Question Answer-ing", "label": "Embodied Question Answer-ing", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Cognitive mapping and planning for visual navigation", "label": "Cognitive mapping and planning for visual navigation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning agile and dynamic motor skills for legged robots", "label": "Learning agile and dynamic motor skills for legged robots", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "To learn or not to learn: Analyzing the role of learning for navigation in virtual envi-ronments", "label": "To learn or not to learn: Analyzing the role of learning for navigation in virtual envi-ronments", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "AI2-THOR: An interactive 3D environment for visual AI", "label": "AI2-THOR: An interactive 3D environment for visual AI", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Benchmarking classic and learned navigation in complex 3D environments", "label": "Benchmarking classic and learned navigation in complex 3D environments", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "ORB-SLAM2: An open-source SLAM system for monocular, stereo and RGB-D cameras", "label": "ORB-SLAM2: An open-source SLAM system for monocular, stereo and RGB-D cameras", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Pyrobot: An open-source robotics framework for re-search and benchmarking", "label": "Pyrobot: An open-source robotics framework for re-search and benchmarking", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "VirtualHome: Sim-ulating household activities via programs", "label": "VirtualHome: Sim-ulating household activities via programs", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "MINOS: Mul-timodal indoor simulator for navigation in complex environ-ments", "label": "MINOS: Mul-timodal indoor simulator for navigation in complex environ-ments", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Proximal policy optimization algo-rithms", "label": "Proximal policy optimization algo-rithms", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The development of em-bodied cognition: Six lessons from babies", "label": "The development of em-bodied cognition: Six lessons from babies", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Semantic scene comple-tion from a single depth image", "label": "Semantic scene comple-tion from a single depth image", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The Replica dataset: A digital replica of indoor spaces", "label": "The Replica dataset: A digital replica of indoor spaces", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Building generalizable agents with a realistic and rich 3D environment", "label": "Building generalizable agents with a realistic and rich 3D environment", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Gibson env: Real-world perception for embodied agents", "label": "Gibson env: Real-world perception for embodied agents", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "CHALET: Cornell house agent learning environment", "label": "CHALET: Cornell house agent learning environment", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Starcraft brood war data mining", "label": "Starcraft brood war data mining", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Re-International inforcement learning through asynchronous advantage actor-critic on a gpu", "label": "Re-International inforcement learning through asynchronous advantage actor-critic on a gpu", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A survey of monte carlo tree search methods", "label": "A survey of monte carlo tree search methods", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "On the development of a free rts game engine", "label": "On the development of a free rts game engine", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Vizdoom: A doom-based ai research platform for visual reinforcement learning", "label": "Vizdoom: A doom-based ai research platform for visual reinforcement learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Playing fps games with deep reinforcement learning", "label": "Playing fps games with deep reinforcement learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning to navigate in complex environments", "label": "Learning to navigate in complex environments", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Asynchronous methods for deep reinforcement learning", "label": "Asynchronous methods for deep reinforcement learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "pages 58\u201364", "label": "pages 58\u201364", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Better computer go player with neural network and long-term prediction", "label": "Better computer go player with neural network and long-term prediction", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Training agent for \ufb01rst-person shooter game with actor-critic curriculum learning", "label": "Training agent for \ufb01rst-person shooter game with actor-critic curriculum learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Purine: A bi-graph based deep learning framework", "label": "Purine: A bi-graph based deep learning framework", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Factors of transferability for a generic convnet representation", "label": "Factors of transferability for a generic convnet representation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Lcnn: Lookup-based convolutional neural network", "label": "Lcnn: Lookup-based convolutional neural network", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep affect prediction in-the-wild: Aff-wild database and challenge", "label": "Deep affect prediction in-the-wild: Aff-wild database and challenge", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": ": Fully automatic facial action recognition in spon-taneous behavior", "label": ": Fully automatic facial action recognition in spon-taneous behavior", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": ": Im-agenet: A large-scale hierarchical image database", "label": ": Im-agenet: A large-scale hierarchical image database", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": ": A 3d facial ex-pression database for facial behavior research", "label": ": A 3d facial ex-pression database for facial behavior research", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Convolutional neural networks at constrained time cost", "label": "Convolutional neural networks at constrained time cost", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multi-column In CVPR", "label": "Multi-column In CVPR", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Understanding deep architectures using a recursive convolutional network", "label": "Understanding deep architectures using a recursive convolutional network", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Spatial pyramid pool-ing in deep convolutional networks for visual recognition", "label": "Spatial pyramid pool-ing in deep convolutional networks for visual recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Some improvements on deep convolutional neural network based image classi\ufb01cation", "label": "Some improvements on deep convolutional neural network based image classi\ufb01cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "One weird trick for parallelizing convolu-tional neural networks", "label": "One weird trick for parallelizing convolu-tional neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Recti\ufb01ed linear units improve In ICML", "label": "Recti\ufb01ed linear units improve In ICML", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Cnn features off-the-shelf: An astounding baseline for recog-niton", "label": "Cnn features off-the-shelf: An astounding baseline for recog-niton", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Adapting In Proc", "label": "Adapting In Proc", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Decaf: A deep convolutional ac-tivation feature for generic visual recognition", "label": "Decaf: A deep convolutional ac-tivation feature for generic visual recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Rich feature hierarchies for accurate object detection and seman-In Proc", "label": "Rich feature hierarchies for accurate object detection and seman-In Proc", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep con-volutional ranking for multilabel image annotation", "label": "Deep con-volutional ranking for multilabel image annotation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Itera-tive quantization: a procrustean approach to learning binary codes for large-scale image retrieval", "label": "Itera-tive quantization: a procrustean approach to learning binary codes for large-scale image retrieval", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The mir \ufb02ickr retrieval eval-uation", "label": "The mir \ufb02ickr retrieval eval-uation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Ir evaluation methods for re-In Proc", "label": "Ir evaluation methods for re-In Proc", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Optimizing search engines using clickthrough data", "label": "Optimizing search engines using clickthrough data", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning to hash with binary recon-In Proc", "label": "Learning to hash with binary recon-In Proc", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Optimizing ranking measures for compact binary code learning", "label": "Optimizing ranking measures for compact binary code learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Supervised hashing with kernels", "label": "Supervised hashing with kernels", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Minimal loss hashing for com-pact binary codes", "label": "Minimal loss hashing for com-pact binary codes", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Semantic hashing", "label": "Semantic hashing", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fast pose In Proc", "label": "Fast pose In Proc", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multimodal learning with deep boltzmann machines", "label": "Multimodal learning with deep boltzmann machines", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep learning face represen-tation from predicting 10", "label": "Deep learning face represen-tation from predicting 10", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Small codes and large image databases for recognition", "label": "Small codes and large image databases for recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Semi-supervised hash-ing for scalable image retrieval", "label": "Semi-supervised hash-ing for scalable image retrieval", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning hash codes with listwise supervision", "label": "Learning hash codes with listwise supervision", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Order preserving hashing for approximate nearest neighbor search", "label": "Order preserving hashing for approximate nearest neighbor search", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Supervised hash-ing for image retrieval via image representation learning", "label": "Supervised hash-ing for image retrieval via image representation learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Overfeat: Integrated recognition, localization and detection using convolutional networks", "label": "Overfeat: Integrated recognition, localization and detection using convolutional networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fast supervised hashing with decision trees for high-dimensional data", "label": "Fast supervised hashing with decision trees for high-dimensional data", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fully Convolutional Networks for Semantic Segmentation", "label": "Fully Convolutional Networks for Semantic Segmentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep Sliding Shapes for amodal 3D object detection in RGB-D images", "label": "Deep Sliding Shapes for amodal 3D object detection in RGB-D images", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multiscale combinatorial grouping", "label": "Multiscale combinatorial grouping", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning hierarchical sparse features for rgb-(d) object recognition", "label": "Learning hierarchical sparse features for rgb-(d) object recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "3d object proposals for accurate object class detection", "label": "3d object proposals for accurate object class detection", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "3D deep shape descriptor", "label": "3D deep shape descriptor", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Cross modal distillation for supervision transfer", "label": "Cross modal distillation for supervision transfer", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Amodal com-pletion and size constancy in natural scenes", "label": "Amodal com-pletion and size constancy in natural scenes", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Unsupervised feature learning for 3d scene labeling", "label": "Unsupervised feature learning for 3d scene labeling", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "R-CNN minus R", "label": "R-CNN minus R", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "VoxNet: A 3D convolutional In IROS", "label": "VoxNet: A 3D convolutional In IROS", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Faster R-CNN: To-wards real-time object detection with region proposal net-works", "label": "Faster R-CNN: To-wards real-time object detection with region proposal net-works", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "DeepPano: Deep panoramic representation for 3-D shape recognition", "label": "DeepPano: Deep panoramic representation for 3-D shape recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Convolutional-recursive deep learning for 3D object classi\ufb01-cation", "label": "Convolutional-recursive deep learning for 3D object classi\ufb01-cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Sliding Shapes for 3D object detection in depth images", "label": "Sliding Shapes for 3D object detection in depth images", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Smeulders", "label": "Smeulders", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Robust real-time visual odometry for dense rgb-d mapping", "label": "Robust real-time visual odometry for dense rgb-d mapping", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "3D ShapeNets: A deep representation for volumetric shapes", "label": "3D ShapeNets: A deep representation for volumetric shapes", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "DeepShape: Deep learned shape descriptor for 3D shape matching and retrieval", "label": "DeepShape: Deep learned shape descriptor for 3D shape matching and retrieval", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Three-dimensional object detec-tion and layout prediction using clouds of oriented gradients", "label": "Three-dimensional object detec-tion and layout prediction using clouds of oriented gradients", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Hierarchical adversarially learned inference", "label": "Hierarchical adversarially learned inference", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Unsupervised semantic parsing of video collections", "label": "Unsupervised semantic parsing of video collections", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Density sensitive hashing", "label": "Density sensitive hashing", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The Priority R-tree: a practically ef\ufb01cient and worst-case optimal R-tree", "label": "The Priority R-tree: a practically ef\ufb01cient and worst-case optimal R-tree", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Spectral Regression: A Regression Framework for Ef\ufb01cient Reg-ularized Subspace Learning", "label": "Spectral Regression: A Regression Framework for Ef\ufb01cient Reg-ularized Subspace Learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "algorithms", "label": "algorithms", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fast locality-sensitive hashing", "label": "Fast locality-sensitive hashing", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Continuous visible nearest neighbor query processing in spatial databases", "label": "Continuous visible nearest neighbor query processing in spatial databases", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Iterative quantization: A procrustean approach to learning binary codes", "label": "Iterative quantization: A procrustean approach to learning binary codes", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Scalable similarity search with In IEEE International Conference on optimized kernel hashing", "label": "Scalable similarity search with In IEEE International Conference on optimized kernel hashing", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Product quantization for IEEE Trans", "label": "Product quantization for IEEE Trans", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Semi-supervised simhash for ef\ufb01cient document similarity search", "label": "Semi-supervised simhash for ef\ufb01cient document similarity search", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Extensions of Lipschitz map-pings into a Hilbert space", "label": "Extensions of Lipschitz map-pings into a Hilbert space", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A posteriori multi-probe locality sensitive hashing", "label": "A posteriori multi-probe locality sensitive hashing", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Random maximum margin hashing", "label": "Random maximum margin hashing", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Voronoi-based k nearest In International neighbor search for spatial network databases", "label": "Voronoi-based k nearest In International neighbor search for spatial network databases", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fast nearest neighbor search in medical image databases", "label": "Fast nearest neighbor search in medical image databases", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Kernelized locality-sensitive hashing In IEEE International Conference on for scalable image search", "label": "Kernelized locality-sensitive hashing In IEEE International Conference on for scalable image search", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Hashing algorithms In The Neural Information Processing for large-scale learning", "label": "Hashing algorithms In The Neural Information Processing for large-scale learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multi-probe lsh: Ef\ufb01cient indexing for high-dimensional similarity search", "label": "Multi-probe lsh: Ef\ufb01cient indexing for high-dimensional similarity search", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Weakly-supervised hashing in In IEEE Conference on Computer Vision and Pattern kernel space", "label": "Weakly-supervised hashing in In IEEE Conference on Computer Vision and Pattern kernel space", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Minimal loss hashing for compact binary codes", "label": "Minimal loss hashing for compact binary codes", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Entropy based nearest neighbor search in high 10 dimensions", "label": "Entropy based nearest neighbor search in high 10 dimensions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Locality sensitive hashing: A comparison of hash function types and querying mechanisms", "label": "Locality sensitive hashing: A comparison of hash function types and querying mechanisms", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Locality-sensitive binary codes from shift-invariant kernels", "label": "Locality-sensitive binary codes from shift-invariant kernels", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Semi-supervised hashing for scalable image retrieval", "label": "Semi-supervised hashing for scalable image retrieval", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Sequential projection learning In International Conference on for hashing with compact codes", "label": "Sequential projection learning In International Conference on for hashing with compact codes", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Complemen-In IEEE tary hashing for approximate nearest neighbor search", "label": "Complemen-In IEEE tary hashing for approximate nearest neighbor search", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Laplacian co-hashing of terms and documents", "label": "Laplacian co-hashing of terms and documents", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Self-taught hashing for fast similarity search", "label": "Self-taught hashing for fast similarity search", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Representation learning: A review and new perspectives", "label": "Representation learning: A review and new perspectives", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "CARLA: An open urban driving simulator", "label": "CARLA: An open urban driving simulator", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Xnor-net: Imagenet classi\ufb01cation using binary convolutional neural networks", "label": "Xnor-net: Imagenet classi\ufb01cation using binary convolutional neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multi-Scale Context Aggregation by Dilated Convolutions", "label": "Multi-Scale Context Aggregation by Dilated Convolutions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": ", and Tchamitchian, Ph", "label": ", and Tchamitchian, Ph", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Lawrence", "label": "Lawrence", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Robust watertight manifold surface generation method for shapenet models", "label": "Robust watertight manifold surface generation method for shapenet models", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Instance-aware semantic segmentation via multi-task network cascades", "label": "Instance-aware semantic segmentation via multi-task network cascades", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning to seg-ment object candidates", "label": "Learning to seg-ment object candidates", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Compete to compute", "label": "Compete to compute", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Edge boxes: Locating object proposals from edges", "label": "Edge boxes: Locating object proposals from edges", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Cpmc: Automatic ob-ject segmentation using constrained parametric min-cuts", "label": "Cpmc: Automatic ob-ject segmentation using constrained parametric min-cuts", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Boxsup: Exploiting bounding boxes to supervise convolutional networks for semantic seg-mentation", "label": "Boxsup: Exploiting bounding boxes to supervise convolutional networks for semantic seg-mentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Object detection via a multi-region \u0026 semantic segmentation-aware cnn model", "label": "Object detection via a multi-region \u0026 semantic segmentation-aware cnn model", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": ", and Kira, Z", "label": ", and Kira, Z", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": ", and Bous-quet, O", "label": ", and Bous-quet, O", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": ", and Gerolin, A", "label": ", and Gerolin, A", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": ", and Yoshida, Y", "label": ", and Yoshida, Y", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "and Cuturi, M", "label": "and Cuturi, M", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": ", and Pock, T", "label": ", and Pock, T", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "and Bach, F", "label": "and Bach, F", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": ", and Grosse, R", "label": ", and Grosse, R", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "and Bottou, L", "label": "and Bottou, L", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": ", and Bottou, L", "label": ", and Bottou, L", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": ", and Munos, R", "label": ", and Munos, R", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": ", and Metz, L", "label": ", and Metz, L", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "and Rosasco, L", "label": "and Rosasco, L", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": ", and Goodfellow, I", "label": ", and Goodfellow, I", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": ", and Peyr\u00b4e, G", "label": ", and Peyr\u00b4e, G", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": ", and Bengio, Y", "label": ", and Bengio, Y", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Latent predictor networks for code generation", "label": "Latent predictor networks for code generation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Material recognition in the wild with the materials in context database", "label": "Material recognition in the wild with the materials in context database", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Tensor\ufb02ow: A sys-In 12th USENIX tem for large-scale machine learning", "label": "Tensor\ufb02ow: A sys-In 12th USENIX tem for large-scale machine learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Collecting highly paral-lel data for paraphrase evaluation", "label": "Collecting highly paral-lel data for paraphrase evaluation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Revisit-ing distributed synchronous sgd", "label": "Revisit-ing distributed synchronous sgd", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Mxnet: A \ufb02exible and e\ufb03cient machine learning library for heterogeneous dis-tributed systems", "label": "Mxnet: A \ufb02exible and e\ufb03cient machine learning library for heterogeneous dis-tributed systems", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Pipelined Back-propagation for Context-dependent Deep Neural Networks", "label": "Pipelined Back-propagation for Context-dependent Deep Neural Networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Project adam: Building an e\ufb03cient and scalable deep learning training system", "label": "Project adam: Building an e\ufb03cient and scalable deep learning training system", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Geeps: Scalable deep learning on distributed gpus with a gpu-specialized parameter server", "label": "Geeps: Scalable deep learning on distributed gpus with a gpu-specialized parameter server", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Meteor universal: Language speci\ufb01c translation evaluation for any target language", "label": "Meteor universal: Language speci\ufb01c translation evaluation for any target language", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Adaptive subgradi-ent methods for online learning and stochastic optimiza-tion", "label": "Adaptive subgradi-ent methods for online learning and stochastic optimiza-tion", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Accurate", "label": "Accurate", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Omnivore: An optimizer for multi-device deep learning on cpus and gpus", "label": "Omnivore: An optimizer for multi-device deep learning on cpus and gpus", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "More e\ufb00ective distributed ml via a stale synchronous parallel parame-ter server", "label": "More e\ufb00ective distributed ml via a stale synchronous parallel parame-ter server", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Batch normalization: Accelerat-ing deep network training by reducing internal covariate shift", "label": "Batch normalization: Accelerat-ing deep network training by reducing internal covariate shift", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Ca\ufb00e: Con-volutional architecture for fast feature embedding", "label": "Ca\ufb00e: Con-volutional architecture for fast feature embedding", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A convolutional neural network for modelling sentences", "label": "A convolutional neural network for modelling sentences", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Large-scale video classi\ufb01cation with convolutional neural networks", "label": "Large-scale video classi\ufb01cation with convolutional neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Practical bayesian optimization of machine learning algorithms", "label": "Practical bayesian optimization of machine learning algorithms", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Automating model search for large scale machine learning", "label": "Automating model search for large scale machine learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Optimization of collective communication operations in mpich", "label": "Optimization of collective communication operations in mpich", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Lecture 6", "label": "Lecture 6", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A bridging model for parallel computation", "label": "A bridging model for parallel computation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Sequence to sequence-video to text", "label": "Sequence to sequence-video to text", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Show and tell: A neural image caption generator", "label": "Show and tell: A neural image caption generator", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Lightlda: Big topic models on modest computer clusters", "label": "Lightlda: Big topic models on modest computer clusters", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Poseidon: An ef-\ufb01cient communication architecture for distributed deep In 2017 USENIX Annual learning on GPU clusters", "label": "Poseidon: An ef-\ufb01cient communication architecture for distributed deep In 2017 USENIX Annual learning on GPU clusters", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "STRADS: a distributed framework for scheduled model parallel machine learning", "label": "STRADS: a distributed framework for scheduled model parallel machine learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "On model parallelization and scheduling strategies for distributed machine learning", "label": "On model parallelization and scheduling strategies for distributed machine learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Scaling distributed machine learning with the parameter server", "label": "Scaling distributed machine learning with the parameter server", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Distributed graphlab: A framework for machine learning in the cloud", "label": "Distributed graphlab: A framework for machine learning in the cloud", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "De-vice placement optimization with reinforcement learning", "label": "De-vice placement optimization with reinforcement learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "On bayesian methods for seeking the ex-tremum", "label": "On bayesian methods for seeking the ex-tremum", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "CNTK: Microsoft\u2019s open-source deep-learning toolkit", "label": "CNTK: Microsoft\u2019s open-source deep-learning toolkit", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "On paralleliz-ability of stochastic gradient descent for speech dnns", "label": "On paralleliz-ability of stochastic gradient descent for speech dnns", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "1-bit stochas-tic gradient descent and its application to data-parallel distributed training of speech dnns", "label": "1-bit stochas-tic gradient descent and its application to data-parallel distributed training of speech dnns", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Visual recognition with humans in the loop", "label": "Visual recognition with humans in the loop", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Towards scalable dataset construction: An active learning approach", "label": "Towards scalable dataset construction: An active learning approach", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Scalable multi-label annotation", "label": "Scalable multi-label annotation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning generative visual models from few training examples: An incremental bayesian approach tested on 101 object categories", "label": "Learning generative visual models from few training examples: An incremental bayesian approach tested on 101 object categories", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep neural networks are easily fooled: High con\ufb01dence predictions for unrecognizable images", "label": "Deep neural networks are easily fooled: High con\ufb01dence predictions for unrecognizable images", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Best of both worlds: human-machine collaboration for object annotation", "label": "Best of both worlds: human-machine collaboration for object annotation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Active learning literature survey", "label": "Active learning literature survey", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Intriguing properties of neural networks", "label": "Intriguing properties of neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Support vector machine active learning with applications to text classi\ufb01cation", "label": "Support vector machine active learning with applications to text classi\ufb01cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multi-level active prediction of useful image annotations for In D", "label": "Multi-level active prediction of useful image annotations for In D", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multiclass recognition and part localization with humans in the loop", "label": "Multiclass recognition and part localization with humans in the loop", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep image: Scaling up image recognition", "label": "Deep image: Scaling up image recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Squeezeseg: Convolutional neural nets with recurrent crf for real-time road-object segmentation from 3d lidar point cloud", "label": "Squeezeseg: Convolutional neural nets with recurrent crf for real-time road-object segmentation from 3d lidar point cloud", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning by tracking: siamese cnn for robust target association", "label": "Learning by tracking: siamese cnn for robust target association", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Discrete-continuous optimization for multi-target tracking", "label": "Discrete-continuous optimization for multi-target tracking", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Robust online multi-object tracking based on tracklet con\ufb01dence and online discriminative appearance learning", "label": "Robust online multi-object tracking based on tracklet con\ufb01dence and online discriminative appearance learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Robust people tracking with global trajectory optimization", "label": "Robust people tracking with global trajectory optimization", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multiple object track-ing using k-shortest paths optimization", "label": "Multiple object track-ing using k-shortest paths optimization", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Evaluating multiple object track-ing performance: The CLEAR MOT metrics", "label": "Evaluating multiple object track-ing performance: The CLEAR MOT metrics", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Alextrac: Af\ufb01n-ity learning by exploring temporal reinforcement within association chains", "label": "Alextrac: Af\ufb01n-ity learning by exploring temporal reinforcement within association chains", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "xgboost: extreme gradient boosting", "label": "xgboost: extreme gradient boosting", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "CN-NTracker: Online discriminative object tracking via deep convolu-tional neural network", "label": "CN-NTracker: Online discriminative object tracking via deep convolu-tional neural network", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Near-online multi-target tracking with aggregated local \ufb02ow descriptor", "label": "Near-online multi-target tracking with aggregated local \ufb02ow descriptor", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multiple target tracking in world coordinate with single", "label": "Multiple target tracking in world coordinate with single", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A uni\ufb01ed framework for multi-target track-ing and collective activity recognition", "label": "A uni\ufb01ed framework for multi-target track-ing and collective activity recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The way they move: Tracking targets with similar appearance", "label": "The way they move: Tracking targets with similar appearance", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Classifying plankton with deep neural networks", "label": "Classifying plankton with deep neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Rotation-invariant convolu-tional neural networks for galaxy morphology prediction", "label": "Rotation-invariant convolu-tional neural networks for galaxy morphology prediction", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fast feature pyramids for object detection", "label": "Fast feature pyramids for object detection", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Human tracking using convo-IEEE Transactions on Neural Networks", "label": "Human tracking using convo-IEEE Transactions on Neural Networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Two-frame motion estimation based on polynomial expansion", "label": "Two-frame motion estimation based on polynomial expansion", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "FlowNet: Learning Optical Flow with Convolutional Networks", "label": "FlowNet: Learning Optical Flow with Convolutional Networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep-Stereo: Learning to predict new views from the world\u2019s imagery", "label": "Deep-Stereo: Learning to predict new views from the world\u2019s imagery", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Two-granularity tracking: mediating trajectory and detections graphs for tracking un-der occlusions", "label": "Two-granularity tracking: mediating trajectory and detections graphs for tracking un-der occlusions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Stochastic gradient boosting", "label": "Stochastic gradient boosting", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Hough forests for object detection", "label": "Hough forests for object detection", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "3d traf\ufb01c scene understanding from movable platforms", "label": "3d traf\ufb01c scene understanding from movable platforms", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Delving deep into recti-\ufb01ers: Surpassing human-level performance on imagenet classi\ufb01ca-tion", "label": "Delving deep into recti-\ufb01ers: Surpassing human-level performance on imagenet classi\ufb01ca-tion", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A linear programming approach for multiple object tracking", "label": "A linear programming approach for multiple object tracking", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Mcmc-based particle \ufb01ltering for tracking a variable number of interacting targets", "label": "Mcmc-based particle \ufb01ltering for tracking a variable number of interacting targets", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multiple hypothesis tracking revisited: Blending in modern appearance model", "label": "Multiple hypothesis tracking revisited: Blending in modern appearance model", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Lerning an image-based motion context for multiple people tracking", "label": "Lerning an image-based motion context for multiple people tracking", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Motchallenge 2015: Towards a benchmark for multi-target tracking", "label": "Motchallenge 2015: Towards a benchmark for multi-target tracking", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Everybody needs somebody: Modeling social and grouping behavior on a linear pro-gramming multiple people tracker", "label": "Everybody needs somebody: Modeling social and grouping behavior on a linear pro-gramming multiple people tracker", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Branch-and-price global optimization for multi-view multi-object tracking", "label": "Branch-and-price global optimization for multi-view multi-object tracking", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deeptrack: Learning discriminative fea-ture representations online for robust visual tracking", "label": "Deeptrack: Learning discriminative fea-ture representations online for robust visual tracking", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning to associate: Hybrid-boosted multi-target tracker for crowded scene", "label": "Learning to associate: Hybrid-boosted multi-target tracker for crowded scene", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multiple object tracking: A review", "label": "Multiple object tracking: A review", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Joint tracking and segmentation of multiple targets", "label": "Joint tracking and segmentation of multiple targets", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multi-target tracking by discrete-continuous energy minimization", "label": "Multi-target tracking by discrete-continuous energy minimization", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Continuous energy minimization for multitarget tracking", "label": "Continuous energy minimization for multitarget tracking", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Globally-optimal greedy algorithms for tracking a variable number of objects", "label": "Globally-optimal greedy algorithms for tracking a variable number of objects", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Joint probabilistic data association revisited", "label": "Joint probabilistic data association revisited", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning pedestrian dynamics from the real world", "label": "Learning pedestrian dynamics from the real world", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning to divide and conquer for online multi-target tracking", "label": "Learning to divide and conquer for online multi-target tracking", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "DeepFace: Clos-ing the gap to human-level performance in face veri\ufb01cation", "label": "DeepFace: Clos-ing the gap to human-level performance in face veri\ufb01cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Cas-caded ensemble of convolutional neural networks and handcrafted features for mitosis detection", "label": "Cas-caded ensemble of convolutional neural networks and handcrafted features for mitosis detection", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Transferring rich feature hierarchies for robust visual tracking", "label": "Transferring rich feature hierarchies for robust visual tracking", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning optimal parameters for multi-target tracking", "label": "Learning optimal parameters for multi-target tracking", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Stacked generalization", "label": "Stacked generalization", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Ef\ufb01cient track linking methods for track graphs using network-\ufb02ow and set-cover techniques", "label": "Ef\ufb01cient track linking methods for track graphs using network-\ufb02ow and set-cover techniques", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning to track: Online multi-object tracking by decision making", "label": "Learning to track: Online multi-object tracking by decision making", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Who are you with and where are you going? CVPR", "label": "Who are you with and where are you going? CVPR", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "An online learned crf model for multi-target tracking", "label": "An online learned crf model for multi-target tracking", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Bayesian multi-object track-ing using motion context from multiple objects", "label": "Bayesian multi-object track-ing using motion context from multiple objects", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multiple target tracking using spatio-temporal Markov chain Monte Carlo data association", "label": "Multiple target tracking using spatio-temporal Markov chain Monte Carlo data association", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning to compare image patches via convolutional neural networks", "label": "Learning to compare image patches via convolutional neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Gmcp-tracker: Global multi-object tracking using generalized minimum clique graphs", "label": "Gmcp-tracker: Global multi-object tracking using generalized minimum clique graphs", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Computing the stereo matching cost with a convolutional neural network", "label": "Computing the stereo matching cost with a convolutional neural network", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Improving multiview face detection with multi-task deep convolutional neural networks", "label": "Improving multiview face detection with multi-task deep convolutional neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Global data association for multi-object tracking using network \ufb02ows", "label": "Global data association for multi-object tracking using network \ufb02ows", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding", "label": "Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Squeezenet: Alexnet-level accuracy with 50x fewer parameters and\u00a1 1mb model size", "label": "Squeezenet: Alexnet-level accuracy with 50x fewer parameters and\u00a1 1mb model size", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Incremental network quantization: Towards lossless cnns with lowprecision weights", "label": "Incremental network quantization: Towards lossless cnns with lowprecision weights", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Inferring and executing programs for visual reasoning", "label": "Inferring and executing programs for visual reasoning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learn-ing to compose neural networks for question answering", "label": "Learn-ing to compose neural networks for question answering", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Neural module networks", "label": "Neural module networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "VQA: Visual question answering", "label": "VQA: Visual question answering", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deepcoder: Learning to write programs", "label": "Deepcoder: Learning to write programs", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Making neural programming architectures generalize via recursion", "label": "Making neural programming architectures generalize via recursion", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Visual dialog", "label": "Visual dialog", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Exploring nearest neighbor approaches for image cap-tioning", "label": "Exploring nearest neighbor approaches for image cap-tioning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multimodal compact bilinear pooling for visual question answering and visual grounding", "label": "Multimodal compact bilinear pooling for visual question answering and visual grounding", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Compact bilinear pooling", "label": "Compact bilinear pooling", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Making the V in VQA matter: Elevating the role of image understanding in visual question answering", "label": "Making the V in VQA matter: Elevating the role of image understanding in visual question answering", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Neural turing ma-chines", "label": "Neural turing ma-chines", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Modeling relationships in referential expressions with com-positional modular networks", "label": "Modeling relationships in referential expressions with com-positional modular networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Revisiting visual question answering baselines", "label": "Revisiting visual question answering baselines", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "CLEVR: A diagnostic dataset for compositional language and elementary visual reasoning", "label": "CLEVR: A diagnostic dataset for compositional language and elementary visual reasoning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Inferring algorithmic patterns with stack-augmented recurrent nets", "label": "Inferring algorithmic patterns with stack-augmented recurrent nets", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Visual question answering: Datasets", "label": "Visual question answering: Datasets", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Accurate unlexicalized parsing", "label": "Accurate unlexicalized parsing", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Y", "label": "Y", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Neural random-access machines", "label": "Neural random-access machines", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Building machines that learn and think like people", "label": "Building machines that learn and think like people", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Neural symbolic machines: Learning semantic parsers on freebase with weak supervision", "label": "Neural symbolic machines: Learning semantic parsers on freebase with weak supervision", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning dependency-based compositional semantics", "label": "Learning dependency-based compositional semantics", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Hierarchical question-image co-attention for visual question answering", "label": "Hierarchical question-image co-attention for visual question answering", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A multi-world approach to question answering about real-world scenes based on uncer-tain input", "label": "A multi-world approach to question answering about real-world scenes based on uncer-tain input", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Ask your neu-rons: A neural-based approach to answering questions about images", "label": "Ask your neu-rons: A neural-based approach to answering questions about images", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning models for actions and person-object interactions with transfer to question answer-ing", "label": "Learning models for actions and person-object interactions with transfer to question answer-ing", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Neural pro-grammer: Inducing latent programs with gradient descent", "label": "Neural pro-grammer: Inducing latent programs with gradient descent", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Neural programmer-interpreters", "label": "Neural programmer-interpreters", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "End-to-end memory networks", "label": "End-to-end memory networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Movieqa: Understanding stories in movies through question-answering", "label": "Movieqa: Understanding stories in movies through question-answering", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Memory networks", "label": "Memory networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Simple statistical gradient-following algo-rithms for connectionist reinforcement learning", "label": "Simple statistical gradient-following algo-rithms for connectionist reinforcement learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Understanding Natural Language", "label": "Understanding Natural Language", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Visual question answering: A survey of methods and datasets", "label": "Visual question answering: A survey of methods and datasets", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Dynamic memory net-ICML", "label": "Dynamic memory net-ICML", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Stacked attention networks for image question answering", "label": "Stacked attention networks for image question answering", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning simple algorithms from examples", "label": "Learning simple algorithms from examples", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning to execute", "label": "Learning to execute", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Reinforcement learning neural turing machines", "label": "Reinforcement learning neural turing machines", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Yin and yang: Balancing and answering binary visual questions", "label": "Yin and yang: Balancing and answering binary visual questions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Visual7W: Grounded question answering in images", "label": "Visual7W: Grounded question answering in images", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "TensorFlow: Large-scale machine learning on heterogeneous systems", "label": "TensorFlow: Large-scale machine learning on heterogeneous systems", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Tensor-\ufb02ow: Large-scale machine learning on heteroge-neous distributed systems", "label": "Tensor-\ufb02ow: Large-scale machine learning on heteroge-neous distributed systems", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Pedestrian detection with a large-\ufb01eld-of-view deep network", "label": "Pedestrian detection with a large-\ufb01eld-of-view deep network", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multiple ob-ject recognition with visual attention", "label": "Multiple ob-ject recognition with visual attention", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "vin", "label": "vin", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Web 1T 5-gram version 1", "label": "Web 1T 5-gram version 1", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The Chubby lock service for loosely-In Proceedings of coupled distributed systems", "label": "The Chubby lock service for loosely-In Proceedings of coupled distributed systems", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Sample size selection in optimization methods for machine learning", "label": "Sample size selection in optimization methods for machine learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "One billion word bench-mark for measuring progress in statistical lan-CoRR", "label": "One billion word bench-mark for measuring progress in statistical lan-CoRR", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "In Inter-Revisiting distributed synchronous SGD", "label": "In Inter-Revisiting distributed synchronous SGD", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "MXNet: A \ufb02exible and ef\ufb01cient machine learning library for heterogeneous dis-In Proceedings of the Workshop tributed systems", "label": "MXNet: A \ufb02exible and ef\ufb01cient machine learning library for heterogeneous dis-In Proceedings of the Workshop tributed systems", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "cuDNN: Ef\ufb01cient primitives for deep learning", "label": "cuDNN: Ef\ufb01cient primitives for deep learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Project Adam: Building an ef\ufb01cient and scalable deep learning train-In 11th USENIX Symposium ing system", "label": "Project Adam: Building an ef\ufb01cient and scalable deep learning train-In 11th USENIX Symposium ing system", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "convnet-benchmarks", "label": "convnet-benchmarks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "LIN-In Proceed-Qits: Big data on little clients", "label": "LIN-In Proceed-Qits: Big data on little clients", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The missing piece in complex analytics: Low latency", "label": "The missing piece in complex analytics: Low latency", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "GeePS: Scalable deep learning on distributed GPUs with a GPU-specialized parameter server", "label": "GeePS: Scalable deep learning on distributed GPUs with a GPU-specialized parameter server", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Document em-arXiv preprint bedding with paragraph vectors", "label": "Document em-arXiv preprint bedding with paragraph vectors", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Mapreduce: Simpli\ufb01ed In Proceedings data processing on large clusters", "label": "Mapreduce: Simpli\ufb01ed In Proceedings data processing on large clusters", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multilin-gual acoustic models using distributed deep neural In Acoustics", "label": "Multilin-gual acoustic models using distributed deep neural In Acoustics", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Mesos: A platform for \ufb01ne-grained resource In Proceedings of the sharing in the data center", "label": "Mesos: A platform for \ufb01ne-grained resource In Proceedings of the sharing in the data center", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning distributed representa-In Proceedings of the Eighth tions of concepts", "label": "Learning distributed representa-In Proceedings of the Eighth tions of concepts", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep neural networks for acoustic modeling in speech recognition: The shared views of four research IEEE Signal Process", "label": "Deep neural networks for acoustic modeling in speech recognition: The shared views of four research IEEE Signal Process", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "ZooKeeper: Wait-free coordination for internet-the 2010 scale systems", "label": "ZooKeeper: Wait-free coordination for internet-the 2010 scale systems", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Batch normalization: Ac-celerating deep network training by reducing inter-nal covariate shift", "label": "Batch normalization: Ac-celerating deep network training by reducing inter-nal covariate shift", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "a small self-contained low-precision GEMM library", "label": "a small self-contained low-precision GEMM library", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "On using very large target vocabulary for neural In Proceedings of the 53rd machine translation", "label": "On using very large target vocabulary for neural In Proceedings of the 53rd machine translation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Caffe: Convolutional architecture for fast fea-ture embedding", "label": "Caffe: Convolutional architecture for fast fea-ture embedding", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Serial order: A parallel dis-ICS report Institute for Cognitive Science", "label": "Serial order: A parallel dis-ICS report Institute for Cognitive Science", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Google supercharges machine learning tasks with TPU custom chip", "label": "Google supercharges machine learning tasks with TPU custom chip", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "One weird trick for paralleliz-ing convolutional neural networks", "label": "One weird trick for paralleliz-ing convolutional neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Ima-geNet classi\ufb01cation with deep convolutional neural networks", "label": "Ima-geNet classi\ufb01cation with deep convolutional neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Exploring strategies for training deep Journal of Machine Learn-neural networks", "label": "Exploring strategies for training deep Journal of Machine Learn-neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fast algorithms for convo-lutional neural networks", "label": "Fast algorithms for convo-lutional neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Building high-level features using large scale unsupervised learn-ing", "label": "Building high-level features using large scale unsupervised learn-ing", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Scaling distributed machine learn-In 11th USENIX ing with the Parameter Server", "label": "Scaling distributed machine learn-In 11th USENIX ing with the Parameter Server", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Ef\ufb01cient mini-batch training for stochastic opti-the 20th ACM mization", "label": "Ef\ufb01cient mini-batch training for stochastic opti-the 20th ACM mization", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "lan-guage modeling", "label": "lan-guage modeling", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Move evaluation in Go using deep convolutional neural networks", "label": "Move evaluation in Go using deep convolutional neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Scal-In Proceedings ability! But at what COST? of the 15th USENIX Conference on Hot Top-ics in Operating Systems", "label": "Scal-In Proceedings ability! But at what COST? of the 15th USENIX Conference on Hot Top-ics in Operating Systems", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Ef\ufb01cient estimation of word representations in In International Conference on vector space", "label": "Ef\ufb01cient estimation of word representations in In International Conference on vector space", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Human-level control through deep reinforcement learning", "label": "Human-level control through deep reinforcement learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "SparkNet: Training deep networks in Spark", "label": "SparkNet: Training deep networks in Spark", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Naiad: a timely data\ufb02ow system", "label": "Naiad: a timely data\ufb02ow system", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Toward acceler-ating deep learning at scale using specialized In Hot Chips: A Symposium on High logic", "label": "Toward acceler-ating deep learning at scale using specialized In Hot Chips: A Symposium on High logic", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "On the dif\ufb01culty of training recurrent neural net-In ICML (3)", "label": "On the dif\ufb01culty of training recurrent neural net-In ICML (3)", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Nvidia devtech blog post", "label": "Nvidia devtech blog post", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Hogwild: A lock-free approach to parallelizing stochastic In Advances in Neural In-gradient descent", "label": "Hogwild: A lock-free approach to parallelizing stochastic In Advances in Neural In-gradient descent", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Dandelion: a compiler and runtime In Proceedings of for heterogeneous systems", "label": "Dandelion: a compiler and runtime In Proceedings of for heterogeneous systems", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "ImageNet Large Scale Visual International Journal of Recognition Challenge", "label": "ImageNet Large Scale Visual International Journal of Recognition Challenge", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "chitecture for parallel topic models", "label": "chitecture for parallel topic models", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "On recti\ufb01ed lin-ear units for speech processing", "label": "On recti\ufb01ed lin-ear units for speech processing", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "On the importance of initialization and In Proceedings momentum in deep learning", "label": "On the importance of initialization and In Proceedings momentum in deep learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Large-scale clus-In Pro-ter management at Google with Borg", "label": "Large-scale clus-In Pro-ter management at Google with Borg", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Grammar as a foreign lan-guage", "label": "Grammar as a foreign lan-guage", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "DryadLINQ: A system for general-purpose distributed data-parallel lan-the 8th USENIX guage", "label": "DryadLINQ: A system for general-purpose distributed data-parallel lan-the 8th USENIX guage", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep convolutional ranking for multilabel image annotation", "label": "Deep convolutional ranking for multilabel image annotation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning the semantics of words and pictures", "label": "Learning the semantics of words and pictures", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Animals on the web", "label": "Animals on the web", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "hierarchical image database", "label": "hierarchical image database", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Object recognition as machine translation: Learning a lexicon for a \ufb01xed image vocabulary", "label": "Object recognition as machine translation: Learning a lexicon for a \ufb01xed image vocabulary", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Semi-supervised learning in gigantic image collections", "label": "Semi-supervised learning in gigantic image collections", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A multi-view embedding space for internet images, tags, and their semantics", "label": "A multi-view embedding space for internet images, tags, and their semantics", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "learning binary codes", "label": "learning binary codes", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multimodal semi-supervised learning for image classi\ufb01cation", "label": "Multimodal semi-supervised learning for image classi\ufb01cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Beyond bags of features: Spatial pyra-mid matching for recognizing natural scene categories", "label": "Beyond bags of features: Spatial pyra-mid matching for recognizing natural scene categories", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A new baseline for image annotation", "label": "A new baseline for image annotation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Modeling the shape of the scene: a holistic representation of the spatial envelope", "label": "Modeling the shape of the scene: a holistic representation of the spatial envelope", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fisher kernels on visual vocabularies for image categorization", "label": "Fisher kernels on visual vocabularies for image categorization", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Evaluating color descriptors for object and scene recognition", "label": "Evaluating color descriptors for object and scene recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Regularization of neural networks using dropconnect", "label": "Regularization of neural networks using dropconnect", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Wsabie: Scaling up to large vocabulary image annotation", "label": "Wsabie: Scaling up to large vocabulary image annotation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Linear spatial pyramid matching uisng sparse coding for image classi\ufb01cation", "label": "Linear spatial pyramid matching uisng sparse coding for image classi\ufb01cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Stochastic pooling for regularization of deep convolutional neural networks", "label": "Stochastic pooling for regularization of deep convolutional neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Circulant binary embedding", "label": "Circulant binary embedding", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep structure inference network for facial action unit recognition", "label": "Deep structure inference network for facial action unit recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Personalised gam-ing", "label": "Personalised gam-ing", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Structure inference machines: Recurrent neural networks for an-alyzing relations in group activity recognition", "label": "Structure inference machines: Recurrent neural networks for an-alyzing relations in group activity recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A virtual human inter-viewer for healthcare decision support", "label": "A virtual human inter-viewer for healthcare decision support", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Facial action unit event detection by cas-cade of tasks", "label": "Facial action unit event detection by cas-cade of tasks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Facs manual", "label": "Facs manual", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Multi-conditional latent variable model for joint facial action unit detection", "label": "Multi-conditional latent variable model for joint facial action unit detection", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Recognition of action units in the wild with deep nets and a new global-local loss", "label": "Recognition of action units in the wild with deep nets and a new global-local loss", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Role of facial expressions in social interac-tions", "label": "Role of facial expressions in social interac-tions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep learning the dynamic appearance and shape of facial action units", "label": "Deep learning the dynamic appearance and shape of facial action units", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Continu-ous pain intensity estimation from facial expressions", "label": "Continu-ous pain intensity estimation from facial expressions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Auto-matic prediction of frustration", "label": "Auto-matic prediction of frustration", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "One millisecond face align-ment with an ensemble of regression trees", "label": "One millisecond face align-ment with an ensemble of regression trees", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Automatic recognition of deceptive facial expressions of emotion", "label": "Automatic recognition of deceptive facial expressions of emotion", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Bp4d-spontaneous: a high-resolution spontaneous 3d dy-namic facial expression database", "label": "Bp4d-spontaneous: a high-resolution spontaneous 3d dy-namic facial expression database", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Joint patch and multi-label learning for fa-cial action unit detection", "label": "Joint patch and multi-label learning for fa-cial action unit detection", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep region and multi-label learning for facial action unit detection", "label": "Deep region and multi-label learning for facial action unit detection", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Condi-tional random \ufb01elds as recurrent neural networks", "label": "Condi-tional random \ufb01elds as recurrent neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning multiscale active facial patches for expression analysis", "label": "Learning multiscale active facial patches for expression analysis", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Action unit de-tection with region adaptation", "label": "Action unit de-tection with region adaptation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Automatically detecting pain in video through facial action units", "label": "Automatically detecting pain in video through facial action units", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep face In British Machine Vision Conference", "label": "Deep face In British Machine Vision Conference", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Grad-cam: Visual explana-tions from deep networks via gradient-based localiza-tion", "label": "Grad-cam: Visual explana-tions from deep networks via gradient-based localiza-tion", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Very deep convo-lutional networks for large-scale image recognition", "label": "Very deep convo-lutional networks for large-scale image recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Ex-ploiting sparsity and co-occurrence structure for ac-tion unit recognition", "label": "Ex-ploiting sparsity and co-occurrence structure for ac-tion unit recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep-face: Closing the gap to human-level performance in face veri\ufb01cation", "label": "Deep-face: Closing the gap to human-level performance in face veri\ufb01cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Social sig-nal processing: Survey of an emerging domain", "label": "Social sig-nal processing: Survey of an emerging domain", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Capturing global semantic relationships for facial action unit recogni-tion", "label": "Capturing global semantic relationships for facial action unit recogni-tion", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Constrained joint cascade regression framework for simultaneous facial action unit recogni-tion and facial landmark detection", "label": "Constrained joint cascade regression framework for simultaneous facial action unit recogni-tion and facial landmark detection", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Con\ufb01dence preserving machine for facial ac-tion unit detection", "label": "Con\ufb01dence preserving machine for facial ac-tion unit detection", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Task-dependent multi-task multiple kernel learning for facial action unit de-tection", "label": "Task-dependent multi-task multiple kernel learning for facial action unit de-tection", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Extending the openai gym for robotics: a toolkit for reinforcearXiv preprint ment learning using ros and gazebo", "label": "Extending the openai gym for robotics: a toolkit for reinforcearXiv preprint ment learning using ros and gazebo", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "On-line Q-learning using connectionist systems", "label": "On-line Q-learning using connectionist systems", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "SqueezeNet: AlexNetlevel accuracy with 50x fewer parameters and\u003c 0", "label": "SqueezeNet: AlexNetlevel accuracy with 50x fewer parameters and\u003c 0", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Squeezenet: Alexnet-level accuracy with 50x fewer parameters and\u00a1 0", "label": "Squeezenet: Alexnet-level accuracy with 50x fewer parameters and\u00a1 0", "shape": "dot", "size": 10}]);
        edges = new vis.DataSet([{"from": "", "to": "PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database", "weight": 1}, {"from": "PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database", "to": "Deep learning for visual understanding: A review", "weight": 1}, {"from": "PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database", "to": "Deep convolutional neural networks for image classification: A comprehensive review", "weight": 1}, {"from": "PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database", "to": "Deepfashion: Powering robust clothes recognition and retrieval with rich annotations", "weight": 1}, {"from": "PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database", "to": "3d shapenets: A deep representation for volumetric shapes", "weight": 1}, {"from": "PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database", "to": "Seeing 3d chairs: exemplar part-based 2d-3d alignment using a large dataset of cad models", "weight": 1}, {"from": "PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database", "to": "Benchmark Datasets for Fault Detection and Classification in Sensor Data", "weight": 1}, {"from": "PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database", "to": "A style-based generator architecture for generative adversarial networks", "weight": 1}, {"from": "PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database", "to": "A compact embedding for facial expression similarity", "weight": 1}, {"from": "PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database", "to": "Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding", "weight": 1}, {"from": "PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database", "to": "3d object representations for fine-grained categorization", "weight": 1}, {"from": "PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database", "to": "Fashionista: A fashion-aware graphical system for exploring visually similar items", "weight": 1}, {"from": "PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database", "to": "Fashionai: A hierarchical dataset for fashion understanding", "weight": 1}, {"from": "PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database", "to": "Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms", "weight": 1}, {"from": "PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database", "to": "Fashion-gen: The generative fashion dataset and challenge", "weight": 1}, {"from": "PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database", "to": "Very deep convolutional networks for large-scale image recognition", "weight": 1}, {"from": "PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database", "to": "Going deeper with convolutions", "weight": 1}, {"from": "PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database", "to": "Deep residual learning for image recognition", "weight": 1}, {"from": "PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database", "to": "Densely connected convolutional networks", "weight": 1}, {"from": "PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database", "to": "Efficientnet: Rethinking model scaling for convolutional neural networks", "weight": 1}, {"from": "PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database", "to": "Central similarity quantization for efficient image and video retrieval", "weight": 1}, {"from": "PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database", "to": "Hashnet: Deep learning to hash by continuation", "weight": 1}, {"from": "PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database", "to": "Incomplete multi-modal visual data grouping", "weight": 1}, {"from": "PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database", "to": "Doubly Aligned Incomplete Multi-view Clustering", "weight": 1}, {"from": "PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database", "to": "Incomplete Multiview Spectral Clustering With Adaptive Graph Learning", "weight": 1}, {"from": "PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database", "to": "Anchors bring ease: An embarrassingly simple approach to partial multi-view clustering", "weight": 1}, {"from": "PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database", "to": "A comparison of extrinsic clustering evaluation metrics based on formal constraints", "weight": 1}, {"from": "PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database", "to": "Adaptive structure discovery for multimedia analysis using multiple features", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Emotionet: An accurate", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Large scale online learning of image similarity through ranking", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Deep struc-ture inference network for facial action unit recognition", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Self-report captures 27 dis-tinct categories of emotion bridged by continuous gradi-ents", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Clarifying the conceptualiza-tion", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "From individual to group-level emotion recog-nition: Emotiw 5", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "R", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "O", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Facial Action Coding System -Manual", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Candid portrait ACM Transactions on Graphics", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Deep metric learning with hierarchical triplet loss", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Understanding the dif\ufb01culty of In AISTATS", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Challenges in representation learning: A report on three machine learning contests", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "I", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "MS-Celeb-1M: A dataset and benchmark for large scale face recognition", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Triplet-center loss for multi-view 3D object retrieval", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "In defense of the triplet loss for person re-identi\ufb01cation", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Densely connected convolutional networks", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "The MegaFace benchmark: 1 million faces for recognition at scale", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Adam: A method for stochastic optimization", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "DEAP: A database for emotion analysis using physiological sig-nals", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Self-supervised In learning of a facial attribute embedding from video", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Deep af-fect prediction in-the-wild: Aff-wild database and challenge", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "AFEW-VA database for valence and arousal estimation in-the-wild", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Convolutional deep belief networks on CIFAR-10", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Deep facial expression recognition: A survey", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Reliable crowdsourcing and deep locality-preserving learning for unconstrained facial expres-sion recognition", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Deep relative distance learning: Tell the difference between similar vehicles", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Deep learning face attributes in the wild", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "The extended Cohn-Kanade dataset (CK+): A complete dataset for action unit and emotion-speci\ufb01ed expression", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Auto-matic analysis of facial actions: A survey", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Facial expression recognition from near-infrared videos", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Fast training of triplet-based deep binary embedding networks", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Affectiva-MIT facial expression dataset (AM-FED): Naturalistic and spontaneous facial expressions collected in-the-wild", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Basic dimensions for a general psychological theory: Implications for personality", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "LSTM-based facial performance capture using embedding between expressions", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Affect-Net: A database for facial expression", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Facial expression recognition from world wild web", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Level playing \ufb01eld for million scale face recognition", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Web-In ICME", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Introducing the RECOLA multimodal corpus of remote col-laborative and affective interactions", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "A circumplex model of affect", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "FaceNet: A In uni\ufb01ed embedding for face recognition and clustering", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Deep adaptive attention for joint facial action unit detection and face alignment", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Deep metric learning via lifted structured feature embedding", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "DeepFace: Closing the gap to human-level performance in face veri\ufb01ca-tion", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Learning \ufb01ne-grained im-age similarity with deep ranking", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Deep metric learning with angular loss", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Distance metric learning for large margin nearest neighbor classi\ufb01cation", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "From facial expression recognition to interpersonal relation prediction", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding", "to": "Mesh segmentation-a comparative study", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding", "to": "A framework for the objective evaluation of segmentation algorithms using a ground-truth of human segmented 3D-models", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding", "to": "T", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding", "to": "Linking WordNet to 3D shapes", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding", "to": "A benchmark for 3D mesh segmentation", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding", "to": "3D se-mantic segmentation with submanifold sparse convolutional networks", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding", "to": "Parts of recognition", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding", "to": "Co-segmentation of 3D shapes via subspace clustering", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding", "to": "Learning to predict part mobility from a sin-gle static snapshot", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding", "to": "Learning how objects function via co-analysis of interactions", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding", "to": "Predictive and generative neural networks for object functionality", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding", "to": "Robust watertight mani-fold surface generation method for shapenet models", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding", "to": "Explor-ing shape variations by 3d-model decomposition and part-In Computer Graphics Forum", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding", "to": "Learning 3D mesh segmentation and labeling", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding", "to": "Shape2pose: Human-centric shape analysis", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding", "to": "Escape from cells: Deep kd-networks for the recognition of 3D point cloud models", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding", "to": "Ai2-thor: An interactive 3d environment for vi-sual ai", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding", "to": "Parameter learning and con-vergent inference for dense random \ufb01elds", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding", "to": "The hungarian method for the assignment prob-lem", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding", "to": "PointGrid: A deep network for 3D shape understanding", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding", "to": "SO-Net: Self-organizing network for point cloud analysis", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding", "to": "Grass: Generative recursive autoencoders for shape structures", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding", "to": "PointCNN: Convolution on X -transformed points", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding", "to": "Physical primitive decomposition", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding", "to": "Explo-ration of continuous variability in collections of 3d shapes", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding", "to": "Virtualhome: Simulating household activities via programs", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding", "to": "PointNet: Deep learning on point sets for 3D classi\ufb01cation and segmentation", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding", "to": "PointNet++: Deep hierarchical feature learning on point sets in a metric space", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding", "to": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Con-point cloud processing", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding", "to": "Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding", "to": "SGPN: Sim-ilarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding", "to": "Learning to group and label \ufb01ne-grained shape components", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding", "to": "Active co-analysis of a set of shapes", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding", "to": "Dynamic graph cnn for learning on point clouds", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding", "to": "VoxSegNet: Volumetric CNNs for semantic part segmentation of 3D shapes", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding", "to": "Structure-aware generative network for 3d-shape modeling", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding", "to": "Spider-CNN: Deep learning on point sets with parameterized con-volutional \ufb01lters", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding", "to": "Chalet: Cornell house agent learning environment", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding", "to": "Learning hierarchical shape segmentation and labeling from online repositories", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding", "to": "V", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding", "to": "SyncSpecCNN: Syn-chronized spectral CNN for 3D shape segmentation", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding", "to": "Visual semantic plan-ning using deep successor representations", "weight": 1}, {"from": "Fashionista: A fashion-aware graphical system for exploring visually similar items", "to": "Image-based recommendations on styles and substitutes", "weight": 1}, {"from": "Fashionista: A fashion-aware graphical system for exploring visually similar items", "to": "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative \ufb01ltering", "weight": 1}, {"from": "Fashionista: A fashion-aware graphical system for exploring visually similar items", "to": "VBPR: visual bayesian personalized ranking from implicit feedback", "weight": 1}, {"from": "Fashionista: A fashion-aware graphical system for exploring visually similar items", "to": "Lotusx: a position-aware xml graphical search system with auto-completion", "weight": 1}, {"from": "Fashionista: A fashion-aware graphical system for exploring visually similar items", "to": "Imagenet classi\ufb01cation with deep convolutional neural networks", "weight": 1}, {"from": "Fashionista: A fashion-aware graphical system for exploring visually similar items", "to": "One-class collaborative \ufb01ltering", "weight": 1}, {"from": "Fashionista: A fashion-aware graphical system for exploring visually similar items", "to": "Accelerating t-SNE using tree-based algorithms", "weight": 1}, {"from": "Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms", "to": "", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "A note on the inception score", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Viton: An image-based virtual try-on network", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Stacked generative adversarial networks", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Image-to-image translation with conditional adversarial networks", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Getting the look: clothing recognition and segmentation for automatic prod-uct suggestions in everyday photos", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Progres-sive growing of gans for improved quality, stability, and variation", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Where to buy it: Matching street clothing photos in online shops", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Hierar-chical adversarially learned inference", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": ", et al", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Apparel classi\ufb01cation with style", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Clothes co-parsing via joint image segmentation and la-beling with application to clothing retrieval", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Describing cloth-ing by semantic attributes", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Deep domain adaptation for describing people based on \ufb01ne-grained clothing attributes", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Stochastic video generation with a learned prior", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "et al", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Microsoft coco: Common objects in context", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Street-to-shop: Cross-scenario clothing retrieval via parts In Computer Vision and alignment and auxiliary set", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Deep learning face attributes in the wild", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": ", and Tang, X", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Unpaired image-to-image translation using cycle-consistent adver-sarial networks", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Generative adversarial text to image synthesis", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Improved techniques for training In Advances in Neural Information Processing gans", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Bidirectional recurrent neural networks", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Neuroaesthetics in fashion: Modeling the perception of fashionability", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Amortised map inference for image super-resolution", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Unsuper-vised cross-domain image generation", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Visualizing data us-ing t-SNE", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Attention is all you need", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Learning visual clothing style with heteroge-neous dyadic co-occurrences", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Birdsnap: Large-scale \ufb01ne-grained visual categorization of birds", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Food-101\u2013 mining discriminative components with random forests", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Proxylessnas: Direct neural architecture search on target task and hardware", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Xception: Deep learning with depthwise separa-ble convolutions", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Autoaugment: Learning augmentation policies from data", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Sigmoid-weighted linear units for neural network function approximation in reinforcement learning", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Squeezenext: Hardware-aware neural network design", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Deep residual learning for image recognition", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Mask r-cnn", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Amc: Automl for model compression and acceleration on mobile devices", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Gaussian error linear units (gelus)", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Mobilenets: Ef\ufb01cient convolutional neural networks for mobile vision applications", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Squeeze-and-excitation net-works", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Deep networks with stochastic depth", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Densely connected convolutional networks", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Gpipe: Ef\ufb01cient training of giant neural networks using pipeline parallelism", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": ", and Keutzer, K", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "On the expressive power of deep neural networks", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "V", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Collecting a large-scale dataset of \ufb01ne-grained cars", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Learning multiple layers of features from tiny images", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Imagenet classi\ufb01cation with deep convolutional neural networks", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Searching for activation functions", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Regu-larized evolution for image classi\ufb01er architecture search", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": ", et al", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Resnet with one-neuron hidden layers is a universal approximator", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Mobilenetv2: Inverted residuals and linear bottlenecks", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Feature pyramid networks for object detection", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Progressive neural architecture search", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "The expres-sive power of neural networks: A view from the width", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Shuf\ufb02enet v2: Practical guidelines for ef\ufb01cient cnn architecture design", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Explor-ing the limits of weakly supervised pretraining", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "On the expressive power of overlapping architectures of deep learning", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Dropout: a simple way to prevent neural networks from over\ufb01tting", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Going deeper with convolutions", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Rethinking the inception architecture for computer vision", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Inception-v4, inception-resnet and the impact of residual connections on learning", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Fine-grained visual classi\ufb01cation of aircraft", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "MnasNet: Platform-aware neural architecture search for mobile", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Domain adaptive transfer learning with spe-cialist models", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Aggre-gated residual transformations for deep neural networks", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Automated \ufb02ower clas-si\ufb01cation over a large number of classes", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Netadapt: Platform-aware neural net-work adaptation for mobile applications", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Cats and dogs", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Wide residual networks", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Polynet: A pursuit of structural diversity in very deep networks", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Shuf\ufb02enet: An ex-tremely ef\ufb01cient convolutional neural network for mobile devices", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Learning deep features for discriminative localization", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Neural architecture search with reinforcement learning", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Learning transferable architectures for scalable image recognition", "weight": 1}, {"from": "Central similarity quantization for efficient image and video retrieval", "to": "", "weight": 1}, {"from": "Hashnet: Deep learning to hash by continuation", "to": "", "weight": 1}, {"from": "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative \ufb01ltering", "to": "Instance-based learning algorithms", "weight": 1}, {"from": "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative \ufb01ltering", "to": "The bellkor solution to the net\ufb02ix prize", "weight": 1}, {"from": "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative \ufb01ltering", "to": "On the approximation of curves by line segments using dynamic programming", "weight": 1}, {"from": "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative \ufb01ltering", "to": "The net\ufb02ix prize", "weight": 1}, {"from": "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative \ufb01ltering", "to": "Image-based recommendations on styles and substitutes", "weight": 1}, {"from": "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative \ufb01ltering", "to": "One-class collaborative \ufb01ltering", "weight": 1}, {"from": "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative \ufb01ltering", "to": "Gbpr: Group preference based bayesian personalized ranking for one-class collaborative \ufb01ltering", "weight": 1}, {"from": "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative \ufb01ltering", "to": "One-class collaborative \ufb01ltering with random graphs", "weight": 1}, {"from": "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative \ufb01ltering", "to": "Bpr: Bayesian personalized ranking from implicit feedback", "weight": 1}, {"from": "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative \ufb01ltering", "to": "Imagenet large scale visual recognition challenge", "weight": 1}, {"from": "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative \ufb01ltering", "to": "Neuroaesthetics in fashion: Modeling the perception of fashionability", "weight": 1}, {"from": "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative \ufb01ltering", "to": "Matchbox: large scale online bayesian recommendations", "weight": 1}, {"from": "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative \ufb01ltering", "to": "The problem of concept drift: de\ufb01nitions and related work", "weight": 1}, {"from": "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative \ufb01ltering", "to": "Accelerating t-sne using tree-based algorithms", "weight": 1}, {"from": "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative \ufb01ltering", "to": "Learning visual clothing style with heterogeneous dyadic co-occurrences", "weight": 1}, {"from": "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative \ufb01ltering", "to": "Mining concept-drifting data streams using ensemble classi\ufb01ers", "weight": 1}, {"from": "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative \ufb01ltering", "to": "Beyond clicks: dwell time for personalization", "weight": 1}, {"from": "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative \ufb01ltering", "to": "Daily-aware personalized recommendation based on feature-level time series analysis", "weight": 1}, {"from": "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative \ufb01ltering", "to": "Leveraging social connections to improve personalized ranking for collaborative \ufb01ltering", "weight": 1}, {"from": "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative \ufb01ltering", "to": "Music recommendations with temporal context awareness", "weight": 1}, {"from": "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative \ufb01ltering", "to": "Is a picture really worth a thousand words?-on the role of images in e-commerce", "weight": 1}, {"from": "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative \ufb01ltering", "to": "Time weight collaborative \ufb01ltering", "weight": 1}, {"from": "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative \ufb01ltering", "to": "Decaf: A deep convolutional activation feature for generic visual recognition", "weight": 1}, {"from": "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative \ufb01ltering", "to": "Mymedialite: A free recommender system library", "weight": 1}, {"from": "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative \ufb01ltering", "to": "Determinants of internet auction success and closing price: An exploratory study", "weight": 1}, {"from": "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative \ufb01ltering", "to": "A study on the impact of product images on user clicks for online shopping", "weight": 1}, {"from": "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative \ufb01ltering", "to": "Vbpr: Visual bayesian personalized ranking from implicit feedback", "weight": 1}, {"from": "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative \ufb01ltering", "to": "Collaborative \ufb01ltering for implicit feedback datasets", "weight": 1}, {"from": "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative \ufb01ltering", "to": "Large scale visual recommendations from street fashion images", "weight": 1}, {"from": "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative \ufb01ltering", "to": "Caffe: Convolutional architecture for fast feature embedding", "weight": 1}, {"from": "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative \ufb01ltering", "to": "Getting the look: clothing recognition and segmentation for automatic product suggestions in everyday photos", "weight": 1}, {"from": "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative \ufb01ltering", "to": "Recognizing image style", "weight": 1}, {"from": "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative \ufb01ltering", "to": "Learning drifting concepts: Example selection vs", "weight": 1}, {"from": "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative \ufb01ltering", "to": "Collaborative \ufb01ltering with temporal dynamics", "weight": 1}, {"from": "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative \ufb01ltering", "to": "Advances in collaborative \ufb01ltering", "weight": 1}, {"from": "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative \ufb01ltering", "to": "Imagenet classi\ufb01cation with deep convolutional neural networks", "weight": 1}, {"from": "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative \ufb01ltering", "to": "Multi-relational matrix factorization using bayesian personalized ranking for social network data", "weight": 1}, {"from": "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative \ufb01ltering", "to": "Temporal diversity in recommender systems", "weight": 1}, {"from": "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative \ufb01ltering", "to": "RAPID: rating pictorial aesthetics using deep learning", "weight": 1}, {"from": "Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative \ufb01ltering", "to": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews", "weight": 1}, {"from": "VBPR: visual bayesian personalized ranking from implicit feedback", "to": "", "weight": 1}, {"from": "HoME: a arXiv preprint Household Multimodal Environment", "to": "Fostering mathematical thinking through playful learning", "weight": 1}, {"from": "HoME: a arXiv preprint Household Multimodal Environment", "to": "Object perception and object naming in early development", "weight": 1}, {"from": "HoME: a arXiv preprint Household Multimodal Environment", "to": "Infants rapidly learn word-referent mappings via cross-situational statistics", "weight": 1}, {"from": "HoME: a arXiv preprint Household Multimodal Environment", "to": "", "weight": 1}, {"from": "HoME: a arXiv preprint Household Multimodal Environment", "to": "Zero-shot task generalization with multi-task deep reinforcement learning", "weight": 1}, {"from": "HoME: a arXiv preprint Household Multimodal Environment", "to": "Guesswhat?! visual object discovery through multi-modal dialogue", "weight": 1}, {"from": "HoME: a arXiv preprint Household Multimodal Environment", "to": "Virtual embodiment: A scalable long-term strategy for arti\ufb01cial intelligence research", "weight": 1}, {"from": "HoME: a arXiv preprint Household Multimodal Environment", "to": "Imagenet classi\ufb01cation with deep convolutional neural networks", "weight": 1}, {"from": "HoME: a arXiv preprint Household Multimodal Environment", "to": "Distributed representations of words and phrases and their compositionality", "weight": 1}, {"from": "HoME: a arXiv preprint Household Multimodal Environment", "to": "Vqa: Visual question answering", "weight": 1}, {"from": "HoME: a arXiv preprint Household Multimodal Environment", "to": "The arcade learning environment: An evaluation platform for general agents", "weight": 1}, {"from": "HoME: a arXiv preprint Household Multimodal Environment", "to": "Gated-attention architectures for task-oriented language grounding", "weight": 1}, {"from": "HoME: a arXiv preprint Household Multimodal Environment", "to": "Word and object", "weight": 1}, {"from": "HoME: a arXiv preprint Household Multimodal Environment", "to": "Reinforcement learning with unsupervised auxiliary tasks", "weight": 1}, {"from": "HoME: a arXiv preprint Household Multimodal Environment", "to": "ImageNet Large Scale Visual Recognition Challenge", "weight": 1}, {"from": "HoME: a arXiv preprint Household Multimodal Environment", "to": "Domain randomization for transferring deep neural networks from simulation to the real world", "weight": 1}, {"from": "HoME: a arXiv preprint Household Multimodal Environment", "to": "Semantic scene completion from a single depth image", "weight": 1}, {"from": "HoME: a arXiv preprint Household Multimodal Environment", "to": "Accelerated beam tracing algorithm", "weight": 1}, {"from": "HoME: a arXiv preprint Household Multimodal Environment", "to": "Openai gym", "weight": 1}, {"from": "HoME: a arXiv preprint Household Multimodal Environment", "to": "The malmo platform for arti\ufb01cial intelligence experimentation", "weight": 1}, {"from": "HoME: a arXiv preprint Household Multimodal Environment", "to": "ViZDoom: A Doom-based AI research platform for visual reinforcement learning", "weight": 1}, {"from": "HoME: a arXiv preprint Household Multimodal Environment", "to": "Target-driven Visual Navigation in Indoor Scenes using Deep Reinforcement Learning", "weight": 1}, {"from": "HoME: a arXiv preprint Household Multimodal Environment", "to": "Vision-and-language navigation: Interpreting visually-grounded navigation instructions in real environments", "weight": 1}, {"from": "HoME: a arXiv preprint Household Multimodal Environment", "to": "Example-based synthesis of 3d object arrangements", "weight": 1}, {"from": "HoME: a arXiv preprint Household Multimodal Environment", "to": "Matterport3d: Learning from rgb-d data in indoor environments", "weight": 1}, {"from": "HoME: a arXiv preprint Household Multimodal Environment", "to": "Scenenet: An annotated model generator for indoor scene understanding", "weight": 1}, {"from": "HoME: a arXiv preprint Household Multimodal Environment", "to": "The panda3d graphics engine", "weight": 1}, {"from": "The arcade learning environment: An evaluation platform for general agents", "to": "", "weight": 1}, {"from": "Semantic scene completion from a single depth image", "to": "", "weight": 1}, {"from": "Matterport3d: Learning from rgb-d data in indoor environments", "to": "", "weight": 1}, {"from": "Scenenet: An annotated model generator for indoor scene understanding", "to": "Seeing 3D chairs: exemplar part-based 2D-3D alignment us-ing a large dataset of CAD models", "weight": 1}, {"from": "Scenenet: An annotated model generator for indoor scene understanding", "to": "Domain Separation Networks", "weight": 1}, {"from": "Scenenet: An annotated model generator for indoor scene understanding", "to": "ShapeNet: An Information-Rich 3D Model Repository", "weight": 1}, {"from": "Scenenet: An annotated model generator for indoor scene understanding", "to": "Procedural Generation of Videos to Train Deep Ac-tion Recognition Networks", "weight": 1}, {"from": "Scenenet: An annotated model generator for indoor scene understanding", "to": "Semantic Scene Completion from a Single Depth Image", "weight": 1}, {"from": "Scenenet: An annotated model generator for indoor scene understanding", "to": "Example-based synthesis of 3d object arrangements", "weight": 1}, {"from": "Scenenet: An annotated model generator for indoor scene understanding", "to": "Align-In ing 3D models to RGB-D images of cluttered scenes", "weight": 1}, {"from": "Scenenet: An annotated model generator for indoor scene understanding", "to": "Real-Time Camera Tracking: When is High Frame-Rate Best? In ECCV", "weight": 1}, {"from": "Scenenet: An annotated model generator for indoor scene understanding", "to": "V", "weight": 1}, {"from": "Scenenet: An annotated model generator for indoor scene understanding", "to": "A Benchmark for RGB-D Visual Odometry", "weight": 1}, {"from": "Scenenet: An annotated model generator for indoor scene understanding", "to": "Flownet 2", "weight": 1}, {"from": "Scenenet: An annotated model generator for indoor scene understanding", "to": "A practical guide to global illumination using photon maps", "weight": 1}, {"from": "Scenenet: An annotated model generator for indoor scene understanding", "to": "Imagenet clas-si\ufb01cation with deep convolutional neural networks", "weight": 1}, {"from": "Scenenet: An annotated model generator for indoor scene understanding", "to": "SemanticFusion: Dense 3D Semantic Mapping with Convo-lutional Neural Networks", "weight": 1}, {"from": "Scenenet: An annotated model generator for indoor scene understanding", "to": "Progressive photon mapping on gpus", "weight": 1}, {"from": "Scenenet: An annotated model generator for indoor scene understanding", "to": "Learning Deep Object Detectors from 3D Models", "weight": 1}, {"from": "Scenenet: An annotated model generator for indoor scene understanding", "to": "UnrealCV: Connecting computer vi-sion to unreal engine", "weight": 1}, {"from": "Scenenet: An annotated model generator for indoor scene understanding", "to": "Playing for data: Ground truth from computer games", "weight": 1}, {"from": "Scenenet: An annotated model generator for indoor scene understanding", "to": "The SYNTHIA Dataset: A large collection of synthetic images for semantic segmentation of urban scenes", "weight": 1}, {"from": "Scenenet: An annotated model generator for indoor scene understanding", "to": "On being the right scale: Sizing large collec-tions of 3D models", "weight": 1}, {"from": "Scenenet: An annotated model generator for indoor scene understanding", "to": "Indoor segmentation and support inference from RGBD images", "weight": 1}, {"from": "Scenenet: An annotated model generator for indoor scene understanding", "to": "SUN RGB-D: A In CVPR", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "Towards principled methods for training 1 generative adversarial networks", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "Wasserstein GAN", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "Neural photo editing with introspective adversarial networks", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "Mode regularized generative adversarial networks", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "Maximum-likelihood augmented discrete generative adversarial networks", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "InfoGAN: Interpretable representation learning by informa-tion maximizing generative adversarial nets", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "Deep generative In image models using a laplacian pyramid of adversarial networks", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "Tutorial on variational autoencoders", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "Generative multi-adversarial networks", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "Conditional generative adversarial networks for convolu-tional face generation", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "Generative adversarial nets", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "Improved training of wasserstein gans", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "Deep residual learning for image recognition", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "Gans trained by a two time-scale update rule converge to a local nash equilibrium", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "Stacked generative adversarial networks", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "Image-to-image translation with conditional adversarial networks", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "Progressive growing of gans for improved quality", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "Adam: A method for stochastic optimization", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "Autoencoding beyond pixels using a learned similarity metric", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "Photo-realistic single image super-resolution using a generative adversarial network", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "Generating images from captions with attention", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "Least squares generative adversarial networks", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "Unrolled generative adversarial networks", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "Conditional generative adversarial nets", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "Plug \u0026 play generative networks: Conditional iterative generation of images in latent space", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "Conditional image synthesis with auxiliary classi\ufb01er GANs", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "Unsupervised representation In learning with deep convolutional generative adversarial networks", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "Learning what and where to draw", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "Learning deep representations of \ufb01ne-grained visual descriptions", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "Generative adversarial text-to-image synthesis", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "Generating interpretable images with controllable structure", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "Stochastic backpropaga-In ICML", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "The statistics of natural images", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "ImageNet Large Scale Visual Recognition Challenge", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "Improved techniques for training GANs", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "Rethinking the inception architecture for computer vision", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "Amortised map inference for image super-resolution", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "Unsupervised cross-domain image generation", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "Pixel recurrent neural networks", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "N", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "Visualizing high-dimensional data using t-sne", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "Matching networks for one shot learning", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "Generating videos with scene dynamics", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "The Caltech-UCSD Birds-200-2011 Dataset", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "Generative image modeling using style and structure adversarial networks", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "Multi-scale structural In Signals", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "Attribute2image: Conditional image generation from visual attributes", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "LR-GAN: layered recursive generative adversarial networks for image generation", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "LSUN: Construction of a large-scale image dataset using deep learning with humans in the loop", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "StackGAN: Text to photo-realistic image synthesis with stacked gener-ative adversarial networks", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "Energy-based generative adversarial network", "weight": 1}, {"from": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "to": "Generative visual manipulation on the natural image manifold", "weight": 1}, {"from": "Amortised map inference for image super-resolution", "to": "", "weight": 1}, {"from": "Xception: Deep learning with depthwise separable convolutions", "to": "Tensor-Flow: Large-scale machine learning on heterogeneous sys-tems", "weight": 1}, {"from": "Xception: Deep learning with depthwise separable convolutions", "to": "Keras", "weight": 1}, {"from": "Xception: Deep learning with depthwise separable convolutions", "to": "Learning visual representations at scale", "weight": 1}, {"from": "Xception: Deep learning with depthwise separable convolutions", "to": "Factorized convolutional neural networks", "weight": 1}, {"from": "Xception: Deep learning with depthwise separable convolutions", "to": "Visualizing and understanding convolutional networks", "weight": 1}, {"from": "Xception: Deep learning with depthwise separable convolutions", "to": "Deep residual learning for image recognition", "weight": 1}, {"from": "Xception: Deep learning with depthwise separable convolutions", "to": "Distilling the knowledge in a neural network", "weight": 1}, {"from": "Xception: Deep learning with depthwise separable convolutions", "to": "Mobilenets: Ef\ufb01cient convolutional neural net-works for mobile vision applications", "weight": 1}, {"from": "Xception: Deep learning with depthwise separable convolutions", "to": "Flattened convolutional neural networks for feedforward acceleration", "weight": 1}, {"from": "Xception: Deep learning with depthwise separable convolutions", "to": "Imagenet classi\ufb01cation with deep convolutional neural networks", "weight": 1}, {"from": "Xception: Deep learning with depthwise separable convolutions", "to": "L", "weight": 1}, {"from": "Xception: Deep learning with depthwise separable convolutions", "to": "Network in network", "weight": 1}, {"from": "Xception: Deep learning with depthwise separable convolutions", "to": "Simplifying ConvNets for Fast Learning", "weight": 1}, {"from": "Xception: Deep learning with depthwise separable convolutions", "to": "Acceleration of stochas-tic approximation by averaging", "weight": 1}, {"from": "Xception: Deep learning with depthwise separable convolutions", "to": "J", "weight": 1}, {"from": "Xception: Deep learning with depthwise separable convolutions", "to": "Rigid-motion scattering for image classi\ufb01cation", "weight": 1}, {"from": "Xception: Deep learning with depthwise separable convolutions", "to": "Rotation", "weight": 1}, {"from": "Xception: Deep learning with depthwise separable convolutions", "to": "Tf-slim", "weight": 1}, {"from": "Xception: Deep learning with depthwise separable convolutions", "to": "Very deep convolutional networks for large-scale image recognition", "weight": 1}, {"from": "Xception: Deep learning with depthwise separable convolutions", "to": "Inception-v4", "weight": 1}, {"from": "Xception: Deep learning with depthwise separable convolutions", "to": "Going deeper with convolutions", "weight": 1}, {"from": "Xception: Deep learning with depthwise separable convolutions", "to": "Rethinking the inception architecture for computer vision", "weight": 1}, {"from": "Flattened convolutional neural networks for feedforward acceleration", "to": "M", "weight": 1}, {"from": "Flattened convolutional neural networks for feedforward acceleration", "to": ", and Hoffman, T", "weight": 1}, {"from": "Flattened convolutional neural networks for feedforward acceleration", "to": "", "weight": 1}, {"from": "Flattened convolutional neural networks for feedforward acceleration", "to": "Learning separable \ufb01lters", "weight": 1}, {"from": "Training deep nets with sublinear memory cost", "to": "", "weight": 1}, {"from": "Training deep nets with sublinear memory cost", "to": "An introduction to computational networks and the computational network toolkit", "weight": 1}, {"from": "Training deep nets with sublinear memory cost", "to": "Theano: a CPU and GPU math expression compiler", "weight": 1}, {"from": "Training deep nets with sublinear memory cost", "to": "MXNet: A \ufb02exible and ef\ufb01cient machine learning library for heterogeneous distributed systems", "weight": 1}, {"from": "Training deep nets with sublinear memory cost", "to": "Large scale distributed deep networks", "weight": 1}, {"from": "Training deep nets with sublinear memory cost", "to": "Deep learning", "weight": 1}, {"from": "Training deep nets with sublinear memory cost", "to": "Algorithm 799: Revolve: An implementation of checkpointing for the reverse or adjoint mode of computational differentiation", "weight": 1}, {"from": "Training deep nets with sublinear memory cost", "to": "Deep residual learning for image recognition", "weight": 1}, {"from": "Training deep nets with sublinear memory cost", "to": "Identity mappings in deep residual networks", "weight": 1}, {"from": "Training deep nets with sublinear memory cost", "to": "Long short-term memory", "weight": 1}, {"from": "Training deep nets with sublinear memory cost", "to": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "weight": 1}, {"from": "Training deep nets with sublinear memory cost", "to": "Virtualizing deep neural networks for memory-ef\ufb01cient neural network design", "weight": 1}, {"from": "Training deep nets with sublinear memory cost", "to": "Training very deep networks", "weight": 1}, {"from": "Training deep nets with sublinear memory cost", "to": "arXiv preprint Highway long short-term memory rnns for distant speech recognition", "weight": 1}, {"from": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "to": "", "weight": 1}, {"from": "Faster r-cnn: Towards real-time object detection with region proposal networks", "to": "", "weight": 1}, {"from": "Functional correspondence by matrix completion", "to": "", "weight": 1}, {"from": "Functional correspondence by matrix completion", "to": "23(2):1214\u20131236", "weight": 1}, {"from": "Playing atari with deep reinforcement learning", "to": "", "weight": 1}, {"from": "Playing atari with deep reinforcement learning", "to": "The arcade learning environment: An evaluation platform for general agents", "weight": 1}, {"from": "Playing atari with deep reinforcement learning", "to": "Speech recognition with deep recurrent neural networks", "weight": 1}, {"from": "Playing atari with deep reinforcement learning", "to": "Actor-critic reinforcement learning with energy-based policies", "weight": 1}, {"from": "Playing atari with deep reinforcement learning", "to": "Prioritized sweeping: Reinforcement learning with less data and less real time", "weight": 1}, {"from": "Playing atari with deep reinforcement learning", "to": "Why did td-gammon work", "weight": 1}, {"from": "Playing atari with deep reinforcement learning", "to": "Reinforcement learning with factored states and actions", "weight": 1}, {"from": "Playing atari with deep reinforcement learning", "to": "Reinforcement Learning: An Introduction", "weight": 1}, {"from": "Playing atari with deep reinforcement learning", "to": "Q-learning", "weight": 1}, {"from": "Scenenet RGB-D: 5m photorealistic images of synthetic indoor trajectories with ground truth", "to": "Seeing 3D chairs: exemplar part-based 2D-3D alignment us-ing a large dataset of CAD models", "weight": 1}, {"from": "Scenenet RGB-D: 5m photorealistic images of synthetic indoor trajectories with ground truth", "to": "Domain Separation Networks", "weight": 1}, {"from": "Scenenet RGB-D: 5m photorealistic images of synthetic indoor trajectories with ground truth", "to": "ShapeNet: An Information-Rich 3D Model Repository", "weight": 1}, {"from": "Scenenet RGB-D: 5m photorealistic images of synthetic indoor trajectories with ground truth", "to": "Procedural Generation of Videos to Train Deep Ac-tion Recognition Networks", "weight": 1}, {"from": "Scenenet RGB-D: 5m photorealistic images of synthetic indoor trajectories with ground truth", "to": "Semantic Scene Completion from a Single Depth Image", "weight": 1}, {"from": "Scenenet RGB-D: 5m photorealistic images of synthetic indoor trajectories with ground truth", "to": "Example-based synthesis of 3d object arrangements", "weight": 1}, {"from": "Scenenet RGB-D: 5m photorealistic images of synthetic indoor trajectories with ground truth", "to": "Align-In ing 3D models to RGB-D images of cluttered scenes", "weight": 1}, {"from": "Scenenet RGB-D: 5m photorealistic images of synthetic indoor trajectories with ground truth", "to": "Real-Time Camera Tracking: When is High Frame-Rate Best? In ECCV", "weight": 1}, {"from": "Scenenet RGB-D: 5m photorealistic images of synthetic indoor trajectories with ground truth", "to": "V", "weight": 1}, {"from": "Scenenet RGB-D: 5m photorealistic images of synthetic indoor trajectories with ground truth", "to": "A Benchmark for RGB-D Visual Odometry", "weight": 1}, {"from": "Scenenet RGB-D: 5m photorealistic images of synthetic indoor trajectories with ground truth", "to": "Flownet 2", "weight": 1}, {"from": "Scenenet RGB-D: 5m photorealistic images of synthetic indoor trajectories with ground truth", "to": "A practical guide to global illumination using photon maps", "weight": 1}, {"from": "Scenenet RGB-D: 5m photorealistic images of synthetic indoor trajectories with ground truth", "to": "Imagenet clas-si\ufb01cation with deep convolutional neural networks", "weight": 1}, {"from": "Scenenet RGB-D: 5m photorealistic images of synthetic indoor trajectories with ground truth", "to": "SemanticFusion: Dense 3D Semantic Mapping with Convo-lutional Neural Networks", "weight": 1}, {"from": "Scenenet RGB-D: 5m photorealistic images of synthetic indoor trajectories with ground truth", "to": "Progressive photon mapping on gpus", "weight": 1}, {"from": "Scenenet RGB-D: 5m photorealistic images of synthetic indoor trajectories with ground truth", "to": "Learning Deep Object Detectors from 3D Models", "weight": 1}, {"from": "Scenenet RGB-D: 5m photorealistic images of synthetic indoor trajectories with ground truth", "to": "UnrealCV: Connecting computer vi-sion to unreal engine", "weight": 1}, {"from": "Scenenet RGB-D: 5m photorealistic images of synthetic indoor trajectories with ground truth", "to": "Playing for data: Ground truth from computer games", "weight": 1}, {"from": "Scenenet RGB-D: 5m photorealistic images of synthetic indoor trajectories with ground truth", "to": "The SYNTHIA Dataset: A large collection of synthetic images for semantic segmentation of urban scenes", "weight": 1}, {"from": "Scenenet RGB-D: 5m photorealistic images of synthetic indoor trajectories with ground truth", "to": "On being the right scale: Sizing large collec-tions of 3D models", "weight": 1}, {"from": "Scenenet RGB-D: 5m photorealistic images of synthetic indoor trajectories with ground truth", "to": "Indoor segmentation and support inference from RGBD images", "weight": 1}, {"from": "Scenenet RGB-D: 5m photorealistic images of synthetic indoor trajectories with ground truth", "to": "SUN RGB-D: A In CVPR", "weight": 1}, {"from": "Resnet with one-neuron hidden layers is a universal approximator", "to": "On the optimization of deep networks: Implicit acceleration by overparameterization", "weight": 1}, {"from": "Resnet with one-neuron hidden layers is a universal approximator", "to": "Universal approximation bounds for superpositions of a sigmoidal function", "weight": 1}, {"from": "Resnet with one-neuron hidden layers is a universal approximator", "to": "On decision regions of narrow deep neural networks", "weight": 1}, {"from": "Resnet with one-neuron hidden layers is a universal approximator", "to": "Sgd learns over-parameterized networks In The International Conference on Learning that provably generalize on linearly separable data", "weight": 1}, {"from": "Resnet with one-neuron hidden layers is a universal approximator", "to": "The loss surfaces of multilayer networks", "weight": 1}, {"from": "Resnet with one-neuron hidden layers is a universal approximator", "to": "On the expressive power of deep learning: A tensor analysis", "weight": 1}, {"from": "Resnet with one-neuron hidden layers is a universal approximator", "to": "Approximation by superpositions of a sigmoidal function", "weight": 1}, {"from": "Resnet with one-neuron hidden layers is a universal approximator", "to": "Gradient descent learns one-hidden-layer cnn: Don\u2019t be afraid of spurious local minima", "weight": 1}, {"from": "Resnet with one-neuron hidden layers is a universal approximator", "to": "The power of depth for feedforward neural networks", "weight": 1}, {"from": "Resnet with one-neuron hidden layers is a universal approximator", "to": "On the approximate realization of continuous mappings by neural networks", "weight": 1}, {"from": "Resnet with one-neuron hidden layers is a universal approximator", "to": "Approximating continuous functions by relu nets of minimal width", "weight": 1}, {"from": "Resnet with one-neuron hidden layers is a universal approximator", "to": "Identity matters in deep learning", "weight": 1}, {"from": "Resnet with one-neuron hidden layers is a universal approximator", "to": "Deep residual learning for image recognition", "weight": 1}, {"from": "Resnet with one-neuron hidden layers is a universal approximator", "to": "Identity mappings in deep residual networks", "weight": 1}, {"from": "Resnet with one-neuron hidden layers is a universal approximator", "to": "Multilayer feedforward networks are universal approximators", "weight": 1}, {"from": "Resnet with one-neuron hidden layers is a universal approximator", "to": "Deep learning without poor local minima", "weight": 1}, {"from": "Resnet with one-neuron hidden layers is a universal approximator", "to": "Imagenet classi\ufb01cation with deep convolutional neural networks", "weight": 1}, {"from": "Resnet with one-neuron hidden layers is a universal approximator", "to": "Kolmogorov\u2019s theorem and multilayer neural networks", "weight": 1}, {"from": "Resnet with one-neuron hidden layers is a universal approximator", "to": "Gradient-based learning applied to document recognition", "weight": 1}, {"from": "Resnet with one-neuron hidden layers is a universal approximator", "to": "Why deep neural networks for function approximation? In The International Conference on Learning Representations (ICLR)", "weight": 1}, {"from": "Resnet with one-neuron hidden layers is a universal approximator", "to": "The expressive power of neural networks: A view from the width", "weight": 1}, {"from": "Resnet with one-neuron hidden layers is a universal approximator", "to": "Neural networks for optimal approximation of smooth and analytic functions", "weight": 1}, {"from": "Resnet with one-neuron hidden layers is a universal approximator", "to": "Deep vs", "weight": 1}, {"from": "Resnet with one-neuron hidden layers is a universal approximator", "to": "The loss surface of deep and wide neural networks", "weight": 1}, {"from": "Resnet with one-neuron hidden layers is a universal approximator", "to": "The power of deeper networks for expressing natural functions", "weight": 1}, {"from": "Resnet with one-neuron hidden layers is a universal approximator", "to": "Weight sharing is crucial to succesful optimization", "weight": 1}, {"from": "Resnet with one-neuron hidden layers is a universal approximator", "to": "Are resnets provably better than linear predictors? arXiv:1804", "weight": 1}, {"from": "Resnet with one-neuron hidden layers is a universal approximator", "to": "Very deep convolutional networks for large-scale image recognition", "weight": 1}, {"from": "Resnet with one-neuron hidden layers is a universal approximator", "to": "Dropout: A simple way to prevent neural networks from over\ufb01tting", "weight": 1}, {"from": "Resnet with one-neuron hidden layers is a universal approximator", "to": "W", "weight": 1}, {"from": "Resnet with one-neuron hidden layers is a universal approximator", "to": "Deep networks are e\ufb00ective encoders of periodicity", "weight": 1}, {"from": "Resnet with one-neuron hidden layers is a universal approximator", "to": "Bene\ufb01ts of depth in neural networks", "weight": 1}, {"from": "Resnet with one-neuron hidden layers is a universal approximator", "to": "Error bounds for approximations with deep relu networks", "weight": 1}, {"from": "Resnet with one-neuron hidden layers is a universal approximator", "to": "Optimal approximation of continuous functions by very deep relu networks", "weight": 1}, {"from": "Resnet with one-neuron hidden layers is a universal approximator", "to": "Global optimality conditions for deep neural networks", "weight": 1}, {"from": "Resnet with one-neuron hidden layers is a universal approximator", "to": "Understanding deep learning requires rethinking generalization", "weight": 1}, {"from": "On the optimization of deep networks: Implicit acceleration by overparameterization", "to": ", et al", "weight": 1}, {"from": "On the optimization of deep networks: Implicit acceleration by overparameterization", "to": "Finding approximate local minima faster than gradient descent", "weight": 1}, {"from": "On the optimization of deep networks: Implicit acceleration by overparameterization", "to": "Understanding deep neural networks with recti\ufb01ed linear units", "weight": 1}, {"from": "On the optimization of deep networks: Implicit acceleration by overparameterization", "to": "Neural networks and principal component analysis: Learning from examples without local minima", "weight": 1}, {"from": "On the optimization of deep networks: Implicit acceleration by overparameterization", "to": "Elementary differential equations and boundary value problems, volume 9", "weight": 1}, {"from": "On the optimization of deep networks: Implicit acceleration by overparameterization", "to": "Advanced calculus", "weight": 1}, {"from": "On the optimization of deep networks: Implicit acceleration by overparameterization", "to": "Accel-erated methods for non-convex optimization", "weight": 1}, {"from": "On the optimization of deep networks: Implicit acceleration by overparameterization", "to": "The loss surfaces of multilayer networks", "weight": 1}, {"from": "On the optimization of deep networks: Implicit acceleration by overparameterization", "to": "Analysis and design of convolutional net-works via hierarchical tensor decompositions", "weight": 1}, {"from": "On the optimization of deep networks: Implicit acceleration by overparameterization", "to": "Depth separation for neural networks", "weight": 1}, {"from": "On the optimization of deep networks: Implicit acceleration by overparameterization", "to": "On the ability of neural nets to express distributions", "weight": 1}, {"from": "On the optimization of deep networks: Implicit acceleration by overparameterization", "to": "On the compu-tational ef\ufb01ciency of training neural networks", "weight": 1}, {"from": "On the optimization of deep networks: Implicit acceleration by overparameterization", "to": "Adaptive subgradient methods for online learning and stochastic optimization", "weight": 1}, {"from": "On the optimization of deep networks: Implicit acceleration by overparameterization", "to": "A method of solving a convex programming problem with convergence rate o (1/k2)", "weight": 1}, {"from": "On the optimization of deep networks: Implicit acceleration by overparameterization", "to": "The power of depth for feedforward neural networks", "weight": 1}, {"from": "On the optimization of deep networks: Implicit acceleration by overparameterization", "to": "Updating quasi-newton matrices with limited storage", "weight": 1}, {"from": "On the optimization of deep networks: Implicit acceleration by overparameterization", "to": "Effect of batch learning in multilayer neural net-works", "weight": 1}, {"from": "On the optimization of deep networks: Implicit acceleration by overparameterization", "to": "Escaping from saddle points\u2014online stochastic gradient for tensor decomposition", "weight": 1}, {"from": "On the optimization of deep networks: Implicit acceleration by overparameterization", "to": "Why momentum really works", "weight": 1}, {"from": "On the optimization of deep networks: Implicit acceleration by overparameterization", "to": "Deep learning, volume 1", "weight": 1}, {"from": "On the optimization of deep networks: Implicit acceleration by overparameterization", "to": "Qualitatively characterizing neural network optimization problems", "weight": 1}, {"from": "On the optimization of deep networks: Implicit acceleration by overparameterization", "to": "", "weight": 1}, {"from": "On the optimization of deep networks: Implicit acceleration by overparameterization", "to": "Identity matters in deep learning", "weight": 1}, {"from": "On the optimization of deep networks: Implicit acceleration by overparameterization", "to": "Deep residual learning for image recognition", "weight": 1}, {"from": "On the optimization of deep networks: Implicit acceleration by overparameterization", "to": "Optimization and dynamical systems", "weight": 1}, {"from": "On the optimization of deep networks: Implicit acceleration by overparameterization", "to": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "weight": 1}, {"from": "On the optimization of deep networks: Implicit acceleration by overparameterization", "to": "Beating the Perils of Non-Convexity: Guaranteed Training of Neural Networks using Tensor Methods", "weight": 1}, {"from": "On the optimization of deep networks: Implicit acceleration by overparameterization", "to": "Deep learning without poor local minima", "weight": 1}, {"from": "On the optimization of deep networks: Implicit acceleration by overparameterization", "to": "Adam: A method for stochastic optimiza-tion", "weight": 1}, {"from": "On the optimization of deep networks: Implicit acceleration by overparameterization", "to": "On the expressive power of deep neural networks", "weight": 1}, {"from": "On the optimization of deep networks: Implicit acceleration by overparameterization", "to": "On the calibration of sensor arrays for pattern recog-nition using the minimal number of experiments", "weight": 1}, {"from": "On the optimization of deep networks: Implicit acceleration by overparameterization", "to": "On the quality of the initial basin in overspeci\ufb01ed neural networks", "weight": 1}, {"from": "On the optimization of deep networks: Implicit acceleration by overparameterization", "to": "Spurious local minima are com-arXiv preprint mon in two-layer relu neural networks", "weight": 1}, {"from": "On the optimization of deep networks: Implicit acceleration by overparameterization", "to": "Exact solutions to the nonlinear dynamics of learning in deep linear neural networks", "weight": 1}, {"from": "On the optimization of deep networks: Implicit acceleration by overparameterization", "to": "No bad local minima: Data independent training error guarantees for multilayer neural networks", "weight": 1}, {"from": "On the optimization of deep networks: Implicit acceleration by overparameterization", "to": "Dropout: a simple way to prevent neural net-works from over\ufb01tting", "weight": 1}, {"from": "On the optimization of deep networks: Implicit acceleration by overparameterization", "to": "A differential equation for modeling nesterovs accelerated gradient method: Theory and insights", "weight": 1}, {"from": "On the optimization of deep networks: Implicit acceleration by overparameterization", "to": "and Hinton, G", "weight": 1}, {"from": "On the optimization of deep networks: Implicit acceleration by overparameterization", "to": "Chemical gas sensor drift compensation using classi\ufb01er ensembles", "weight": 1}, {"from": "On the optimization of deep networks: Implicit acceleration by overparameterization", "to": "A variational per-spective on accelerated methods in optimization", "weight": 1}, {"from": "On the optimization of deep networks: Implicit acceleration by overparameterization", "to": "Adadelta: an adaptive learning rate method", "weight": 1}, {"from": "Identity matters in deep learning", "to": "", "weight": 1}, {"from": "Identity matters in deep learning", "to": "The loss surfaces of multilayer networks", "weight": 1}, {"from": "Identity matters in deep learning", "to": "Deep residual learn-ing for image recognition", "weight": 1}, {"from": "Identity matters in deep learning", "to": "Extensions of lipschitz mappings into a hilbert space", "weight": 1}, {"from": "The expressive power of neural networks: A view from the width", "to": "", "weight": 1}, {"from": "The expressive power of neural networks: A view from the width", "to": "On the expressive power of deep learning: A tensor analysis", "weight": 1}, {"from": "The expressive power of neural networks: A view from the width", "to": "Shallow vs", "weight": 1}, {"from": "The expressive power of neural networks: A view from the width", "to": "The power of depth for feedforward neural networks", "weight": 1}, {"from": "The expressive power of neural networks: A view from the width", "to": "Deep residual learning for image recognition", "weight": 1}, {"from": "The expressive power of neural networks: A view from the width", "to": "Multilayer feedforward networks are universal approximators", "weight": 1}, {"from": "Weight sharing is crucial to succesful optimization", "to": "", "weight": 1}, {"from": "Weight sharing is crucial to succesful optimization", "to": "Provable bounds for learning some deep representations", "weight": 1}, {"from": "Weight sharing is crucial to succesful optimization", "to": "Globally optimal gradient descent for a convnet with gaussian inputs", "weight": 1}, {"from": "Weight sharing is crucial to succesful optimization", "to": "The loss surfaces of multilayer networks", "weight": 1}, {"from": "Weight sharing is crucial to succesful optimization", "to": "Global optimality in tensor factorization, deep learning, and beyond", "weight": 1}, {"from": "Weight sharing is crucial to succesful optimization", "to": "Identity matters in deep learning", "weight": 1}, {"from": "Weight sharing is crucial to succesful optimization", "to": "Beating the perils of non-convexity: Guaran-teed training of neural networks using tensor methods", "weight": 1}, {"from": "Weight sharing is crucial to succesful optimization", "to": "E\ufb03cient learning of generalized linear and single index models with isotonic regression", "weight": 1}, {"from": "Weight sharing is crucial to succesful optimization", "to": "The isotron algorithm: High-dimensional isotonic regression", "weight": 1}, {"from": "Weight sharing is crucial to succesful optimization", "to": "On the computational e\ufb03ciency of training neural networks", "weight": 1}, {"from": "Weight sharing is crucial to succesful optimization", "to": "The landscape of empirical risk for non-convex losses", "weight": 1}, {"from": "Weight sharing is crucial to succesful optimization", "to": "On the quality of the initial basin in overspeci\ufb01ed neural networks", "weight": 1}, {"from": "Weight sharing is crucial to succesful optimization", "to": "Understanding machine learning: From theory to algorithms", "weight": 1}, {"from": "Weight sharing is crucial to succesful optimization", "to": "Failures of deep learning", "weight": 1}, {"from": "Weight sharing is crucial to succesful optimization", "to": "No bad local minima: Data independent training error guarantees for multilayer neural networks", "weight": 1}, {"from": "Weight sharing is crucial to succesful optimization", "to": "l1-regularized neural networks are improperly learnable in polynomial time", "weight": 1}, {"from": "FaceNet: A In uni\ufb01ed embedding for face recognition and clustering", "to": "", "weight": 1}, {"from": "Mobilenetv2: Inverted residuals and linear bottlenecks", "to": "Im-agenet large scale visual recognition challenge", "weight": 1}, {"from": "Mobilenetv2: Inverted residuals and linear bottlenecks", "to": "", "weight": 1}, {"from": "Mobilenetv2: Inverted residuals and linear bottlenecks", "to": "The pascal visual object classes challenge a retrospective", "weight": 1}, {"from": "Mobilenetv2: Inverted residuals and linear bottlenecks", "to": "Random search for hyper-parameter optimization", "weight": 1}, {"from": "Mobilenetv2: Inverted residuals and linear bottlenecks", "to": "Mobilenets: Ef\ufb01cient convolutional neural net-CoRR, works for mobile vision applications", "weight": 1}, {"from": "Mobilenetv2: Inverted residuals and linear bottlenecks", "to": "CoRR, residual networks", "weight": 1}, {"from": "Mobilenetv2: Inverted residuals and linear bottlenecks", "to": "Caffe: Convolutional architecture for fast feature embed-ding", "weight": 1}, {"from": "Mobilenetv2: Inverted residuals and linear bottlenecks", "to": "Ssd: Single shot multibox detector", "weight": 1}, {"from": "Mobilenetv2: Inverted residuals and linear bottlenecks", "to": "Better, stronger", "weight": 1}, {"from": "Mobilenetv2: Inverted residuals and linear bottlenecks", "to": "Faster r-cnn: Towards real-time object In Ad-detection with region proposal networks", "weight": 1}, {"from": "Mobilenetv2: Inverted residuals and linear bottlenecks", "to": "R-fcn: Object detection via region-based fully con-volutional networks", "weight": 1}, {"from": "Mobilenetv2: Inverted residuals and linear bottlenecks", "to": "Overfeat: Integrated recognition, localiza-tion and detection using convolutional networks", "weight": 1}, {"from": "Mobilenetv2: Inverted residuals and linear bottlenecks", "to": "Modeling local and global defor-mations in deep learning: Epitomic convolution, multiple instance learning, and sliding window de-tection", "weight": 1}, {"from": "Mobilenetv2: Inverted residuals and linear bottlenecks", "to": "Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs", "weight": 1}, {"from": "Mobilenetv2: Inverted residuals and linear bottlenecks", "to": "Se-mantic contours from inverse detectors", "weight": 1}, {"from": "Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs", "to": "", "weight": 1}, {"from": "Bayesian locality sensitive hashing for fast similarity search", "to": "Building rome in a day", "weight": 1}, {"from": "Bayesian locality sensitive hashing for fast similarity search", "to": "Near-optimal hashing algorithms for approximate nearest neighbor in high dimensions", "weight": 1}, {"from": "Bayesian locality sensitive hashing for fast similarity search", "to": "Scaling up all pairs similarity search", "weight": 1}, {"from": "Bayesian locality sensitive hashing for fast similarity search", "to": "Min-wise independent permutations (extended abstract)", "weight": 1}, {"from": "Bayesian locality sensitive hashing for fast similarity search", "to": "Syntactic clustering of the web", "weight": 1}, {"from": "Bayesian locality sensitive hashing for fast similarity search", "to": "Similarity estimation techniques from rounding algorithms", "weight": 1}, {"from": "Bayesian locality sensitive hashing for fast similarity search", "to": "Locality-sensitive hashing scheme based on p-stable distributions", "weight": 1}, {"from": "Bayesian locality sensitive hashing for fast similarity search", "to": "When close enough is good enough: Approximate positional indexes for e\ufb03cient ranked retrieval", "weight": 1}, {"from": "Bayesian locality sensitive hashing for fast similarity search", "to": "Similarity search in high dimensions via hashing", "weight": 1}, {"from": "Bayesian locality sensitive hashing for fast similarity search", "to": "Finding near-duplicate web pages: a large-scale evaluation of algorithms", "weight": 1}, {"from": "Bayesian locality sensitive hashing for fast similarity search", "to": "Approximate nearest neighbors: towards removing the curse of dimensionality", "weight": 1}, {"from": "Bayesian locality sensitive hashing for fast similarity search", "to": "Fast image search for learned metrics", "weight": 1}, {"from": "Bayesian locality sensitive hashing for fast similarity search", "to": "What is Twitter", "weight": 1}, {"from": "Bayesian locality sensitive hashing for fast similarity search", "to": "Rcv1: A new benchmark collection for text categorization research", "weight": 1}, {"from": "Bayesian locality sensitive hashing for fast similarity search", "to": "b-bit minwise hashing", "weight": 1}, {"from": "Bayesian locality sensitive hashing for fast similarity search", "to": "The link-prediction problem for social networks", "weight": 1}, {"from": "Bayesian locality sensitive hashing for fast similarity search", "to": "Multi-probe lsh: e\ufb03cient indexing for high-dimensional similarity search", "weight": 1}, {"from": "Bayesian locality sensitive hashing for fast similarity search", "to": "Detecting near-duplicates for web crawling", "weight": 1}, {"from": "Bayesian locality sensitive hashing for fast similarity search", "to": "Measurement and Analysis of Online Social Networks", "weight": 1}, {"from": "Bayesian locality sensitive hashing for fast similarity search", "to": "Randomized algorithms and nlp: using locality sensitive hash function for high speed noun clustering", "weight": 1}, {"from": "Bayesian locality sensitive hashing for fast similarity search", "to": "Symmetrizations for clustering directed graphs", "weight": 1}, {"from": "Bayesian locality sensitive hashing for fast similarity search", "to": "Local graph sparsi\ufb01cation for scalable clustering", "weight": 1}, {"from": "Bayesian locality sensitive hashing for fast similarity search", "to": "Quality and e\ufb03ciency in high dimensional nearest neighbor search", "weight": 1}, {"from": "Bayesian locality sensitive hashing for fast similarity search", "to": "E\ufb03cient similarity joins for near duplicate detection", "weight": 1}, {"from": "Bayesian locality sensitive hashing for fast similarity search", "to": "Atlas: a probabilistic algorithm for high dimensional similarity search", "weight": 1}, {"from": "Bayesian locality sensitive hashing for fast similarity search", "to": "Introduction to semi-supervised learning", "weight": 1}, {"from": "The megaface benchmark: 1 million faces for recognition at scale", "to": "Face description with local binary patterns: Application to face recognition", "weight": 1}, {"from": "The megaface benchmark: 1 million faces for recognition at scale", "to": "Unconstrained face recognition: Identifying a person of in-terest from a media collection", "weight": 1}, {"from": "The megaface benchmark: 1 million faces for recognition at scale", "to": "P", "weight": 1}, {"from": "The megaface benchmark: 1 million faces for recognition at scale", "to": "Bayesian face revisited: A joint formulation", "weight": 1}, {"from": "The megaface benchmark: 1 million faces for recognition at scale", "to": "The fg-net aging database", "weight": 1}, {"from": "The megaface benchmark: 1 million faces for recognition at scale", "to": "Can a poor veri\ufb01cation system be a good identi\ufb01cation system? a preliminary study", "weight": 1}, {"from": "The megaface benchmark: 1 million faces for recognition at scale", "to": "Yale face database", "weight": 1}, {"from": "The megaface benchmark: 1 million faces for recognition at scale", "to": "Image and Vision Computing", "weight": 1}, {"from": "The megaface benchmark: 1 million faces for recognition at scale", "to": "Models of large population In Computer Vision and Pattern recognition performance", "weight": 1}, {"from": "The megaface benchmark: 1 million faces for recognition at scale", "to": "Report on the evaluation of 2d still-image face recognition algorithms", "weight": 1}, {"from": "The megaface benchmark: 1 million faces for recognition at scale", "to": "When face recognition meets with deep learning: an evaluation of convolutional neural networks for face recognition", "weight": 1}, {"from": "The megaface benchmark: 1 million faces for recognition at scale", "to": "Labeled faces in the wild: A database for studying face recognition in unconstrained environments", "weight": 1}, {"from": "The megaface benchmark: 1 million faces for recognition at scale", "to": "Illumination-aware age progression", "weight": 1}, {"from": "The megaface benchmark: 1 million faces for recognition at scale", "to": "Face recognition in uncon-strained videos with matched background similarity", "weight": 1}, {"from": "The megaface benchmark: 1 million faces for recognition at scale", "to": "Supervised descent method and its applications to face alignment", "weight": 1}, {"from": "The megaface benchmark: 1 million faces for recognition at scale", "to": "Learning face represen-tation from scratch", "weight": 1}, {"from": "The megaface benchmark: 1 million faces for recognition at scale", "to": "Face recognition: A literature survey", "weight": 1}, {"from": "The megaface benchmark: 1 million faces for recognition at scale", "to": "A case study on unconstrained facial recognition using the boston marathon bombings sus-pects", "weight": 1}, {"from": "The megaface benchmark: 1 million faces for recognition at scale", "to": "Attribute and simile classi\ufb01ers for face veri\ufb01cation", "weight": 1}, {"from": "The megaface benchmark: 1 million faces for recognition at scale", "to": "Describable visual attributes for face veri\ufb01cation and image search", "weight": 1}, {"from": "The megaface benchmark: 1 million faces for recognition at scale", "to": "A discriminative model for Information Forensics and age invariant face recognition", "weight": 1}, {"from": "The megaface benchmark: 1 million faces for recognition at scale", "to": "Face detection without bells and whistles", "weight": 1}, {"from": "The megaface benchmark: 1 million faces for recognition at scale", "to": "Face recognition for web-scale datasets", "weight": 1}, {"from": "The megaface benchmark: 1 million faces for recognition at scale", "to": "A", "weight": 1}, {"from": "The megaface benchmark: 1 million faces for recognition at scale", "to": "Facenet: A uni-\ufb01ed embedding for face recognition and clustering", "weight": 1}, {"from": "The megaface benchmark: 1 million faces for recognition at scale", "to": "Autotagging face-book: Social network context improves photo annotation", "weight": 1}, {"from": "The megaface benchmark: 1 million faces for recognition at scale", "to": "Deepid3: Face recognition with very deep neural networks", "weight": 1}, {"from": "The megaface benchmark: 1 million faces for recognition at scale", "to": "Deeply learned face repre-sentations are sparse", "weight": 1}, {"from": "The megaface benchmark: 1 million faces for recognition at scale", "to": "Deepface: Closing the gap to human-level performance in face veri\ufb01ca-tion", "weight": 1}, {"from": "The megaface benchmark: 1 million faces for recognition at scale", "to": "Web-arXiv preprint face identi\ufb01cation", "weight": 1}, {"from": "The megaface benchmark: 1 million faces for recognition at scale", "to": "The new data and new challenges in multimedia research", "weight": 1}, {"from": "The megaface benchmark: 1 million faces for recognition at scale", "to": "Robust real-time face detection", "weight": 1}, {"from": "The megaface benchmark: 1 million faces for recognition at scale", "to": "Face search at scale: 80 million gallery", "weight": 1}, {"from": "When face recognition meets with deep learning: an evaluation of convolutional neural networks for face recognition", "to": "Face recognition In Computer vision-eccv 2004", "weight": 1}, {"from": "When face recognition meets with deep learning: an evaluation of convolutional neural networks for face recognition", "to": "Recog-nition of blurred faces using local phase quantization", "weight": 1}, {"from": "When face recognition meets with deep learning: an evaluation of convolutional neural networks for face recognition", "to": "Mul-tiscale local phase quantization for robust component-based face recognition using kernel fusion of multiple descriptors", "weight": 1}, {"from": "When face recognition meets with deep learning: an evaluation of convolutional neural networks for face recognition", "to": "Return of the devil in the details: Delving deep into convo-lutional nets", "weight": 1}, {"from": "When face recognition meets with deep learning: an evaluation of convolutional neural networks for face recognition", "to": "Bayesian face revisited: A joint formulation", "weight": 1}, {"from": "When face recognition meets with deep learning: an evaluation of convolutional neural networks for face recognition", "to": "Blessing of dimension-ality: High-dimensional feature and its ef\ufb01cient compression for face veri\ufb01cation", "weight": 1}, {"from": "When face recognition meets with deep learning: an evaluation of convolutional neural networks for face recognition", "to": "Is that you? met-ric learning approaches for face identi\ufb01cation", "weight": 1}, {"from": "When face recognition meets with deep learning: an evaluation of convolutional neural networks for face recognition", "to": "Delving deep into recti\ufb01ers: Surpassing human-level performance on imagenet classi\ufb01cation", "weight": 1}, {"from": "When face recognition meets with deep learning: an evaluation of convolutional neural networks for face recognition", "to": "Improving neural networks by pre-venting co-adaptation of feature detectors", "weight": 1}, {"from": "When face recognition meets with deep learning: an evaluation of convolutional neural networks for face recognition", "to": "Learning to align from scratch", "weight": 1}, {"from": "When face recognition meets with deep learning: an evaluation of convolutional neural networks for face recognition", "to": "Labeled faces in the wild: A database for studying face recognition in unconstrained environments", "weight": 1}, {"from": "When face recognition meets with deep learning: an evaluation of convolutional neural networks for face recognition", "to": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "weight": 1}, {"from": "When face recognition meets with deep learning: an evaluation of convolutional neural networks for face recognition", "to": "Imagenet classi\ufb01cation with deep convolutional neural networks", "weight": 1}, {"from": "When face recognition meets with deep learning: an evaluation of convolutional neural networks for face recognition", "to": "Probabilistic models for inference about identity", "weight": 1}, {"from": "When face recognition meets with deep learning: an evaluation of convolutional neural networks for face recognition", "to": "Learning multi-scale block local binary patterns for face recognition", "weight": 1}, {"from": "When face recognition meets with deep learning: an evaluation of convolutional neural networks for face recognition", "to": "Fisher Vector Faces in the Wild", "weight": 1}, {"from": "When face recognition meets with deep learning: an evaluation of convolutional neural networks for face recognition", "to": "Very deep convolutional networks for large-scale image recognition", "weight": 1}, {"from": "When face recognition meets with deep learning: an evaluation of convolutional neural networks for face recognition", "to": "Deep learning face representation by joint identi\ufb01cation-veri\ufb01cation", "weight": 1}, {"from": "When face recognition meets with deep learning: an evaluation of convolutional neural networks for face recognition", "to": "Hybrid deep learning for In Computer Vision (ICCV)", "weight": 1}, {"from": "When face recognition meets with deep learning: an evaluation of convolutional neural networks for face recognition", "to": "Deep learning face represen-In Computer Vision tation from predicting 10", "weight": 1}, {"from": "When face recognition meets with deep learning: an evaluation of convolutional neural networks for face recognition", "to": "Deeply learned face repre-sentations are sparse", "weight": 1}, {"from": "When face recognition meets with deep learning: an evaluation of convolutional neural networks for face recognition", "to": "Going deeper with convolutions", "weight": 1}, {"from": "When face recognition meets with deep learning: an evaluation of convolutional neural networks for face recognition", "to": "L", "weight": 1}, {"from": "When face recognition meets with deep learning: an evaluation of convolutional neural networks for face recognition", "to": "Deepface: Closing the gap to human-level performance in face veri\ufb01ca-tion", "weight": 1}, {"from": "When face recognition meets with deep learning: an evaluation of convolutional neural networks for face recognition", "to": "Face recognition using eigen-In Computer Vision and Pattern Recognition", "weight": 1}, {"from": "When face recognition meets with deep learning: an evaluation of convolutional neural networks for face recognition", "to": "Matconvnet \u2013 convolutional neural networks for matlab", "weight": 1}, {"from": "When face recognition meets with deep learning: an evaluation of convolutional neural networks for face recognition", "to": "Learning face represen-tation from scratch", "weight": 1}, {"from": "When face recognition meets with deep learning: an evaluation of convolutional neural networks for face recognition", "to": "Z", "weight": 1}, {"from": "A", "to": "", "weight": 1}, {"from": "Deepid3: Face recognition with very deep neural networks", "to": "Unconstrained face recognition: Identifying a person of interest from a media collection", "weight": 1}, {"from": "Deepid3: Face recognition with very deep neural networks", "to": "A practical transfer learning algorithm for face veri\ufb01cation", "weight": 1}, {"from": "Deepid3: Face recognition with very deep neural networks", "to": "Bayesian face revisited: A joint formulation", "weight": 1}, {"from": "Deepid3: Face recognition with very deep neural networks", "to": "Blessing of dimensionality: High-dimensional feature and its ef\ufb01cient compression for face veri\ufb01cation", "weight": 1}, {"from": "Deepid3: Face recognition with very deep neural networks", "to": "Improving neural networks by preventing co-adaptation of feature detectors", "weight": 1}, {"from": "Deepid3: Face recognition with very deep neural networks", "to": "Labeled Faces in the Wild: A database for studying face recognition in unconstrained environments", "weight": 1}, {"from": "Deepid3: Face recognition with very deep neural networks", "to": "Surpassing human-level face veri\ufb01cation performance on LFW with GaussianFace", "weight": 1}, {"from": "Deepid3: Face recognition with very deep neural networks", "to": "Surpassing human-level face veri\ufb01cation In Proc", "weight": 1}, {"from": "Deepid3: Face recognition with very deep neural networks", "to": "Recti\ufb01ed linear units improve restricted Boltzmann machines", "weight": 1}, {"from": "Deepid3: Face recognition with very deep neural networks", "to": "Very deep convolutional networks for large-scale image recognition", "weight": 1}, {"from": "Deepid3: Face recognition with very deep neural networks", "to": "Deep learning face In Proc", "weight": 1}, {"from": "Deepid3: Face recognition with very deep neural networks", "to": "Hybrid deep learning for face veri\ufb01cation", "weight": 1}, {"from": "Deepid3: Face recognition with very deep neural networks", "to": "Deep learning face representation by joint identi\ufb01cation-veri\ufb01cation", "weight": 1}, {"from": "Deepid3: Face recognition with very deep neural networks", "to": "Deeply learned face representations are sparse", "weight": 1}, {"from": "Deepid3: Face recognition with very deep neural networks", "to": "Going deeper with convolutions", "weight": 1}, {"from": "Deepid3: Face recognition with very deep neural networks", "to": "DeepFace: Closing the gap to human-level performance in face veri\ufb01ca-tion", "weight": 1}, {"from": "Deepid3: Face recognition with very deep neural networks", "to": "Web-Technical report", "weight": 1}, {"from": "Deepid3: Face recognition with very deep neural networks", "to": "Learning face repre-sentation from scratch", "weight": 1}, {"from": "Deepid3: Face recognition with very deep neural networks", "to": "Deep learning identity-preserving face space", "weight": 1}, {"from": "Deepid3: Face recognition with very deep neural networks", "to": "Deep learning and disentangling face representation by multi-view perceptron", "weight": 1}, {"from": "Deepid3: Face recognition with very deep neural networks", "to": "Recover canonical-view faces in the wild with deep neural networks", "weight": 1}, {"from": "Face search at scale: 80 million gallery", "to": "Scalable face image retrieval using attribute-enhanced sparse codewords", "weight": 1}, {"from": "Face search at scale: 80 million gallery", "to": "Scalable face image retrieval with identity-based quantization and multi-reference re-ranking", "weight": 1}, {"from": "Face search at scale: 80 million gallery", "to": "Labeled faces in the wild: A database for studying face recognition in unconstrained environments", "weight": 1}, {"from": "Face search at scale: 80 million gallery", "to": "Face retriever: Pre-\ufb01ltering the gallery via deep neural net", "weight": 1}, {"from": "Face search at scale: 80 million gallery", "to": "Bayesian face revisited: A joint formulation", "weight": 1}, {"from": "Face search at scale: 80 million gallery", "to": "Learning face representation from scratch", "weight": 1}, {"from": "Face search at scale: 80 million gallery", "to": "Product quantization for nearest neighbor search", "weight": 1}, {"from": "Face search at scale: 80 million gallery", "to": "Face recognition vendor (frvt): Performance of face identi\ufb01cation algorithms", "weight": 1}, {"from": "Face search at scale: 80 million gallery", "to": "Pushing the frontiers of unconstrained face detection and recognition: Iarpa janus benchmark", "weight": 1}, {"from": "Face search at scale: 80 million gallery", "to": "Attribute and simile classi\ufb01ers for face veri\ufb01cation", "weight": 1}, {"from": "Face search at scale: 80 million gallery", "to": "Megaface: A million faces for recognition at scale", "weight": 1}, {"from": "Face search at scale: 80 million gallery", "to": "A data-driven approach to cleaning large face datasets", "weight": 1}, {"from": "Face search at scale: 80 million gallery", "to": "Fast matching by 2 lines of code for large scale face recognition systems", "weight": 1}, {"from": "Face search at scale: 80 million gallery", "to": "The feret evaluation methodology for face-recognition algorithms", "weight": 1}, {"from": "Face search at scale: 80 million gallery", "to": "Towards incremental and large scale face recognition", "weight": 1}, {"from": "Face search at scale: 80 million gallery", "to": "Overview of the face recognition grand challenge", "weight": 1}, {"from": "Face search at scale: 80 million gallery", "to": "Ef\ufb01cient face retrieval using synecdoches", "weight": 1}, {"from": "Face search at scale: 80 million gallery", "to": "Unconstrained face recognition: Identifying a person of interest from a media collection", "weight": 1}, {"from": "Face search at scale: 80 million gallery", "to": "A benchmark study of large-scale unconstrained face recognition", "weight": 1}, {"from": "Face search at scale: 80 million gallery", "to": "Z", "weight": 1}, {"from": "Face search at scale: 80 million gallery", "to": "Facenet: A uni\ufb01ed embedding for face recognition and clustering", "weight": 1}, {"from": "Face search at scale: 80 million gallery", "to": "A survey of content-based image retrieval with high-level semantics", "weight": 1}, {"from": "Face search at scale: 80 million gallery", "to": "Retrieval-based face annotation by weak label regularized local coordinate coding", "weight": 1}, {"from": "Face search at scale: 80 million gallery", "to": "Modeling LSH for performance tuning", "weight": 1}, {"from": "Face search at scale: 80 million gallery", "to": "Discrimination of characters by a multi-stage recognition process", "weight": 1}, {"from": "Face search at scale: 80 million gallery", "to": "Deep learning for content-based image retrieval: A comprehensive study", "weight": 1}, {"from": "Face search at scale: 80 million gallery", "to": "Very deep convolutional networks for large-scale image recognition", "weight": 1}, {"from": "Face search at scale: 80 million gallery", "to": "One millisecond face alignment with an ensemble of regression trees", "weight": 1}, {"from": "Face search at scale: 80 million gallery", "to": "Imagenet classi\ufb01cation with deep convolutional neural networks", "weight": 1}, {"from": "Face search at scale: 80 million gallery", "to": "Dropout: A simple way to prevent neural networks from over\ufb01tting", "weight": 1}, {"from": "Face search at scale: 80 million gallery", "to": "Locally optimized product quantization for approximate nearest neighbor search", "weight": 1}, {"from": "Face search at scale: 80 million gallery", "to": "On combining classi\ufb01ers", "weight": 1}, {"from": "Face search at scale: 80 million gallery", "to": "Score normalization in multimodal biometric systems", "weight": 1}, {"from": "Face search at scale: 80 million gallery", "to": "On the link between error correlation and error reduction in decision tree ensembles", "weight": 1}, {"from": "Face search at scale: 80 million gallery", "to": "Deepface: Closing the gap to human-level performance in face veri\ufb01cation", "weight": 1}, {"from": "Face search at scale: 80 million gallery", "to": "Deep learning face representation by joint identi\ufb01cation-veri\ufb01cation", "weight": 1}, {"from": "Face search at scale: 80 million gallery", "to": "Deepid3: Face recognition with very deep neural networks", "weight": 1}, {"from": "Face search at scale: 80 million gallery", "to": "Naive-deep face recognition: Touching the limit of LFW benchmark or not?", "weight": 1}, {"from": "Face search at scale: 80 million gallery", "to": "Robust real-time face detection", "weight": 1}, {"from": "Face search at scale: 80 million gallery", "to": "Unsupervised joint alignment of complex images", "weight": 1}, {"from": "Face search at scale: 80 million gallery", "to": "A case study of automated face recognition: The boston marathon bombings suspects", "weight": 1}, {"from": "Deep functional maps: Structured prediction for dense shape correspondence", "to": "", "weight": 1}, {"from": "Deep functional maps: Structured prediction for dense shape correspondence", "to": "8(2):1141\u20131160", "weight": 1}, {"from": "Wide residual networks", "to": "", "weight": 1}, {"from": "Wide residual networks", "to": "editors, Proceedings of the 32nd International Conference on Machine Learning (ICML-15), pages 448\u2013456", "weight": 1}, {"from": "Wide residual networks", "to": "Inception-v4, inception-resnet and the impact of residual connections on learning", "weight": 1}, {"from": "ebear: An expressive bear-like robot", "to": "A \u201csomatic alphabet\u201d approach to \u201csensitive skin\u201d", "weight": 1}, {"from": "ebear: An expressive bear-like robot", "to": "Emotions and robot artists: State-of-the-art and research challenges", "weight": 1}, {"from": "ebear: An expressive bear-like robot", "to": "The expression of the emotions in man and animals", "weight": 1}, {"from": "ebear: An expressive bear-like robot", "to": "Facial Action Coding System: A Technique Palo Alto: Consulting for the Measurement of Facial Movement", "weight": 1}, {"from": "ebear: An expressive bear-like robot", "to": "Tutelage and collab-oration for humanoid robots", "weight": 1}, {"from": "ebear: An expressive bear-like robot", "to": "The shape of simon: creative design of a humanoid robot shell", "weight": 1}, {"from": "ebear: An expressive bear-like robot", "to": "icat: Experimenting with animabotics", "weight": 1}, {"from": "ebear: An expressive bear-like robot", "to": "Design and testing of a hybrid expressive face for a humanoid robot", "weight": 1}, {"from": "ebear: An expressive bear-like robot", "to": "Animating visible speech and facial expressions", "weight": 1}, {"from": "ebear: An expressive bear-like robot", "to": "Handbook of the International Phonetic Association: A guide to the use of the International Phonetic Alphabet", "weight": 1}, {"from": "ebear: An expressive bear-like robot", "to": "Nonparametric regression and spline smoothing", "weight": 1}, {"from": "ebear: An expressive bear-like robot", "to": "A design methodology for expressing emotion on robot faces", "weight": 1}, {"from": "ebear: An expressive bear-like robot", "to": "Facial expression recognition using hessianmkl based multiclass-svm", "weight": 1}, {"from": "ebear: An expressive bear-like robot", "to": "The extended cohn-kanade dataset (ck+): A complete dataset for action unit and emotion-speci\ufb01ed expression", "weight": 1}, {"from": "ebear: An expressive bear-like robot", "to": "Induced disgust", "weight": 1}, {"from": "ebear: An expressive bear-like robot", "to": "Supervised descent method and its applications to face alignment", "weight": 1}, {"from": "ebear: An expressive bear-like robot", "to": "Histograms of oriented gradients for human detection", "weight": 1}, {"from": "ebear: An expressive bear-like robot", "to": "Face recognition with local binary patterns", "weight": 1}, {"from": "ebear: An expressive bear-like robot", "to": "Facial expression recognition using game theory", "weight": 1}, {"from": "ebear: An expressive bear-like robot", "to": "Local directional number pattern for face analysis: Face and expression recognition", "weight": 1}, {"from": "ebear: An expressive bear-like robot", "to": "Facial expression recognition based on local binary patterns: A comprehensive study", "weight": 1}, {"from": "Vizdoom: A doom-based ai research platform In IEEE Conference on for visual reinforcement learning", "to": "", "weight": 1}, {"from": "Vizdoom: A doom-based ai research platform In IEEE Conference on for visual reinforcement learning", "to": "A vision-based reinforcement learning for coordination of soccer playing behaviors", "weight": 1}, {"from": "Vizdoom: A doom-based ai research platform In IEEE Conference on for visual reinforcement learning", "to": "pages 276\u2013282", "weight": 1}, {"from": "Vizdoom: A doom-based ai research platform In IEEE Conference on for visual reinforcement learning", "to": "Reinforcement In Intelligent Robots and learning for a vision based mobile robot", "weight": 1}, {"from": "Vizdoom: A doom-based ai research platform In IEEE Conference on for visual reinforcement learning", "to": "editors, Proceedings of the Fourteenth International Conference on Ar-ti\ufb01cial Intelligence and Statistics (AISTATS-11), volume 15, pages 315\u2013 323", "weight": 1}, {"from": "Vizdoom: A doom-based ai research platform In IEEE Conference on for visual reinforcement learning", "to": "Believable Bot Navigation via Playback of Human Traces, pages 151\u2013170", "weight": 1}, {"from": "Vizdoom: A doom-based ai research platform In IEEE Conference on for visual reinforcement learning", "to": "Deep auto-encoder neural net-works in reinforcement learning", "weight": 1}, {"from": "Vizdoom: A doom-based ai research platform In IEEE Conference on for visual reinforcement learning", "to": "Recti\ufb01er nonlinearities improve neural network acoustic models", "weight": 1}, {"from": "Vizdoom: A doom-based ai research platform In IEEE Conference on for visual reinforcement learning", "to": "RE-TALIATE: learning winning policies in \ufb01rst-person shooter games", "weight": 1}, {"from": "Vizdoom: A doom-based ai research platform In IEEE Conference on for visual reinforcement learning", "to": "Continuous and Reinforcement Learning Methods for First-Person Shooter Games", "weight": 1}, {"from": "Vizdoom: A doom-based ai research platform In IEEE Conference on for visual reinforcement learning", "to": "Computer game engines for developing \ufb01rst-person virtual environments", "weight": 1}, {"from": "Visual semantic planning using deep successor representations", "to": "", "weight": 1}, {"from": "The devil is in the details: an evaluation of recent feature encoding methods", "to": "", "weight": 1}, {"from": "The devil is in the details: an evaluation of recent feature encoding methods", "to": "PatchMatch: A Randomized Correspon-dence Algorithm for Structural Image Editing", "weight": 1}, {"from": "The devil is in the details: an evaluation of recent feature encoding methods", "to": "Random Sample Consensus: A Paradigm for Model Fitting with Applications to Image Analysis and Automated Cartography", "weight": 1}, {"from": "The devil is in the details: an evaluation of recent feature encoding methods", "to": "ImageNet Classi\ufb01cation with Deep Convolutional Neural Networks", "weight": 1}, {"from": "The devil is in the details: an evaluation of recent feature encoding methods", "to": "A Benchmark Dataset and Evaluation Methodology for Video Object Segmentation", "weight": 1}, {"from": "The devil is in the details: an evaluation of recent feature encoding methods", "to": "FaceForen-sics: A Large-Scale Video Dataset for Forgery Detection in Human Faces", "weight": 1}, {"from": "The devil is in the details: an evaluation of recent feature encoding methods", "to": "Going Deeper With Convolutions", "weight": 1}, {"from": "The devil is in the details: an evaluation of recent feature encoding methods", "to": "Attention is All You Need", "weight": 1}, {"from": "The devil is in the details: an evaluation of recent feature encoding methods", "to": "Space-Time Completion of Video", "weight": 1}, {"from": "The devil is in the details: an evaluation of recent feature encoding methods", "to": "The Unreasonable Effectiveness of Deep In IEEE Conference on Features as a Perceptual Metric", "weight": 1}, {"from": "3D semantic segmentation with submanifold sparse convolutional networks", "to": "", "weight": 1}, {"from": "Video propagation networks", "to": "", "weight": 1}, {"from": "Emotionet: An accurate", "to": "A novel locally linear knn model for visual recognition", "weight": 1}, {"from": "Emotionet: An accurate", "to": "Recognizing imprecisely localized", "weight": 1}, {"from": "Emotionet: An accurate", "to": "Computational models of face perception", "weight": 1}, {"from": "Emotionet: An accurate", "to": "J", "weight": 1}, {"from": "Emotionet: An accurate", "to": "A neural basis of facial action recognition in humans", "weight": 1}, {"from": "Emotionet: An accurate", "to": "Lifting from the deep: Convolutional 3d pose estimation from a single image", "weight": 1}, {"from": "Emotionet: An accurate", "to": "Facial action unit recognition by exploiting their dynamic and semantic relationships", "weight": 1}, {"from": "Emotionet: An accurate", "to": "Transferring face veri\ufb01-cation nets to pain and expression regression", "weight": 1}, {"from": "Emotionet: An accurate", "to": "Multiob-jective optimization for model selection in kernel methods in regression", "weight": 1}, {"from": "Emotionet: An accurate", "to": "Kernel op-IEEE Transactions on timization in discriminant analysis", "weight": 1}, {"from": "Emotionet: An accurate", "to": "Facial affect \u201cin the wild\u201d", "weight": 1}, {"from": "Emotionet: An accurate", "to": "Joint patch and multi-label learning for facial action unit and holistic expression recognition", "weight": 1}, {"from": "Emotionet: An accurate", "to": "A simple", "weight": 1}, {"from": "Emotionet: An accurate", "to": "Emotionet: An accurate", "weight": 1}, {"from": "Emotionet: An accurate", "to": "Survey on rgb", "weight": 1}, {"from": "Emotionet: An accurate", "to": "Emotion recognition in the wild", "weight": 1}, {"from": "Emotionet: An accurate", "to": "Compound facial expres-sions of emotion", "weight": 1}, {"from": "Emotionet: An accurate", "to": "What the Face Reveals: Ba-sic and applied studies of spontaneous expression using the Facial Action Coding System (FACS)", "weight": 1}, {"from": "Emotionet: An accurate", "to": "The pascal visual object classes (voc) chal-lenge", "weight": 1}, {"from": "Emotionet: An accurate", "to": "The \ufb01rst 3d face alignment in the wild (3dfaw) challenge", "weight": 1}, {"from": "Emotionet: An accurate", "to": "Support vector machines in face recognition with occlusions", "weight": 1}, {"from": "Emotionet: An accurate", "to": "The megaface benchmark: 1 million faces for recognition at scale", "weight": 1}, {"from": "Emotionet: An accurate", "to": "An analysis of facial expres-sion recognition under partial facial image occlusion", "weight": 1}, {"from": "Emotionet: An accurate", "to": "Imagenet classi\ufb01cation with deep convolutional neural networks", "weight": 1}, {"from": "Caffe: Convolutional architecture for fast feature embedding", "to": "Torch7: A MATLAB-like environment for machine learning", "weight": 1}, {"from": "Caffe: Convolutional architecture for fast feature embedding", "to": "Decaf: A deep convolutional activation feature for generic visual recognition", "weight": 1}, {"from": "Caffe: Convolutional architecture for fast feature embedding", "to": "Rich feature hierarchies for accurate object detection and semantic segmentation", "weight": 1}, {"from": "Caffe: Convolutional architecture for fast feature embedding", "to": "Pylearn2: a machine learning research library", "weight": 1}, {"from": "Caffe: Convolutional architecture for fast feature embedding", "to": "Open-vocabulary object retrieval", "weight": 1}, {"from": "Caffe: Convolutional architecture for fast feature embedding", "to": "Recognizing image style", "weight": 1}, {"from": "Caffe: Convolutional architecture for fast feature embedding", "to": "cuda-convnet", "weight": 1}, {"from": "Caffe: Convolutional architecture for fast feature embedding", "to": "ImageNet classi\ufb01cation with deep convolutional neural networks", "weight": 1}, {"from": "Caffe: Convolutional architecture for fast feature embedding", "to": "Overfeat: Integrated recognition", "weight": 1}, {"from": "Caffe: Convolutional architecture for fast feature embedding", "to": "Selective search for object recognition", "weight": 1}, {"from": "Caffe: Convolutional architecture for fast feature embedding", "to": "Panda: Pose aligned networks for deep attribute modeling", "weight": 1}, {"from": "Decaf: A deep convolutional activation feature for generic visual recognition", "to": "A framework for learning predictive structures from multiple tasks and unlabeled data", "weight": 1}, {"from": "Decaf: A deep convolutional activation feature for generic visual recognition", "to": "Van", "weight": 1}, {"from": "Decaf: A deep convolutional activation feature for generic visual recognition", "to": "", "weight": 1}, {"from": "Decaf: A deep convolutional activation feature for generic visual recognition", "to": "POOF: Part-based one-vs-one features for \ufb01ne-grained categorization, face veri\ufb01cation, and attribute estimation", "weight": 1}, {"from": "Decaf: A deep convolutional activation feature for generic visual recognition", "to": "Kernel descriptors for visual recog-nition", "weight": 1}, {"from": "Decaf: A deep convolutional activation feature for generic visual recognition", "to": "Multitask learning", "weight": 1}, {"from": "Decaf: A deep convolutional activation feature for generic visual recognition", "to": "Dlid: Deep learn-ing for domain adaptation by interpolating between domains", "weight": 1}, {"from": "Decaf: A deep convolutional activation feature for generic visual recognition", "to": "Histograms of oriented gradients for human detection", "weight": 1}, {"from": "Decaf: A deep convolutional activation feature for generic visual recognition", "to": "In ImageNet: A Large-Scale Hierarchical Image Database", "weight": 1}, {"from": "Decaf: A deep convolutional activation feature for generic visual recognition", "to": "Learning generative visual models from few training examples: an incremental Bayesian approach tested on 101 object categories", "weight": 1}, {"from": "Decaf: A deep convolutional activation feature for generic visual recognition", "to": "Object detection with discriminatively trained part-based mod-els", "weight": 1}, {"from": "Decaf: A deep convolutional activation feature for generic visual recognition", "to": "Geodesic \ufb02ow kernel for unsupervised domain adaptation", "weight": 1}, {"from": "Decaf: A deep convolutional activation feature for generic visual recognition", "to": "Reducing the dimensionality of data with neural networks", "weight": 1}, {"from": "Decaf: A deep convolutional activation feature for generic visual recognition", "to": ", Sutskever, and Salakhutdinov, R", "weight": 1}, {"from": "Decaf: A deep convolutional activation feature for generic visual recognition", "to": "Ef\ufb01cient learning of domain-invariant image representations", "weight": 1}, {"from": "Decaf: A deep convolutional activation feature for generic visual recognition", "to": "Multi-arXiv preprint label prediction via compressed sensing", "weight": 1}, {"from": "Decaf: A deep convolutional activation feature for generic visual recognition", "to": ", and LeCun, Y", "weight": 1}, {"from": "Decaf: A deep convolutional activation feature for generic visual recognition", "to": "ImageNet clas-si\ufb01cation with deep convolutional neural networks", "weight": 1}, {"from": "Decaf: A deep convolutional activation feature for generic visual recognition", "to": "What you saw is not what you get: Domain adaptation using asymmetric kernel trans-forms", "weight": 1}, {"from": "Decaf: A deep convolutional activation feature for generic visual recognition", "to": "Learning hierarchical invariant spatio-temporal features for action recognition with independent subspace analysis", "weight": 1}, {"from": "Decaf: A deep convolutional activation feature for generic visual recognition", "to": "Building high-level features using large scale unsupervised learning", "weight": 1}, {"from": "Decaf: A deep convolutional activation feature for generic visual recognition", "to": "Backpropagation applied to hand-written zip code recognition", "weight": 1}, {"from": "Decaf: A deep convolutional activation feature for generic visual recognition", "to": "Gradient-based learning applied to document recognition", "weight": 1}, {"from": "Decaf: A deep convolutional activation feature for generic visual recognition", "to": "Object bank: A high-level image representation for scene classi\ufb01cation \u0026 semantic feature sparsi\ufb01cation", "weight": 1}, {"from": "Decaf: A deep convolutional activation feature for generic visual recognition", "to": "Unsupervised and transfer learning challenge: a deep learning approach", "weight": 1}, {"from": "Decaf: A deep convolutional activation feature for generic visual recognition", "to": "Modeling the shape of the scene: A holistic representation of the spatial envelope", "weight": 1}, {"from": "Decaf: A deep convolutional activation feature for generic visual recognition", "to": "Transfer learning for In image classication with sparse prototype representations", "weight": 1}, {"from": "Decaf: A deep convolutional activation feature for generic visual recognition", "to": "Self-In taught learning: Transfer learning from unlabeled data", "weight": 1}, {"from": "Decaf: A deep convolutional activation feature for generic visual recognition", "to": "Histograms of sparse codes for object detection", "weight": 1}, {"from": "Decaf: A deep convolutional activation feature for generic visual recognition", "to": "Adapting visual category models to new domains", "weight": 1}, {"from": "Decaf: A deep convolutional activation feature for generic visual recognition", "to": "Unsupervised discovery of mid-level discriminative patches", "weight": 1}, {"from": "Decaf: A deep convolutional activation feature for generic visual recognition", "to": "Unbiased look at dataset bias", "weight": 1}, {"from": "Decaf: A deep convolutional activation feature for generic visual recognition", "to": "Visualizing data using t-sne", "weight": 1}, {"from": "Decaf: A deep convolutional activation feature for generic visual recognition", "to": "Locality-constrained linear coding for image classi\ufb01cation", "weight": 1}, {"from": "Decaf: A deep convolutional activation feature for generic visual recognition", "to": "Sun database: Large-scale scene recognition from abbey to zoo", "weight": 1}, {"from": "Decaf: A deep convolutional activation feature for generic visual recognition", "to": "Deformable part descriptors for \ufb01ne-grained recognition and attribute pre-diction", "weight": 1}, {"from": "Mask-cnn: Localizing parts and selecting descriptors for \ufb01ne-grained bird species categorization", "to": "Object detection using strongly-supervised deformable part models", "weight": 1}, {"from": "Mask-cnn: Localizing parts and selecting descriptors for \ufb01ne-grained bird species categorization", "to": "Bird species categorization using pose normalized deep convolutional nets", "weight": 1}, {"from": "Mask-cnn: Localizing parts and selecting descriptors for \ufb01ne-grained bird species categorization", "to": "Visual recognition using embedded feature selection for curvature self-similarity", "weight": 1}, {"from": "Mask-cnn: Localizing parts and selecting descriptors for \ufb01ne-grained bird species categorization", "to": "Local alignments for \ufb01ne-grained categorization", "weight": 1}, {"from": "Mask-cnn: Localizing parts and selecting descriptors for \ufb01ne-grained bird species categorization", "to": "Part-stacked CNN for \ufb01ne-grained visual categorization", "weight": 1}, {"from": "Mask-cnn: Localizing parts and selecting descriptors for \ufb01ne-grained bird species categorization", "to": "Spatial transformer networks", "weight": 1}, {"from": "Mask-cnn: Localizing parts and selecting descriptors for \ufb01ne-grained bird species categorization", "to": "Fine-grained recognition without part annotations", "weight": 1}, {"from": "Mask-cnn: Localizing parts and selecting descriptors for \ufb01ne-grained bird species categorization", "to": "ImageNet classi\ufb01cation with deep convolutional neural networks", "weight": 1}, {"from": "Mask-cnn: Localizing parts and selecting descriptors for \ufb01ne-grained bird species categorization", "to": "Deep LAC: Deep localization", "weight": 1}, {"from": "Mask-cnn: Localizing parts and selecting descriptors for \ufb01ne-grained bird species categorization", "to": "Fully convolutional networks for semantic segmentation", "weight": 1}, {"from": "Mask-cnn: Localizing parts and selecting descriptors for \ufb01ne-grained bird species categorization", "to": "GrabCut: Interactive foreground extraction using iterated graph cuts", "weight": 1}, {"from": "Mask-cnn: Localizing parts and selecting descriptors for \ufb01ne-grained bird species categorization", "to": "Neural activation constellations: Unsupervised part model discovery with convolutional networks", "weight": 1}, {"from": "Mask-cnn: Localizing parts and selecting descriptors for \ufb01ne-grained bird species categorization", "to": "Very deep convolutional networks for large-scale image recognition", "weight": 1}, {"from": "Mask-cnn: Localizing parts and selecting descriptors for \ufb01ne-grained bird species categorization", "to": "MatConvNet: Convolutional neural networks for MATLAB", "weight": 1}, {"from": "Mask-cnn: Localizing parts and selecting descriptors for \ufb01ne-grained bird species categorization", "to": "The Caltech-UCSD birds-200-2011 dataset", "weight": 1}, {"from": "Mask-cnn: Localizing parts and selecting descriptors for \ufb01ne-grained bird species categorization", "to": "The application of two-level attention models in deep convolutional neural network for \ufb01ne-grained image classi\ufb01cation", "weight": 1}, {"from": "Mask-cnn: Localizing parts and selecting descriptors for \ufb01ne-grained bird species categorization", "to": "Adaptive deconvolutional networks for mid and high level feature learning", "weight": 1}, {"from": "Mask-cnn: Localizing parts and selecting descriptors for \ufb01ne-grained bird species categorization", "to": "Part-based R-CNNs for \ufb01ne-grained category detection", "weight": 1}, {"from": "Mask-cnn: Localizing parts and selecting descriptors for \ufb01ne-grained bird species categorization", "to": "Compact representation for image classi\ufb01cation: To choose or to compress? In CVPR", "weight": 1}, {"from": "Mask-cnn: Localizing parts and selecting descriptors for \ufb01ne-grained bird species categorization", "to": "Picking deep \ufb01lter resonses for \ufb01ne-grained image recognition", "weight": 1}, {"from": "Mask-cnn: Localizing parts and selecting descriptors for \ufb01ne-grained bird species categorization", "to": "Weakly supervised \ufb01ne-grained categorization with part-based image representation", "weight": 1}, {"from": "Squeezenext: Hardware-aware neural network design", "to": "Origami: A 803-gop/s/w IEEE Transac-convolutional network accelerator", "weight": 1}, {"from": "Squeezenext: Hardware-aware neural network design", "to": "Neu\ufb02ow: A runtime recon-\ufb01gurable data\ufb02ow processor for vision", "weight": 1}, {"from": "Squeezenext: Hardware-aware neural network design", "to": "Cnp: An fpga-based processor for convolutional networks", "weight": 1}, {"from": "Squeezenext: Hardware-aware neural network design", "to": "Integrated model", "weight": 1}, {"from": "Squeezenext: Hardware-aware neural network design", "to": "A 240 g-ops/s mobile coprocessor for deep In Proceedings of the IEEE Con-neural networks", "weight": 1}, {"from": "Squeezenext: Hardware-aware neural network design", "to": "Deep compres-sion: Compressing deep neural networks with prun-In-ing", "weight": 1}, {"from": "Squeezenext: Hardware-aware neural network design", "to": "Learning both weights and connections for ef\ufb01cient neural network", "weight": 1}, {"from": "Squeezenext: Hardware-aware neural network design", "to": "Deep resid-ual learning for image recognition", "weight": 1}, {"from": "Squeezenext: Hardware-aware neural network design", "to": "Shuf\ufb02e net: An ap-plication of generalized perfect shuf\ufb02es to multihop lightwave networks", "weight": 1}, {"from": "Squeezenext: Hardware-aware neural network design", "to": "Mobilenets: Ef\ufb01cient convolutional neural networks arXiv preprint for mobile vision applications", "weight": 1}, {"from": "Squeezenext: Hardware-aware neural network design", "to": "Condensenet: An ef\ufb01cient densenet using learned group convolutions", "weight": 1}, {"from": "Squeezenext: Hardware-aware neural network design", "to": "Densely connected convolutional networks", "weight": 1}, {"from": "Squeezenext: Hardware-aware neural network design", "to": "Quantized neural networks: Training neural networks with low precision weights and acti-vations", "weight": 1}, {"from": "Squeezenext: Hardware-aware neural network design", "to": "SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and\u003c 0", "weight": 1}, {"from": "Squeezenext: Hardware-aware neural network design", "to": "Batch normalization: Accel-erating deep network training by reducing internal co-variate shift", "weight": 1}, {"from": "Squeezenext: Hardware-aware neural network design", "to": "Speed-ing up convolutional neural networks with low rank expansions", "weight": 1}, {"from": "Squeezenext: Hardware-aware neural network design", "to": "C", "weight": 1}, {"from": "Squeezenext: Hardware-aware neural network design", "to": "Im-agenet classi\ufb01cation with deep convolutional neural networks", "weight": 1}, {"from": "Squeezenext: Hardware-aware neural network design", "to": "Weighted-entropy-based quantization for deep neural networks", "weight": 1}, {"from": "Squeezenext: Hardware-aware neural network design", "to": "Xnor-net: Imagenet classi\ufb01cation using binary convo-lutional neural networks", "weight": 1}, {"from": "Squeezenext: Hardware-aware neural network design", "to": "Darknet: Open source neural networks in c", "weight": 1}, {"from": "Squeezenext: Hardware-aware neural network design", "to": "Roo\ufb02ine: an insightful visual performance model for multicore architectures", "weight": 1}, {"from": "Squeezenext: Hardware-aware neural network design", "to": "Squeezedet: Uni\ufb01ed", "weight": 1}, {"from": "Squeezenext: Hardware-aware neural network design", "to": "Squeeze-seg: Convolutional neural nets with recurrent crf for real-time road-object segmentation from 3d lidar point cloud", "weight": 1}, {"from": "Squeezenext: Hardware-aware neural network design", "to": "Deep layer aggrega-tion", "weight": 1}, {"from": "Squeezenext: Hardware-aware neural network design", "to": "S", "weight": 1}, {"from": "Condensenet: An ef\ufb01cient densenet using learned group convolutions", "to": "Learning the number of neurons in deep networks", "weight": 1}, {"from": "Condensenet: An ef\ufb01cient densenet using learned group convolutions", "to": "Adaptive neural networks for fast test-time prediction", "weight": 1}, {"from": "Condensenet: An ef\ufb01cient densenet using learned group convolutions", "to": "Model compression", "weight": 1}, {"from": "Condensenet: An ef\ufb01cient densenet using learned group convolutions", "to": "In Compressing neural networks with the hashing trick", "weight": 1}, {"from": "Condensenet: An ef\ufb01cient densenet using learned group convolutions", "to": "Xception: Deep learning with depthwise sepa-rable convolutions", "weight": 1}, {"from": "Condensenet: An ef\ufb01cient densenet using learned group convolutions", "to": "Imagenet: A large-scale hierarchical image database", "weight": 1}, {"from": "Condensenet: An ef\ufb01cient densenet using learned group convolutions", "to": "M", "weight": 1}, {"from": "Condensenet: An ef\ufb01cient densenet using learned group convolutions", "to": "Adaptive computation time for recurrent neural networks", "weight": 1}, {"from": "Condensenet: An ef\ufb01cient densenet using learned group convolutions", "to": "Deep compres-sion: Compressing deep neural networks with pruning", "weight": 1}, {"from": "Condensenet: An ef\ufb01cient densenet using learned group convolutions", "to": "Learning both weights and connections for ef\ufb01cient neural network", "weight": 1}, {"from": "Condensenet: An ef\ufb01cient densenet using learned group convolutions", "to": "Optimal brain sur-geon and general network pruning", "weight": 1}, {"from": "Condensenet: An ef\ufb01cient densenet using learned group convolutions", "to": "Deep residual learning for image recognition", "weight": 1}, {"from": "Condensenet: An ef\ufb01cient densenet using learned group convolutions", "to": "Identity mappings in deep residual networks", "weight": 1}, {"from": "Condensenet: An ef\ufb01cient densenet using learned group convolutions", "to": "Channel pruning for accelerat-ing very deep neural networks", "weight": 1}, {"from": "Condensenet: An ef\ufb01cient densenet using learned group convolutions", "to": "Distilling the knowl-edge in a neural network", "weight": 1}, {"from": "Condensenet: An ef\ufb01cient densenet using learned group convolutions", "to": "Mobilenets: Ef\ufb01-cient convolutional neural networks for mobile vision appli-cations", "weight": 1}, {"from": "Condensenet: An ef\ufb01cient densenet using learned group convolutions", "to": "Multi-scale dense networks for resource ef\ufb01cient image classi\ufb01cation", "weight": 1}, {"from": "Condensenet: An ef\ufb01cient densenet using learned group convolutions", "to": "Snapshot ensembles: Train 1", "weight": 1}, {"from": "Condensenet: An ef\ufb01cient densenet using learned group convolutions", "to": "Densely connected convolutional networks", "weight": 1}, {"from": "Condensenet: An ef\ufb01cient densenet using learned group convolutions", "to": "Deep networks with stochastic depth", "weight": 1}, {"from": "Condensenet: An ef\ufb01cient densenet using learned group convolutions", "to": "Binarized neural networks", "weight": 1}, {"from": "Condensenet: An ef\ufb01cient densenet using learned group convolutions", "to": "Squeezenet: Alexnet-level accuracy with 50x fewer parameters and 0", "weight": 1}, {"from": "Condensenet: An ef\ufb01cient densenet using learned group convolutions", "to": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "weight": 1}, {"from": "Condensenet: An ef\ufb01cient densenet using learned group convolutions", "to": "Learning multiple layers of features from tiny images", "weight": 1}, {"from": "Condensenet: An ef\ufb01cient densenet using learned group convolutions", "to": "classi\ufb01cation with deep convolutional neural networks", "weight": 1}, {"from": "Condensenet: An ef\ufb01cient densenet using learned group convolutions", "to": "Fractalnet: Ultra-deep neural networks without residuals", "weight": 1}, {"from": "Condensenet: An ef\ufb01cient densenet using learned group convolutions", "to": "volume 2", "weight": 1}, {"from": "Condensenet: An ef\ufb01cient densenet using learned group convolutions", "to": "Pruning \ufb01lters for ef\ufb01cient convnets", "weight": 1}, {"from": "Condensenet: An ef\ufb01cient densenet using learned group convolutions", "to": "Network in network", "weight": 1}, {"from": "Condensenet: An ef\ufb01cient densenet using learned group convolutions", "to": "Learning ef\ufb01cient convolutional networks through network slimming", "weight": 1}, {"from": "Condensenet: An ef\ufb01cient densenet using learned group convolutions", "to": "SGDR: stochastic gradient de-scent with restarts", "weight": 1}, {"from": "Condensenet: An ef\ufb01cient densenet using learned group convolutions", "to": "Recti\ufb01ed linear units improve re-stricted boltzmann machines", "weight": 1}, {"from": "Condensenet: An ef\ufb01cient densenet using learned group convolutions", "to": "Xnor-net: Imagenet classi\ufb01cation using binary convolutional neu-ral networks", "weight": 1}, {"from": "Condensenet: An ef\ufb01cient densenet using learned group convolutions", "to": "Fitnets: Hints for thin deep nets", "weight": 1}, {"from": "Condensenet: An ef\ufb01cient densenet using learned group convolutions", "to": "J", "weight": 1}, {"from": "Condensenet: An ef\ufb01cient densenet using learned group convolutions", "to": "Striving for simplicity: The all convolutional net", "weight": 1}, {"from": "Condensenet: An ef\ufb01cient densenet using learned group convolutions", "to": "Dropout: a simple way to prevent neu-ral networks from over\ufb01tting", "weight": 1}, {"from": "Condensenet: An ef\ufb01cient densenet using learned group convolutions", "to": "Training very deep networks", "weight": 1}, {"from": "Condensenet: An ef\ufb01cient densenet using learned group convolutions", "to": "Going deeper with convolutions", "weight": 1}, {"from": "Condensenet: An ef\ufb01cient densenet using learned group convolutions", "to": "Aggregated residual transformations for deep neural networks", "weight": 1}, {"from": "Condensenet: An ef\ufb01cient densenet using learned group convolutions", "to": "Model selection and estimation in re-gression with grouped variables", "weight": 1}, {"from": "Condensenet: An ef\ufb01cient densenet using learned group convolutions", "to": "Wide residual networks", "weight": 1}, {"from": "Condensenet: An ef\ufb01cient densenet using learned group convolutions", "to": "Interleaved group convolutions for deep neural networks", "weight": 1}, {"from": "Condensenet: An ef\ufb01cient densenet using learned group convolutions", "to": "Shuf\ufb02enet: An extremely ef\ufb01cient convolutional neural network for mobile devices", "weight": 1}, {"from": "Condensenet: An ef\ufb01cient densenet using learned group convolutions", "to": "Deep convolu-tional neural networks with merge-and-run mappings", "weight": 1}, {"from": "Condensenet: An ef\ufb01cient densenet using learned group convolutions", "to": "Learn-ing transferable architectures for scalable image recognition", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "Orientation-boosted voxel nets for 3d object recognition", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "Segnet: A deep convolutional encoder-decoder architecture for image segmentation", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "Learning 6d object pose estimation using In Proc", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "Uncertainty-driven 6d pose estimation of ob-In Proc", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "Generative and discriminative voxel modeling with convolutional neural networks", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "Shapenet: An information-rich 3d model repository", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "A large dataset of object scans", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "3d-r2n2: A uni\ufb01ed approach for single and multi-view 3d object reconstruction", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "P", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "Vote3deep: Fast object detection in 3d point clouds using ef-\ufb01cient convolutional neural networks", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "Real time head pose In Proc", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "Deep-stereo: Learning to predict new views from the world\u2019s im-agery", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "Ef-\ufb01cient 2d and 3d facade segmentation using auto-context", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "Laplacian pyramid reconstruc-tion and re\ufb01nement for semantic segmentation", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "Learning a predictable and generative vector representation In Proc", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "Spatially-sparse convolutional neural networks", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "Sparse 3d convolutional neural networks", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "Delving deep into recti\ufb01ers: Surpassing human-level performance on imagenet classi\ufb01cation", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "Deep residual learning In Proc", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "Fusionnet: 3d object classi\ufb01cation using multiple data representations", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "Point cloud labeling using 3d convolu-tional neural network", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "Single-view reconstruc-In tion via joint analysis of image and shape collections", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "Learning sparse high dimensional \ufb01lters: Image \ufb01ltering", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "An octree-based approach towards ef\ufb01cient variational range data fusion", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "Adam: A method for stochastic optimization", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "Imagenet classi\ufb01cation with deep convolutional neural networks", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "Ef\ufb01cient sparse voxel octrees", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "FPNN: \ufb01eld probing neural networks for 3d data", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "3d all the way: Semantic segmentation of urban scenes from start to end in 3d", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "Voxnet: A 3d convolutional In Proc", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "Geometric modeling using octree encod-ing", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "Real-time rendering In Proc", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "V-net: Fully convo-lutional neural networks for volumetric medical image seg-mentation", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "Deep3d: Fully au-tomatic 2d-to-3d video conversion with deep convolutional In Proc", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "Generic 3d representation via pose estimation and matching", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "Adaptive decon-volutional networks for mid and high level feature learning", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "Deepcon-text: Context-encoding neural pathways for 3d holistic scene understanding", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "Kinectfusion: Real-time dense surface map-ping and tracking", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "Volumetric and multi-view cnns for object classi\ufb01cation on 3d data", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "Faster R-CNN: towards real-time object detection with region proposal net-works", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "Unsupervised learning of 3d structure from images", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "Learning where to classify in multi-view semantic segmentation", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "Discriminatively trained templates for 3d object detection: A real-time scalable ap-proach", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "Vconv-dae: Deep vol-arXiv", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "Deep sliding shapes for amodal 3d object detection in RGB-D images", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "Multi-view convolutional neural networks for 3d shape In Proc", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "Multi-view 3d models from single images with a convolutional network", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "Latent-class hough forests for 3d object detection and pose estima-In Proc", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "Towards prob-abilistic volumetric reconstruction using ray potentials", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "Learning descriptors for object recognition and 3d pose estimation", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "Single image 3d interpreter net-work", "weight": 1}, {"from": "Octnet: Learning Deep 3D Representations at High Resolutions", "to": "3d shapenets: A deep representation for volumetric shapes", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "The protein data bank", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "A benchmark for 3D mesh segmentation", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "Schelling points on 3D surface meshes", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "ImageNet: A large-scale hierarchical image database", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "Example-based synthesis of 3D object arrangements", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "Fine-grained semi-supervised labeling of large shape collections", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "Developing an engineering shape benchmark for CAD models", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "A probabilistic model for component-based shape synthesis", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "Mobius transformations for global intrinsic symmetry analysis", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "Learning part-based templates from large collections of 3D shapes", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "Exploring collections of 3D models using fuzzy correspondences", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "PDBsum: A web-based database of summaries and analyses of all PDB structures", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "Cre-ating consistent scene graphs using a probabilistic grammar", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "Building a large annotated corpus of english: The Penn Treebank", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "Simpli\ufb01cation and repair of polygonal models using volumetric techniques", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "Building a database of 3D scenes from user annotations", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "The Princeton shape benchmark", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "Sliding shapes for 3D ob-ject detection in depth images", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "A large-scale shape benchmark for 3D object retrieval: Toy-ohashi shape benchmark", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "La-belMe: Online image annotation and applications", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "3D ShapeNets: A Deep Representation for Volumetric Shapes", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "Beyond PASCAL: A benchmark for 3D object detection in the wild", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "Retrieving articulated 3-D mod-els using medial surfaces and their graph spectra", "weight": 1}, {"from": "Expressionbot: An emotive lifelike robotic face for face-to-face communication", "to": "", "weight": 1}, {"from": "Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions", "to": "Action recognition in video using sparse coding and relative features", "weight": 1}, {"from": "Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions", "to": "FAUST: Dataset and evaluation for 3D mesh registration", "weight": 1}, {"from": "Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions", "to": "Fast convolutional sparse coding", "weight": 1}, {"from": "Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions", "to": "Spectral networks and locally connected networks on graphs", "weight": 1}, {"from": "Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions", "to": "", "weight": 1}, {"from": "Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions", "to": "Atomic decomposition by basis pursuit", "weight": 1}, {"from": "Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions", "to": "Indexing by latent semantic analysis", "weight": 1}, {"from": "Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions", "to": "Coupled func-tional maps", "weight": 1}, {"from": "Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions", "to": "Fine-grained semi-supervised labeling of large shape collections", "weight": 1}, {"from": "Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions", "to": "Recurrent slice networks for 3d segmen-tation on point clouds", "weight": 1}, {"from": "Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions", "to": "Joint shape segmentation with linear programming", "weight": 1}, {"from": "Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions", "to": "Functional map networks for analyzing and exploring large shape collections", "weight": 1}, {"from": "Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions", "to": "3D shape segmentation with projective convolutional networks", "weight": 1}, {"from": "Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions", "to": "Escape from cells: Deep kd-networks for the recogni-tion of 3d point cloud models", "weight": 1}, {"from": "Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions", "to": "Functional correspondence by matrix completion", "weight": 1}, {"from": "Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions", "to": "Ef\ufb01cient sparse coding algorithms", "weight": 1}, {"from": "Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions", "to": "Learning overcomplete representations", "weight": 1}, {"from": "Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions", "to": "Deep functional maps: Structured prediction for dense shape correspondence", "weight": 1}, {"from": "Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions", "to": "Informative descriptor preservation via commutativity for shape matching", "weight": 1}, {"from": "Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions", "to": "Emergence of simple-cell receptive \ufb01eld properties by learning a sparse code for natural images", "weight": 1}, {"from": "Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions", "to": "Sparse coding of sensory inputs", "weight": 1}, {"from": "Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions", "to": "Functional maps: a \ufb02exible representation of maps between shapes", "weight": 1}, {"from": "Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions", "to": "Sparse modeling of intrinsic correspondences", "weight": 1}, {"from": "Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions", "to": "Frustum pointnets for 3d object detection from rgb-d data", "weight": 1}, {"from": "Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions", "to": "Pointnet: Deep learning on point sets for 3d classi\ufb01cation and segmentation", "weight": 1}, {"from": "Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions", "to": "Pointnet++: Deep hierarchical feature learning on point sets in a metric space", "weight": 1}, {"from": "Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions", "to": "Partial functional correspondence", "weight": 1}, {"from": "Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions", "to": "A concise and provably informative multi-scale signature based on heat diffusion", "weight": 1}, {"from": "Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions", "to": "Image co-segmentation via consistent functional maps", "weight": 1}, {"from": "Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions", "to": "Sgpn: Similarity group proposal network for 3d point cloud instance segmentation", "weight": 1}, {"from": "Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions", "to": "Dynamic graph cnn for learning on point clouds", "weight": 1}, {"from": "Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions", "to": "A scalable active framework for region annotation in 3d shape collections", "weight": 1}, {"from": "Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions", "to": "Syncspeccnn: Synchronized spectral cnn for 3d shape segmentation", "weight": 1}, {"from": "Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions", "to": "Deconvolutional networks", "weight": 1}, {"from": "Action recognition in video using sparse coding and relative features", "to": "Human activity analysis", "weight": 1}, {"from": "Action recognition in video using sparse coding and relative features", "to": "K-SVD: An al-gorithm for designing overcomplete dictionaries for sparse representation", "weight": 1}, {"from": "Action recognition in video using sparse coding and relative features", "to": "Human action recogni-In tion from inter-temporal dictionaries of key-sequences", "weight": 1}, {"from": "Action recognition in video using sparse coding and relative features", "to": "Action synopsis: Pose selection and illustration", "weight": 1}, {"from": "Action recognition in video using sparse coding and relative features", "to": "Trajectory-based \ufb01sher kernel representation for action recognition in videos", "weight": 1}, {"from": "Action recognition in video using sparse coding and relative features", "to": "Representing shape with a spatial pyramid kernel", "weight": 1}, {"from": "Action recognition in video using sparse coding and relative features", "to": "Detecting people using mutually consistent poselet activations", "weight": 1}, {"from": "Action recognition in video using sparse coding and relative features", "to": "Sparse modeling of human ac-tions from motion imagery", "weight": 1}, {"from": "Action recognition in video using sparse coding and relative features", "to": "Behavior recognition via sparse spatio-temporal features", "weight": 1}, {"from": "Action recognition in video using sparse coding and relative features", "to": "Optimally sparse representation in general (non orthogonal) dictionaries via l1 minimization", "weight": 1}, {"from": "Action recognition in video using sparse coding and relative features", "to": "See all by looking at a few: Sparse modeling for \ufb01nding representative objects", "weight": 1}, {"from": "Action recognition in video using sparse coding and relative features", "to": "Object detection with discriminatively trained part based models", "weight": 1}, {"from": "Action recognition in video using sparse coding and relative features", "to": "A dual algorithm for the solu-tion of nonlinear variational problems via \ufb01nite-element ap-proximations", "weight": 1}, {"from": "Action recognition in video using sparse coding and relative features", "to": "Actom sequence models for ef\ufb01cient action detection", "weight": 1}, {"from": "Action recognition in video using sparse coding and relative features", "to": "Activity represen-tation with motion hierarchies", "weight": 1}, {"from": "Action recognition in video using sparse coding and relative features", "to": "Learning sparse representations for human action recognition", "weight": 1}, {"from": "Action recognition in video using sparse coding and relative features", "to": "Action recognition in video by sparse representation on covariance manifolds of silhou-ette tunnels", "weight": 1}, {"from": "Action recognition in video using sparse coding and relative features", "to": "Trajectory-based modeling of human actions with motion reference points", "weight": 1}, {"from": "Action recognition in video using sparse coding and relative features", "to": "Creating ef\ufb01cient codebooks for vi-In IEEE Int", "weight": 1}, {"from": "Action recognition in video using sparse coding and relative features", "to": "A spatio-temporal descriptor based on 3D-gradients", "weight": 1}, {"from": "Action recognition in video using sparse coding and relative features", "to": "Attribute and simile classi\ufb01ers for face veri\ufb01cation", "weight": 1}, {"from": "Action recognition in video using sparse coding and relative features", "to": "Space-time interest points", "weight": 1}, {"from": "Action recognition in video using sparse coding and relative features", "to": "In IEEE Learning realistic human actions from movies", "weight": 1}, {"from": "Action recognition in video using sparse coding and relative features", "to": "Recognizing human actions using multiple features", "weight": 1}, {"from": "Action recognition in video using sparse coding and relative features", "to": "Recognizing human ac-tions by attributes", "weight": 1}, {"from": "Action recognition in video using sparse coding and relative features", "to": "Boosted key-frame selec-tion and correlated pyramidal feature representation for hu-man action recognition", "weight": 1}, {"from": "Action recognition in video using sparse coding and relative features", "to": "Modeling temporal structure of decomposable motion segments for activity clas-si\ufb01cation", "weight": 1}, {"from": "Action recognition in video using sparse coding and relative features", "to": "Action and event recognition with \ufb01sher vectors on a compact feature set", "weight": 1}, {"from": "Action recognition in video using sparse coding and relative features", "to": "Relative attributes", "weight": 1}, {"from": "Action recognition in video using sparse coding and relative features", "to": "Discovering discrim-inative action parts from mid-level video representations", "weight": 1}, {"from": "Action recognition in video using sparse coding and relative features", "to": "Poselet key-framing: A model for human activity recognition", "weight": 1}, {"from": "Action recognition in video using sparse coding and relative features", "to": "Action Bank: A high-level rep-resentation of activity in video", "weight": 1}, {"from": "Action recognition in video using sparse coding and relative features", "to": "Action Snippets: How many In IEEE frames does human action recognition require? Conf", "weight": 1}, {"from": "Action recognition in video using sparse coding and relative features", "to": "Recognizing human In Int", "weight": 1}, {"from": "Action recognition in video using sparse coding and relative features", "to": "Modeling motion of body parts for action recognition", "weight": 1}, {"from": "Action recognition in video using sparse coding and relative features", "to": "Improved object categorization and detection using comparative object simi-larity", "weight": 1}, {"from": "Action recognition in video using sparse coding and relative features", "to": "Dense trajecto-ries and motion boundary descriptors for action recognition", "weight": 1}, {"from": "Action recognition in video using sparse coding and relative features", "to": "Evaluation of local spatio-temporal features for action recog-nition", "weight": 1}, {"from": "Action recognition in video using sparse coding and relative features", "to": "Hidden part models for human action recognition: Probabilistic versus max margin", "weight": 1}, {"from": "Action recognition in video using sparse coding and relative features", "to": "Action recognition using exemplar-based embedding", "weight": 1}, {"from": "Action recognition in video using sparse coding and relative features", "to": "Action recognition in videos acquired by a moving camera using motion decomposition of lagragian particle trajectories", "weight": 1}, {"from": "Action recognition in video using sparse coding and relative features", "to": "The power of comparative reasoning", "weight": 1}, {"from": "Action recognition in video using sparse coding and relative features", "to": "A Hough transform-based voting framework for action recognition", "weight": 1}, {"from": "Action recognition in video using sparse coding and relative features", "to": "Real-time action recognition by spatiotemporal semantic and structural forest", "weight": 1}, {"from": "Action recognition in video using sparse coding and relative features", "to": "Information theoretic key frame selection for action recognition", "weight": 1}, {"from": "Action recognition in video using sparse coding and relative features", "to": "Learning spatial and temporal extents of human actions for action detection", "weight": 1}, {"from": "Action recognition in video using sparse coding and relative features", "to": "Capturing long-tail distributions of object subcategories", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "A learned feature descriptor for object recognition in RGB-D data", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "Unsupervised feature learning for RGB-D based object recognition", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "Shapenet: An information-rich 3d model repository", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "AttribIt: Content creation with semantic at-tributes", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "Probabilistic reasoning for assembly-based 3D modeling", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "A benchmark for 3D mesh segmentation", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "A large dataset of object scans", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "Deep \ufb01lter banks for texture recognition and segmentation", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "3D object detec-tion and viewpoint estimation with a deformable 3D cuboid model", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "Upright ori-entation of man-made objects", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "3D mesh labeling via deep convolutional neural networks", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "Perceptual organization In and recognition of indoor scenes from RGB-D images", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "Learning rich features from RGB-D images for object detection and segmentation", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "Simul-taneous detection and segmentation", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "Hyper-columns for object segmentation and \ufb01ne-grained localiza-tion", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "Fusenet: Incorporating depth into semantic segmentation via fusion-based CNN architecture", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "Co-segmentation of 3D shapes via subspace clustering", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "Analysis and syn-thesis of 3D shape families via deep-learned generative mod-els of surfaces", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "Shape synthesis from sketches via procedural models and convolu-tional networks", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "Joint shape segmenta-tion with linear programming", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "Functional map networks for analyzing and exploring large shape collections", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "Single-view reconstruc-tion via joint analysis of image and shape collections", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "A probabilistic model for component-based shape synthesis", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "Learn-ing 3D mesh segmentation and labeling", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "Learning part-based templates from large collections of 3D shapes", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "Probabilistic Graphical Models: Principles and Techniques", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "A large-scale hierarchi-cal multi-view RGB-D object dataset", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "FPM: Fine pose parts-In Proc", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "C", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "Fully convolutional networks for semantic segmentation", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "Function-ality preserving shape style transfer", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "Feed-forward semantic segmentation with zoom-out features", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "Learning deconvolution net-work for semantic segmentation", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "Multi-view and 3D deformable part models", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "Illumination for computer generated pictures", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "Volumetric and multi-view CNNs for object classi-\ufb01cation on 3D data", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "Unsupervised learning of 3D structure from images", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "Semantic 3D Object Maps for Everyday Robot Manipulation", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "Contextual part analogies in 3D objects", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "Real-time human pose recog-nition in parts from a single depth image", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "Unsupervised co-segmentation of a set of shapes Trans", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "Very deep convolutional networks for large-scale image recognition", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "SUN RGB-D: In Proc", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "Deep sliding shapes for amodal arXiv preprint 3D object detection in RGB-D images", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "Multi-view convolutional neural networks for 3D shape recogni-tion", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "Prior knowledge for part correspondence", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "Reg-ularization of neural networks using DropConnect", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "Active co-analysis of a set of shapes", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "Projective analysis for 3D shape segmentation", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "Pro-jective feature learning for 3D shapes with multi-view depth images", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "Data-driven shape analysis and processing", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "Example-based 3D object re-construction from line drawings", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "Perspec-tive transformer nets: Learning single-view 3D object recon-struction without 3D supervision", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "A scalable ac-tive framework for region annotation in 3D shape collections", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "Multi-scale context aggregation by di-lated convolutions", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "Co-segmentation of textured 3D shapes with sparse annotations", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "Conditional random \ufb01elds as recurrent neural networks", "weight": 1}, {"from": "3D shape segmentation with projective convolutional networks", "to": "Learning dense correspondence via 3D-guided cycle consistency", "weight": 1}, {"from": "Pointnet++: Deep hierarchical feature learning on point sets in a metric space", "to": "The wave kernel signature: A quantum mechanical approach to shape analysis", "weight": 1}, {"from": "Pointnet++: Deep hierarchical feature learning on point sets in a metric space", "to": "Classi\ufb01cation and segmentation of terrestrial laser scanner point clouds using local variance information", "weight": 1}, {"from": "Pointnet++: Deep hierarchical feature learning on point sets in a metric space", "to": "Spectral networks and locally connected networks on graphs", "weight": 1}, {"from": "Pointnet++: Deep hierarchical feature learning on point sets in a metric space", "to": "ShapeNet: An Information-Rich 3D Model Repository", "weight": 1}, {"from": "Pointnet++: Deep hierarchical feature learning on point sets in a metric space", "to": "Scannet: Richly-annotated 3d reconstructions of indoor scenes", "weight": 1}, {"from": "Pointnet++: Deep hierarchical feature learning on point sets in a metric space", "to": "Dimensionality based scale selection in 3d lidar point clouds", "weight": 1}, {"from": "Pointnet++: Deep hierarchical feature learning on point sets in a metric space", "to": "Towards 3d lidar point cloud registration improvement using optimal neighborhood knowledge", "weight": 1}, {"from": "Pointnet++: Deep hierarchical feature learning on point sets in a metric space", "to": "Deep residual learning for image recognition", "weight": 1}, {"from": "Pointnet++: Deep hierarchical feature learning on point sets in a metric space", "to": "Adam: A method for stochastic optimization", "weight": 1}, {"from": "Pointnet++: Deep hierarchical feature learning on point sets in a metric space", "to": "Gradient-based learning applied to document recognition", "weight": 1}, {"from": "Pointnet++: Deep hierarchical feature learning on point sets in a metric space", "to": "Non-rigid 3D Shape Retrieval", "weight": 1}, {"from": "Pointnet++: Deep hierarchical feature learning on point sets in a metric space", "to": "Network in network", "weight": 1}, {"from": "Pointnet++: Deep hierarchical feature learning on point sets in a metric space", "to": "Deep learning with geodesic moments for 3d shape classi\ufb01cation", "weight": 1}, {"from": "Pointnet++: Deep hierarchical feature learning on point sets in a metric space", "to": "Geodesic convolutional neural networks on riemannian manifolds", "weight": 1}, {"from": "Pointnet++: Deep hierarchical feature learning on point sets in a metric space", "to": "M", "weight": 1}, {"from": "Pointnet++: Deep hierarchical feature learning on point sets in a metric space", "to": "Estimating surface normals in noisy point cloud data", "weight": 1}, {"from": "Pointnet++: Deep hierarchical feature learning on point sets in a metric space", "to": "Structure sensor-3d scanning", "weight": 1}, {"from": "Pointnet++: Deep hierarchical feature learning on point sets in a metric space", "to": "Point-based multiscale surface representation", "weight": 1}, {"from": "Pointnet++: Deep hierarchical feature learning on point sets in a metric space", "to": "Pointnet: Deep learning on point sets for 3d classi\ufb01cation and segmentation", "weight": 1}, {"from": "Pointnet++: Deep hierarchical feature learning on point sets in a metric space", "to": "Volumetric and multi-view cnns for object classi\ufb01cation on 3d data", "weight": 1}, {"from": "Pointnet++: Deep hierarchical feature learning on point sets in a metric space", "to": "Octnet: Learning deep 3d representations at high resolutions", "weight": 1}, {"from": "Pointnet++: Deep hierarchical feature learning on point sets in a metric space", "to": "Interior distance using barycentric coordinates", "weight": 1}, {"from": "Pointnet++: Deep hierarchical feature learning on point sets in a metric space", "to": "Best practices for convolutional neural networks applied to visual document analysis", "weight": 1}, {"from": "Pointnet++: Deep hierarchical feature learning on point sets in a metric space", "to": "Very deep convolutional networks for large-scale image recognition", "weight": 1}, {"from": "Pointnet++: Deep hierarchical feature learning on point sets in a metric space", "to": "Multi-view convolutional neural networks for 3d shape recognition", "weight": 1}, {"from": "Pointnet++: Deep hierarchical feature learning on point sets in a metric space", "to": "A concise and provably informative multi-scale signature based on heat diffusion", "weight": 1}, {"from": "Pointnet++: Deep hierarchical feature learning on point sets in a metric space", "to": "Order matters: Sequence to sequence for sets", "weight": 1}, {"from": "Pointnet++: Deep hierarchical feature learning on point sets in a metric space", "to": "Semantic point cloud interpretation based on optimal neighborhoods", "weight": 1}, {"from": "Pointnet++: Deep hierarchical feature learning on point sets in a metric space", "to": "3d shapenets: A deep representation for volumetric shapes", "weight": 1}, {"from": "Pointnet++: Deep hierarchical feature learning on point sets in a metric space", "to": "A scalable active framework for region annotation in 3d shape collections", "weight": 1}, {"from": "Pointnet++: Deep hierarchical feature learning on point sets in a metric space", "to": "Syncspeccnn: Synchronized spectral cnn for 3d shape segmentation", "weight": 1}, {"from": "Sgpn: Similarity group proposal network for 3d point cloud instance segmentation", "to": "", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Deep learning", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Sequence to sequence learning with neural networks", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Convolutional networks and applications in vision", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "A committee of neural networks for traf\ufb01c sign classi\ufb01cation", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Imagenet classi\ufb01cation with deep convolutional neural networks", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Learning hierar-chical features for scene labeling", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Deepface: Closing the gap to human-level performance in face veri\ufb01cation", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Very deep convolutional networks for large-scale image recognition", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Deep residual learning for image recognition", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Deep learning: methods and applications", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Natural image statistics and neural representation", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "An exact mapping between the variational renormalization group and deep learning", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Invariant scattering convolution networks", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "A mathematical motivation for complex-valued convolutional net-works", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Backpropagation applied to handwritten ZIP code recognition", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Maxout networks", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "The multiscale structure of non-differentiable image manifolds", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Which spatial partition trees are adaptive to intrinsic dimension?\u201d in Proc", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "A global geometric framework for nonlinear dimensionality reduction", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Nonlinear dimensionality reduction by locally linear embedding", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Visualizing data using t-SNE", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Laplacian eigenmaps for dimensionality reduction and data representation", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Diffusion maps", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Dimensionality reduction by learning an invariant mapping", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "DeepWalk: Online learning of social representations", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "LINE: Large-scale information network embedding", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "GraRep: Learning graph representations with global structural information", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Ef\ufb01cient estimation of word representations in vector space", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Network motifs: simple building blocks of complex net-works", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "A concise and provably informative multi-scale signature based on heat diffusion", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Learning spectral descriptors for deformable shape correspondence", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Distributed representations of words and phrases and their compositionality", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Friendship and mobility: user movement in location-based social networks", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "The emerging \ufb01eld of signal processing on graphs: Ex-tending high-dimensional data analysis to networks and other irregular domains", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Deep convolutional networks on graph-structured data", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Convolutional neural networks on graphs with fast localized spectral \ufb01ltering", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Diffusion-convolutional neural networks", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Geodesic convolutional neural networks on Riemannian manifolds", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "J", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "A new model for learning in graph domains", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Gated graph sequence neural networks", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Learning multiagent com-munication with backpropagation", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Spectral networks and locally connected networks on graphs", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "D", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Convolutional networks on graphs for learning molecular \ufb01ngerprints", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Geometric matrix com-pletion with recurrent multi-graph neural networks", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Object detection with discriminatively trained part-based models", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "P", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Striving for simplicity: The all convolutional net", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "A wavelet tour of signal processing", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "The loss surfaces of multilayer networks", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "On the quality of the initial basin in overspeci\ufb01ed neural networks", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Net2net: Accelerating learning via knowledge transfer", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Topology and geometry of half-recti\ufb01ed network optimization", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Discrete laplace operators: no free lunch", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Computing discrete minimal surfaces and their conjugates", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "The Laplacian on a Riemannian manifold: an introduc-tion to analysis on manifolds", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "A tutorial on spectral clustering", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Multimodal manifold analysis by simultaneous diagonal-ization of Laplacians", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Learning the 2-d topology of images", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Semi-supervised classi\ufb01cation with graph convolutional networks", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "The graph neural network model", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "A compositional object-based approach to learning physical dynamics", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Interaction networks for learning about objects", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Selecting receptive \ufb01elds in deep networks", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "E", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Vertex-frequency analysis on graphs", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Diffusion wavelets", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Diffusion-driven multiscale analysis on manifolds and graphs: top-down and bottom-up constructions", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Multiscale wavelets on trees", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Wavelets on graphs via deep learning", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Deep Haar scattering networks", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Spatial transformer networks", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Learn-ing to generate chairs", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Wavenet: A generative model for raw audio", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Collective classi\ufb01cation in network data", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Learning fast approximations of sparse coding", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Exact matrix completion via convex opti-mization", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Matrix factorization techniques for recommender systems", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Recommender systems with social regularization", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Matrix completion on graphs", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Collaborative \ufb01ltering with graph information: Consistency and scalable methods", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "A harmonic extension approach for collaborative ranking", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Multi-view convolutional neural networks for 3D shape recognition", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Dense human body correspondences using convolutional networks", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "3D shapenets: A deep representation for volumetric shapes", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Volumetric and multi-view CNNs for object classi\ufb01cation on 3D data", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Generalized multidimensional scaling: a framework for isometry-invariant partial surface matching", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Scale-invariant heat kernel signa-tures for non-rigid shape recognition", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Blended intrinsic maps", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "ShapeGoogle: Geometric words and expressions for invariant shape retrieval", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Functional maps: a \ufb02exible representation of maps between shapes", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Recent trends", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Unique signatures of his-tograms for local surface description", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "R", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "The generation of a unique machine description for chemical structure", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Extended-connectivity \ufb01ngerprints", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "The dynamic functional connectome: State-of-the-art and perspectives", "weight": 1}, {"from": "Geometric deep learning: Going beyond euclidean data", "to": "Distance metric learning using graph convolutional net-works: Application to functional brain networks", "weight": 1}, {"from": "Gaussian error linear units (gelus)", "to": "", "weight": 1}, {"from": "Deep networks with stochastic depth", "to": ": Imagenet: A large-scale hierarchical image database", "weight": 1}, {"from": "Deep networks with stochastic depth", "to": "", "weight": 1}, {"from": "Gpipe: Ef\ufb01cient training of giant neural networks using pipeline parallelism", "to": "", "weight": 1}, {"from": "Gpipe: Ef\ufb01cient training of giant neural networks using pipeline parallelism", "to": "Deep contextualized word representations", "weight": 1}, {"from": "Gpipe: Ef\ufb01cient training of giant neural networks using pipeline parallelism", "to": "Bert: Pre-training of deep bidirectional transformers for language understanding", "weight": 1}, {"from": "Gpipe: Ef\ufb01cient training of giant neural networks using pipeline parallelism", "to": "Imagenet: A large-scale hierarchical image database", "weight": 1}, {"from": "Gpipe: Ef\ufb01cient training of giant neural networks using pipeline parallelism", "to": "Aggregated residual transformations for deep neural networks", "weight": 1}, {"from": "Gpipe: Ef\ufb01cient training of giant neural networks using pipeline parallelism", "to": "Squeeze-and-excitation networks", "weight": 1}, {"from": "Gpipe: Ef\ufb01cient training of giant neural networks using pipeline parallelism", "to": "Learning transferable architectures for scalable image recognition", "weight": 1}, {"from": "Gpipe: Ef\ufb01cient training of giant neural networks using pipeline parallelism", "to": "Regularized evolution for image classi\ufb01er architecture search", "weight": 1}, {"from": "Gpipe: Ef\ufb01cient training of giant neural networks using pipeline parallelism", "to": "Algorithm 799: revolve: an implementation of check-pointing for the reverse or adjoint mode of computational differentiation", "weight": 1}, {"from": "Gpipe: Ef\ufb01cient training of giant neural networks using pipeline parallelism", "to": "Training deep nets with sublinear memory cost", "weight": 1}, {"from": "Gpipe: Ef\ufb01cient training of giant neural networks using pipeline parallelism", "to": "Mxnet: A \ufb02exible and ef\ufb01cient machine learning library for heterogeneous distributed systems", "weight": 1}, {"from": "Gpipe: Ef\ufb01cient training of giant neural networks using pipeline parallelism", "to": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "weight": 1}, {"from": "Gpipe: Ef\ufb01cient training of giant neural networks using pipeline parallelism", "to": "Megdet: A large mini-batch object detector", "weight": 1}, {"from": "Gpipe: Ef\ufb01cient training of giant neural networks using pipeline parallelism", "to": "Cnn features off-the-shelf: An astounding baseline for recognition", "weight": 1}, {"from": "Gpipe: Ef\ufb01cient training of giant neural networks using pipeline parallelism", "to": "Fully convolutional networks for semantic segmentation", "weight": 1}, {"from": "Gpipe: Ef\ufb01cient training of giant neural networks using pipeline parallelism", "to": "Improved regularization of convolutional neural networks with cutout", "weight": 1}, {"from": "Gpipe: Ef\ufb01cient training of giant neural networks using pipeline parallelism", "to": "Autoaugment: Learning augmentation policies from data", "weight": 1}, {"from": "Gpipe: Ef\ufb01cient training of giant neural networks using pipeline parallelism", "to": "Exploring the limits of weakly supervised pretraining", "weight": 1}, {"from": "Gpipe: Ef\ufb01cient training of giant neural networks using pipeline parallelism", "to": "Object-part attention model for \ufb01ne-grained image classi\ufb01cation", "weight": 1}, {"from": "Gpipe: Ef\ufb01cient training of giant neural networks using pipeline parallelism", "to": "Large scale \ufb01ne-grained categorization and domain-speci\ufb01c transfer learning", "weight": 1}, {"from": "Gpipe: Ef\ufb01cient training of giant neural networks using pipeline parallelism", "to": "Deep layer aggregation", "weight": 1}, {"from": "Gpipe: Ef\ufb01cient training of giant neural networks using pipeline parallelism", "to": "Mask-cnn: Localizing parts and selecting descriptors for \ufb01ne-grained bird species categorization", "weight": 1}, {"from": "Gpipe: Ef\ufb01cient training of giant neural networks using pipeline parallelism", "to": "Fixup initialization: Residual learning without normalization", "weight": 1}, {"from": "Gpipe: Ef\ufb01cient training of giant neural networks using pipeline parallelism", "to": "Device placement opti-mization with reinforcement learning", "weight": 1}, {"from": "Gpipe: Ef\ufb01cient training of giant neural networks using pipeline parallelism", "to": "Pipedream: Fast and ef\ufb01cient pipeline parallel dnn training", "weight": 1}, {"from": "MnasNet: Platform-aware neural architecture search for mobile", "to": "Naik, and R", "weight": 1}, {"from": "MnasNet: Platform-aware neural architecture search for mobile", "to": "Wei, and M", "weight": 1}, {"from": "MnasNet: Platform-aware neural architecture search for mobile", "to": "Metzen, and F", "weight": 1}, {"from": "MnasNet: Platform-aware neural architecture search for mobile", "to": "Zhao, and K", "weight": 1}, {"from": "MnasNet: Platform-aware neural architecture search for mobile", "to": "Yang, and E", "weight": 1}, {"from": "MnasNet: Platform-aware neural architecture search for mobile", "to": "Jia, and K", "weight": 1}, {"from": "MnasNet: Platform-aware neural architecture search for mobile", "to": "", "weight": 1}, {"from": "MnasNet: Platform-aware neural architecture search for mobile", "to": "Ren, and J", "weight": 1}, {"from": "MnasNet: Platform-aware neural architecture search for mobile", "to": "Li, and S", "weight": 1}, {"from": "MnasNet: Platform-aware neural architecture search for mobile", "to": "Andreetto, and H", "weight": 1}, {"from": "MnasNet: Platform-aware neural architecture search for mobile", "to": "Chen, W", "weight": 1}, {"from": "MnasNet: Platform-aware neural architecture search for mobile", "to": "Shen, and G", "weight": 1}, {"from": "MnasNet: Platform-aware neural architecture search for mobile", "to": "van der Maaten, and K", "weight": 1}, {"from": "MnasNet: Platform-aware neural architecture search for mobile", "to": "Dally, and K", "weight": 1}, {"from": "MnasNet: Platform-aware neural architecture search for mobile", "to": "Adam, and D", "weight": 1}, {"from": "MnasNet: Platform-aware neural architecture search for mobile", "to": "Poczos, and E", "weight": 1}, {"from": "MnasNet: Platform-aware neural architecture search for mobile", "to": "Doll\u00b4ar, and C", "weight": 1}, {"from": "MnasNet: Platform-aware neural architecture search for mobile", "to": "Huang, and K", "weight": 1}, {"from": "MnasNet: Platform-aware neural architecture search for mobile", "to": "Fernando, and K", "weight": 1}, {"from": "MnasNet: Platform-aware neural architecture search for mobile", "to": "Simonyan, and Y", "weight": 1}, {"from": "MnasNet: Platform-aware neural architecture search for mobile", "to": "Zheng, and J", "weight": 1}, {"from": "MnasNet: Platform-aware neural architecture search for mobile", "to": "Le, and J", "weight": 1}, {"from": "MnasNet: Platform-aware neural architecture search for mobile", "to": "Huang, and Q", "weight": 1}, {"from": "MnasNet: Platform-aware neural architecture search for mobile", "to": "Bernstein, et al", "weight": 1}, {"from": "MnasNet: Platform-aware neural architecture search for mobile", "to": "Radford, and O", "weight": 1}, {"from": "MnasNet: Platform-aware neural architecture search for mobile", "to": "Vanhoucke, and A", "weight": 1}, {"from": "MnasNet: Platform-aware neural architecture search for mobile", "to": "Sze, and H", "weight": 1}, {"from": "MnasNet: Platform-aware neural architecture search for mobile", "to": "Lin, and J", "weight": 1}, {"from": "MnasNet: Platform-aware neural architecture search for mobile", "to": "\u00a8O", "weight": 1}, {"from": "MnasNet: Platform-aware neural architecture search for mobile", "to": "Shlens, and Q", "weight": 1}, {"from": ": A 3d facial expression database for facial behavior research", "to": "", "weight": 1}, {"from": "Deep metric learning via lifted structured feature embedding", "to": "Learning visual similarity for product design with convolutional neural networks", "weight": 1}, {"from": "Deep metric learning via lifted structured feature embedding", "to": "Out-of-sample ex-tensions for lle", "weight": 1}, {"from": "Deep metric learning via lifted structured feature embedding", "to": "Signature veri\ufb01cation using a \u201csiamese\u201d time delay neural network", "weight": 1}, {"from": "Deep metric learning via lifted structured feature embedding", "to": "Large scale online learning of image similarity through ranking", "weight": 1}, {"from": "Deep metric learning via lifted structured feature embedding", "to": "Learning a similarity metric discriminatively", "weight": 1}, {"from": "Deep metric learning via lifted structured feature embedding", "to": "Extreme multi class classi\ufb01cation", "weight": 1}, {"from": "Deep metric learning via lifted structured feature embedding", "to": "Multidimensional scaling", "weight": 1}, {"from": "Deep metric learning via lifted structured feature embedding", "to": "https://sites", "weight": 1}, {"from": "Deep metric learning via lifted structured feature embedding", "to": "ImageNet Large Scale Visual Recognition Challenge", "weight": 1}, {"from": "Deep metric learning via lifted structured feature embedding", "to": "Facenet: A uni-\ufb01ed embedding for face recognition and clustering", "weight": 1}, {"from": "Deep metric learning via lifted structured feature embedding", "to": "Zero-shot learning through cross-modal transfer", "weight": 1}, {"from": "Deep metric learning via lifted structured feature embedding", "to": "Going deeper with convolutions", "weight": 1}, {"from": "Deep metric learning via lifted structured feature embedding", "to": "In Pose-sensitive embedding by nonlinear nca regression", "weight": 1}, {"from": "Deep metric learning via lifted structured feature embedding", "to": "Support vector machine learning for interdependent and structured output spaces", "weight": 1}, {"from": "Deep metric learning via lifted structured feature embedding", "to": "Accelerating t-sne using tree-based algo-rithms", "weight": 1}, {"from": "Deep metric learning via lifted structured feature embedding", "to": "The caltech-ucsd birds-200-2011 dataset", "weight": 1}, {"from": "Deep metric learning via lifted structured feature embedding", "to": "Learning \ufb01ne-grained im-age similarity with deep ranking", "weight": 1}, {"from": "Deep metric learning via lifted structured feature embedding", "to": "Distance metric learning for large margin nearest neighbor classi\ufb01cation", "weight": 1}, {"from": "Deep metric learning via lifted structured feature embedding", "to": "Wsabi: Scaling up to large vocabulary image annotation", "weight": 1}, {"from": "Deep metric learning via lifted structured feature embedding", "to": "http:// www", "weight": 1}, {"from": "Deep metric learning via lifted structured feature embedding", "to": "Clustering by passing messages between data points", "weight": 1}, {"from": "Deep metric learning via lifted structured feature embedding", "to": "Devise: A deep visual-semantic embedding model", "weight": 1}, {"from": "Deep metric learning via lifted structured feature embedding", "to": "Neighbourhood component analysis", "weight": 1}, {"from": "Deep metric learning via lifted structured feature embedding", "to": "Dimensionality reduc-tion by learning an invariant mapping", "weight": 1}, {"from": "Deep metric learning via lifted structured feature embedding", "to": "Product quantization for nearest neighbor search", "weight": 1}, {"from": "Deep metric learning via lifted structured feature embedding", "to": "Caffe: Convolu-tional architecture for fast feature embedding", "weight": 1}, {"from": "Deep metric learning via lifted structured feature embedding", "to": "Cutting-plane training of structural svms", "weight": 1}, {"from": "Deep metric learning via lifted structured feature embedding", "to": "Principal component analysis", "weight": 1}, {"from": "Deep metric learning via lifted structured feature embedding", "to": "3d object repre-ICCV 3dRR-13", "weight": 1}, {"from": "Deep metric learning via lifted structured feature embedding", "to": "Imagenet clas-si\ufb01cation with deep convolutional neural networks", "weight": 1}, {"from": "Deep metric learning via lifted structured feature embedding", "to": "Attribute-based classi\ufb01cation for zero-shot visual object categoriza-tion", "weight": 1}, {"from": "Deep metric learning via lifted structured feature embedding", "to": "Joint embeddings of shapes and images via cnn image pu-ri\ufb01cation", "weight": 1}, {"from": "Deep metric learning via lifted structured feature embedding", "to": "Introduction to Information Retrieval", "weight": 1}, {"from": "Deep metric learning via lifted structured feature embedding", "to": "Metric learning for large scale image classi\ufb01cation: Generalizaing to new classes at near-zero cost", "weight": 1}, {"from": "Deep metric learning via lifted structured feature embedding", "to": "Zero-shot learning with semantic output codes", "weight": 1}, {"from": "Deep metric learning via lifted structured feature embedding", "to": "Fastxml: A fast", "weight": 1}, {"from": "Deep metric learning via lifted structured feature embedding", "to": "Fine-grained visual cat-egorization via multi-stage metric learning", "weight": 1}, {"from": "Deep metric learning via lifted structured feature embedding", "to": "Evaluating knowl-edge transfer and zero-shot learn-ing in a large-scale setting", "weight": 1}, {"from": "Deep metric learning with hierarchical triplet loss", "to": ": Visualizing data using t-sne", "weight": 1}, {"from": "Challenges in representation learning: A report on three machine learning contests", "to": "", "weight": 1}, {"from": "Challenges in representation learning: A report on three machine learning contests", "to": "David W", "weight": 1}, {"from": "Challenges in representation learning: A report on three machine learning contests", "to": "Support vector networks", "weight": 1}, {"from": "Challenges in representation learning: A report on three machine learning contests", "to": "Maxout networks", "weight": 1}, {"from": "Challenges in representation learning: A report on three machine learning contests", "to": "Local learn-ing to improve bag of visual words model for facial expression recognition", "weight": 1}, {"from": "Challenges in representation learning: A report on three machine learning contests", "to": "Constructing hierarchical image-tags bimodal representations for word tags alternative choice", "weight": 1}, {"from": "Triplet-center loss for multi-view 3D object retrieval", "to": "Gift: A real-time and scalable 3d shape search engine", "weight": 1}, {"from": "Triplet-center loss for multi-view 3D object retrieval", "to": "Gift: Towards scalable 3d shape retrieval", "weight": 1}, {"from": "Triplet-center loss for multi-view 3D object retrieval", "to": "Ensemble diffusion for retrieval", "weight": 1}, {"from": "Triplet-center loss for multi-view 3D object retrieval", "to": "A", "weight": 1}, {"from": "Triplet-center loss for multi-view 3D object retrieval", "to": "J", "weight": 1}, {"from": "Triplet-center loss for multi-view 3D object retrieval", "to": "Shapenet: An information-rich 3d model repository", "weight": 1}, {"from": "Triplet-center loss for multi-view 3D object retrieval", "to": "Learning a similarity metric discriminatively", "weight": 1}, {"from": "Triplet-center loss for multi-view 3D object retrieval", "to": "Deep correlated metric learning for sketch-based 3d shape retrieval", "weight": 1}, {"from": "Triplet-center loss for multi-view 3D object retrieval", "to": "Ranking on cross-domain man-In Cyberworlds ifold for sketch-based 3d model retrieval", "weight": 1}, {"from": "Triplet-center loss for multi-view 3D object retrieval", "to": "Deep aggregation of local 3d geometric features for 3d model retrieval", "weight": 1}, {"from": "Triplet-center loss for multi-view 3D object retrieval", "to": "In defense of the triplet loss for person re-identi\ufb01cation", "weight": 1}, {"from": "Triplet-center loss for multi-view 3D object retrieval", "to": "Deep learning advances in computer vision with 3d data: A survey", "weight": 1}, {"from": "Triplet-center loss for multi-view 3D object retrieval", "to": "Pairwise de-composition of image sequences for active multi-view recog-nition", "weight": 1}, {"from": "Triplet-center loss for multi-view 3D object retrieval", "to": "Escape from cells: Deep kd-networks for the recognition of 3d point cloud models", "weight": 1}, {"from": "Triplet-center loss for multi-view 3D object retrieval", "to": "classi\ufb01cation with deep convolutional neural networks", "weight": 1}, {"from": "Triplet-center loss for multi-view 3D object retrieval", "to": "Shrec\u201913 track: Large scale sketch-based 3d shape retrieval", "weight": 1}, {"from": "Triplet-center loss for multi-view 3D object retrieval", "to": "Fpnn: Field probing neural networks for 3d data", "weight": 1}, {"from": "Triplet-center loss for multi-view 3D object retrieval", "to": "Deep rel-ative distance learning: Tell the difference between similar vehicles", "weight": 1}, {"from": "Triplet-center loss for multi-view 3D object retrieval", "to": "Voxnet: A 3d convolutional In IROS", "weight": 1}, {"from": "Triplet-center loss for multi-view 3D object retrieval", "to": "Sparse 3d convolutional neural networks for large-scale shape retrieval", "weight": 1}, {"from": "Triplet-center loss for multi-view 3D object retrieval", "to": "Deep metric learning via lifted structured feature embedding", "weight": 1}, {"from": "Triplet-center loss for multi-view 3D object retrieval", "to": "Pointnet: Deep learning on point sets for 3d classi\ufb01cation and segmentation", "weight": 1}, {"from": "Triplet-center loss for multi-view 3D object retrieval", "to": "Volumetric and multi-view cnns for object classi-\ufb01cation on 3d data", "weight": 1}, {"from": "Triplet-center loss for multi-view 3D object retrieval", "to": "Pointnet++: Deep hierarchical feature learning on point sets in a metric space", "weight": 1}, {"from": "Triplet-center loss for multi-view 3D object retrieval", "to": "F", "weight": 1}, {"from": "Triplet-center loss for multi-view 3D object retrieval", "to": "Facenet: A uni-\ufb01ed embedding for face recognition and clustering", "weight": 1}, {"from": "Triplet-center loss for multi-view 3D object retrieval", "to": "Orientation-In BMVC", "weight": 1}, {"from": "Triplet-center loss for multi-view 3D object retrieval", "to": "Deeppano: Deep IEEE panoramic representation for 3-d shape recognition", "weight": 1}, {"from": "Triplet-center loss for multi-view 3D object retrieval", "to": "Very deep con-large-scale image recognition", "weight": 1}, {"from": "Triplet-center loss for multi-view 3D object retrieval", "to": "Multi-view convolutional neural networks for 3d shape recognition", "weight": 1}, {"from": "Triplet-center loss for multi-view 3D object retrieval", "to": "A survey of content based 3d shape retrieval methods", "weight": 1}, {"from": "Triplet-center loss for multi-view 3D object retrieval", "to": "Sketch-based 3d shape retrieval using convolutional neural networks", "weight": 1}, {"from": "Triplet-center loss for multi-view 3D object retrieval", "to": "Normface: L 2 hypersphere embedding for face veri\ufb01cation", "weight": 1}, {"from": "Triplet-center loss for multi-view 3D object retrieval", "to": "Deep metric learning with angular loss", "weight": 1}, {"from": "Triplet-center loss for multi-view 3D object retrieval", "to": "A discriminative fea-ture learning approach for deep face recognition", "weight": 1}, {"from": "Triplet-center loss for multi-view 3D object retrieval", "to": "3d shapenets: A deep representation for volumetric shapes", "weight": 1}, {"from": "Triplet-center loss for multi-view 3D object retrieval", "to": "Learning barycentric rep-resentations of 3d shapes for sketch-based 3d shape retrieval", "weight": 1}, {"from": "Triplet-center loss for multi-view 3D object retrieval", "to": "Deepshape: Deep-learned shape descriptor for 3d shape retrieval", "weight": 1}, {"from": "Triplet-center loss for multi-view 3D object retrieval", "to": "Learning cross-domain neural networks for sketch-based 3d shape retrieval", "weight": 1}, {"from": "Fast training of triplet-based deep binary embedding networks", "to": "Theano: new features and speed improvements", "weight": 1}, {"from": "Fast training of triplet-based deep binary embedding networks", "to": "Hashing with binary autoencoders", "weight": 1}, {"from": "Fast training of triplet-based deep binary embedding networks", "to": "Bayesian face In Proc", "weight": 1}, {"from": "Fast training of triplet-based deep binary embedding networks", "to": "Deep hashing for compact binary codes learning", "weight": 1}, {"from": "Fast training of triplet-based deep binary embedding networks", "to": "P", "weight": 1}, {"from": "Fast training of triplet-based deep binary embedding networks", "to": "Itera-tive quantization: A procrustean approach to learning binary IEEE Trans", "weight": 1}, {"from": "Fast training of triplet-based deep binary embedding networks", "to": "Labeled faces in the wild: A database for studying face recognition in unconstrained environments", "weight": 1}, {"from": "Fast training of triplet-based deep binary embedding networks", "to": "Caffe: Convolutional architecture for fast feature embedding", "weight": 1}, {"from": "Fast training of triplet-based deep binary embedding networks", "to": "Revisiting kernelized locality-sensitive hashing for improved large-scale image re-trieval", "weight": 1}, {"from": "Fast training of triplet-based deep binary embedding networks", "to": "Pushing the frontiers of unconstrained face detection and recognition: Iarpa janus benchmark a", "weight": 1}, {"from": "Fast training of triplet-based deep binary embedding networks", "to": "Learning multiple layers of features from tiny images", "weight": 1}, {"from": "Fast training of triplet-based deep binary embedding networks", "to": "Learning to hash with binary re-constructive embeddings", "weight": 1}, {"from": "Fast training of triplet-based deep binary embedding networks", "to": "Kernelized locality-sensitive In Proc", "weight": 1}, {"from": "Fast training of triplet-based deep binary embedding networks", "to": "Simultaneous feature learning and hash coding with deep neural networks", "weight": 1}, {"from": "Fast training of triplet-based deep binary embedding networks", "to": "Learning hash functions using column generation", "weight": 1}, {"from": "Fast training of triplet-based deep binary embedding networks", "to": "Fast supervised hashing with decision trees for high-In Proc", "weight": 1}, {"from": "Fast training of triplet-based deep binary embedding networks", "to": "Supervised descent method and its applications to face alignment", "weight": 1}, {"from": "Fast training of triplet-based deep binary embedding networks", "to": "Learning face represen-tation from scratch", "weight": 1}, {"from": "Fast training of triplet-based deep binary embedding networks", "to": "Bit-scalable deep hashing with regularized similarity learning for image retrieval", "weight": 1}, {"from": "Fast training of triplet-based deep binary embedding networks", "to": "Deep semantic ranking based hashing for multi-label image retrieval", "weight": 1}, {"from": "Fast training of triplet-based deep binary embedding networks", "to": "A general two-step approach to learning-based hashing", "weight": 1}, {"from": "Fast training of triplet-based deep binary embedding networks", "to": "Super-vised hashing with kernels", "weight": 1}, {"from": "Fast training of triplet-based deep binary embedding networks", "to": "Hashing with graphs", "weight": 1}, {"from": "Fast training of triplet-based deep binary embedding networks", "to": "Face detection without bells and whistles", "weight": 1}, {"from": "Fast training of triplet-based deep binary embedding networks", "to": "Hamming distance metric learning", "weight": 1}, {"from": "Fast training of triplet-based deep binary embedding networks", "to": "Recognizing indoor scenes", "weight": 1}, {"from": "Fast training of triplet-based deep binary embedding networks", "to": "Imagenet large scale visual recog-nition challenge", "weight": 1}, {"from": "Fast training of triplet-based deep binary embedding networks", "to": "FaceNet: A uni\ufb01ed embedding for face recognition and clustering", "weight": 1}, {"from": "Fast training of triplet-based deep binary embedding networks", "to": "Supervised dis-crete hashing", "weight": 1}, {"from": "Fast training of triplet-based deep binary embedding networks", "to": "Inductive hashing on manifolds", "weight": 1}, {"from": "Fast training of triplet-based deep binary embedding networks", "to": "Very deep convolutional networks for large-scale image recognition", "weight": 1}, {"from": "Fast training of triplet-based deep binary embedding networks", "to": "Deepid3: Face recognition with very deep neural networks", "weight": 1}, {"from": "Fast training of triplet-based deep binary embedding networks", "to": "Deepface: Closing the gap to human-level performance in face veri\ufb01ca-tion", "weight": 1}, {"from": "Fast training of triplet-based deep binary embedding networks", "to": "Face search at scale: 80 million gallery", "weight": 1}, {"from": "Fast training of triplet-based deep binary embedding networks", "to": "Learning \ufb01ne-grained image similarity with deep ranking", "weight": 1}, {"from": "Fast training of triplet-based deep binary embedding networks", "to": "Distance metric learning for large margin nearest neighbor classi\ufb01cation", "weight": 1}, {"from": "Fast training of triplet-based deep binary embedding networks", "to": "Multidimensional spectral hashing", "weight": 1}, {"from": "Fast training of triplet-based deep binary embedding networks", "to": "Spectral hashing", "weight": 1}, {"from": "Facial expression recognition from world wild web", "to": "Imagenet: A large-scale hierarchical image database", "weight": 1}, {"from": "Facial expression recognition from world wild web", "to": "R", "weight": 1}, {"from": "Facial expression recognition from world wild web", "to": "Static fa-cial expression analysis in tough conditions: Data", "weight": 1}, {"from": "Facial expression recognition from world wild web", "to": "Why is this canadian hacker better http: than facebook at detecting gun photos? //www", "weight": 1}, {"from": "Facial expression recognition from world wild web", "to": "Why is facial expression anal-In Proceedings of the 2013 ysis in the wild challenging? on Emotion recognition in the wild challenge and workshop", "weight": 1}, {"from": "Facial expression recognition from world wild web", "to": "D", "weight": 1}, {"from": "Facial expression recognition from world wild web", "to": "Automatically recognizing facial expression: Predicting engagement and frustration", "weight": 1}, {"from": "Facial expression recognition from world wild web", "to": "Local features based facial expression recognition with face reg-istration errors", "weight": 1}, {"from": "Facial expression recognition from world wild web", "to": "Image and Vision Computing", "weight": 1}, {"from": "Facial expression recognition from world wild web", "to": "C", "weight": 1}, {"from": "Facial expression recognition from world wild web", "to": "Facial interaction between ani-In Systems", "weight": 1}, {"from": "Facial expression recognition from world wild web", "to": "Imagenet classi\ufb01cation with deep convolutional neural networks", "weight": 1}, {"from": "Facial expression recognition from world wild web", "to": "Gabor feature based classi\ufb01ca-tion using the enhanced \ufb01sher linear discriminant model for face recognition", "weight": 1}, {"from": "Facial expression recognition from world wild web", "to": "Au-aware deep In Automatic networks for facial expression recognition", "weight": 1}, {"from": "Facial expression recognition from world wild web", "to": "Coding facial expressions with gabor wavelets", "weight": 1}, {"from": "Facial expression recognition from world wild web", "to": "Disfa: A spontaneous facial action intensity database", "weight": 1}, {"from": "Facial expression recognition from world wild web", "to": "Affectiva-mit facial expression dataset (am-fed): Naturalistic and spontaneous facial expressions collected", "weight": 1}, {"from": "Facial expression recognition from world wild web", "to": "Pca-based dictionary building for accurate facial expression Journal of Visual recognition via sparse representation", "weight": 1}, {"from": "Facial expression recognition from world wild web", "to": "In-tensity estimation of spontaneous facial action units based on their sparsity properties", "weight": 1}, {"from": "Facial expression recognition from world wild web", "to": "Going deeper in facial expression recognition using deep neural networks", "weight": 1}, {"from": "Facial expression recognition from world wild web", "to": "Expressionbot: An emo-tive lifelike robotic face for face-to-face communication", "weight": 1}, {"from": "Facial expression recognition from world wild web", "to": "Bidirectional warping of active appearance model", "weight": 1}, {"from": "Facial expression recognition from world wild web", "to": "Learning and transferring mid-level image representations using convolu-In Proceedings of the IEEE Con-tional neural networks", "weight": 1}, {"from": "Facial expression recognition from world wild web", "to": "Web-based database for facial expression analysis", "weight": 1}, {"from": "Facial expression recognition from world wild web", "to": "Face alignment at 3000 fps via regressing local binary features", "weight": 1}, {"from": "Facial expression recognition from world wild web", "to": "Impact of face registration errors on recognition", "weight": 1}, {"from": "Facial expression recognition from world wild web", "to": "300 faces in-the-wild challenge: Database and results", "weight": 1}, {"from": "Facial expression recognition from world wild web", "to": "Emotion recognition in the wild via sparse transductive transfer linear discriminant analysis", "weight": 1}, {"from": "Facial expression recognition from world wild web", "to": "300 faces in-the-wild challenge: The \ufb01rst facial landmark In Proceedings of the IEEE Inter-localization challenge", "weight": 1}, {"from": "Facial expression recognition from world wild web", "to": "A semi-automatic methodology for facial landmark annota-tion", "weight": 1}, {"from": "Facial expression recognition from world wild web", "to": "Facial expression recognition based on local binary patterns: A comprehensive study", "weight": 1}, {"from": "Facial expression recognition from world wild web", "to": "Learning from noisy labels with deep neural networks", "weight": 1}, {"from": "Facial expression recognition from world wild web", "to": "Going deeper with convolutions", "weight": 1}, {"from": "Facial expression recognition from world wild web", "to": "Deepface: Closing the gap to human-level performance in face veri\ufb01ca-tion", "weight": 1}, {"from": "Facial expression recognition from world wild web", "to": "Deep learning using linear support vector machines", "weight": 1}, {"from": "Facial expression recognition from world wild web", "to": "Deeppose: Human pose estima-tion via deep neural networks", "weight": 1}, {"from": "Facial expression recognition from world wild web", "to": "Deep learn-In Neural Networks: ing via semi-supervised embedding", "weight": 1}, {"from": "Facial expression recognition from world wild web", "to": "Learn-ing from massive noisy labeled data for image classi\ufb01cation", "weight": 1}, {"from": "Facial expression recognition from world wild web", "to": "face-alignment-in-3000fps", "weight": 1}, {"from": "Facial expression recognition from world wild web", "to": "Image based static facial expression In Pro-recognition with multiple deep network learning", "weight": 1}, {"from": "Facial expression recognition from world wild web", "to": "ebear: An expres-sive bear-like robot", "weight": 1}, {"from": "Facial expression recognition from world wild web", "to": "Facial expression recognition based on local phase quantization and sparse representation", "weight": 1}, {"from": "From facial expression recognition to interpersonal relation prediction", "to": "", "weight": 1}, {"from": "Learning visual clothing style with heterogeneous dyadic co-occurrences", "to": "", "weight": 1}, {"from": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews", "to": "Expertise identi\ufb01cation and visualization from CVS", "weight": 1}, {"from": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews", "to": "Scalable collaborative \ufb01ltering with jointly derived neighborhood interpolation weights", "weight": 1}, {"from": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews", "to": "The Net\ufb02ix prize", "weight": 1}, {"from": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews", "to": "A survey of longest common subsequence algorithms", "weight": 1}, {"from": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews", "to": "The Development of Expertise in Pedagogy", "weight": 1}, {"from": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews", "to": "Learning to recognize reliable users and content in social media with coupled mutual reinforcement", "weight": 1}, {"from": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews", "to": "P@noptic expert: Searching for experts not just for documents", "weight": 1}, {"from": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews", "to": "Writing expertise and second-language pro\ufb01ciency", "weight": 1}, {"from": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews", "to": "No country for old members: User lifecycle and linguistic change in online communities", "weight": 1}, {"from": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews", "to": "Time weight collaborative \ufb01ltering", "weight": 1}, {"from": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews", "to": "Churn prediction in new users of Yahoo! Answers", "weight": 1}, {"from": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews", "to": "Expert judgment: Some necessary conditions and an example", "weight": 1}, {"from": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews", "to": "Sequential and temporal dynamics of online opinion", "weight": 1}, {"from": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews", "to": "Effects of search experience and subject knowledge on the search tactics of novice and experienced searchers", "weight": 1}, {"from": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews", "to": "Opinion spam and analysis", "weight": 1}, {"from": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews", "to": "Discovering authorities in question answer communities by using link analysis", "weight": 1}, {"from": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews", "to": "Enhancing expert \ufb01nding using organizational hierarchies", "weight": 1}, {"from": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews", "to": "Amazon", "weight": 1}, {"from": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews", "to": "Recommender systems with social regularization", "weight": 1}, {"from": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews", "to": "Information Theory", "weight": 1}, {"from": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews", "to": "Learning attitudes and attributes from multi-aspect reviews", "weight": 1}, {"from": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews", "to": "Online product opinions: Incidence", "weight": 1}, {"from": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews", "to": "Language use as a re\ufb02ection of socialization in online communities", "weight": 1}, {"from": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews", "to": "Updating quasi-newton matrices with limited storage", "weight": 1}, {"from": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews", "to": "Early detection of potential experts in question answering communities", "weight": 1}, {"from": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews", "to": "editors", "weight": 1}, {"from": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews", "to": "The language of children and adolescents: The acquisition of communicative competence", "weight": 1}, {"from": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews", "to": "Adaptive web search based on user pro\ufb01le constructed without any effort from users", "weight": 1}, {"from": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews", "to": "Second language use", "weight": 1}, {"from": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews", "to": "The problem of concept drift: De\ufb01nitions and related work", "weight": 1}, {"from": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews", "to": "Characterizing the in\ufb02uence of domain expertise on web search behavior", "weight": 1}, {"from": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews", "to": "Learning in the presence of concept drift and hidden contexts", "weight": 1}, {"from": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews", "to": "Temporal recommendation on graphs via long-and short-term preference fusion", "weight": 1}, {"from": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews", "to": "Temporal collaborative \ufb01ltering with bayesian probabilistic tensor factorization", "weight": 1}, {"from": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews", "to": "Churn in social networks", "weight": 1}, {"from": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews", "to": "Dynamic weighted majority: An ensemble method for drifting concepts", "weight": 1}, {"from": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews", "to": "Collaborative \ufb01ltering with temporal dynamics", "weight": 1}, {"from": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews", "to": "Advances in collaborative \ufb01ltering", "weight": 1}, {"from": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews", "to": "Matrix factorization techniques for recommender systems", "weight": 1}, {"from": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews", "to": "Classi\ufb01er ensembles for changing environments", "weight": 1}, {"from": "From amateurs to connoisseurs: modeling the evolution of user expertise through online reviews", "to": "Temporal collaborative \ufb01ltering with adaptive neighbourhoods", "weight": 1}, {"from": "Gift: A real-time and scalable 3d shape search engine", "to": "", "weight": 1}, {"from": "Gift: Towards scalable 3d shape retrieval", "to": "", "weight": 1}, {"from": "Escape from cells: Deep kd-networks for the recognition of 3d point cloud models", "to": "Multidimensional binary search trees used for associative searching", "weight": 1}, {"from": "Escape from cells: Deep kd-networks for the recognition of 3d point cloud models", "to": "Learning class-speci\ufb01c descrip-tors for deformable shapes using localized spectral convolu-tional networks", "weight": 1}, {"from": "Escape from cells: Deep kd-networks for the recognition of 3d point cloud models", "to": "J", "weight": 1}, {"from": "Escape from cells: Deep kd-networks for the recognition of 3d point cloud models", "to": "Generative and discriminative voxel modeling with convolutional neural networks", "weight": 1}, {"from": "Escape from cells: Deep kd-networks for the recognition of 3d point cloud models", "to": "Signature veri\ufb01ca-Interna-tion using a siamese time delay neural network", "weight": 1}, {"from": "Escape from cells: Deep kd-networks for the recognition of 3d point cloud models", "to": "Spectral networks and locally connected networks on graphs", "weight": 1}, {"from": "Escape from cells: Deep kd-networks for the recognition of 3d point cloud models", "to": "T", "weight": 1}, {"from": "Escape from cells: Deep kd-networks for the recognition of 3d point cloud models", "to": "Learning a similarity metric discriminatively", "weight": 1}, {"from": "Escape from cells: Deep kd-networks for the recognition of 3d point cloud models", "to": "volume 55", "weight": 1}, {"from": "Escape from cells: Deep kd-networks for the recognition of 3d point cloud models", "to": "R-trees: A Dynamic Index Structure for Spatial Searching", "weight": 1}, {"from": "Escape from cells: Deep kd-networks for the recognition of 3d point cloud models", "to": "Fusionnet: 3d object classi\ufb01-cation using multiple data representations", "weight": 1}, {"from": "Escape from cells: Deep kd-networks for the recognition of 3d point cloud models", "to": "K", "weight": 1}, {"from": "Escape from cells: Deep kd-networks for the recognition of 3d point cloud models", "to": "TI-POOLING: transformation-invariant pooling for feature learning in convolutional neural networks", "weight": 1}, {"from": "Escape from cells: Deep kd-networks for the recognition of 3d point cloud models", "to": "Gradient-based learning applied to document recognition", "weight": 1}, {"from": "Escape from cells: Deep kd-networks for the recognition of 3d point cloud models", "to": "Fpnn: Field probing neural networks for 3d data", "weight": 1}, {"from": "Escape from cells: Deep kd-networks for the recognition of 3d point cloud models", "to": "Fully convolutional networks for semantic segmentation", "weight": 1}, {"from": "Escape from cells: Deep kd-networks for the recognition of 3d point cloud models", "to": "Voxnet: A 3d convolutional In Proc", "weight": 1}, {"from": "Escape from cells: Deep kd-networks for the recognition of 3d point cloud models", "to": "Octree encoding: A new technique for the representation", "weight": 1}, {"from": "Escape from cells: Deep kd-networks for the recognition of 3d point cloud models", "to": "Pointnet: Deep learning on point sets for 3d classi\ufb01cation and segmentation", "weight": 1}, {"from": "Escape from cells: Deep kd-networks for the recognition of 3d point cloud models", "to": "Volumetric and multi-view cnns for object classi\ufb01-cation on 3d data", "weight": 1}, {"from": "Escape from cells: Deep kd-networks for the recognition of 3d point cloud models", "to": "H", "weight": 1}, {"from": "Escape from cells: Deep kd-networks for the recognition of 3d point cloud models", "to": "Octnet: Learn-ing deep 3d representations at high resolutions", "weight": 1}, {"from": "Escape from cells: Deep kd-networks for the recognition of 3d point cloud models", "to": "U-net: Convolu-tional networks for biomedical image segmentation", "weight": 1}, {"from": "Escape from cells: Deep kd-networks for the recognition of 3d point cloud models", "to": "The design and analysis of spatial data structures", "weight": 1}, {"from": "Escape from cells: Deep kd-networks for the recognition of 3d point cloud models", "to": "F", "weight": 1}, {"from": "Escape from cells: Deep kd-networks for the recognition of 3d point cloud models", "to": "Learning a distance metric from relative comparisons", "weight": 1}, {"from": "Escape from cells: Deep kd-networks for the recognition of 3d point cloud models", "to": "Study for applying computer-generated images to vi-sual simulation", "weight": 1}, {"from": "Escape from cells: Deep kd-networks for the recognition of 3d point cloud models", "to": "Dynamic edge-conditioned \ufb01lters in convolutional neural networks on graphs", "weight": 1}, {"from": "Escape from cells: Deep kd-networks for the recognition of 3d point cloud models", "to": "Parsing nat-ural scenes and natural language with recursive neural net-works", "weight": 1}, {"from": "Escape from cells: Deep kd-networks for the recognition of 3d point cloud models", "to": "Multi-view convolutional neural networks for 3d shape recognition", "weight": 1}, {"from": "Escape from cells: Deep kd-networks for the recognition of 3d point cloud models", "to": "Learning deep embeddings with histogram loss", "weight": 1}, {"from": "Escape from cells: Deep kd-networks for the recognition of 3d point cloud models", "to": "Voting for voting in online point cloud object detection", "weight": 1}, {"from": "Escape from cells: Deep kd-networks for the recognition of 3d point cloud models", "to": "Learning a probabilistic latent space of object shapes via 3d generative-adversarial modeling", "weight": 1}, {"from": "Escape from cells: Deep kd-networks for the recognition of 3d point cloud models", "to": "3d shapenets: A deep representation for volumetric shapes", "weight": 1}, {"from": "Escape from cells: Deep kd-networks for the recognition of 3d point cloud models", "to": "V", "weight": 1}, {"from": "Fpnn: Field probing neural networks for 3d data", "to": "Anisotropic diffusion descriptors", "weight": 1}, {"from": "Fpnn: Field probing neural networks for 3d data", "to": "Shape google: Geometric words and expressions for invariant shape retrieval", "weight": 1}, {"from": "Fpnn: Field probing neural networks for 3d data", "to": "On visual similarity based 3d model retrieval", "weight": 1}, {"from": "Fpnn: Field probing neural networks for 3d data", "to": "", "weight": 1}, {"from": "Fpnn: Field probing neural networks for 3d data", "to": "Imagenet: A large-scale hierarchical image database", "weight": 1}, {"from": "Fpnn: Field probing neural networks for 3d data", "to": "Understanding the dif\ufb01culty of training deep feedforward neural networks", "weight": 1}, {"from": "Fpnn: Field probing neural networks for 3d data", "to": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "weight": 1}, {"from": "Fpnn: Field probing neural networks for 3d data", "to": "Caffe: Convolutional architecture for fast feature embedding", "weight": 1}, {"from": "Fpnn: Field probing neural networks for 3d data", "to": "Using spin images for ef\ufb01cient object recognition in cluttered 3d scenes", "weight": 1}, {"from": "Fpnn: Field probing neural networks for 3d data", "to": "Deep learning", "weight": 1}, {"from": "Fpnn: Field probing neural networks for 3d data", "to": "Learning spectral descriptors for deformable shape correspondence", "weight": 1}, {"from": "Fpnn: Field probing neural networks for 3d data", "to": "Geodesic convolutional neural networks on riemannian manifolds", "weight": 1}, {"from": "Fpnn: Field probing neural networks for 3d data", "to": "Voxnet: A 3d convolutional neural network for real-In IEEE/RSJ International Conference on Intelligent Robots and time object recognition", "weight": 1}, {"from": "Fpnn: Field probing neural networks for 3d data", "to": "Recti\ufb01ed linear units improve restricted boltzmann machines", "weight": 1}, {"from": "Fpnn: Field probing neural networks for 3d data", "to": "Real-time 3d reconstruction at scale using voxel hashing", "weight": 1}, {"from": "Fpnn: Field probing neural networks for 3d data", "to": "Shape distributions", "weight": 1}, {"from": "Fpnn: Field probing neural networks for 3d data", "to": "Volumetric and multi-view cnns for object classi\ufb01cation on 3d data", "weight": 1}, {"from": "Fpnn: Field probing neural networks for 3d data", "to": "Imagenet large scale visual recognition challenge", "weight": 1}, {"from": "Fpnn: Field probing neural networks for 3d data", "to": "Deeppano: Deep panoramic repre-sentation for 3-d shape recognition", "weight": 1}, {"from": "Fpnn: Field probing neural networks for 3d data", "to": "Convolutional-recursive deep learning for 3d object classi\ufb01cation", "weight": 1}, {"from": "Fpnn: Field probing neural networks for 3d data", "to": "Dropout: A simple way to prevent neural networks from over\ufb01tting", "weight": 1}, {"from": "Fpnn: Field probing neural networks for 3d data", "to": "Multi-view convolutional neural networks for 3d shape recognition", "weight": 1}, {"from": "Fpnn: Field probing neural networks for 3d data", "to": "Learning representations by back-propagating errors", "weight": 1}, {"from": "Normface: L 2 hypersphere embedding for face veri\ufb01cation", "to": "", "weight": 1}, {"from": "CNN features off-the-shelf: an astounding baseline In Computer Vision and Pattern Recognifor recognition", "to": "", "weight": 1}, {"from": "AffectNet: A database for facial expression", "to": "", "weight": 1}, {"from": "Gift: A realtime and scalable 3d shape search engine", "to": "", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "Menpo: A comprehensive platform for para-metric image alignment and visual deformable models", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "A uni\ufb01ed frame-work for compositional \ufb01tting of active appearance mod-els", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "A 3D Dynamic Database for Unconstrained Face Recognition", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "A Grassmannian Framework for Face Recognition of 3D Dy-namic Sequences with Challenging Conditions", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "A grassmann framework for 4d facial shape analysis", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "Vt-kfer: A kinect-based rgbd+time dataset for spontaneous and non-spontaneous facial expression recognition", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "Optimal step non-rigid icp algorithms for surface registration", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "From pixels to response maps: Discrimina-tive image \ufb01ltering for face alignment in the wild", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "A New Approach to Linear Filtering and Prediction Problems", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "Assess-ing the uniqueness and permanence of facial actions for use in biometric applications", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "Face veri\ufb01cation from 3d and grey level clues", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "A morphable model for the synthesis of 3d faces", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "3d face morphable models \"in-the-wild\"", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "Large scale 3d morphable models", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "Optimal uv spaces for facial mor-phable model construction", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "High res-olution passive facial performance capture", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "3d face sketch modeling and assessment for component based face recognition", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "Faceware-house: A 3d facial expression database for visual comput-ing", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "Automatic 3d facial expression analysis in videos", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "Statistical non-rigid icp algorithm and its application to 3d face align-ment", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "In the pursuit of effective af-fective computing: The relationship between features and registration", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "A facs valid 3d dynamic action unit database with applications to 3d dy-namic morphable facial modeling", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "Facial Action Coding System", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "A 3-d audio-visual corpus of affective communication", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "Anthropometric 3d face recognition", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "Fully au-In ICPR", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "Three-dimensional face recognition using combinations of surface feature map subspace components", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "Long short-term mem-ory", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "Adam: A method for stochastic op-timization", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "3d In ACII", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "Facial behaviometrics: The case In of facial deformation in spontaneous smile/laughter", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "The discriminant elastic graph matching algorithm applied to frontal face veri\ufb01ca-tion", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "Bp4d-spontaneous: a high-resolution spontaneous 3d dynamic facial expression database", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "Multimodal spontaneous emotion corpus for human behavior analysis", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "Robust 3d face recognition using learned visual codebook", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "Hi4d-adsip 3-d dynamic facial articulation database", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "GavabDB: a 3D Face Database", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "Sparse localized deformation com-ponents", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "3d morphable face models re-visited", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "A 3d face model for pose and illumination invariant face recognition", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "Overview of the face recognition grand challenge", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "Multimodal biometric database dmcsv1 of 3d face and hand scans", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "N", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "Ef-fect of illumination on automatic expression recognition: A novel 3d relightable facial database", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "Tracking vertex \ufb02ow and model adaptation for three-dimensional spatiotempo-ral face analysis", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "Synthesizing obama: Learning lip sync from audio", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "Demo of face2face: Real-time face capture and reenactment of rgb videos", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "A high-resolution 3d dynamic facial expression database", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "A 3d fa-cial expression database for facial behavior research", "weight": 1}, {"from": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "to": "The photoface database", "weight": 1}, {"from": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "to": "Fast high-dimensional \ufb01ltering using the permutohedral lattice", "weight": 1}, {"from": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "to": "Non-linear Gaussian \ufb01lters perform-In DAGM", "weight": 1}, {"from": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "to": "GIFT: In Proc", "weight": 1}, {"from": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "to": "Learning class-speci\ufb01c descrip-tors for deformable shapes using localized spectral convolu-tional networks", "weight": 1}, {"from": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "to": "J", "weight": 1}, {"from": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "to": "Generative and discriminative voxel modeling with convolutional neural networks", "weight": 1}, {"from": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "to": "Geometric deep learning: Going beyond eu-clidean data", "weight": 1}, {"from": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "to": "Spectral networks and locally connected networks on graphs", "weight": 1}, {"from": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "to": "3D object classi\ufb01cation via spherical projections", "weight": 1}, {"from": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "to": "Convolu-tional neural networks on graphs with fast localized spectral \ufb01ltering", "weight": 1}, {"from": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "to": "The Pascal Visual Ob-ject Classes Challenge: A retrospective", "weight": 1}, {"from": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "to": "GWCNN: A metric alignment layer for deep shape analysis", "weight": 1}, {"from": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "to": "Ef\ufb01cient 2D and 3D facade segmentation using auto-context", "weight": 1}, {"from": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "to": "PointNet: A 3D convo-lutional neural network for real-time object class recognition", "weight": 1}, {"from": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "to": "Submanifold sparse con-volutional networks", "weight": 1}, {"from": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "to": "Hyper-columns for object segmentation and \ufb01ne-grained localiza-tion", "weight": 1}, {"from": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "to": "FusionNet: 3D object classi\ufb01ca-tion using multiple data representations", "weight": 1}, {"from": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "to": "Deep convolutional net-works on graph-structured data", "weight": 1}, {"from": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "to": "Learning local shape descriptors with view-based convolutional neural networks", "weight": 1}, {"from": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "to": "Video propagation networks", "weight": 1}, {"from": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "to": "Learning sparse high dimensional \ufb01lters: Image \ufb01ltering", "weight": 1}, {"from": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "to": "Caffe: Convolutional architecture for fast feature embedding", "weight": 1}, {"from": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "to": "3D shape segmentation with projective convolutional networks", "weight": 1}, {"from": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "to": "Permutohedral lat-tice CNNs", "weight": 1}, {"from": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "to": "Adam: A method for stochastic opti-mization", "weight": 1}, {"from": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "to": "Escape from cells: Deep Kd-Networks for the recognition of 3D point cloud models", "weight": 1}, {"from": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "to": "Convolutional neural networks on surfaces via seamless toric covers", "weight": 1}, {"from": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "to": "Geodesic convolutional neural networks on Riemannian manifolds", "weight": 1}, {"from": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "to": "3D convolutional neural net-In Proc", "weight": 1}, {"from": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "to": "Geometric deep learning on graphs and manifolds using mixture model CNNs", "weight": 1}, {"from": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "to": "Illumination for computer generated pictures", "weight": 1}, {"from": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "to": "PointNet: Deep learning on point sets for 3D classi\ufb01cation and segmentation", "weight": 1}, {"from": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "to": "Volumetric and multi-view CNNs for object classi\ufb01cation on 3D data", "weight": 1}, {"from": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "to": "PointNet++: Deep hierarchical feature learning on point sets in a metric space", "weight": 1}, {"from": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "to": "Oct-NetFusion: Learning depth fusion from data", "weight": 1}, {"from": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "to": "Octnet: Learning deep 3D representations at high resolutions", "weight": 1}, {"from": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "to": "Learning where to classify in multi-view semantic segmentation", "weight": 1}, {"from": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "to": "Orientation-boosted voxel nets for 3D object recognition", "weight": 1}, {"from": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "to": "Deep learning 3D shape surfaces using geometry images", "weight": 1}, {"from": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "to": "Multi-view convolutional neural networks for 3D shape recognition", "weight": 1}, {"from": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "to": "Octree gen-erating networks: Ef\ufb01cient convolutional architectures for high-resolution 3D outputs", "weight": 1}, {"from": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "to": "Bilateral \ufb01ltering for gray and color images", "weight": 1}, {"from": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "to": "3D shapenets: A deep representation for volumetric shapes", "weight": 1}, {"from": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "to": "V", "weight": 1}, {"from": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "to": "SyncSpecCNN: Syn-chronized spectral CNN for 3D shape segmentation", "weight": 1}, {"from": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "to": "Deep sets", "weight": 1}, {"from": "Geometric deep learning on graphs and manifolds using mixture model CNNs", "to": "", "weight": 1}, {"from": "Geometric deep learning on graphs and manifolds using mixture model CNNs", "to": "10(4):740\u2013756", "weight": 1}, {"from": "Cnn features off-the-shelf: An astounding baseline for recognition", "to": "", "weight": 1}, {"from": "Aligning Books and Movies: Towards Story-like Visual Explanations by Watching Movies and Reading Books", "to": "", "weight": 1}, {"from": "Bert: Pre-training of deep bidirectional transformers for language understanding", "to": "", "weight": 1}, {"from": "Domain adaptive transfer learning with specialist models", "to": "Analyzing the per-formance of multilayer neural networks for object recogni-tion", "weight": 1}, {"from": "Domain adaptive transfer learning with specialist models", "to": "How HBOs Silicon Valley built Not Hotdog with mobile TensorFlow", "weight": 1}, {"from": "Domain adaptive transfer learning with specialist models", "to": "Factors of transferability for a generic con-vnet representation", "weight": 1}, {"from": "Domain adaptive transfer learning with specialist models", "to": "Birdsnap: Large-scale \ufb01ne-grained visual categorization of birds", "weight": 1}, {"from": "Domain adaptive transfer learning with specialist models", "to": "Food-101 -mining discriminative components with random forests", "weight": 1}, {"from": "Domain adaptive transfer learning with specialist models", "to": "Deeplab: Semantic image segmentation with deep convolutional nets", "weight": 1}, {"from": "Domain adaptive transfer learning with specialist models", "to": "D", "weight": 1}, {"from": "Domain adaptive transfer learning with specialist models", "to": "Large scale \ufb01ne-grained categorization and domain-speci\ufb01c trans-fer learning", "weight": 1}, {"from": "Domain adaptive transfer learning with specialist models", "to": "Decaf: A deep convolutional acti-vation feature for generic visual recognition", "weight": 1}, {"from": "Domain adaptive transfer learning with specialist models", "to": "Borrowing treasures from the wealthy: Deep transfer learning through selective joint \ufb01ne-tuning", "weight": 1}, {"from": "Domain adaptive transfer learning with specialist models", "to": "Fast r-cnn", "weight": 1}, {"from": "Domain adaptive transfer learning with specialist models", "to": "Mask r-cnn", "weight": 1}, {"from": "Domain adaptive transfer learning with specialist models", "to": "Speed/accuracy trade-offs for modern convolutional ob-ject detectors", "weight": 1}, {"from": "Domain adaptive transfer learning with specialist models", "to": "Gpipe: Ef\ufb01cient training of giant neural net-works using pipeline parallelism", "weight": 1}, {"from": "Domain adaptive transfer learning with specialist models", "to": "Do better imagenet models transfer better? CoRR", "weight": 1}, {"from": "Domain adaptive transfer learning with specialist models", "to": "Collecting a large-scale dataset of \ufb01ne-grained cars", "weight": 1}, {"from": "Domain adaptive transfer learning with specialist models", "to": "The unreasonable effec-tiveness of noisy data for \ufb01ne-grained recognition", "weight": 1}, {"from": "Domain adaptive transfer learning with specialist models", "to": "Learning multiple layers of features from tiny images", "weight": 1}, {"from": "Domain adaptive transfer learning with specialist models", "to": "Imagenet classi\ufb01cation with deep convolutional neural networks", "weight": 1}, {"from": "Domain adaptive transfer learning with specialist models", "to": "Ex-ploring the limits of weakly supervised pretraining", "weight": 1}, {"from": "Domain adaptive transfer learning with specialist models", "to": "Fine-grained visual classi\ufb01cation of aircraft", "weight": 1}, {"from": "Domain adaptive transfer learning with specialist models", "to": "Cats and dogs", "weight": 1}, {"from": "Domain adaptive transfer learning with specialist models", "to": "Cnn features off-the-shelf: An astounding baseline for recog-nition", "weight": 1}, {"from": "Domain adaptive transfer learning with specialist models", "to": "Regular-ized evolution for image classi\ufb01er architecture search", "weight": 1}, {"from": "Domain adaptive transfer learning with specialist models", "to": "Faster r-cnn: Towards real-time object detection with region proposal net-works", "weight": 1}, {"from": "Domain adaptive transfer learning with specialist models", "to": "Imagenet large scale visual recog-Int", "weight": 1}, {"from": "Domain adaptive transfer learning with specialist models", "to": "Adjusting the outputs of a classi\ufb01er to new a priori probabilities: A simple procedure", "weight": 1}, {"from": "Domain adaptive transfer learning with specialist models", "to": "Fully convolutional IEEE Trans", "weight": 1}, {"from": "Domain adaptive transfer learning with specialist models", "to": "Improving predictive inference under covari-ate shift by weighting the log-likelihood function", "weight": 1}, {"from": "Domain adaptive transfer learning with specialist models", "to": "When training and test sets are different: Characterising learning transfer", "weight": 1}, {"from": "Domain adaptive transfer learning with specialist models", "to": "S", "weight": 1}, {"from": "Domain adaptive transfer learning with specialist models", "to": "Revisiting Unreasonable Effectiveness of Data in Deep Learning Era", "weight": 1}, {"from": "Domain adaptive transfer learning with specialist models", "to": "Rethinking the inception architecture for computer vision", "weight": 1}, {"from": "Domain adaptive transfer learning with specialist models", "to": "Yfcc100m: The new data in multimedia research", "weight": 1}, {"from": "Domain adaptive transfer learning with specialist models", "to": "How trans-ferable are features in deep neural networks? In Advances in Neural Information Processing Systems", "weight": 1}, {"from": "Domain adaptive transfer learning with specialist models", "to": "Deep layer aggregation", "weight": 1}, {"from": "Domain adaptive transfer learning with specialist models", "to": "Taskonomy: Disentangling task transfer learn-In IEEE Conference on Computer Vision and Pattern ing", "weight": 1}, {"from": "Domain adaptive transfer learning with specialist models", "to": "Do-main adaptation under target and conditional shift", "weight": 1}, {"from": "Domain adaptive transfer learning with specialist models", "to": "Learn-ing transferable architectures for scalable image recognition", "weight": 1}, {"from": "Deeplab: Semantic image segmentation with deep convolutional nets", "to": "", "weight": 1}, {"from": "Borrowing treasures from the wealthy: Deep transfer learning through selective joint \ufb01ne-tuning", "to": "From generic to speci\ufb01c deep representations In Proceedings of the IEEE Con-for visual recognition", "weight": 1}, {"from": "Borrowing treasures from the wealthy: Deep transfer learning through selective joint \ufb01ne-tuning", "to": "Multipath sparse coding using hierarchical matching pursuit", "weight": 1}, {"from": "Borrowing treasures from the wealthy: Deep transfer learning through selective joint \ufb01ne-tuning", "to": "Multitask learning", "weight": 1}, {"from": "Borrowing treasures from the wealthy: Deep transfer learning through selective joint \ufb01ne-tuning", "to": "Deep \ufb01l-ter banks for texture recognition", "weight": 1}, {"from": "Borrowing treasures from the wealthy: Deep transfer learning through selective joint \ufb01ne-tuning", "to": "Decaf: A deep convolutional acti-vation feature for generic visual recognition", "weight": 1}, {"from": "Borrowing treasures from the wealthy: Deep transfer learning through selective joint \ufb01ne-tuning", "to": "Visual event IEEE recognition in videos by learning from web data", "weight": 1}, {"from": "Borrowing treasures from the wealthy: Deep transfer learning through selective joint \ufb01ne-tuning", "to": "Predicting depth", "weight": 1}, {"from": "Borrowing treasures from the wealthy: Deep transfer learning through selective joint \ufb01ne-tuning", "to": "Multi-task feature learning", "weight": 1}, {"from": "Borrowing treasures from the wealthy: Deep transfer learning through selective joint \ufb01ne-tuning", "to": "Local alignments for \ufb01ne-grained categoriza-tion", "weight": 1}, {"from": "Borrowing treasures from the wealthy: Deep transfer learning through selective joint \ufb01ne-tuning", "to": "Rich fea-ture hierarchies for accurate object detection and semantic In Proceedings of the IEEE conference on segmentation", "weight": 1}, {"from": "Borrowing treasures from the wealthy: Deep transfer learning through selective joint \ufb01ne-tuning", "to": "Caltech-256 object cat-egory dataset", "weight": 1}, {"from": "Borrowing treasures from the wealthy: Deep transfer learning through selective joint \ufb01ne-tuning", "to": "Deep residual learn-ing for image recognition", "weight": 1}, {"from": "Borrowing treasures from the wealthy: Deep transfer learning through selective joint \ufb01ne-tuning", "to": "Identity mappings in deep residual networks", "weight": 1}, {"from": "Borrowing treasures from the wealthy: Deep transfer learning through selective joint \ufb01ne-tuning", "to": "Scene recognition with cnns: objects", "weight": 1}, {"from": "Borrowing treasures from the wealthy: Deep transfer learning through selective joint \ufb01ne-tuning", "to": "Learning transferrable knowledge for semantic segmentation with deep convolu-In IEEE Conference on Computer tional neural network", "weight": 1}, {"from": "Borrowing treasures from the wealthy: Deep transfer learning through selective joint \ufb01ne-tuning", "to": "Correcting sample selection bias by unlabeled data", "weight": 1}, {"from": "Borrowing treasures from the wealthy: Deep transfer learning through selective joint \ufb01ne-tuning", "to": "Caffe: Convolu-tional architecture for fast feature embedding", "weight": 1}, {"from": "Borrowing treasures from the wealthy: Deep transfer learning through selective joint \ufb01ne-tuning", "to": "Very deep convolutional net-arXiv preprint works for large-scale image recognition", "weight": 1}, {"from": "Borrowing treasures from the wealthy: Deep transfer learning through selective joint \ufb01ne-tuning", "to": "Novel dataset for \ufb01ne-grained image categorization: Stanford dogs", "weight": 1}, {"from": "Borrowing treasures from the wealthy: Deep transfer learning through selective joint \ufb01ne-tuning", "to": "The unreasonable ef-fectiveness of noisy data for \ufb01ne-grained recognition", "weight": 1}, {"from": "Borrowing treasures from the wealthy: Deep transfer learning through selective joint \ufb01ne-tuning", "to": "Imagenet classi\ufb01cation with deep convolutional neural networks", "weight": 1}, {"from": "Borrowing treasures from the wealthy: Deep transfer learning through selective joint \ufb01ne-tuning", "to": "Fully convolutional networks for semantic segmentation", "weight": 1}, {"from": "Borrowing treasures from the wealthy: Deep transfer learning through selective joint \ufb01ne-tuning", "to": "Learning transferable features with deep adaptation networks", "weight": 1}, {"from": "Borrowing treasures from the wealthy: Deep transfer learning through selective joint \ufb01ne-tuning", "to": "Understanding deep image representations by inverting them", "weight": 1}, {"from": "Borrowing treasures from the wealthy: Deep transfer learning through selective joint \ufb01ne-tuning", "to": "Texture features for brows-IEEE Transactions on ing and retrieval of image data", "weight": 1}, {"from": "Borrowing treasures from the wealthy: Deep transfer learning through selective joint \ufb01ne-tuning", "to": "A survey on transfer learning", "weight": 1}, {"from": "Borrowing treasures from the wealthy: Deep transfer learning through selective joint \ufb01ne-tuning", "to": "Multi-task learning for classi\ufb01cation with dirichlet process priors", "weight": 1}, {"from": "Borrowing treasures from the wealthy: Deep transfer learning through selective joint \ufb01ne-tuning", "to": "Hd-cnn: Hierarchical deep convolutional neural networks for large scale visual recognition", "weight": 1}, {"from": "Borrowing treasures from the wealthy: Deep transfer learning through selective joint \ufb01ne-tuning", "to": "Multi-scale In pyramid pooling for deep convolutional representation", "weight": 1}, {"from": "Borrowing treasures from the wealthy: Deep transfer learning through selective joint \ufb01ne-tuning", "to": "How trans-ferable are features in deep neural networks? In Advances in neural information processing systems", "weight": 1}, {"from": "Borrowing treasures from the wealthy: Deep transfer learning through selective joint \ufb01ne-tuning", "to": "Visualizing and understanding convolutional networks", "weight": 1}, {"from": "Borrowing treasures from the wealthy: Deep transfer learning through selective joint \ufb01ne-tuning", "to": "Learning deep features for scene recognition using places database", "weight": 1}, {"from": "Borrowing treasures from the wealthy: Deep transfer learning through selective joint \ufb01ne-tuning", "to": "Transformation pursuit for image classi\ufb01cation", "weight": 1}, {"from": "Borrowing treasures from the wealthy: Deep transfer learning through selective joint \ufb01ne-tuning", "to": "Fine-grained visual categorization via multi-stage metric learning", "weight": 1}, {"from": "Borrowing treasures from the wealthy: Deep transfer learning through selective joint \ufb01ne-tuning", "to": "Recognizing indoor scenes", "weight": 1}, {"from": "Borrowing treasures from the wealthy: Deep transfer learning through selective joint \ufb01ne-tuning", "to": "Faster r-cnn: Towards real-time object detection with region proposal networks", "weight": 1}, {"from": "Borrowing treasures from the wealthy: Deep transfer learning through selective joint \ufb01ne-tuning", "to": "Metric learn-ing with adaptive density discrimination", "weight": 1}, {"from": "Borrowing treasures from the wealthy: Deep transfer learning through selective joint \ufb01ne-tuning", "to": "J", "weight": 1}, {"from": "Borrowing treasures from the wealthy: Deep transfer learning through selective joint \ufb01ne-tuning", "to": "Cnn features off-the-shelf: an astounding baseline for recognition", "weight": 1}, {"from": "Borrowing treasures from the wealthy: Deep transfer learning through selective joint \ufb01ne-tuning", "to": "Neural activation constellations: Unsupervised part model discovery with convolutional net-works", "weight": 1}, {"from": "Borrowing treasures from the wealthy: Deep transfer learning through selective joint \ufb01ne-tuning", "to": "Dropout: a simple way to prevent neu-ral networks from over\ufb01tting", "weight": 1}, {"from": "Borrowing treasures from the wealthy: Deep transfer learning through selective joint \ufb01ne-tuning", "to": "In IEEE Conference on Going deeper with convolutions", "weight": 1}, {"from": "Borrowing treasures from the wealthy: Deep transfer learning through selective joint \ufb01ne-tuning", "to": "Simultane-ous deep transfer across domains and tasks", "weight": 1}, {"from": "Borrowing treasures from the wealthy: Deep transfer learning through selective joint \ufb01ne-tuning", "to": "Locality-constrained linear coding for image classi\ufb01cation", "weight": 1}, {"from": "Borrowing treasures from the wealthy: Deep transfer learning through selective joint \ufb01ne-tuning", "to": "Harvesting discrimi-native meta objects with deep cnn features for scene classi\ufb01-cation", "weight": 1}, {"from": "Borrowing treasures from the wealthy: Deep transfer learning through selective joint \ufb01ne-tuning", "to": "Hyper-class aug-mented and regularized deep learning for \ufb01ne-grained im-In Proceedings of the IEEE Conference age classi\ufb01cation", "weight": 1}, {"from": "Fast r-cnn", "to": "OverFeat: Integrated Recognition", "weight": 1}, {"from": "Fast r-cnn", "to": "Very deep convolutional networks for large-scale image recognition", "weight": 1}, {"from": "Fast r-cnn", "to": "Selective search for object recognition", "weight": 1}, {"from": "Fast r-cnn", "to": "Rapid object detection using a boosted cascade of simple features", "weight": 1}, {"from": "Fast r-cnn", "to": "Restructuring of deep neural network acoustic models with singular value decomposition", "weight": 1}, {"from": "Fast r-cnn", "to": "Do we need more training data or better models for object detec-tion? In BMVC", "weight": 1}, {"from": "Fast r-cnn", "to": "segDeepM: Exploiting segmentation and context in deep In CVPR", "weight": 1}, {"from": "Fast r-cnn", "to": "Se-mantic segmentation with second-order pooling", "weight": 1}, {"from": "Fast r-cnn", "to": "Multitask learning", "weight": 1}, {"from": "Fast r-cnn", "to": "Return of the devil in the details: Delving deep into convo-lutional nets", "weight": 1}, {"from": "Fast r-cnn", "to": "ImageNet: A large-scale hierarchical image database", "weight": 1}, {"from": "Fast r-cnn", "to": "Exploiting linear structure within convolutional networks for ef\ufb01cient evaluation", "weight": 1}, {"from": "Fast r-cnn", "to": "Scalable object detection using deep neural networks", "weight": 1}, {"from": "Fast r-cnn", "to": "The PASCAL Visual Object Classes (VOC) Challenge", "weight": 1}, {"from": "Fast r-cnn", "to": "Object detection with discriminatively trained part based models", "weight": 1}, {"from": "Fast r-cnn", "to": "Rich fea-ture hierarchies for accurate object detection and semantic segmentation", "weight": 1}, {"from": "Fast r-cnn", "to": "Region-based convolutional networks for accurate object detection and segmentation", "weight": 1}, {"from": "Fast r-cnn", "to": "Spatial pyramid pooling In in deep convolutional networks for visual recognition", "weight": 1}, {"from": "Fast r-cnn", "to": "R", "weight": 1}, {"from": "Fast r-cnn", "to": "Caffe: Convolutional architecture for fast feature embedding", "weight": 1}, {"from": "Fast r-cnn", "to": "ImageNet clas-si\ufb01cation with deep convolutional neural networks", "weight": 1}, {"from": "Fast r-cnn", "to": "Beyond bags of features: Spatial pyramid matching for recognizing natural scene categories", "weight": 1}, {"from": "Fast r-cnn", "to": "Backpropagation applied to handwritten zip code recognition", "weight": 1}, {"from": "Fast r-cnn", "to": "Network in network", "weight": 1}, {"from": "Fast r-cnn", "to": "Microsoft COCO: common objects in context", "weight": 1}, {"from": "Revisiting Unreasonable Effectiveness of Data in Deep Learning Era", "to": "", "weight": 1}, {"from": "Yfcc100m: The new data in multimedia research", "to": "", "weight": 1}, {"from": "Yfcc100m: The new data in multimedia research", "to": ", et al", "weight": 1}, {"from": "Learning deep embeddings with histogram loss", "to": "", "weight": 1}, {"from": "SyncSpecCNN: Synchronized Spectral CNN for 3D Shape Segmentation", "to": "ShapeNet: An Information-Rich 3D Model Repository", "weight": 1}, {"from": "SyncSpecCNN: Synchronized Spectral CNN for 3D Shape Segmentation", "to": "Convolu-tional neural networks on graphs with fast localized spectral \ufb01ltering", "weight": 1}, {"from": "SyncSpecCNN: Synchronized Spectral CNN for 3D Shape Segmentation", "to": "Convolutional networks on graphs for learning molecular \ufb01ngerprints", "weight": 1}, {"from": "SyncSpecCNN: Synchronized Spectral CNN for 3D Shape Segmentation", "to": "3d mesh labeling via deep convolutional neural networks", "weight": 1}, {"from": "SyncSpecCNN: Synchronized Spectral CNN for 3D Shape Segmentation", "to": "Deep convolu-tional networks on graph-structured data", "weight": 1}, {"from": "SyncSpecCNN: Synchronized Spectral CNN for 3D Shape Segmentation", "to": "K", "weight": 1}, {"from": "SyncSpecCNN: Synchronized Spectral CNN for 3D Shape Segmentation", "to": "Learning 3d mesh segmentation and labeling", "weight": 1}, {"from": "SyncSpecCNN: Synchronized Spectral CNN for 3D Shape Segmentation", "to": "Shape2pose: human-centric shape analysis", "weight": 1}, {"from": "SyncSpecCNN: Synchronized Spectral CNN for 3D Shape Segmentation", "to": "Learning part-based templates from large collections of 3d shapes", "weight": 1}, {"from": "SyncSpecCNN: Synchronized Spectral CNN for 3D Shape Segmentation", "to": "Segmentation of 3d meshes through spectral clustering", "weight": 1}, {"from": "SyncSpecCNN: Synchronized Spectral CNN for 3D Shape Segmentation", "to": "Mesh segmentation via spectral In Computer Graphics embedding and contour analysis", "weight": 1}, {"from": "SyncSpecCNN: Synchronized Spectral CNN for 3D Shape Segmentation", "to": "Fully convolutional In Proceedings of networks for semantic segmentation", "weight": 1}, {"from": "SyncSpecCNN: Synchronized Spectral CNN for 3D Shape Segmentation", "to": "Learning 3d part detection In 2014 2nd International from sparsely labeled data", "weight": 1}, {"from": "SyncSpecCNN: Synchronized Spectral CNN for 3D Shape Segmentation", "to": "Geodesic convolutional neural networks on riemannian man-ifolds", "weight": 1}, {"from": "SyncSpecCNN: Synchronized Spectral CNN for 3D Shape Segmentation", "to": "Learning class-speci\ufb01c de-scriptors for deformable shapes using localized spectral In Computer Graphics Forum", "weight": 1}, {"from": "SyncSpecCNN: Synchronized Spectral CNN for 3D Shape Segmentation", "to": "J", "weight": 1}, {"from": "SyncSpecCNN: Synchronized Spectral CNN for 3D Shape Segmentation", "to": "Spectral networks and locally connected networks on graphs", "weight": 1}, {"from": "SyncSpecCNN: Synchronized Spectral CNN for 3D Shape Segmentation", "to": "Functional maps: a \ufb02exible representation of maps between shapes", "weight": 1}, {"from": "SyncSpecCNN: Synchronized Spectral CNN for 3D Shape Segmentation", "to": "Vertex-frequency analysis on graphs", "weight": 1}, {"from": "SyncSpecCNN: Synchronized Spectral CNN for 3D Shape Segmentation", "to": "Angular synchronization by eigenvectors and Applied and computational semide\ufb01nite programming", "weight": 1}, {"from": "SyncSpecCNN: Synchronized Spectral CNN for 3D Shape Segmentation", "to": "Going deeper with convolutions", "weight": 1}, {"from": "SyncSpecCNN: Synchronized Spectral CNN for 3D Shape Segmentation", "to": "Image co-segmentation via consistent functional maps", "weight": 1}, {"from": "SyncSpecCNN: Synchronized Spectral CNN for 3D Shape Segmentation", "to": "Unsupervised multi-class joint In 2014 IEEE Conference on Computer Vision and Pattern Recognition", "weight": 1}, {"from": "SyncSpecCNN: Synchronized Spectral CNN for 3D Shape Segmentation", "to": "Interactive shape co-segmentation via label propagation", "weight": 1}, {"from": "SyncSpecCNN: Synchronized Spectral CNN for 3D Shape Segmentation", "to": "3d shape segmentation In Computer and labeling via extreme learning machine", "weight": 1}, {"from": "SyncSpecCNN: Synchronized Spectral CNN for 3D Shape Segmentation", "to": "A scalable active framework for region annotation in 3d shape collections", "weight": 1}, {"from": "SyncSpecCNN: Synchronized Spectral CNN for 3D Shape Segmentation", "to": "Multi-scale context aggregation by arXiv preprint arXiv:1511", "weight": 1}, {"from": "Yolo9000: Better", "to": "Inception-v4", "weight": 1}, {"from": "Yolo9000: Better", "to": "Going deeper with convolutions", "weight": 1}, {"from": "Yolo9000: Better", "to": "Yfcc100m: The new data in multimedia research", "weight": 1}, {"from": "Yolo9000: Better", "to": "Inside-outside net: Detecting objects in context with skip arXiv preprint pooling and recurrent neural networks", "weight": 1}, {"from": "Yolo9000: Better", "to": "Imagenet: A large-scale hierarchical image database", "weight": 1}, {"from": "Yolo9000: Better", "to": "The pascal visual object classes (voc) chal-lenge", "weight": 1}, {"from": "Yolo9000: Better", "to": "Fast R-CNN", "weight": 1}, {"from": "Yolo9000: Better", "to": "Deep residual learn-ing for image recognition", "weight": 1}, {"from": "Yolo9000: Better", "to": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "weight": 1}, {"from": "Yolo9000: Better", "to": "Imagenet classi\ufb01cation with deep convolutional neural networks", "weight": 1}, {"from": "Yolo9000: Better", "to": "Network in network", "weight": 1}, {"from": "Yolo9000: Better", "to": "SSD: single shot multibox detector", "weight": 1}, {"from": "Yolo9000: Better", "to": "Introduction to wordnet: An on-line lexical database", "weight": 1}, {"from": "Yolo9000: Better", "to": "Darknet: Open source neural networks in c", "weight": 1}, {"from": "Yolo9000: Better", "to": "You only look once: Uni\ufb01ed", "weight": 1}, {"from": "Yolo9000: Better", "to": "Faster r-cnn: To-wards real-time object detection with region proposal net-works", "weight": 1}, {"from": "Yolo9000: Better", "to": "ImageNet Large Scale Visual Recognition Challenge", "weight": 1}, {"from": "Yolo9000: Better", "to": "Very deep convolutional networks for large-scale image recognition", "weight": 1}, {"from": "Fine-grained visual categorization via multi-stage metric learning", "to": "", "weight": 1}, {"from": "Vizdoom: A doom-based AI research platform for visual reinforcement learning", "to": "", "weight": 1}, {"from": "Vizdoom: A doom-based AI research platform for visual reinforcement learning", "to": "A vision-based reinforcement learning for coordination of soccer playing behaviors", "weight": 1}, {"from": "Vizdoom: A doom-based AI research platform for visual reinforcement learning", "to": "pages 276\u2013282", "weight": 1}, {"from": "Vizdoom: A doom-based AI research platform for visual reinforcement learning", "to": "Reinforcement In Intelligent Robots and learning for a vision based mobile robot", "weight": 1}, {"from": "Vizdoom: A doom-based AI research platform for visual reinforcement learning", "to": "editors, Proceedings of the Fourteenth International Conference on Ar-ti\ufb01cial Intelligence and Statistics (AISTATS-11), volume 15, pages 315\u2013 323", "weight": 1}, {"from": "Vizdoom: A doom-based AI research platform for visual reinforcement learning", "to": "Believable Bot Navigation via Playback of Human Traces, pages 151\u2013170", "weight": 1}, {"from": "Vizdoom: A doom-based AI research platform for visual reinforcement learning", "to": "Deep auto-encoder neural net-works in reinforcement learning", "weight": 1}, {"from": "Vizdoom: A doom-based AI research platform for visual reinforcement learning", "to": "Recti\ufb01er nonlinearities improve neural network acoustic models", "weight": 1}, {"from": "Vizdoom: A doom-based AI research platform for visual reinforcement learning", "to": "RE-TALIATE: learning winning policies in \ufb01rst-person shooter games", "weight": 1}, {"from": "Vizdoom: A doom-based AI research platform for visual reinforcement learning", "to": "Continuous and Reinforcement Learning Methods for First-Person Shooter Games", "weight": 1}, {"from": "Vizdoom: A doom-based AI research platform for visual reinforcement learning", "to": "Computer game engines for developing \ufb01rst-person virtual environments", "weight": 1}, {"from": "Bidirectional warping of active appearance model", "to": "Lucas-kanade 20 years on: A uni-fying framework", "weight": 1}, {"from": "Bidirectional warping of active appearance model", "to": "Active appearance models", "weight": 1}, {"from": "Bidirectional warping of active appearance model", "to": "C", "weight": 1}, {"from": "Bidirectional warping of active appearance model", "to": "Generic vs", "weight": 1}, {"from": "Bidirectional warping of active appearance model", "to": "In Automatic Face Gesture Recognition", "weight": 1}, {"from": "Bidirectional warping of active appearance model", "to": "Fast motion estimation using Image Processing", "weight": 1}, {"from": "Bidirectional warping of active appearance model", "to": "M", "weight": 1}, {"from": "Bidirectional warping of active appearance model", "to": "A framework for automated measurement of the intensity of non-posed facial action units", "weight": 1}, {"from": "Bidirectional warping of active appearance model", "to": "Active appearance models revis-ited", "weight": 1}, {"from": "Bidirectional warping of active appearance model", "to": "Bidirec-tional Composition on Lie Groups for Gradient-Based Im-Image Processing", "weight": 1}, {"from": "Chalet: Cornell house agent learning environment", "to": "Vision-and-language navigation: Interpreting visually-grounded nav-igation instructions in real environments", "weight": 1}, {"from": "Chalet: Cornell house agent learning environment", "to": "", "weight": 1}, {"from": "Chalet: Cornell house agent learning environment", "to": "HoME: a arXiv preprint Household Multimodal Environment", "weight": 1}, {"from": "Chalet: Cornell house agent learning environment", "to": "Embodied Question Answering", "weight": 1}, {"from": "Chalet: Cornell house agent learning environment", "to": "IQA: Visual Question Answering in Interactive Environ-ments", "weight": 1}, {"from": "Chalet: Cornell house agent learning environment", "to": "arXiv preprint Learning in a Simulated 3D World", "weight": 1}, {"from": "Chalet: Cornell house agent learning environment", "to": "Vizdoom: A doom-based AI research platform for visual reinforce-ment learning", "weight": 1}, {"from": "Chalet: Cornell house agent learning environment", "to": "Playing atari with deep rein-forcement learning", "weight": 1}, {"from": "Chalet: Cornell house agent learning environment", "to": "Control of memory, active perception, and action in minecraft", "weight": 1}, {"from": "Chalet: Cornell house agent learning environment", "to": "Evolution strategies as a scalable alternative to reinforce-ment learning", "weight": 1}, {"from": "Chalet: Cornell house agent learning environment", "to": "MINOS: Multimodal Indoor Simulator for Navigation in Complex Environments", "weight": 1}, {"from": "Chalet: Cornell house agent learning environment", "to": "A corpus of natural language for visual reasoning", "weight": 1}, {"from": "Chalet: Cornell house agent learning environment", "to": "Building Generalizable Agents with a Realistic and Rich 3D Environment", "weight": 1}, {"from": "Chalet: Cornell house agent learning environment", "to": "Extending the openai gym for robotics: a toolkit for reinforce-arXiv preprint ment learning using ros and gazebo", "weight": 1}, {"from": "Chalet: Cornell house agent learning environment", "to": "Target-driven visual navigation in indoor scenes using deep re-inforcement learning", "weight": 1}, {"from": "Control of memory, active perception, and action in minecraft", "to": "", "weight": 1}, {"from": "MINOS: Multimodal Indoor Simulator for Navigation in Complex Environments", "to": "", "weight": 1}, {"from": "Building Generalizable Agents with a Realistic and Rich 3D Environment", "to": "", "weight": 1}, {"from": "Interleaved group convolutions for deep neural networks", "to": "Multi-residual networks", "weight": 1}, {"from": "Interleaved group convolutions for deep neural networks", "to": "The power of sparsity in convolutional neural networks", "weight": 1}, {"from": "Interleaved group convolutions for deep neural networks", "to": "Mxnet: A \ufb02exible and ef\ufb01-cient machine learning library for heterogeneous distributed systems", "weight": 1}, {"from": "Interleaved group convolutions for deep neural networks", "to": "Xception: Deep learning with depthwise separa-ble convolutions", "weight": 1}, {"from": "Interleaved group convolutions for deep neural networks", "to": "Ima-genet: A large-scale hierarchical image database", "weight": 1}, {"from": "Interleaved group convolutions for deep neural networks", "to": "Exploiting linear structure within convolutional net-works for ef\ufb01cient evaluation", "weight": 1}, {"from": "Interleaved group convolutions for deep neural networks", "to": "Deep compression: Com-pressing deep neural network with pruning", "weight": 1}, {"from": "Interleaved group convolutions for deep neural networks", "to": "Learning both In weights and connections for ef\ufb01cient neural network", "weight": 1}, {"from": "Interleaved group convolutions for deep neural networks", "to": "Delving deep into recti\ufb01ers: Surpassing human-level performance on imagenet classi\ufb01cation", "weight": 1}, {"from": "Interleaved group convolutions for deep neural networks", "to": "Deep residual learning for image recognition", "weight": 1}, {"from": "Interleaved group convolutions for deep neural networks", "to": "Identity mappings in deep residual networks", "weight": 1}, {"from": "Interleaved group convolutions for deep neural networks", "to": "Densely connected convolutional networks", "weight": 1}, {"from": "Interleaved group convolutions for deep neural networks", "to": "Deep networks with stochastic depth", "weight": 1}, {"from": "Interleaved group convolutions for deep neural networks", "to": "Deep roots: Improving CNN ef\ufb01ciency with hierarchical \ufb01l-ter groups", "weight": 1}, {"from": "Interleaved group convolutions for deep neural networks", "to": "Training cnns with low-rank \ufb01lters for ef\ufb01-cient image classi\ufb01cation", "weight": 1}, {"from": "Interleaved group convolutions for deep neural networks", "to": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "weight": 1}, {"from": "Interleaved group convolutions for deep neural networks", "to": "Speeding up convolutional neural networks with low rank expansions", "weight": 1}, {"from": "Interleaved group convolutions for deep neural networks", "to": "Flattened convolu-tional neural networks for feedforward acceleration", "weight": 1}, {"from": "Interleaved group convolutions for deep neural networks", "to": "Compression of deep convolutional neural networks for fast and low power mobile applications", "weight": 1}, {"from": "Interleaved group convolutions for deep neural networks", "to": "Learning multiple layers of features from tiny images", "weight": 1}, {"from": "Interleaved group convolutions for deep neural networks", "to": "classi\ufb01cation with deep convolutional neural networks", "weight": 1}, {"from": "Interleaved group convolutions for deep neural networks", "to": "Fractal-net: Ultra-deep neural networks without residuals", "weight": 1}, {"from": "Interleaved group convolutions for deep neural networks", "to": "Deeply-supervised nets", "weight": 1}, {"from": "Interleaved group convolutions for deep neural networks", "to": "Pruning \ufb01lters for ef\ufb01cient convnets", "weight": 1}, {"from": "Interleaved group convolutions for deep neural networks", "to": "Network in network", "weight": 1}, {"from": "Interleaved group convolutions for deep neural networks", "to": "Simplifying convnets for fast learning", "weight": 1}, {"from": "Interleaved group convolutions for deep neural networks", "to": "Fitnets: Hints for thin deep nets", "weight": 1}, {"from": "Interleaved group convolutions for deep neural networks", "to": "Rigid-motion scattering for texture classi\ufb01cation", "weight": 1}, {"from": "Interleaved group convolutions for deep neural networks", "to": "Very deep convolu-tional networks for large-scale image recognition", "weight": 1}, {"from": "Interleaved group convolutions for deep neural networks", "to": "Swapout: Learning In NIPS", "weight": 1}, {"from": "Interleaved group convolutions for deep neural networks", "to": "Striving for simplicity: The all convolutional net", "weight": 1}, {"from": "Interleaved group convolutions for deep neural networks", "to": "Training very deep networks", "weight": 1}, {"from": "Interleaved group convolutions for deep neural networks", "to": "Inception-v4", "weight": 1}, {"from": "Interleaved group convolutions for deep neural networks", "to": "Going deeper with convolutions", "weight": 1}, {"from": "Interleaved group convolutions for deep neural networks", "to": "Rethinking the inception architecture for computer vision", "weight": 1}, {"from": "Interleaved group convolutions for deep neural networks", "to": "Resnet in resnet: Gener-alizing residual architectures", "weight": 1}, {"from": "Interleaved group convolutions for deep neural networks", "to": "80 million tiny images: A large data set for nonparametric object and scene recognition", "weight": 1}, {"from": "Interleaved group convolutions for deep neural networks", "to": "Deeply-fused nets", "weight": 1}, {"from": "Interleaved group convolutions for deep neural networks", "to": "Learning structured sparsity in deep neural networks", "weight": 1}, {"from": "Interleaved group convolutions for deep neural networks", "to": "Ag-gregated residual transformations for deep neural networks", "weight": 1}, {"from": "Interleaved group convolutions for deep neural networks", "to": "Wide residual networks", "weight": 1}, {"from": "Interleaved group convolutions for deep neural networks", "to": "On the connec-tion of deep fusion to ensembling", "weight": 1}, {"from": "Exploring the limits of weakly supervised pretraining", "to": "", "weight": 1}, {"from": "Speeding up convolutional neural networks with low rank expansions", "to": "End-to-End Text Recognition with Hybrid HMM Maxout Models", "weight": 1}, {"from": "Speeding up convolutional neural networks with low rank expansions", "to": "PhotoOCR: Reading text in un-controlled conditions", "weight": 1}, {"from": "Speeding up convolutional neural networks with low rank expansions", "to": "Character recognition in natural images", "weight": 1}, {"from": "Speeding up convolutional neural networks with low rank expansions", "to": "Predicting parameters in deep learning", "weight": 1}, {"from": "Speeding up convolutional neural networks with low rank expansions", "to": "Exploiting linear structure within convolutional networks for ef\ufb01cient evaluation", "weight": 1}, {"from": "Speeding up convolutional neural networks with low rank expansions", "to": "Large-scale fpga-based convolutional networks", "weight": 1}, {"from": "Speeding up convolutional neural networks with low rank expansions", "to": "Scene parsing with multiscale feature learning", "weight": 1}, {"from": "Speeding up convolutional neural networks with low rank expansions", "to": "Multi-digit number In recognition from street view imagery using deep convolutional neural networks", "weight": 1}, {"from": "Speeding up convolutional neural networks with low rank expansions", "to": "Maxout networks", "weight": 1}, {"from": "Speeding up convolutional neural networks with low rank expansions", "to": "Improving neural networks by preventing co-adaptation of feature detectors", "weight": 1}, {"from": "Speeding up convolutional neural networks with low rank expansions", "to": "arXiv preprint Implementing ef\ufb01cient convnet descriptor pyramids", "weight": 1}, {"from": "Speeding up convolutional neural networks with low rank expansions", "to": "Caffe: An open source convolutional architecture for fast feature embedding", "weight": 1}, {"from": "Speeding up convolutional neural networks with low rank expansions", "to": "F", "weight": 1}, {"from": "Speeding up convolutional neural networks with low rank expansions", "to": "Learning convolutional feature hierarchies for visual recognition", "weight": 1}, {"from": "Speeding up convolutional neural networks with low rank expansions", "to": "ImageNet classi\ufb01cation with deep con-volutional neural networks", "weight": 1}, {"from": "Speeding up convolutional neural networks with low rank expansions", "to": "Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations", "weight": 1}, {"from": "Speeding up convolutional neural networks with low rank expansions", "to": "ICDAR 2005 text locating competition results", "weight": 1}, {"from": "Speeding up convolutional neural networks with low rank expansions", "to": "Simplifying convnets for fast learning", "weight": 1}, {"from": "Speeding up convolutional neural networks with low rank expansions", "to": "Fast training of convolutional networks through ffts", "weight": 1}, {"from": "Speeding up convolutional neural networks with low rank expansions", "to": "A method for text localization and recognition in real-world images", "weight": 1}, {"from": "Speeding up convolutional neural networks with low rank expansions", "to": "Text localization in real-world images using ef\ufb01ciently pruned exhaustive search", "weight": 1}, {"from": "Speeding up convolutional neural networks with low rank expansions", "to": "Real-time scene text localization and recognition", "weight": 1}, {"from": "Speeding up convolutional neural networks with low rank expansions", "to": "Scene text localization and recognition with oriented stroke detection", "weight": 1}, {"from": "Speeding up convolutional neural networks with low rank expansions", "to": "Learning and transferring mid-level image representations using convolutional neural networks", "weight": 1}, {"from": "Speeding up convolutional neural networks with low rank expansions", "to": "Using text-spotting to query the world", "weight": 1}, {"from": "Speeding up convolutional neural networks with low rank expansions", "to": "Large scale mining and retrieval of visual data in a multimodal context", "weight": 1}, {"from": "Speeding up convolutional neural networks with low rank expansions", "to": "Cnn features off-the-shelf: an astounding baseline for recognition", "weight": 1}, {"from": "Speeding up convolutional neural networks with low rank expansions", "to": "Are sparse representations really relevant for image classi\ufb01cation? In Computer Vision and Pattern Recognition (CVPR)", "weight": 1}, {"from": "Speeding up convolutional neural networks with low rank expansions", "to": "Learning separable \ufb01lters", "weight": 1}, {"from": "Speeding up convolutional neural networks with low rank expansions", "to": "Overfeat: Integrated recognition", "weight": 1}, {"from": "Speeding up convolutional neural networks with low rank expansions", "to": "ICDAR 2011 robust reading competition chal-lenge 2: Reading text in scene images", "weight": 1}, {"from": "Speeding up convolutional neural networks with low rank expansions", "to": "Sparselet models for ef\ufb01cient multiclass object detection", "weight": 1}, {"from": "Speeding up convolutional neural networks with low rank expansions", "to": "Discriminatively activated sparselets", "weight": 1}, {"from": "Speeding up convolutional neural networks with low rank expansions", "to": "Deep-Face: Closing the gap to human-level performance in face veri\ufb01cation", "weight": 1}, {"from": "Speeding up convolutional neural networks with low rank expansions", "to": "DeepPose: Human pose estimation via deep neural net-works", "weight": 1}, {"from": "Speeding up convolutional neural networks with low rank expansions", "to": "Segmentation as selective In Computer Vision (ICCV)", "weight": 1}, {"from": "Speeding up convolutional neural networks with low rank expansions", "to": "Improving the speed of neural networks on In Proc", "weight": 1}, {"from": "Speeding up convolutional neural networks with low rank expansions", "to": "End-to-end scene text recognition", "weight": 1}, {"from": "Speeding up convolutional neural networks with low rank expansions", "to": "End-to-end text recognition with con-In Pattern Recognition (ICPR)", "weight": 1}, {"from": "Speeding up convolutional neural networks with low rank expansions", "to": "A framework for improved video text detection and recognition", "weight": 1}, {"from": "OctNetFusion: Learning depth fusion from data", "to": "", "weight": 1}, {"from": "Deeppose: Human pose estimation via deep neural networks", "to": "", "weight": 1}, {"from": "SpiderCNN: Deep learning on point sets with parameterized convolutional \ufb01lters", "to": "", "weight": 1}, {"from": "Dominant set clustering and pooling for multi-view 3d object recognition", "to": "", "weight": 1}, {"from": "Dominant set clustering and pooling for multi-view 3d object recognition", "to": "Gift: A real-time and scalable 3D shape search engine", "weight": 1}, {"from": "Dominant set clustering and pooling for multi-view 3d object recognition", "to": "Generative and In Advances in discriminative voxel modeling with convolutional neural networks", "weight": 1}, {"from": "Dominant set clustering and pooling for multi-view 3d object recognition", "to": "Dominant-set clustering: A review", "weight": 1}, {"from": "Dominant set clustering and pooling for multi-view 3d object recognition", "to": "Return of the devil in the details: Delving deep into convolutional nets", "weight": 1}, {"from": "Dominant set clustering and pooling for multi-view 3d object recognition", "to": "Deep residual learning for image recognition", "weight": 1}, {"from": "Dominant set clustering and pooling for multi-view 3d object recognition", "to": "Pairwise Decomposition of Image Sequences for Active Multi-View Recognition", "weight": 1}, {"from": "Dominant set clustering and pooling for multi-view 3d object recognition", "to": "Rotation invari-ant spherical harmonic representation of 3D shape descriptors", "weight": 1}, {"from": "Dominant set clustering and pooling for multi-view 3d object recognition", "to": "Hough transform and 3D SURF for robust three dimensional classi\ufb01cation", "weight": 1}, {"from": "Dominant set clustering and pooling for multi-view 3d object recognition", "to": "View-based 3-D object recognition using shock graphs", "weight": 1}, {"from": "Dominant set clustering and pooling for multi-view 3d object recognition", "to": "Voxnet: A 3D convolutional neural network for real-time object recognition", "weight": 1}, {"from": "Dominant set clustering and pooling for multi-view 3d object recognition", "to": "Visual learning and recognition of 3-D objects from appearance", "weight": 1}, {"from": "Dominant set clustering and pooling for multi-view 3d object recognition", "to": "A new graph-theoretic approach to clustering and segmentation", "weight": 1}, {"from": "Dominant set clustering and pooling for multi-view 3d object recognition", "to": "Dominant sets and pairwise clustering", "weight": 1}, {"from": "Dominant set clustering and pooling for multi-view 3d object recognition", "to": "Volumetric and Multi-View CNNs for Object Classi\ufb01cation on 3D Data", "weight": 1}, {"from": "Dominant set clustering and pooling for multi-view 3d object recognition", "to": "Deep learning 3D shape surfaces using In Proceedings of the European Conference on Computer Vision geometry images", "weight": 1}, {"from": "Dominant set clustering and pooling for multi-view 3d object recognition", "to": "Multi-view convolutional neural networks for 3D shape recognition", "weight": 1}, {"from": "Dominant set clustering and pooling for multi-view 3d object recognition", "to": "Inception-v4, inception-resnet and the impact of residual connections on learning", "weight": 1}, {"from": "Dominant set clustering and pooling for multi-view 3d object recognition", "to": "Learn-ing a probabilistic latent space of object shapes via 3D generative-adversarial modeling", "weight": 1}, {"from": "Dominant set clustering and pooling for multi-view 3d object recognition", "to": "3D shapenets: A deep representation for volumetric shapes", "weight": 1}, {"from": "Octree generating networks: Ef\ufb01cient convolutional architectures for high-resolution 3D outputs", "to": "FAUST: Dataset and evaluation for 3D mesh registration", "weight": 1}, {"from": "Octree generating networks: Ef\ufb01cient convolutional architectures for high-resolution 3D outputs", "to": "SSD: Smooth Signed Distance Surface Reconstruction", "weight": 1}, {"from": "Octree generating networks: Ef\ufb01cient convolutional architectures for high-resolution 3D outputs", "to": "ShapeNet: An Information-Rich 3D Model Repository", "weight": 1}, {"from": "Octree generating networks: Ef\ufb01cient convolutional architectures for high-resolution 3D outputs", "to": "Voxresnet: Deep vox-elwise residual networks for volumetric brain segmentation", "weight": 1}, {"from": "Octree generating networks: Ef\ufb01cient convolutional architectures for high-resolution 3D outputs", "to": "3d-r2n2: A uni\ufb01ed approach for single and multi-view 3d object reconstruction", "weight": 1}, {"from": "Octree generating networks: Ef\ufb01cient convolutional architectures for high-resolution 3D outputs", "to": "Cumulative generation of octree models from range data", "weight": 1}, {"from": "Octree generating networks: Ef\ufb01cient convolutional architectures for high-resolution 3D outputs", "to": "Deep shape from a low number of silhouettes", "weight": 1}, {"from": "Octree generating networks: Ef\ufb01cient convolutional architectures for high-resolution 3D outputs", "to": "P", "weight": 1}, {"from": "Octree generating networks: Ef\ufb01cient convolutional architectures for high-resolution 3D outputs", "to": "Learning to generate chairs", "weight": 1}, {"from": "Octree generating networks: Ef\ufb01cient convolutional architectures for high-resolution 3D outputs", "to": "A point set generation network for 3d object reconstruction from a single image", "weight": 1}, {"from": "Octree generating networks: Ef\ufb01cient convolutional architectures for high-resolution 3D outputs", "to": "Fusion of depth maps with multiple scales", "weight": 1}, {"from": "Octree generating networks: Ef\ufb01cient convolutional architectures for high-resolution 3D outputs", "to": "3d shape induction from 2d views of multiple objects", "weight": 1}, {"from": "Octree generating networks: Ef\ufb01cient convolutional architectures for high-resolution 3D outputs", "to": "Linear octtrees for fast processing of three-dimensional objects", "weight": 1}, {"from": "Octree generating networks: Ef\ufb01cient convolutional architectures for high-resolution 3D outputs", "to": "Learn-ing a predictable and generative vector representation for ob-jects", "weight": 1}, {"from": "Octree generating networks: Ef\ufb01cient convolutional architectures for high-resolution 3D outputs", "to": "Spatially-sparse convolutional neural networks", "weight": 1}, {"from": "Octree generating networks: Ef\ufb01cient convolutional architectures for high-resolution 3D outputs", "to": "Sparse 3d convolutional neural networks", "weight": 1}, {"from": "Octree generating networks: Ef\ufb01cient convolutional architectures for high-resolution 3D outputs", "to": "Deep disentan-gled representations for volumetric reconstruction", "weight": 1}, {"from": "Octree generating networks: Ef\ufb01cient convolutional architectures for high-resolution 3D outputs", "to": "Caffe: Con-volutional architecture for fast feature embedding", "weight": 1}, {"from": "Octree generating networks: Ef\ufb01cient convolutional architectures for high-resolution 3D outputs", "to": "Unsupervised learning of 3d structure from images", "weight": 1}, {"from": "Octree generating networks: Ef\ufb01cient convolutional architectures for high-resolution 3D outputs", "to": "Perceptual losses for real-time style transfer and super-resolution", "weight": 1}, {"from": "Octree generating networks: Ef\ufb01cient convolutional architectures for high-resolution 3D outputs", "to": "Poisson surface reconstruction", "weight": 1}, {"from": "Octree generating networks: Ef\ufb01cient convolutional architectures for high-resolution 3D outputs", "to": "Adam: A method for stochastic optimization", "weight": 1}, {"from": "Octree generating networks: Ef\ufb01cient convolutional architectures for high-resolution 3D outputs", "to": "Geodesic convolutional neural networks on rie-mannian manifolds", "weight": 1}, {"from": "Octree generating networks: Ef\ufb01cient convolutional architectures for high-resolution 3D outputs", "to": "Octree encoding: A new technique for the rep-resentation", "weight": 1}, {"from": "Octree generating networks: Ef\ufb01cient convolutional architectures for high-resolution 3D outputs", "to": "Learning deconvolution net-work for semantic segmentation", "weight": 1}, {"from": "Octree generating networks: Ef\ufb01cient convolutional architectures for high-resolution 3D outputs", "to": "Pointnet: Deep learning on point sets for 3d classi\ufb01cation and segmentation", "weight": 1}, {"from": "Octree generating networks: Ef\ufb01cient convolutional architectures for high-resolution 3D outputs", "to": "Unsupervised repre-sentation learning with deep convolutional generative adver-sarial networks", "weight": 1}, {"from": "Octree generating networks: Ef\ufb01cient convolutional architectures for high-resolution 3D outputs", "to": "Octnet: Learn-ing deep 3d representations at high resolutions", "weight": 1}, {"from": "Octree generating networks: Ef\ufb01cient convolutional architectures for high-resolution 3D outputs", "to": "Vconv-dae: Deep volu-metric shape learning without object labels", "weight": 1}, {"from": "Octree generating networks: Ef\ufb01cient convolutional architectures for high-resolution 3D outputs", "to": "Deep learning 3d shape surfaces using geometry images", "weight": 1}, {"from": "Octree generating networks: Ef\ufb01cient convolutional architectures for high-resolution 3D outputs", "to": "Volumetric 3d mapping in real-time on a cpu", "weight": 1}, {"from": "Octree generating networks: Ef\ufb01cient convolutional architectures for high-resolution 3D outputs", "to": "Multi-view 3d models from single images with a convolutional network", "weight": 1}, {"from": "Octree generating networks: Ef\ufb01cient convolutional architectures for high-resolution 3D outputs", "to": "Learning shape abstractions by assembling volumetric prim-itives", "weight": 1}, {"from": "Octree generating networks: Ef\ufb01cient convolutional architectures for high-resolution 3D outputs", "to": "Global", "weight": 1}, {"from": "Octree generating networks: Ef\ufb01cient convolutional architectures for high-resolution 3D outputs", "to": "Learning a probabilistic latent space of object shapes via 3d generative-adversarial modeling", "weight": 1}, {"from": "Octree generating networks: Ef\ufb01cient convolutional architectures for high-resolution 3D outputs", "to": "3d shapenets: A deep representation for volumetric shapes", "weight": 1}, {"from": "Octree generating networks: Ef\ufb01cient convolutional architectures for high-resolution 3D outputs", "to": "Perspective transformer nets: Learning single-view 3d object reconstruc-tion without 3d supervision", "weight": 1}, {"from": "Octree generating networks: Ef\ufb01cient convolutional architectures for high-resolution 3D outputs", "to": "Syncspeccnn: Syn-chronized spectral CNN for 3d shape segmentation", "weight": 1}, {"from": "Octree generating networks: Ef\ufb01cient convolutional architectures for high-resolution 3D outputs", "to": "Learning semantic deformation \ufb02ows with 3d convolutional networks", "weight": 1}, {"from": "Deepmind lab", "to": "", "weight": 1}, {"from": "ImageNet: A Large-Scale Hierarchical Image Database", "to": "ImageNet: A Large-Scale Hierarchical Image Database", "weight": 1}, {"from": "ImageNet: A Large-Scale Hierarchical Image Database", "to": "WordNet: An Electronic Lexical Database", "weight": 1}, {"from": "ImageNet: A Large-Scale Hierarchical Image Database", "to": "Introduction to MPEG-7: Multimedia New York", "weight": 1}, {"from": "ImageNet: A Large-Scale Hierarchical Image Database", "to": "Color and texture descriptors", "weight": 1}, {"from": "ImageNet: A Large-Scale Hierarchical Image Database", "to": "Mpeg-7 visual motion descriptors", "weight": 1}, {"from": "ImageNet: A Large-Scale Hierarchical Image Database", "to": "Ef\ufb01cient use of mpeg-7 edge histogram descriptor", "weight": 1}, {"from": "Deeply learned face representations are sparse", "to": "Bayesian face revisited: A joint formulation", "weight": 1}, {"from": "Deeply learned face representations are sparse", "to": "Blessing of dimensionality: High-dimensional feature and its ef\ufb01cient compression for face veri\ufb01cation", "weight": 1}, {"from": "Deeply learned face representations are sparse", "to": "Deep attribute In Deep Learning and Unsupervised Feature networks", "weight": 1}, {"from": "Deeply learned face representations are sparse", "to": "Robust classi\ufb01cation using structured sparse representation", "weight": 1}, {"from": "Deeply learned face representations are sparse", "to": "Describing objects by their attributes", "weight": 1}, {"from": "Deeply learned face representations are sparse", "to": "Is that you? Metric learning approaches for face identi\ufb01cation", "weight": 1}, {"from": "Deeply learned face representations are sparse", "to": "Discriminative deep metric In Proc", "weight": 1}, {"from": "Deeply learned face representations are sparse", "to": "Large margin multi-metric learning for face and kinship veri\ufb01cation in the wild", "weight": 1}, {"from": "Deeply learned face representations are sparse", "to": "Large scale strongly supervised ensemble metric learning", "weight": 1}, {"from": "Deeply learned face representations are sparse", "to": "Learning hierarchical representations for face veri\ufb01cation with convo-lutional deep belief networks", "weight": 1}, {"from": "Deeply learned face representations are sparse", "to": "Labeled Faces in the Wild: A database for studying face recognition in unconstrained environments", "weight": 1}, {"from": "Deeply learned face representations are sparse", "to": "Robust and practical face recognition via structured sparsity", "weight": 1}, {"from": "Deeply learned face representations are sparse", "to": "Attribute and simile classi\ufb01ers for face veri\ufb01cation", "weight": 1}, {"from": "Deeply learned face representations are sparse", "to": "Backpropagation applied to handwritten zip code recognition", "weight": 1}, {"from": "Deeply learned face representations are sparse", "to": "Gradient-based learning applied to document recognition", "weight": 1}, {"from": "Deeply learned face representations are sparse", "to": "Eigen-pep for video face recognition", "weight": 1}, {"from": "Deeply learned face representations are sparse", "to": "Sparse representation using nonnegative curds and whey", "weight": 1}, {"from": "Deeply learned face representations are sparse", "to": "Surpassing human-level face veri\ufb01cation performance on LFW with GaussianFace", "weight": 1}, {"from": "Deeply learned face representations are sparse", "to": "A deep sum-product In Proc", "weight": 1}, {"from": "Deeply learned face representations are sparse", "to": "Relative attributes", "weight": 1}, {"from": "Deeply learned face representations are sparse", "to": "Tom-vs-Pete classi\ufb01ers and identity-preserving alignment for face veri\ufb01cation", "weight": 1}, {"from": "Deeply learned face representations are sparse", "to": "Automatic attribute discovery and characterization from noisy web data", "weight": 1}, {"from": "Deeply learned face representations are sparse", "to": "Unconstrained face recognition: Identifying a person of interest from a media collection", "weight": 1}, {"from": "Deeply learned face representations are sparse", "to": "Describing people: Poselet-based attribute classi\ufb01cation", "weight": 1}, {"from": "Deeply learned face representations are sparse", "to": "A practical transfer learning algorithm for face veri\ufb01cation", "weight": 1}, {"from": "Deeply learned face representations are sparse", "to": "Fisher vector faces in the wild", "weight": 1}, {"from": "Deeply learned face representations are sparse", "to": "Hybrid deep learning for face veri\ufb01cation", "weight": 1}, {"from": "Deeply learned face representations are sparse", "to": "Deep learning face representation by joint identi\ufb01cation-veri\ufb01cation", "weight": 1}, {"from": "Deeply learned face representations are sparse", "to": "Deep learning face In Proc", "weight": 1}, {"from": "Deeply learned face representations are sparse", "to": "Multiple one-shots for utilizing class label information", "weight": 1}, {"from": "Deeply learned face representations are sparse", "to": "DeepFace: Closing the gap to human-level performance in face veri\ufb01ca-tion", "weight": 1}, {"from": "Deeply learned face representations are sparse", "to": "Web-Technical report", "weight": 1}, {"from": "Deeply learned face representations are sparse", "to": "Robust boltzmann In Proc", "weight": 1}, {"from": "Deeply learned face representations are sparse", "to": "Neural mechanisms for face perception", "weight": 1}, {"from": "Deeply learned face representations are sparse", "to": "Face recognition in unconstrained videos with matched background similarity", "weight": 1}, {"from": "Deeply learned face representations are sparse", "to": "Robust face recognition via sparse representation", "weight": 1}, {"from": "Deeply learned face representations are sparse", "to": "Gabor feature based sparse represen-tation for face recognition with gabor occlusion dictionary", "weight": 1}, {"from": "Deeply learned face representations are sparse", "to": "An associate-predict model for face recognition", "weight": 1}, {"from": "Deeply learned face representations are sparse", "to": "Sparse representation or collaborative representation: Which helps face recognition? In Proc", "weight": 1}, {"from": "Deeply learned face representations are sparse", "to": "PANDA: Pose aligned networks for deep attribute modeling", "weight": 1}, {"from": "Deeply learned face representations are sparse", "to": "Deep learning identity-preserving face space", "weight": 1}, {"from": "Learning face representation from scratch", "to": "Eigenfaces vs", "weight": 1}, {"from": "Learning face representation from scratch", "to": "Learning deep architectures for AI\u201d", "weight": 1}, {"from": "Learning face representation from scratch", "to": "Bayesian In Computer Vision\u2013 face revisited: A joint formulation\u201d", "weight": 1}, {"from": "Learning face representation from scratch", "to": "Blessing of dimen-sionality: High-dimensional feature and its ef\ufb01cient com-pression for face veri\ufb01cation\u201d", "weight": 1}, {"from": "Learning face representation from scratch", "to": "Improving neural networks by pre-venting co-adaptation of feature detectors\u201d", "weight": 1}, {"from": "Learning face representation from scratch", "to": "Labeled faces in the wild: A database for studying face recognition in unconstrained environments\u201d", "weight": 1}, {"from": "Learning face representation from scratch", "to": "Imagenet classi\ufb01cation with deep convolutional neural networks\u201d", "weight": 1}, {"from": "Learning face representation from scratch", "to": "Attribute and simile classi\ufb01ers for face veri\ufb01cation", "weight": 1}, {"from": "Learning face representation from scratch", "to": "Gradient-based learning applied to document recognition\u201d", "weight": 1}, {"from": "Learning face representation from scratch", "to": "Face recog-nition by exploring information jointly in space", "weight": 1}, {"from": "Learning face representation from scratch", "to": "Learning discriminant face descriptor\u201d", "weight": 1}, {"from": "Learning face representation from scratch", "to": "Illumination in-variant face recognition using near-infrared images\u201d", "weight": 1}, {"from": "Learning face representation from scratch", "to": "Benchmark of large-scale unconstrained face recognition\u201d", "weight": 1}, {"from": "Learning face representation from scratch", "to": "Gabor feature based classi\ufb01ca-tion using the enhanced \ufb01sher linear discriminant model for face recognition\u201d", "weight": 1}, {"from": "Learning face representation from scratch", "to": "Face recognition with decision tree-based local binary patterns\u201d", "weight": 1}, {"from": "Learning face representation from scratch", "to": "Recti\ufb01ed linear units improve restricted boltzmann machines\u201d", "weight": 1}, {"from": "Learning face representation from scratch", "to": "The FERET evaluation methodology for face-recognition algo-IEEE Transactions on Pattern Analysis and Ma-rithms\u201d", "weight": 1}, {"from": "Learning face representation from scratch", "to": "The cmu pose", "weight": 1}, {"from": "Learning face representation from scratch", "to": "Very deep convolutional networks for large-scale image recognition\u201d", "weight": 1}, {"from": "Learning face representation from scratch", "to": "Deep learning face repre-sentation by joint identi\ufb01cation-veri\ufb01cation\u201d", "weight": 1}, {"from": "Learning face representation from scratch", "to": "Going deeper with convolutions\u201d", "weight": 1}, {"from": "Learning face representation from scratch", "to": "Deepface: Closing the gap to human-level performance in face veri\ufb01ca-tion\u201d", "weight": 1}, {"from": "Learning face representation from scratch", "to": "Eigenfaces for recognition\u201d", "weight": 1}, {"from": "Learning face representation from scratch", "to": "Face recognition in unconstrained videos with matched background similarity\u201d", "weight": 1}, {"from": "Learning face representation from scratch", "to": "Towards pose robust face recognition\u201d", "weight": 1}, {"from": "Facenet: A uni\ufb01ed embedding for face recognition and clustering", "to": "", "weight": 1}, {"from": "Predictive and generative neural networks for object functionality", "to": "", "weight": 1}, {"from": "SO-Net: Self-organizing network for point cloud analysis", "to": "Learning representations and generative models for 3d point clouds", "weight": 1}, {"from": "SO-Net: Self-organizing network for point cloud analysis", "to": "Joint 2D-3D-Semantic Data for Indoor Scene Understanding", "weight": 1}, {"from": "SO-Net: Self-organizing network for point cloud analysis", "to": "Gift: A real-time and scalable 3d shape search engine", "weight": 1}, {"from": "SO-Net: Self-organizing network for point cloud analysis", "to": "Multidimensional binary search trees used for associative searching", "weight": 1}, {"from": "SO-Net: Self-organizing network for point cloud analysis", "to": "Learning class-speci\ufb01c descrip-tors for deformable shapes using localized spectral convolu-tional networks", "weight": 1}, {"from": "SO-Net: Self-organizing network for point cloud analysis", "to": "Generative and discriminative voxel modeling with convolutional neural networks", "weight": 1}, {"from": "SO-Net: Self-organizing network for point cloud analysis", "to": "Spectral networks and locally connected networks on graphs", "weight": 1}, {"from": "SO-Net: Self-organizing network for point cloud analysis", "to": "T", "weight": 1}, {"from": "SO-Net: Self-organizing network for point cloud analysis", "to": "Locality-sensitive deconvolution networks with gated fusion for rgb-d indoor semantic segmentation", "weight": 1}, {"from": "SO-Net: Self-organizing network for point cloud analysis", "to": "Multi-column deep neural networks for image classi\ufb01cation", "weight": 1}, {"from": "SO-Net: Self-organizing network for point cloud analysis", "to": "Vote3deep: Fast object detection in 3d point clouds using ef-\ufb01cient convolutional neural networks", "weight": 1}, {"from": "SO-Net: Self-organizing network for point cloud analysis", "to": "Why does unsupervised pre-training help deep learning? Journal of Machine Learning Research", "weight": 1}, {"from": "SO-Net: Self-organizing network for point cloud analysis", "to": "A point set generation network for 3d object reconstruction from a single image", "weight": 1}, {"from": "SO-Net: Self-organizing network for point cloud analysis", "to": "Unsupervised cnn for In single view depth estimation: Geometry to the rescue", "weight": 1}, {"from": "SO-Net: Self-organizing network for point cloud analysis", "to": "Unsuper-vised monocular depth estimation with left-right consistency", "weight": 1}, {"from": "SO-Net: Self-organizing network for point cloud analysis", "to": "Billion-scale similarity search with gpus", "weight": 1}, {"from": "SO-Net: Self-organizing network for point cloud analysis", "to": "Adam: A method for stochastic opti-mization", "weight": 1}, {"from": "SO-Net: Self-organizing network for point cloud analysis", "to": "Escape from cells: Deep kd-networks for the recognition of 3d point cloud models", "weight": 1}, {"from": "SO-Net: Self-organizing network for point cloud analysis", "to": "The self-organizing map", "weight": 1}, {"from": "SO-Net: Self-organizing network for point cloud analysis", "to": "Gradient-based learning applied to document recognition", "weight": 1}, {"from": "SO-Net: Self-organizing network for point cloud analysis", "to": "Fpnn: Field probing neural networks for 3d data", "weight": 1}, {"from": "SO-Net: Self-organizing network for point cloud analysis", "to": "Network in network", "weight": 1}, {"from": "SO-Net: Self-organizing network for point cloud analysis", "to": "Geodesic convolutional neural networks on riemannian man-ifolds", "weight": 1}, {"from": "SO-Net: Self-organizing network for point cloud analysis", "to": "Voxnet: A 3d convolutional neural network for real-time object recognition", "weight": 1}, {"from": "SO-Net: Self-organizing network for point cloud analysis", "to": "Octree encoding: A new technique for the representation", "weight": 1}, {"from": "SO-Net: Self-organizing network for point cloud analysis", "to": "Pointnet: Deep learning on point sets for 3d classi\ufb01cation and segmentation", "weight": 1}, {"from": "SO-Net: Self-organizing network for point cloud analysis", "to": "Volumetric and multi-view cnns for object classi-\ufb01cation on 3d data", "weight": 1}, {"from": "SO-Net: Self-organizing network for point cloud analysis", "to": "Pointnet++: Deep hierarchical feature learning on point sets in a metric space", "weight": 1}, {"from": "SO-Net: Self-organizing network for point cloud analysis", "to": "Deep learning with sets and point clouds", "weight": 1}, {"from": "SO-Net: Self-organizing network for point cloud analysis", "to": "Octnet: Learning deep 3d representations at high resolutions", "weight": 1}, {"from": "SO-Net: Self-organizing network for point cloud analysis", "to": "D", "weight": 1}, {"from": "SO-Net: Self-organizing network for point cloud analysis", "to": "Dynamic edge-conditioned \ufb01lters in convolutional neural networks on graphs", "weight": 1}, {"from": "SO-Net: Self-organizing network for point cloud analysis", "to": "Multi-view convolutional neural networks for 3d shape recognition", "weight": 1}, {"from": "SO-Net: Self-organizing network for point cloud analysis", "to": "Dominant set clustering and pooling for multi-view 3d object recognition", "weight": 1}, {"from": "SO-Net: Self-organizing network for point cloud analysis", "to": "Voting for voting in online point In Robotics: Science and Systems", "weight": 1}, {"from": "SO-Net: Self-organizing network for point cloud analysis", "to": "3d shapenets: A deep representation for volumetric shapes", "weight": 1}, {"from": "SO-Net: Self-organizing network for point cloud analysis", "to": "V", "weight": 1}, {"from": "SO-Net: Self-organizing network for point cloud analysis", "to": "Deep sets", "weight": 1}, {"from": "Virtualhome: Simulating household activities via programs", "to": "", "weight": 1}, {"from": "VoxSegNet: Volumetric CNNs for semantic part segmentation of 3D shapes", "to": "", "weight": 1}, {"from": ": Web-based database for facial expression analysis", "to": "Human computing and machine understanding of human behavior: A survey", "weight": 1}, {"from": ": Web-based database for facial expression analysis", "to": "Machine analysis of facial behaviour: naturalistic and dynamic behaviour", "weight": 1}, {"from": ": Web-based database for facial expression analysis", "to": "", "weight": 1}, {"from": ": Web-based database for facial expression analysis", "to": "Induced disgust", "weight": 1}, {"from": ": Web-based database for facial expression analysis", "to": "Universals and cultural di\ufb00erences in facial expressions of emo-tion", "weight": 1}, {"from": ": Web-based database for facial expression analysis", "to": "Web-based database for facial expression analysis", "weight": 1}, {"from": ": Web-based database for facial expression analysis", "to": "Di\ufb00erentiating between posed and sponta-neous expressions with latent regression bayesian network", "weight": 1}, {"from": ": Web-based database for facial expression analysis", "to": "Convolutional networks and ap-plications in vision", "weight": 1}, {"from": ": Web-based database for facial expression analysis", "to": "Pictures of facial a\ufb00ect", "weight": 1}, {"from": ": Web-based database for facial expression analysis", "to": "A spontaneous micro-expression database: Inducement", "weight": 1}, {"from": ": Web-based database for facial expression analysis", "to": "Exploring human visual system: study to aid the development of automatic facial expression recog-nition framework", "weight": 1}, {"from": ": Web-based database for facial expression analysis", "to": "Automatic a\ufb00ect analysis: From chil-dren to adults", "weight": 1}, {"from": ": Web-based database for facial expression analysis", "to": "Face expression recognition with a 2-channel convolutional neural network", "weight": 1}, {"from": ": Web-based database for facial expression analysis", "to": "Very deep convolutional networks for large-scale image recognition", "weight": 1}, {"from": ": Web-based database for facial expression analysis", "to": "Visualizing and understanding convolutional neural networks", "weight": 1}, {"from": ": Web-based database for facial expression analysis", "to": "Imagenet: A large-scale hierarchical image database", "weight": 1}, {"from": "Coding facial expressions with gabor wavelets", "to": "", "weight": 1}, {"from": "Coding facial expressions with gabor wavelets", "to": "Distortion Invariant Object Recognition in the Dynamic Link Architecture", "weight": 1}, {"from": "Coding facial expressions with gabor wavelets", "to": "Coding Facial Expressions with Gabor Wavelets", "weight": 1}, {"from": "Coding facial expressions with gabor wavelets", "to": "Recognition of facial expression from optical \ufb02ow", "weight": 1}, {"from": "Coding facial expressions with gabor wavelets", "to": "A circumplex model of a\ufb00ect", "weight": 1}, {"from": "Coding facial expressions with gabor wavelets", "to": "Recognizing Human Facial Expressions from Long Image Sequences using Optical Flow", "weight": 1}, {"from": "Coding facial expressions with gabor wavelets", "to": "Comparison between Geometry-based and Gabor-wavelets-based Facial Expression Recognition using Multi-layer Perceptron", "weight": 1}, {"from": "Going deeper in facial expression recognition using deep neural networks", "to": "", "weight": 1}, {"from": "Deep learning using linear support vector machines", "to": "High-performance neural networks for visual object classi\ufb01cation", "weight": 1}, {"from": "Deep learning using linear support vector machines", "to": "", "weight": 1}, {"from": "Deep learning using linear support vector machines", "to": "Large-scale learning with SVM and convolutional for generic object categorization", "weight": 1}, {"from": "Deep learning using linear support vector machines", "to": "What is the best multi-stage architecture for object recognition? In Proc", "weight": 1}, {"from": "Deep learning using linear support vector machines", "to": "Convo-lutional deep belief networks for scalable unsupervised learning of hierarchical representations", "weight": 1}, {"from": "Deep learning using linear support vector machines", "to": "Ssvm: A smooth support vector machine for classi\ufb01cation", "weight": 1}, {"from": "Deep learning using linear support vector machines", "to": "Deep belief networks for phone recognition", "weight": 1}, {"from": "Deep learning using linear support vector machines", "to": ", Di Caro, G", "weight": 1}, {"from": "SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation", "to": "", "weight": 1}, {"from": "Neural photo editing with introspective adversarial networks", "to": "Murphy, , and A", "weight": 1}, {"from": "Neural photo editing with introspective adversarial networks", "to": "Nouri, and E", "weight": 1}, {"from": "Neural photo editing with introspective adversarial networks", "to": "Kr\u00e4henb\u00fchl, and T", "weight": 1}, {"from": "Neural photo editing with introspective adversarial networks", "to": "", "weight": 1}, {"from": "Neural photo editing with introspective adversarial networks", "to": "Pouget-Abadie, Jean, M", "weight": 1}, {"from": "Neural photo editing with introspective adversarial networks", "to": "Weinberger, and L", "weight": 1}, {"from": "Neural photo editing with introspective adversarial networks", "to": "Rezende, and M", "weight": 1}, {"from": "Neural photo editing with introspective adversarial networks", "to": "Dumoulin, and A", "weight": 1}, {"from": "Neural photo editing with introspective adversarial networks", "to": "S\u00f8nderby, and O", "weight": 1}, {"from": "Neural photo editing with introspective adversarial networks", "to": "Wang, and X", "weight": 1}, {"from": "Neural photo editing with introspective adversarial networks", "to": "Metz, and S", "weight": 1}, {"from": "Neural photo editing with introspective adversarial networks", "to": "Bernstein, et al", "weight": 1}, {"from": "Neural photo editing with introspective adversarial networks", "to": "Castillo, and R", "weight": 1}, {"from": "Neural photo editing with introspective adversarial networks", "to": "McClelland, and S", "weight": 1}, {"from": "Neural photo editing with introspective adversarial networks", "to": "Goroshin, and Y", "weight": 1}, {"from": "Neural photo editing with introspective adversarial networks", "to": "Shechtman, and A", "weight": 1}, {"from": "FusionNet: 3D object classi\ufb01cation using multiple data representations", "to": "", "weight": 1}, {"from": "Netadapt: Platform-aware neural network adaptation for mobile applications", "to": "", "weight": 1}, {"from": "Compressing neural networks with the hashing trick", "to": "precision storage for deep learning", "weight": 1}, {"from": "Compressing neural networks with the hashing trick", "to": "", "weight": 1}, {"from": "SeGAN: Segment ing and generating the invisible", "to": "", "weight": 1}, {"from": "Escape from Cells: Deep KdNetworks for The Recognition of 3D Point Cloud Models", "to": "Multidimensional binary search trees used for associative searching", "weight": 1}, {"from": "Escape from Cells: Deep KdNetworks for The Recognition of 3D Point Cloud Models", "to": "Learning class-speci\ufb01c descrip-tors for deformable shapes using localized spectral convolu-tional networks", "weight": 1}, {"from": "Escape from Cells: Deep KdNetworks for The Recognition of 3D Point Cloud Models", "to": "J", "weight": 1}, {"from": "Escape from Cells: Deep KdNetworks for The Recognition of 3D Point Cloud Models", "to": "Generative and discriminative voxel modeling with convolutional neural networks", "weight": 1}, {"from": "Escape from Cells: Deep KdNetworks for The Recognition of 3D Point Cloud Models", "to": "Signature veri\ufb01ca-Interna-tion using a siamese time delay neural network", "weight": 1}, {"from": "Escape from Cells: Deep KdNetworks for The Recognition of 3D Point Cloud Models", "to": "Spectral networks and locally connected networks on graphs", "weight": 1}, {"from": "Escape from Cells: Deep KdNetworks for The Recognition of 3D Point Cloud Models", "to": "T", "weight": 1}, {"from": "Escape from Cells: Deep KdNetworks for The Recognition of 3D Point Cloud Models", "to": "Learning a similarity metric discriminatively", "weight": 1}, {"from": "Escape from Cells: Deep KdNetworks for The Recognition of 3D Point Cloud Models", "to": "volume 55", "weight": 1}, {"from": "Escape from Cells: Deep KdNetworks for The Recognition of 3D Point Cloud Models", "to": "R-trees: A Dynamic Index Structure for Spatial Searching", "weight": 1}, {"from": "Escape from Cells: Deep KdNetworks for The Recognition of 3D Point Cloud Models", "to": "Fusionnet: 3d object classi\ufb01-cation using multiple data representations", "weight": 1}, {"from": "Escape from Cells: Deep KdNetworks for The Recognition of 3D Point Cloud Models", "to": "K", "weight": 1}, {"from": "Escape from Cells: Deep KdNetworks for The Recognition of 3D Point Cloud Models", "to": "TI-POOLING: transformation-invariant pooling for feature learning in convolutional neural networks", "weight": 1}, {"from": "Escape from Cells: Deep KdNetworks for The Recognition of 3D Point Cloud Models", "to": "Gradient-based learning applied to document recognition", "weight": 1}, {"from": "Escape from Cells: Deep KdNetworks for The Recognition of 3D Point Cloud Models", "to": "Fpnn: Field probing neural networks for 3d data", "weight": 1}, {"from": "Escape from Cells: Deep KdNetworks for The Recognition of 3D Point Cloud Models", "to": "Fully convolutional networks for semantic segmentation", "weight": 1}, {"from": "Escape from Cells: Deep KdNetworks for The Recognition of 3D Point Cloud Models", "to": "Voxnet: A 3d convolutional In Proc", "weight": 1}, {"from": "Escape from Cells: Deep KdNetworks for The Recognition of 3D Point Cloud Models", "to": "Octree encoding: A new technique for the representation", "weight": 1}, {"from": "Escape from Cells: Deep KdNetworks for The Recognition of 3D Point Cloud Models", "to": "Pointnet: Deep learning on point sets for 3d classi\ufb01cation and segmentation", "weight": 1}, {"from": "Escape from Cells: Deep KdNetworks for The Recognition of 3D Point Cloud Models", "to": "Volumetric and multi-view cnns for object classi\ufb01-cation on 3d data", "weight": 1}, {"from": "Escape from Cells: Deep KdNetworks for The Recognition of 3D Point Cloud Models", "to": "H", "weight": 1}, {"from": "Escape from Cells: Deep KdNetworks for The Recognition of 3D Point Cloud Models", "to": "Octnet: Learn-ing deep 3d representations at high resolutions", "weight": 1}, {"from": "Escape from Cells: Deep KdNetworks for The Recognition of 3D Point Cloud Models", "to": "U-net: Convolu-tional networks for biomedical image segmentation", "weight": 1}, {"from": "Escape from Cells: Deep KdNetworks for The Recognition of 3D Point Cloud Models", "to": "The design and analysis of spatial data structures", "weight": 1}, {"from": "Escape from Cells: Deep KdNetworks for The Recognition of 3D Point Cloud Models", "to": "F", "weight": 1}, {"from": "Escape from Cells: Deep KdNetworks for The Recognition of 3D Point Cloud Models", "to": "Learning a distance metric from relative comparisons", "weight": 1}, {"from": "Escape from Cells: Deep KdNetworks for The Recognition of 3D Point Cloud Models", "to": "Study for applying computer-generated images to vi-sual simulation", "weight": 1}, {"from": "Escape from Cells: Deep KdNetworks for The Recognition of 3D Point Cloud Models", "to": "Dynamic edge-conditioned \ufb01lters in convolutional neural networks on graphs", "weight": 1}, {"from": "Escape from Cells: Deep KdNetworks for The Recognition of 3D Point Cloud Models", "to": "Parsing nat-ural scenes and natural language with recursive neural net-works", "weight": 1}, {"from": "Escape from Cells: Deep KdNetworks for The Recognition of 3D Point Cloud Models", "to": "Multi-view convolutional neural networks for 3d shape recognition", "weight": 1}, {"from": "Escape from Cells: Deep KdNetworks for The Recognition of 3D Point Cloud Models", "to": "Learning deep embeddings with histogram loss", "weight": 1}, {"from": "Escape from Cells: Deep KdNetworks for The Recognition of 3D Point Cloud Models", "to": "Voting for voting in online point cloud object detection", "weight": 1}, {"from": "Escape from Cells: Deep KdNetworks for The Recognition of 3D Point Cloud Models", "to": "Learning a probabilistic latent space of object shapes via 3d generative-adversarial modeling", "weight": 1}, {"from": "Escape from Cells: Deep KdNetworks for The Recognition of 3D Point Cloud Models", "to": "3d shapenets: A deep representation for volumetric shapes", "weight": 1}, {"from": "Escape from Cells: Deep KdNetworks for The Recognition of 3D Point Cloud Models", "to": "V", "weight": 1}, {"from": "TI-POOLING: transformation-invariant pooling for feature learning in convolutional neural networks", "to": "Signature veri\ufb01ca-Interna-tion using a siamese time delay neural network", "weight": 1}, {"from": "TI-POOLING: transformation-invariant pooling for feature learning in convolutional neural networks", "to": "Invariant scattering convolution net-works", "weight": 1}, {"from": "TI-POOLING: transformation-invariant pooling for feature learning in convolutional neural networks", "to": "An integrated micro-and macroarchitectural analysis of the drosophila brain by computer-assisted serial section electron mi-croscopy", "weight": 1}, {"from": "TI-POOLING: transformation-invariant pooling for feature learning in convolutional neural networks", "to": "Backpropagation: theory", "weight": 1}, {"from": "TI-POOLING: transformation-invariant pooling for feature learning in convolutional neural networks", "to": "Deep neural networks segment neuronal membranes in electron microscopy images", "weight": 1}, {"from": "TI-POOLING: transformation-invariant pooling for feature learning in convolutional neural networks", "to": "Multi-column deep neural networks for image classi\ufb01cation", "weight": 1}, {"from": "TI-POOLING: transformation-invariant pooling for feature learning in convolutional neural networks", "to": "Torch7: A matlab-like environment for machine learning", "weight": 1}, {"from": "TI-POOLING: transformation-invariant pooling for feature learning in convolutional neural networks", "to": "Improving neural networks by pre-venting co-adaptation of feature detectors", "weight": 1}, {"from": "TI-POOLING: transformation-invariant pooling for feature learning in convolutional neural networks", "to": "K", "weight": 1}, {"from": "TI-POOLING: transformation-invariant pooling for feature learning in convolutional neural networks", "to": "Imagenet classi\ufb01cation with deep convolutional neural networks", "weight": 1}, {"from": "TI-POOLING: transformation-invariant pooling for feature learning in convolutional neural networks", "to": "Transformation-invariant convolutional jungles", "weight": 1}, {"from": "TI-POOLING: transformation-invariant pooling for feature learning in convolutional neural networks", "to": "An empirical evaluation of deep architectures on problems with many factors of variation", "weight": 1}, {"from": "TI-POOLING: transformation-invariant pooling for feature learning in convolutional neural networks", "to": "C", "weight": 1}, {"from": "TI-POOLING: transformation-invariant pooling for feature learning in convolutional neural networks", "to": "Convolutional networks for images", "weight": 1}, {"from": "TI-POOLING: transformation-invariant pooling for feature learning in convolutional neural networks", "to": "L", "weight": 1}, {"from": "TI-POOLING: transformation-invariant pooling for feature learning in convolutional neural networks", "to": "Multi-layer feedforward networks with a nonpolynomial activation function can approximate any function", "weight": 1}, {"from": "TI-POOLING: transformation-invariant pooling for feature learning in convolutional neural networks", "to": "Object recognition from local scale-invariant features", "weight": 1}, {"from": "TI-POOLING: transformation-invariant pooling for feature learning in convolutional neural networks", "to": "Lost in quantization: Improving particular object retrieval in large scale image databases", "weight": 1}, {"from": "TI-POOLING: transformation-invariant pooling for feature learning in convolutional neural networks", "to": "Hierarchical models of ob-ject recognition in cortex", "weight": 1}, {"from": "TI-POOLING: transformation-invariant pooling for feature learning in convolutional neural networks", "to": "Segmentation of thin structures in electron micrographs using orientation \ufb01elds", "weight": 1}, {"from": "TI-POOLING: transformation-invariant pooling for feature learning in convolutional neural networks", "to": "Computational tma analysis and cell nucleus classi\ufb01-cation of renal cell carcinoma", "weight": 1}, {"from": "TI-POOLING: transformation-invariant pooling for feature learning in convolutional neural networks", "to": "Learning invariant representations with In Proceedings of the 29th Interna-local transformations", "weight": 1}, {"from": "TI-POOLING: transformation-invariant pooling for feature learning in convolutional neural networks", "to": "Multi-view convolutional neural networks for 3d shape recogni-tion", "weight": 1}, {"from": "TI-POOLING: transformation-invariant pooling for feature learning in convolutional neural networks", "to": "The art of data augmen-tation", "weight": 1}, {"from": "TI-POOLING: transformation-invariant pooling for feature learning in convolutional neural networks", "to": "Deep multiple instance learning for image classi\ufb01cation and auto-annotation", "weight": 1}, {"from": "TI-POOLING: transformation-invariant pooling for feature learning in convolutional neural networks", "to": "Bag-of-visual-words and spatial In Proceedings of extensions for land-use classi\ufb01cation", "weight": 1}, {"from": "TI-POOLING: transformation-invariant pooling for feature learning in convolutional neural networks", "to": "Adadelta: An adaptive learning rate method", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "A", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Fast high-dimensional \ufb01ltering using the permutohedral lattice", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Segnet: A deep convolutional encoder-decoder architecture for image segmentation", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Multi-level adaptive solutions to boundary-value problems", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "A multigrid tutorial", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Scene labeling with lstm recurrent neural networks", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "COCO-Stuff: Thing and stuff classes in context", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Fast", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Xception: Deep learning with depthwise separable convolutions", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "The cityscapes dataset for semantic urban scene understanding", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Convolutional feature masking for joint object and stuff segmentation", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Boxsup: Exploiting bounding boxes to supervise convolutional networks for semantic segmenta-tion", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "R-fcn: Object detection via region-based fully convolutional networks", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "H", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Predicting depth", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "The pascal visual object classes challenge a retrospective", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Multi-level contextual rnns with attention model for scene labeling", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Learning hierarchical features for scene labeling", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Stacked deconvolutional network for semantic segmentation", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Semantic video cnns through representation warping", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Laplacian reconstruction and re\ufb01nement for semantic segmentation", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Fast image scanning with deep max-pooling convolutional neural networks", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Decomposing a scene into geometric and semantically consistent regions", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "The pyramid match kernel: Dis-criminative classi\ufb01cation with sets of image features", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Semantic contours from inverse detectors", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Hyper-columns for object segmentation and \ufb01ne-grained localization", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Spatial pyramid pooling in deep convolutional networks for visual recognition", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Deep residual learning for image recognition", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Multiscale conditional random \ufb01elds for image labeling", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Distilling the knowledge in a neural network", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Long short-term memory", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "A real-time algorithm for signal analysis with the help of the wavelet transform", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Speed/accuracy trade-offs for modern convolutional object detectors", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Gated feedback re\ufb01nement network for dense image labeling", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Fusionseg: Learn-ing to combine motion and appearance for fully automatic segmention of generic objects in videos", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Learning sparse high dimensional \ufb01lters: Image \ufb01ltering", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Video scene parsing with predictive feature learning", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "P", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Recurrent scene parsing with per-spective understanding in the loop", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Ef\ufb01cient inference in fully connected crfs with gaussian edge potentials", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "S", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Imagenet classi\ufb01cation with deep convolutional neural networks", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Associative In hierarchical crfs for object class image segmentation", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Beyond bags of fea-tures: Spatial pyramid matching for recognizing natural scene categories", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Backpropagation applied to handwritten zip code recognition", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Foveanet: Perspective-aware urban scene parsing", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Not all pixels are equal: Dif\ufb01culty-aware semantic segmentation via deep layer cascade", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Semantic object parsing with local-global long short-term memory", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Re\ufb01nenet: Multi-path re\ufb01nement networks with identity mappings for high-resolution semantic segmentation", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "C", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Parsenet: Looking wider to see better", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Semantic image segmentation via deep parsing network", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Fully convolutional networks for semantic segmentation", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Deep dual learning for semantic image segmentation", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Feed-forward semantic segmentation with zoom-out features", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "The role of context for object detection and semantic segmentation in the wild", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Learning deconvolution net-work for semantic segmentation", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Weakly-and semi-supervised learning of a dcnn for semantic image segmentation", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Modeling local and global deformations in deep learning: Epitomic convolution", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Multigrid geometric active contour models", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Large kernel matters\u2013improve semantic segmentation by global convolu-tional network", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Recurrent convolutional neural networks for scene labeling", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Full-resolution residual networks for semantic segmentation in street scenes", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "U-net: Convolutional networks for biomedical image segmentation", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "ImageNet Large Scale Visual Recognition Challenge", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Fully connected deep struc-tured networks", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Overfeat: Integrated recognition", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Semantic segmentation via structured patch prediction", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Textonboost for image understanding: Multi-class object recognition and segmentation by jointly modeling texture", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Be-yond skip connections: Top-down modulation for object de-tection", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Very deep convolutional networks for large-scale image recognition", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Revisiting unreasonable effectiveness of data in deep learning era", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Mixed context networks for semantic segmentation", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Image analysis using multigrid relaxation methods", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Gaus-sian conditional random \ufb01eld network for semantic segmenta-tion", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Learning object inter-actions and descriptions for semantic image segmentation", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Understanding convolution for semantic segmen-tation", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Bridging category-level and instance-level semantic image segmen-tation", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Wider or deeper: Revisiting the resnet model for visual recognition", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Zoom better to see clearer: Huamn part segmentation with auto zoom net", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Combining the best of convolutional layers and recurrent layers: A hybrid network for semantic segmentation", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Describing the scene as a whole: Joint object detection", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Multi-scale context aggregation by dilated convolutions", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Wide residual networks", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Adaptive deconvo-lutional networks for mid and high level feature learning", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Global-residual and local-boundary re\ufb01nement networks for rectifying scene parsing predictions", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Scale-adaptive convolutions for scene parsing", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Pyramid scene parsing network", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Conditional random \ufb01elds as recurrent neural networks", "weight": 1}, {"from": "Rethinking atrous convolution for semantic image segmentation", "to": "Scene parsing through ade20k dataset", "weight": 1}, {"from": "Maximum-likelihood augmented discrete generative adversarial networks", "to": "", "weight": 1}, {"from": "Xception: Deep learning with depthwise separa ble convolutions", "to": "Tensor-Flow: Large-scale machine learning on heterogeneous sys-tems", "weight": 1}, {"from": "Xception: Deep learning with depthwise separa ble convolutions", "to": "Keras", "weight": 1}, {"from": "Xception: Deep learning with depthwise separa ble convolutions", "to": "Learning visual representations at scale", "weight": 1}, {"from": "Xception: Deep learning with depthwise separa ble convolutions", "to": "Factorized convolutional neural networks", "weight": 1}, {"from": "Xception: Deep learning with depthwise separa ble convolutions", "to": "Visualizing and understanding convolutional networks", "weight": 1}, {"from": "Xception: Deep learning with depthwise separa ble convolutions", "to": "Deep residual learning for image recognition", "weight": 1}, {"from": "Xception: Deep learning with depthwise separa ble convolutions", "to": "Distilling the knowledge in a neural network", "weight": 1}, {"from": "Xception: Deep learning with depthwise separa ble convolutions", "to": "Mobilenets: Ef\ufb01cient convolutional neural net-works for mobile vision applications", "weight": 1}, {"from": "Xception: Deep learning with depthwise separa ble convolutions", "to": "Flattened convolutional neural networks for feedforward acceleration", "weight": 1}, {"from": "Xception: Deep learning with depthwise separa ble convolutions", "to": "Imagenet classi\ufb01cation with deep convolutional neural networks", "weight": 1}, {"from": "Xception: Deep learning with depthwise separa ble convolutions", "to": "L", "weight": 1}, {"from": "Xception: Deep learning with depthwise separa ble convolutions", "to": "Network in network", "weight": 1}, {"from": "Xception: Deep learning with depthwise separa ble convolutions", "to": "Simplifying ConvNets for Fast Learning", "weight": 1}, {"from": "Xception: Deep learning with depthwise separa ble convolutions", "to": "Acceleration of stochas-tic approximation by averaging", "weight": 1}, {"from": "Xception: Deep learning with depthwise separa ble convolutions", "to": "J", "weight": 1}, {"from": "Xception: Deep learning with depthwise separa ble convolutions", "to": "Rigid-motion scattering for image classi\ufb01cation", "weight": 1}, {"from": "Xception: Deep learning with depthwise separa ble convolutions", "to": "Rotation", "weight": 1}, {"from": "Xception: Deep learning with depthwise separa ble convolutions", "to": "Tf-slim", "weight": 1}, {"from": "Xception: Deep learning with depthwise separa ble convolutions", "to": "Very deep convolutional networks for large-scale image recognition", "weight": 1}, {"from": "Xception: Deep learning with depthwise separa ble convolutions", "to": "Inception-v4", "weight": 1}, {"from": "Xception: Deep learning with depthwise separa ble convolutions", "to": "Going deeper with convolutions", "weight": 1}, {"from": "Xception: Deep learning with depthwise separa ble convolutions", "to": "Rethinking the inception architecture for computer vision", "weight": 1}, {"from": "Hashing with binary autoencoders", "to": "", "weight": 1}, {"from": "Structure inference machines: Recurrent neural networks for analyzing relations in group activity recognition", "to": "", "weight": 1}, {"from": "Unrolled generative adversarial networks", "to": "", "weight": 1}, {"from": ": Fast point feature histograms (fpfh) for 3d registration", "to": "", "weight": 1}, {"from": "Conditional generative adversarial nets", "to": "", "weight": 1}, {"from": "Ai2-thor: An interactive 3d environment for visual ai", "to": "Deepmind lab", "weight": 1}, {"from": "Ai2-thor: An interactive 3d environment for visual ai", "to": "The arcade learning environment: An evaluation platform for general agents", "weight": 1}, {"from": "Ai2-thor: An interactive 3d environment for visual ai", "to": "Home: a household multimodal environment", "weight": 1}, {"from": "Ai2-thor: An interactive 3d environment for visual ai", "to": "Matterport3d: Learning from rgb-d data in indoor environments", "weight": 1}, {"from": "Ai2-thor: An interactive 3d environment for visual ai", "to": "G", "weight": 1}, {"from": "Ai2-thor: An interactive 3d environment for visual ai", "to": "SeGAN: Segment-ing and generating the invisible", "weight": 1}, {"from": "Ai2-thor: An interactive 3d environment for visual ai", "to": "Virtual worlds as proxy for multi-object tracking analysis", "weight": 1}, {"from": "Ai2-thor: An interactive 3d environment for visual ai", "to": "IQA: Visual question answering in interac-tive environments", "weight": 1}, {"from": "Ai2-thor: An interactive 3d environment for visual ai", "to": "Scenenet: An annotated model generator for indoor scene understand-ing", "weight": 1}, {"from": "Ai2-thor: An interactive 3d environment for visual ai", "to": "The malmo platform for arti\ufb01cial intelligence experimentation", "weight": 1}, {"from": "Ai2-thor: An interactive 3d environment for visual ai", "to": "Vizdoom: A doom-based ai research platform In IEEE Conference on for visual reinforcement learning", "weight": 1}, {"from": "Ai2-thor: An interactive 3d environment for visual ai", "to": "Learning physical intu-ition of block towers by example", "weight": 1}, {"from": "Ai2-thor: An interactive 3d environment for visual ai", "to": "Scenenet RGB-D: 5m photorealistic images of synthetic in-door trajectories with ground truth", "weight": 1}, {"from": "Ai2-thor: An interactive 3d environment for visual ai", "to": "The SYNTHIA Dataset: A large collection of synthetic images for semantic segmentation of urban scenes", "weight": 1}, {"from": "Ai2-thor: An interactive 3d environment for visual ai", "to": "MINOS: Multimodal indoor simulator for navi-gation in complex environments", "weight": 1}, {"from": "Ai2-thor: An interactive 3d environment for visual ai", "to": "Habitat: A platform for embodied ai research", "weight": 1}, {"from": "Ai2-thor: An interactive 3d environment for visual ai", "to": "Semantic scene completion from a single depth image", "weight": 1}, {"from": "Ai2-thor: An interactive 3d environment for visual ai", "to": "Torchcraft: a library for machine learning research on real-time strategy games", "weight": 1}, {"from": "Ai2-thor: An interactive 3d environment for visual ai", "to": "ELF: an extensive", "weight": 1}, {"from": "Ai2-thor: An interactive 3d environment for visual ai", "to": "Learning to learn how to learn: Self-adaptive visual navigation using meta-learning", "weight": 1}, {"from": "Ai2-thor: An interactive 3d environment for visual ai", "to": "TORCS", "weight": 1}, {"from": "Ai2-thor: An interactive 3d environment for visual ai", "to": "In ICLR", "weight": 1}, {"from": "Ai2-thor: An interactive 3d environment for visual ai", "to": "Visual semantic planning using deep successor representations", "weight": 1}, {"from": "Ai2-thor: An interactive 3d environment for visual ai", "to": "Target-driven visual navigation in in-In ICRA", "weight": 1}, {"from": "Home: a household multimodal environment", "to": "Fostering mathematical thinking through playful learning", "weight": 1}, {"from": "Home: a household multimodal environment", "to": "Object perception and object naming in early development", "weight": 1}, {"from": "Home: a household multimodal environment", "to": "Infants rapidly learn word-referent mappings via cross-situational statistics", "weight": 1}, {"from": "Home: a household multimodal environment", "to": "", "weight": 1}, {"from": "Home: a household multimodal environment", "to": "Zero-shot task generalization with multi-task deep reinforcement learning", "weight": 1}, {"from": "Home: a household multimodal environment", "to": "Guesswhat?! visual object discovery through multi-modal dialogue", "weight": 1}, {"from": "Home: a household multimodal environment", "to": "Virtual embodiment: A scalable long-term strategy for arti\ufb01cial intelligence research", "weight": 1}, {"from": "Home: a household multimodal environment", "to": "Imagenet classi\ufb01cation with deep convolutional neural networks", "weight": 1}, {"from": "Home: a household multimodal environment", "to": "Distributed representations of words and phrases and their compositionality", "weight": 1}, {"from": "Home: a household multimodal environment", "to": "Vqa: Visual question answering", "weight": 1}, {"from": "Home: a household multimodal environment", "to": "The arcade learning environment: An evaluation platform for general agents", "weight": 1}, {"from": "Home: a household multimodal environment", "to": "Gated-attention architectures for task-oriented language grounding", "weight": 1}, {"from": "Home: a household multimodal environment", "to": "Word and object", "weight": 1}, {"from": "Home: a household multimodal environment", "to": "Reinforcement learning with unsupervised auxiliary tasks", "weight": 1}, {"from": "Home: a household multimodal environment", "to": "ImageNet Large Scale Visual Recognition Challenge", "weight": 1}, {"from": "Home: a household multimodal environment", "to": "Domain randomization for transferring deep neural networks from simulation to the real world", "weight": 1}, {"from": "Home: a household multimodal environment", "to": "Semantic scene completion from a single depth image", "weight": 1}, {"from": "Home: a household multimodal environment", "to": "Accelerated beam tracing algorithm", "weight": 1}, {"from": "Home: a household multimodal environment", "to": "Openai gym", "weight": 1}, {"from": "Home: a household multimodal environment", "to": "The malmo platform for arti\ufb01cial intelligence experimentation", "weight": 1}, {"from": "Home: a household multimodal environment", "to": "ViZDoom: A Doom-based AI research platform for visual reinforcement learning", "weight": 1}, {"from": "Home: a household multimodal environment", "to": "Target-driven Visual Navigation in Indoor Scenes using Deep Reinforcement Learning", "weight": 1}, {"from": "Home: a household multimodal environment", "to": "Vision-and-language navigation: Interpreting visually-grounded navigation instructions in real environments", "weight": 1}, {"from": "Home: a household multimodal environment", "to": "Example-based synthesis of 3d object arrangements", "weight": 1}, {"from": "Home: a household multimodal environment", "to": "Matterport3d: Learning from rgb-d data in indoor environments", "weight": 1}, {"from": "Home: a household multimodal environment", "to": "Scenenet: An annotated model generator for indoor scene understanding", "weight": 1}, {"from": "Home: a household multimodal environment", "to": "The panda3d graphics engine", "weight": 1}, {"from": "Virtual worlds as proxy for multi-object tracking analysis", "to": "Evaluating Multi-ple Object Tracking Performance: The CLEAR MOT Met-rics", "weight": 1}, {"from": "Virtual worlds as proxy for multi-object tracking analysis", "to": "Teaching 3d geometry to deformable part models", "weight": 1}, {"from": "Virtual worlds as proxy for multi-object tracking analysis", "to": "Data-driven scene understanding from 3d models", "weight": 1}, {"from": "Virtual worlds as proxy for multi-object tracking analysis", "to": "", "weight": 1}, {"from": "Virtual worlds as proxy for multi-object tracking analysis", "to": "Motion capture of hands in action using discriminative salient points", "weight": 1}, {"from": "Virtual worlds as proxy for multi-object tracking analysis", "to": "Simulation as an engine of physical scene understand-ing", "weight": 1}, {"from": "Virtual worlds as proxy for multi-object tracking analysis", "to": "Back to the future: Learning shape models from 3d cad data", "weight": 1}, {"from": "Virtual worlds as proxy for multi-object tracking analysis", "to": "Learning scene-speci\ufb01c pedestrian detectors with-out real data", "weight": 1}, {"from": "Virtual worlds as proxy for multi-object tracking analysis", "to": "Ovvv: Using virtual worlds to design and evaluate surveil-lance systems", "weight": 1}, {"from": "Virtual worlds as proxy for multi-object tracking analysis", "to": "A naturalistic open source movie for opti-cal \ufb02ow evaluation", "weight": 1}, {"from": "Virtual worlds as proxy for multi-object tracking analysis", "to": "Global data as-sociation for multi-object tracking using network \ufb02ows", "weight": 1}, {"from": "Habitat: A platform for embodied ai research", "to": "A dataset for developing and benchmarking active vision", "weight": 1}, {"from": "Habitat: A platform for embodied ai research", "to": "On evaluation of embodied naviga-tion agents", "weight": 1}, {"from": "Habitat: A platform for embodied ai research", "to": "Vision-and-language navigation: In-terpreting visually-grounded navigation instructions in real environments", "weight": 1}, {"from": "Habitat: A platform for embodied ai research", "to": "VQA: Visual Question Answering", "weight": 1}, {"from": "Habitat: A platform for embodied ai research", "to": "3D semantic parsing of large-scale indoor spaces", "weight": 1}, {"from": "Habitat: A platform for embodied ai research", "to": "Learning to drive from simulation without real world labels", "weight": 1}, {"from": "Habitat: A platform for embodied ai research", "to": "HoME: A household multimodal environment", "weight": 1}, {"from": "Habitat: A platform for embodied ai research", "to": "Matterport3D: Learning from RGB-D data in indoor environments", "weight": 1}, {"from": "Habitat: A platform for embodied ai research", "to": "Embodied Question Answer-ing", "weight": 1}, {"from": "Habitat: A platform for embodied ai research", "to": "", "weight": 1}, {"from": "Habitat: A platform for embodied ai research", "to": "Cognitive mapping and planning for visual navigation", "weight": 1}, {"from": "Habitat: A platform for embodied ai research", "to": "Deep residual learning for image recognition", "weight": 1}, {"from": "Habitat: A platform for embodied ai research", "to": "Learning agile and dynamic motor skills for legged robots", "weight": 1}, {"from": "Habitat: A platform for embodied ai research", "to": "To learn or not to learn: Analyzing the role of learning for navigation in virtual envi-ronments", "weight": 1}, {"from": "Habitat: A platform for embodied ai research", "to": "AI2-THOR: An interactive 3D environment for visual AI", "weight": 1}, {"from": "Habitat: A platform for embodied ai research", "to": "Benchmarking classic and learned navigation in complex 3D environments", "weight": 1}, {"from": "Habitat: A platform for embodied ai research", "to": "ORB-SLAM2: An open-source SLAM system for monocular, stereo and RGB-D cameras", "weight": 1}, {"from": "Habitat: A platform for embodied ai research", "to": "Pyrobot: An open-source robotics framework for re-search and benchmarking", "weight": 1}, {"from": "Habitat: A platform for embodied ai research", "to": "VirtualHome: Sim-ulating household activities via programs", "weight": 1}, {"from": "Habitat: A platform for embodied ai research", "to": "MINOS: Mul-timodal indoor simulator for navigation in complex environ-ments", "weight": 1}, {"from": "Habitat: A platform for embodied ai research", "to": "Proximal policy optimization algo-rithms", "weight": 1}, {"from": "Habitat: A platform for embodied ai research", "to": "The development of em-bodied cognition: Six lessons from babies", "weight": 1}, {"from": "Habitat: A platform for embodied ai research", "to": "Semantic scene comple-tion from a single depth image", "weight": 1}, {"from": "Habitat: A platform for embodied ai research", "to": "The Replica dataset: A digital replica of indoor spaces", "weight": 1}, {"from": "Habitat: A platform for embodied ai research", "to": "Building generalizable agents with a realistic and rich 3D environment", "weight": 1}, {"from": "Habitat: A platform for embodied ai research", "to": "Gibson env: Real-world perception for embodied agents", "weight": 1}, {"from": "Habitat: A platform for embodied ai research", "to": "CHALET: Cornell house agent learning environment", "weight": 1}, {"from": "Torchcraft: a library for machine learning research on real-time strategy games", "to": "", "weight": 1}, {"from": "Torchcraft: a library for machine learning research on real-time strategy games", "to": "Starcraft brood war data mining", "weight": 1}, {"from": "ELF: an extensive", "to": "Re-International inforcement learning through asynchronous advantage actor-critic on a gpu", "weight": 1}, {"from": "ELF: an extensive", "to": "", "weight": 1}, {"from": "ELF: an extensive", "to": "A survey of monte carlo tree search methods", "weight": 1}, {"from": "ELF: an extensive", "to": "On the development of a free rts game engine", "weight": 1}, {"from": "ELF: an extensive", "to": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "weight": 1}, {"from": "ELF: an extensive", "to": "Vizdoom: A doom-based ai research platform for visual reinforcement learning", "weight": 1}, {"from": "ELF: an extensive", "to": "Playing fps games with deep reinforcement learning", "weight": 1}, {"from": "ELF: an extensive", "to": "Recti\ufb01er nonlinearities improve neural network acoustic models", "weight": 1}, {"from": "ELF: an extensive", "to": "Learning to navigate in complex environments", "weight": 1}, {"from": "ELF: an extensive", "to": "Asynchronous methods for deep reinforcement learning", "weight": 1}, {"from": "ELF: an extensive", "to": "pages 58\u201364", "weight": 1}, {"from": "ELF: an extensive", "to": "Better computer go player with neural network and long-term prediction", "weight": 1}, {"from": "ELF: an extensive", "to": "Training agent for \ufb01rst-person shooter game with actor-critic curriculum learning", "weight": 1}, {"from": "Mxnet: A \ufb02exible and ef\ufb01cient machine learning library for heterogeneous distributed systems", "to": "Theano: new features and speed improvements", "weight": 1}, {"from": "Mxnet: A \ufb02exible and ef\ufb01cient machine learning library for heterogeneous distributed systems", "to": "", "weight": 1}, {"from": "Mxnet: A \ufb02exible and ef\ufb01cient machine learning library for heterogeneous distributed systems", "to": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "weight": 1}, {"from": "Mxnet: A \ufb02exible and ef\ufb01cient machine learning library for heterogeneous distributed systems", "to": "Purine: A bi-graph based deep learning framework", "weight": 1}, {"from": "Mxnet: A \ufb02exible and ef\ufb01cient machine learning library for heterogeneous distributed systems", "to": "ImageNet Large Scale Visual Recognition Challenge", "weight": 1}, {"from": "Progressive growing of gans for improved quality", "to": "", "weight": 1}, {"from": "Factors of transferability for a generic convnet representation", "to": "", "weight": 1}, {"from": "Lcnn: Lookup-based convolutional neural network", "to": "", "weight": 1}, {"from": "Deep affect prediction in-the-wild: Aff-wild database and challenge", "to": ": Fully automatic facial action recognition in spon-taneous behavior", "weight": 1}, {"from": "Deep affect prediction in-the-wild: Aff-wild database and challenge", "to": ": Im-agenet: A large-scale hierarchical image database", "weight": 1}, {"from": "Deep affect prediction in-the-wild: Aff-wild database and challenge", "to": "", "weight": 1}, {"from": "Deep affect prediction in-the-wild: Aff-wild database and challenge", "to": ": Web-based database for facial expression analysis", "weight": 1}, {"from": "Deep affect prediction in-the-wild: Aff-wild database and challenge", "to": ": A high-resolution In: Automatic Face \u0026 3d dynamic facial expression database", "weight": 1}, {"from": "Deep affect prediction in-the-wild: Aff-wild database and challenge", "to": ": A 3d facial ex-pression database for facial behavior research", "weight": 1}, {"from": "Convolutional neural networks at constrained time cost", "to": "Return of the devil in the details: Delving deep into convo-lutional nets", "weight": 1}, {"from": "Convolutional neural networks at constrained time cost", "to": "Multi-column In CVPR", "weight": 1}, {"from": "Convolutional neural networks at constrained time cost", "to": "Imagenet: A large-scale hierarchical image database", "weight": 1}, {"from": "Convolutional neural networks at constrained time cost", "to": "Exploiting linear structure within convolutional networks for ef\ufb01cient evaluation", "weight": 1}, {"from": "Convolutional neural networks at constrained time cost", "to": "Understanding deep architectures using a recursive convolutional network", "weight": 1}, {"from": "Convolutional neural networks at constrained time cost", "to": "Rich fea-ture hierarchies for accurate object detection and semantic segmentation", "weight": 1}, {"from": "Convolutional neural networks at constrained time cost", "to": "Understanding the dif\ufb01culty of training deep feedforward neural networks", "weight": 1}, {"from": "Convolutional neural networks at constrained time cost", "to": "Simul-taneous detection and segmentation", "weight": 1}, {"from": "Convolutional neural networks at constrained time cost", "to": "Spatial pyramid pool-ing in deep convolutional networks for visual recognition", "weight": 1}, {"from": "Convolutional neural networks at constrained time cost", "to": "Some improvements on deep convolutional neural network based image classi\ufb01cation", "weight": 1}, {"from": "Convolutional neural networks at constrained time cost", "to": "Speeding up convolutional neural networks with low rank expansions", "weight": 1}, {"from": "Convolutional neural networks at constrained time cost", "to": "Caffe: Convolutional architecture for fast feature embedding", "weight": 1}, {"from": "Convolutional neural networks at constrained time cost", "to": "One weird trick for parallelizing convolu-tional neural networks", "weight": 1}, {"from": "Convolutional neural networks at constrained time cost", "to": "Imagenet clas-si\ufb01cation with deep convolutional neural networks", "weight": 1}, {"from": "Convolutional neural networks at constrained time cost", "to": "Backpropagation applied to handwritten zip code recognition", "weight": 1}, {"from": "Convolutional neural networks at constrained time cost", "to": "Network in network", "weight": 1}, {"from": "Convolutional neural networks at constrained time cost", "to": "Simplifying convnets for fast learning", "weight": 1}, {"from": "Convolutional neural networks at constrained time cost", "to": "Recti\ufb01ed linear units improve In ICML", "weight": 1}, {"from": "Convolutional neural networks at constrained time cost", "to": "Cnn features off-the-shelf: An astounding baseline for recog-niton", "weight": 1}, {"from": "Convolutional neural networks at constrained time cost", "to": "J", "weight": 1}, {"from": "Convolutional neural networks at constrained time cost", "to": "Overfeat: Integrated recognition", "weight": 1}, {"from": "Convolutional neural networks at constrained time cost", "to": "Very deep con-large-scale image recognition", "weight": 1}, {"from": "Convolutional neural networks at constrained time cost", "to": "Going deeper with convolutions", "weight": 1}, {"from": "Convolutional neural networks at constrained time cost", "to": "Visualizing and understanding convolutional neural networks", "weight": 1}, {"from": "Deep semantic ranking based hashing for multi-label image retrieval", "to": "Adapting In Proc", "weight": 1}, {"from": "Deep semantic ranking based hashing for multi-label image retrieval", "to": "Decaf: A deep convolutional ac-tivation feature for generic visual recognition", "weight": 1}, {"from": "Deep semantic ranking based hashing for multi-label image retrieval", "to": "Devise: A deep visual-semantic embedding model", "weight": 1}, {"from": "Deep semantic ranking based hashing for multi-label image retrieval", "to": "Similarity search in high dimensions via hashing", "weight": 1}, {"from": "Deep semantic ranking based hashing for multi-label image retrieval", "to": "Rich feature hierarchies for accurate object detection and seman-In Proc", "weight": 1}, {"from": "Deep semantic ranking based hashing for multi-label image retrieval", "to": "Deep con-volutional ranking for multilabel image annotation", "weight": 1}, {"from": "Deep semantic ranking based hashing for multi-label image retrieval", "to": "Itera-tive quantization: a procrustean approach to learning binary codes for large-scale image retrieval", "weight": 1}, {"from": "Deep semantic ranking based hashing for multi-label image retrieval", "to": "The mir \ufb02ickr retrieval eval-uation", "weight": 1}, {"from": "Deep semantic ranking based hashing for multi-label image retrieval", "to": "Ir evaluation methods for re-In Proc", "weight": 1}, {"from": "Deep semantic ranking based hashing for multi-label image retrieval", "to": "Optimizing search engines using clickthrough data", "weight": 1}, {"from": "Deep semantic ranking based hashing for multi-label image retrieval", "to": "One weird trick for parallelizing convolu-tional neural networks", "weight": 1}, {"from": "Deep semantic ranking based hashing for multi-label image retrieval", "to": "classi\ufb01cation with deep convolutional neural networks", "weight": 1}, {"from": "Deep semantic ranking based hashing for multi-label image retrieval", "to": "Learning to hash with binary recon-In Proc", "weight": 1}, {"from": "Deep semantic ranking based hashing for multi-label image retrieval", "to": "Learning hash functions using column generation", "weight": 1}, {"from": "Deep semantic ranking based hashing for multi-label image retrieval", "to": "Optimizing ranking measures for compact binary code learning", "weight": 1}, {"from": "Deep semantic ranking based hashing for multi-label image retrieval", "to": "Supervised hashing with kernels", "weight": 1}, {"from": "Deep semantic ranking based hashing for multi-label image retrieval", "to": "Object recognition from local scale-invariant features", "weight": 1}, {"from": "Deep semantic ranking based hashing for multi-label image retrieval", "to": "Minimal loss hashing for com-pact binary codes", "weight": 1}, {"from": "Deep semantic ranking based hashing for multi-label image retrieval", "to": "Hamming distance metric learning", "weight": 1}, {"from": "Deep semantic ranking based hashing for multi-label image retrieval", "to": "Modeling the shape of the scene: A holistic representation of the spatial envelope", "weight": 1}, {"from": "Deep semantic ranking based hashing for multi-label image retrieval", "to": "Imagenet large scale visual recog-nition challenge", "weight": 1}, {"from": "Deep semantic ranking based hashing for multi-label image retrieval", "to": "Semantic hashing", "weight": 1}, {"from": "Deep semantic ranking based hashing for multi-label image retrieval", "to": "Fast pose In Proc", "weight": 1}, {"from": "Deep semantic ranking based hashing for multi-label image retrieval", "to": "Multimodal learning with deep boltzmann machines", "weight": 1}, {"from": "Deep semantic ranking based hashing for multi-label image retrieval", "to": "Deep learning face represen-tation from predicting 10", "weight": 1}, {"from": "Deep semantic ranking based hashing for multi-label image retrieval", "to": "Small codes and large image databases for recognition", "weight": 1}, {"from": "Deep semantic ranking based hashing for multi-label image retrieval", "to": "Semi-supervised hash-ing for scalable image retrieval", "weight": 1}, {"from": "Deep semantic ranking based hashing for multi-label image retrieval", "to": "Learning hash codes with listwise supervision", "weight": 1}, {"from": "Deep semantic ranking based hashing for multi-label image retrieval", "to": "Learning \ufb01ne-grained image similarity with deep ranking", "weight": 1}, {"from": "Deep semantic ranking based hashing for multi-label image retrieval", "to": "Order preserving hashing for approximate nearest neighbor search", "weight": 1}, {"from": "Deep semantic ranking based hashing for multi-label image retrieval", "to": "Spectral hashing", "weight": 1}, {"from": "Deep semantic ranking based hashing for multi-label image retrieval", "to": "Supervised hash-ing for image retrieval via image representation learning", "weight": 1}, {"from": "Overfeat: Integrated recognition, localization and detection using convolutional networks", "to": "", "weight": 1}, {"from": "Fast supervised hashing with decision trees for high-dimensional data", "to": "", "weight": 1}, {"from": "Fully Convolutional Networks for Semantic Segmentation", "to": "", "weight": 1}, {"from": "Deep Sliding Shapes for amodal 3D object detection in RGB-D images", "to": "Multiscale combinatorial grouping", "weight": 1}, {"from": "Deep Sliding Shapes for amodal 3D object detection in RGB-D images", "to": "Unsupervised feature learning for RGB-D based object recognition", "weight": 1}, {"from": "Deep Sliding Shapes for amodal 3D object detection in RGB-D images", "to": "Learning hierarchical sparse features for rgb-(d) object recognition", "weight": 1}, {"from": "Deep Sliding Shapes for amodal 3D object detection in RGB-D images", "to": "3d object proposals for accurate object class detection", "weight": 1}, {"from": "Deep Sliding Shapes for amodal 3D object detection in RGB-D images", "to": "3D deep shape descriptor", "weight": 1}, {"from": "Deep Sliding Shapes for amodal 3D object detection in RGB-D images", "to": "Fast R-CNN", "weight": 1}, {"from": "Deep Sliding Shapes for amodal 3D object detection in RGB-D images", "to": "Rich fea-ture hierarchies for accurate object detection and semantic segmentation", "weight": 1}, {"from": "Deep Sliding Shapes for amodal 3D object detection in RGB-D images", "to": "Perceptual organization In and recognition of indoor scenes from RGB-D images", "weight": 1}, {"from": "Deep Sliding Shapes for amodal 3D object detection in RGB-D images", "to": "Align-In ing 3D models to RGB-D images of cluttered scenes", "weight": 1}, {"from": "Deep Sliding Shapes for amodal 3D object detection in RGB-D images", "to": "Learning rich features from RGB-D images for object detection and segmentation", "weight": 1}, {"from": "Deep Sliding Shapes for amodal 3D object detection in RGB-D images", "to": "Cross modal distillation for supervision transfer", "weight": 1}, {"from": "Deep Sliding Shapes for amodal 3D object detection in RGB-D images", "to": "Analysis and syn-thesis of 3D shape families via deep-learned generative mod-els of surfaces", "weight": 1}, {"from": "Deep Sliding Shapes for amodal 3D object detection in RGB-D images", "to": "Amodal com-pletion and size constancy in natural scenes", "weight": 1}, {"from": "Deep Sliding Shapes for amodal 3D object detection in RGB-D images", "to": "Unsupervised feature learning for 3d scene labeling", "weight": 1}, {"from": "Deep Sliding Shapes for amodal 3D object detection in RGB-D images", "to": "R-CNN minus R", "weight": 1}, {"from": "Deep Sliding Shapes for amodal 3D object detection in RGB-D images", "to": "VoxNet: A 3D convolutional In IROS", "weight": 1}, {"from": "Deep Sliding Shapes for amodal 3D object detection in RGB-D images", "to": "Faster R-CNN: To-wards real-time object detection with region proposal net-works", "weight": 1}, {"from": "Deep Sliding Shapes for amodal 3D object detection in RGB-D images", "to": "J", "weight": 1}, {"from": "Deep Sliding Shapes for amodal 3D object detection in RGB-D images", "to": "DeepPano: Deep panoramic representation for 3-D shape recognition", "weight": 1}, {"from": "Deep Sliding Shapes for amodal 3D object detection in RGB-D images", "to": "Indoor segmentation and support inference from RGBD images", "weight": 1}, {"from": "Deep Sliding Shapes for amodal 3D object detection in RGB-D images", "to": "Very deep convolutional networks for large-scale image recognition", "weight": 1}, {"from": "Deep Sliding Shapes for amodal 3D object detection in RGB-D images", "to": "Convolutional-recursive deep learning for 3D object classi\ufb01-cation", "weight": 1}, {"from": "Deep Sliding Shapes for amodal 3D object detection in RGB-D images", "to": "Sliding Shapes for 3D object detection in depth images", "weight": 1}, {"from": "Deep Sliding Shapes for amodal 3D object detection in RGB-D images", "to": "Multi-view convolutional neural networks for 3D shape recognition", "weight": 1}, {"from": "Deep Sliding Shapes for amodal 3D object detection in RGB-D images", "to": "Smeulders", "weight": 1}, {"from": "Deep Sliding Shapes for amodal 3D object detection in RGB-D images", "to": "Robust real-time visual odometry for dense rgb-d mapping", "weight": 1}, {"from": "Deep Sliding Shapes for amodal 3D object detection in RGB-D images", "to": "3D ShapeNets: A deep representation for volumetric shapes", "weight": 1}, {"from": "Deep Sliding Shapes for amodal 3D object detection in RGB-D images", "to": "DeepShape: Deep learned shape descriptor for 3D shape matching and retrieval", "weight": 1}, {"from": "Deep Sliding Shapes for amodal 3D object detection in RGB-D images", "to": "Three-dimensional object detec-tion and layout prediction using clouds of oriented gradients", "weight": 1}, {"from": "Hierarchical adversarially learned inference", "to": "", "weight": 1}, {"from": "Unsupervised semantic parsing of video collections", "to": "", "weight": 1}, {"from": "Density sensitive hashing", "to": "Near-optimal hashing algorithms for approximate nearest neighbor in high dimensions", "weight": 1}, {"from": "Density sensitive hashing", "to": "The Priority R-tree: a practically ef\ufb01cient and worst-case optimal R-tree", "weight": 1}, {"from": "Density sensitive hashing", "to": "Spectral Regression: A Regression Framework for Ef\ufb01cient Reg-ularized Subspace Learning", "weight": 1}, {"from": "Density sensitive hashing", "to": "algorithms", "weight": 1}, {"from": "Density sensitive hashing", "to": "Fast locality-sensitive hashing", "weight": 1}, {"from": "Density sensitive hashing", "to": "Locality-sensitive hashing scheme based on p-stable distributions", "weight": 1}, {"from": "Density sensitive hashing", "to": "Continuous visible nearest neighbor query processing in spatial databases", "weight": 1}, {"from": "Density sensitive hashing", "to": "Similarity search in high dimensions via hashing", "weight": 1}, {"from": "Density sensitive hashing", "to": "Iterative quantization: A procrustean approach to learning binary codes", "weight": 1}, {"from": "Density sensitive hashing", "to": "Scalable similarity search with In IEEE International Conference on optimized kernel hashing", "weight": 1}, {"from": "Density sensitive hashing", "to": "Product quantization for IEEE Trans", "weight": 1}, {"from": "Density sensitive hashing", "to": "Semi-supervised simhash for ef\ufb01cient document similarity search", "weight": 1}, {"from": "Density sensitive hashing", "to": "Extensions of Lipschitz map-pings into a Hilbert space", "weight": 1}, {"from": "Density sensitive hashing", "to": "A posteriori multi-probe locality sensitive hashing", "weight": 1}, {"from": "Density sensitive hashing", "to": "Random maximum margin hashing", "weight": 1}, {"from": "Density sensitive hashing", "to": "Voronoi-based k nearest In International neighbor search for spatial network databases", "weight": 1}, {"from": "Density sensitive hashing", "to": "Fast nearest neighbor search in medical image databases", "weight": 1}, {"from": "Density sensitive hashing", "to": "Kernelized locality-sensitive hashing In IEEE International Conference on for scalable image search", "weight": 1}, {"from": "Density sensitive hashing", "to": "Hashing algorithms In The Neural Information Processing for large-scale learning", "weight": 1}, {"from": "Density sensitive hashing", "to": "Hashing with graphs", "weight": 1}, {"from": "Density sensitive hashing", "to": "Multi-probe lsh: Ef\ufb01cient indexing for high-dimensional similarity search", "weight": 1}, {"from": "Density sensitive hashing", "to": "Weakly-supervised hashing in In IEEE Conference on Computer Vision and Pattern kernel space", "weight": 1}, {"from": "Density sensitive hashing", "to": "Minimal loss hashing for compact binary codes", "weight": 1}, {"from": "Density sensitive hashing", "to": "Entropy based nearest neighbor search in high 10 dimensions", "weight": 1}, {"from": "Density sensitive hashing", "to": "Locality sensitive hashing: A comparison of hash function types and querying mechanisms", "weight": 1}, {"from": "Density sensitive hashing", "to": "Locality-sensitive binary codes from shift-invariant kernels", "weight": 1}, {"from": "Density sensitive hashing", "to": "Semantic hashing", "weight": 1}, {"from": "Density sensitive hashing", "to": "Semi-supervised hashing for scalable image retrieval", "weight": 1}, {"from": "Density sensitive hashing", "to": "Sequential projection learning In International Conference on for hashing with compact codes", "weight": 1}, {"from": "Density sensitive hashing", "to": "Spectral hashing", "weight": 1}, {"from": "Density sensitive hashing", "to": "Complemen-In IEEE tary hashing for approximate nearest neighbor search", "weight": 1}, {"from": "Density sensitive hashing", "to": "Laplacian co-hashing of terms and documents", "weight": 1}, {"from": "Density sensitive hashing", "to": "Self-taught hashing for fast similarity search", "weight": 1}, {"from": "Representation learning: A review and new perspectives", "to": "", "weight": 1}, {"from": "Improved regularization of convolutional neural networks with cutout", "to": "", "weight": 1}, {"from": "CARLA: An open urban driving simulator", "to": "", "weight": 1}, {"from": "Xnor-net: Imagenet classi\ufb01cation using binary convolutional neural networks", "to": "", "weight": 1}, {"from": "Multi-Scale Context Aggregation by Dilated Convolutions", "to": ", and Tchamitchian, Ph", "weight": 1}, {"from": "Multi-Scale Context Aggregation by Dilated Convolutions", "to": "Lawrence", "weight": 1}, {"from": "Robust watertight manifold surface generation method for shapenet models", "to": "", "weight": 1}, {"from": "Instance-aware semantic segmentation via multi-task network cascades", "to": "J", "weight": 1}, {"from": "Instance-aware semantic segmentation via multi-task network cascades", "to": "Se-mantic segmentation with second-order pooling", "weight": 1}, {"from": "Instance-aware semantic segmentation via multi-task network cascades", "to": "Weakly-and semi-supervised learning of a dcnn for semantic image segmentation", "weight": 1}, {"from": "Instance-aware semantic segmentation via multi-task network cascades", "to": "Learning to seg-ment object candidates", "weight": 1}, {"from": "Instance-aware semantic segmentation via multi-task network cascades", "to": "Faster R-CNN: To-wards real-time object detection with region proposal net-works", "weight": 1}, {"from": "Instance-aware semantic segmentation via multi-task network cascades", "to": "Very deep convolutional networks for large-scale image recognition", "weight": 1}, {"from": "Instance-aware semantic segmentation via multi-task network cascades", "to": "Compete to compute", "weight": 1}, {"from": "Instance-aware semantic segmentation via multi-task network cascades", "to": "Smeulders", "weight": 1}, {"from": "Instance-aware semantic segmentation via multi-task network cascades", "to": "Visualizing and understanding convolutional neural networks", "weight": 1}, {"from": "Instance-aware semantic segmentation via multi-task network cascades", "to": "Conditional random \ufb01elds as recurrent neural networks", "weight": 1}, {"from": "Instance-aware semantic segmentation via multi-task network cascades", "to": "Edge boxes: Locating object proposals from edges", "weight": 1}, {"from": "Instance-aware semantic segmentation via multi-task network cascades", "to": "Cpmc: Automatic ob-ject segmentation using constrained parametric min-cuts", "weight": 1}, {"from": "Instance-aware semantic segmentation via multi-task network cascades", "to": "Multitask learning", "weight": 1}, {"from": "Instance-aware semantic segmentation via multi-task network cascades", "to": "Boxsup: Exploiting bounding boxes to supervise convolutional networks for semantic seg-mentation", "weight": 1}, {"from": "Instance-aware semantic segmentation via multi-task network cascades", "to": "Convolutional feature masking for joint object and stuff segmentation", "weight": 1}, {"from": "Instance-aware semantic segmentation via multi-task network cascades", "to": "Object detection via a multi-region \u0026 semantic segmentation-aware cnn model", "weight": 1}, {"from": "Instance-aware semantic segmentation via multi-task network cascades", "to": "Fast R-CNN", "weight": 1}, {"from": "Instance-aware semantic segmentation via multi-task network cascades", "to": "Rich fea-ture hierarchies for accurate object detection and semantic segmentation", "weight": 1}, {"from": "Instance-aware semantic segmentation via multi-task network cascades", "to": "Maxout networks", "weight": 1}, {"from": "Instance-aware semantic segmentation via multi-task network cascades", "to": "Semantic contours from inverse detectors", "weight": 1}, {"from": "Instance-aware semantic segmentation via multi-task network cascades", "to": "Simul-taneous detection and segmentation", "weight": 1}, {"from": "Instance-aware semantic segmentation via multi-task network cascades", "to": "Hyper-columns for object segmentation and \ufb01ne-grained localiza-tion", "weight": 1}, {"from": "Instance-aware semantic segmentation via multi-task network cascades", "to": "Spatial pyramid pooling In in deep convolutional networks for visual recognition", "weight": 1}, {"from": "Instance-aware semantic segmentation via multi-task network cascades", "to": "Deep residual learning for image recognition", "weight": 1}, {"from": "Instance-aware semantic segmentation via multi-task network cascades", "to": "Delving deep into recti\ufb01ers: Surpassing human-level performance on imagenet classi\ufb01cation", "weight": 1}, {"from": "Instance-aware semantic segmentation via multi-task network cascades", "to": "K", "weight": 1}, {"from": "Instance-aware semantic segmentation via multi-task network cascades", "to": "Caffe: Convolu-tional architecture for fast feature embedding", "weight": 1}, {"from": "Instance-aware semantic segmentation via multi-task network cascades", "to": "classi\ufb01cation with deep convolutional neural networks", "weight": 1}, {"from": "Instance-aware semantic segmentation via multi-task network cascades", "to": "Backpropagation applied to handwritten zip code recognition", "weight": 1}, {"from": "Instance-aware semantic segmentation via multi-task network cascades", "to": "Fully convolutional networks for semantic segmentation", "weight": 1}, {"from": "Wasserstein GAN", "to": ", and Kira, Z", "weight": 1}, {"from": "Wasserstein GAN", "to": "", "weight": 1}, {"from": "Wasserstein GAN", "to": ", and Bous-quet, O", "weight": 1}, {"from": "Wasserstein GAN", "to": ", and Gerolin, A", "weight": 1}, {"from": "Wasserstein GAN", "to": "P", "weight": 1}, {"from": "Wasserstein GAN", "to": ", and Yoshida, Y", "weight": 1}, {"from": "Wasserstein GAN", "to": "and Cuturi, M", "weight": 1}, {"from": "Wasserstein GAN", "to": ", and Pock, T", "weight": 1}, {"from": "Wasserstein GAN", "to": "and Bach, F", "weight": 1}, {"from": "Wasserstein GAN", "to": ", and Grosse, R", "weight": 1}, {"from": "Wasserstein GAN", "to": "and Bottou, L", "weight": 1}, {"from": "Wasserstein GAN", "to": ", and Bottou, L", "weight": 1}, {"from": "Wasserstein GAN", "to": ", and Munos, R", "weight": 1}, {"from": "Wasserstein GAN", "to": ", and Metz, L", "weight": 1}, {"from": "Wasserstein GAN", "to": "and Rosasco, L", "weight": 1}, {"from": "Wasserstein GAN", "to": ", and Goodfellow, I", "weight": 1}, {"from": "Wasserstein GAN", "to": ", and Peyr\u00b4e, G", "weight": 1}, {"from": "Wasserstein GAN", "to": ", and Bengio, Y", "weight": 1}, {"from": "Latent predictor networks for code generation", "to": "", "weight": 1}, {"from": "Material recognition in the wild with the materials in context database", "to": "", "weight": 1}, {"from": "Pipedream: Fast and ef\ufb01cient pipeline parallel dnn training", "to": "Tensor\ufb02ow: A sys-In 12th USENIX tem for large-scale machine learning", "weight": 1}, {"from": "Pipedream: Fast and ef\ufb01cient pipeline parallel dnn training", "to": "Collecting highly paral-lel data for paraphrase evaluation", "weight": 1}, {"from": "Pipedream: Fast and ef\ufb01cient pipeline parallel dnn training", "to": "Revisit-ing distributed synchronous sgd", "weight": 1}, {"from": "Pipedream: Fast and ef\ufb01cient pipeline parallel dnn training", "to": "Mxnet: A \ufb02exible and e\ufb03cient machine learning library for heterogeneous dis-tributed systems", "weight": 1}, {"from": "Pipedream: Fast and ef\ufb01cient pipeline parallel dnn training", "to": "Pipelined Back-propagation for Context-dependent Deep Neural Networks", "weight": 1}, {"from": "Pipedream: Fast and ef\ufb01cient pipeline parallel dnn training", "to": "Project adam: Building an e\ufb03cient and scalable deep learning training system", "weight": 1}, {"from": "Pipedream: Fast and ef\ufb01cient pipeline parallel dnn training", "to": "J", "weight": 1}, {"from": "Pipedream: Fast and ef\ufb01cient pipeline parallel dnn training", "to": "Geeps: Scalable deep learning on distributed gpus with a gpu-specialized parameter server", "weight": 1}, {"from": "Pipedream: Fast and ef\ufb01cient pipeline parallel dnn training", "to": "G", "weight": 1}, {"from": "Pipedream: Fast and ef\ufb01cient pipeline parallel dnn training", "to": "Meteor universal: Language speci\ufb01c translation evaluation for any target language", "weight": 1}, {"from": "Pipedream: Fast and ef\ufb01cient pipeline parallel dnn training", "to": "Adaptive subgradi-ent methods for online learning and stochastic optimiza-tion", "weight": 1}, {"from": "Pipedream: Fast and ef\ufb01cient pipeline parallel dnn training", "to": "Accurate", "weight": 1}, {"from": "Pipedream: Fast and ef\ufb01cient pipeline parallel dnn training", "to": "Omnivore: An optimizer for multi-device deep learning on cpus and gpus", "weight": 1}, {"from": "Pipedream: Fast and ef\ufb01cient pipeline parallel dnn training", "to": "Deep residual learning for image recognition", "weight": 1}, {"from": "Pipedream: Fast and ef\ufb01cient pipeline parallel dnn training", "to": "L", "weight": 1}, {"from": "Pipedream: Fast and ef\ufb01cient pipeline parallel dnn training", "to": "More e\ufb00ective distributed ml via a stale synchronous parallel parame-ter server", "weight": 1}, {"from": "Pipedream: Fast and ef\ufb01cient pipeline parallel dnn training", "to": "Batch normalization: Accelerat-ing deep network training by reducing internal covariate shift", "weight": 1}, {"from": "Pipedream: Fast and ef\ufb01cient pipeline parallel dnn training", "to": "Ca\ufb00e: Con-volutional architecture for fast feature embedding", "weight": 1}, {"from": "Pipedream: Fast and ef\ufb01cient pipeline parallel dnn training", "to": "A convolutional neural network for modelling sentences", "weight": 1}, {"from": "Pipedream: Fast and ef\ufb01cient pipeline parallel dnn training", "to": "Large-scale video classi\ufb01cation with convolutional neural networks", "weight": 1}, {"from": "Pipedream: Fast and ef\ufb01cient pipeline parallel dnn training", "to": "Practical bayesian optimization of machine learning algorithms", "weight": 1}, {"from": "Pipedream: Fast and ef\ufb01cient pipeline parallel dnn training", "to": "Automating model search for large scale machine learning", "weight": 1}, {"from": "Pipedream: Fast and ef\ufb01cient pipeline parallel dnn training", "to": "Optimization of collective communication operations in mpich", "weight": 1}, {"from": "Pipedream: Fast and ef\ufb01cient pipeline parallel dnn training", "to": "Lecture 6", "weight": 1}, {"from": "Pipedream: Fast and ef\ufb01cient pipeline parallel dnn training", "to": "A bridging model for parallel computation", "weight": 1}, {"from": "Pipedream: Fast and ef\ufb01cient pipeline parallel dnn training", "to": "Sequence to sequence-video to text", "weight": 1}, {"from": "Pipedream: Fast and ef\ufb01cient pipeline parallel dnn training", "to": "Show and tell: A neural image caption generator", "weight": 1}, {"from": "Pipedream: Fast and ef\ufb01cient pipeline parallel dnn training", "to": "Lightlda: Big topic models on modest computer clusters", "weight": 1}, {"from": "Pipedream: Fast and ef\ufb01cient pipeline parallel dnn training", "to": "Poseidon: An ef-\ufb01cient communication architecture for distributed deep In 2017 USENIX Annual learning on GPU clusters", "weight": 1}, {"from": "Pipedream: Fast and ef\ufb01cient pipeline parallel dnn training", "to": "STRADS: a distributed framework for scheduled model parallel machine learning", "weight": 1}, {"from": "Pipedream: Fast and ef\ufb01cient pipeline parallel dnn training", "to": "Adam: A method for stochastic optimization", "weight": 1}, {"from": "Pipedream: Fast and ef\ufb01cient pipeline parallel dnn training", "to": "One weird trick for parallelizing convolu-tional neural networks", "weight": 1}, {"from": "Pipedream: Fast and ef\ufb01cient pipeline parallel dnn training", "to": "Imagenet classi\ufb01cation with deep convolutional neural networks", "weight": 1}, {"from": "Pipedream: Fast and ef\ufb01cient pipeline parallel dnn training", "to": "On model parallelization and scheduling strategies for distributed machine learning", "weight": 1}, {"from": "Pipedream: Fast and ef\ufb01cient pipeline parallel dnn training", "to": "Scaling distributed machine learning with the parameter server", "weight": 1}, {"from": "Pipedream: Fast and ef\ufb01cient pipeline parallel dnn training", "to": "Distributed graphlab: A framework for machine learning in the cloud", "weight": 1}, {"from": "Pipedream: Fast and ef\ufb01cient pipeline parallel dnn training", "to": "De-vice placement optimization with reinforcement learning", "weight": 1}, {"from": "Pipedream: Fast and ef\ufb01cient pipeline parallel dnn training", "to": "On bayesian methods for seeking the ex-tremum", "weight": 1}, {"from": "Pipedream: Fast and ef\ufb01cient pipeline parallel dnn training", "to": "CNTK: Microsoft\u2019s open-source deep-learning toolkit", "weight": 1}, {"from": "Pipedream: Fast and ef\ufb01cient pipeline parallel dnn training", "to": "On paralleliz-ability of stochastic gradient descent for speech dnns", "weight": 1}, {"from": "Pipedream: Fast and ef\ufb01cient pipeline parallel dnn training", "to": "1-bit stochas-tic gradient descent and its application to data-parallel distributed training of speech dnns", "weight": 1}, {"from": "LSUN: Construction of a large-scale image dataset using deep learning with humans in the loop", "to": "Visual recognition with humans in the loop", "weight": 1}, {"from": "LSUN: Construction of a large-scale image dataset using deep learning with humans in the loop", "to": "Towards scalable dataset construction: An active learning approach", "weight": 1}, {"from": "LSUN: Construction of a large-scale image dataset using deep learning with humans in the loop", "to": "Imagenet: A large-scale hierarchical image database", "weight": 1}, {"from": "LSUN: Construction of a large-scale image dataset using deep learning with humans in the loop", "to": "Scalable multi-label annotation", "weight": 1}, {"from": "LSUN: Construction of a large-scale image dataset using deep learning with humans in the loop", "to": "Learning generative visual models from few training examples: An incremental bayesian approach tested on 101 object categories", "weight": 1}, {"from": "LSUN: Construction of a large-scale image dataset using deep learning with humans in the loop", "to": "Delving deep into recti\ufb01ers: Surpassing human-level performance on imagenet classi\ufb01cation", "weight": 1}, {"from": "LSUN: Construction of a large-scale image dataset using deep learning with humans in the loop", "to": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "weight": 1}, {"from": "LSUN: Construction of a large-scale image dataset using deep learning with humans in the loop", "to": "Imagenet classi\ufb01cation with deep convolutional neural networks", "weight": 1}, {"from": "LSUN: Construction of a large-scale image dataset using deep learning with humans in the loop", "to": "Gradient-based learning applied to document recognition", "weight": 1}, {"from": "LSUN: Construction of a large-scale image dataset using deep learning with humans in the loop", "to": "Deep neural networks are easily fooled: High con\ufb01dence predictions for unrecognizable images", "weight": 1}, {"from": "LSUN: Construction of a large-scale image dataset using deep learning with humans in the loop", "to": "J", "weight": 1}, {"from": "LSUN: Construction of a large-scale image dataset using deep learning with humans in the loop", "to": "Best of both worlds: human-machine collaboration for object annotation", "weight": 1}, {"from": "LSUN: Construction of a large-scale image dataset using deep learning with humans in the loop", "to": "Active learning literature survey", "weight": 1}, {"from": "LSUN: Construction of a large-scale image dataset using deep learning with humans in the loop", "to": "Very deep convolutional networks for large-scale image recognition", "weight": 1}, {"from": "LSUN: Construction of a large-scale image dataset using deep learning with humans in the loop", "to": "Going deeper with convolutions", "weight": 1}, {"from": "LSUN: Construction of a large-scale image dataset using deep learning with humans in the loop", "to": "Intriguing properties of neural networks", "weight": 1}, {"from": "LSUN: Construction of a large-scale image dataset using deep learning with humans in the loop", "to": "Support vector machine active learning with applications to text classi\ufb01cation", "weight": 1}, {"from": "LSUN: Construction of a large-scale image dataset using deep learning with humans in the loop", "to": "Unbiased look at dataset bias", "weight": 1}, {"from": "LSUN: Construction of a large-scale image dataset using deep learning with humans in the loop", "to": "Multi-level active prediction of useful image annotations for In D", "weight": 1}, {"from": "LSUN: Construction of a large-scale image dataset using deep learning with humans in the loop", "to": "Multiclass recognition and part localization with humans in the loop", "weight": 1}, {"from": "LSUN: Construction of a large-scale image dataset using deep learning with humans in the loop", "to": "Deep image: Scaling up image recognition", "weight": 1}, {"from": "LSUN: Construction of a large-scale image dataset using deep learning with humans in the loop", "to": "Sun database: Large-scale scene recognition from abbey to zoo", "weight": 1}, {"from": "LSUN: Construction of a large-scale image dataset using deep learning with humans in the loop", "to": "Learning deep features for scene recognition using places database", "weight": 1}, {"from": "Squeezeseg: Convolutional neural nets with recurrent crf for real-time road-object segmentation from 3d lidar point cloud", "to": "", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Discrete-continuous optimization for multi-target tracking", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Robust online multi-object tracking based on tracklet con\ufb01dence and online discriminative appearance learning", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Robust people tracking with global trajectory optimization", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Multiple object track-ing using k-shortest paths optimization", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Evaluating multiple object track-ing performance: The CLEAR MOT metrics", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Alextrac: Af\ufb01n-ity learning by exploring temporal reinforcement within association chains", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "xgboost: extreme gradient boosting", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "CN-NTracker: Online discriminative object tracking via deep convolu-tional neural network", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Near-online multi-target tracking with aggregated local \ufb02ow descriptor", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Multiple target tracking in world coordinate with single", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "A uni\ufb01ed framework for multi-target track-ing and collective activity recognition", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Learning a similarity metric discriminatively", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "The way they move: Tracking targets with similar appearance", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Classifying plankton with deep neural networks", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Rotation-invariant convolu-tional neural networks for galaxy morphology prediction", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Fast feature pyramids for object detection", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Human tracking using convo-IEEE Transactions on Neural Networks", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Two-frame motion estimation based on polynomial expansion", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Object detection with discriminatively trained part based models", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "FlowNet: Learning Optical Flow with Convolutional Networks", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Deep-Stereo: Learning to predict new views from the world\u2019s imagery", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Two-granularity tracking: mediating trajectory and detections graphs for tracking un-der occlusions", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Stochastic gradient boosting", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Hough forests for object detection", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "3d traf\ufb01c scene understanding from movable platforms", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Delving deep into recti-\ufb01ers: Surpassing human-level performance on imagenet classi\ufb01ca-tion", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "A linear programming approach for multiple object tracking", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Mcmc-based particle \ufb01ltering for tracking a variable number of interacting targets", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Multiple hypothesis tracking revisited: Blending in modern appearance model", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "ImageNet classi\ufb01cation with deep convolutional neural networks", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Lerning an image-based motion context for multiple people tracking", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Motchallenge 2015: Towards a benchmark for multi-target tracking", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Everybody needs somebody: Modeling social and grouping behavior on a linear pro-gramming multiple people tracker", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Branch-and-price global optimization for multi-view multi-object tracking", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Deeptrack: Learning discriminative fea-ture representations online for robust visual tracking", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Learning to associate: Hybrid-boosted multi-target tracker for crowded scene", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Multiple object tracking: A review", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Joint tracking and segmentation of multiple targets", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Multi-target tracking by discrete-continuous energy minimization", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Continuous energy minimization for multitarget tracking", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "J", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Globally-optimal greedy algorithms for tracking a variable number of objects", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Joint probabilistic data association revisited", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Learning pedestrian dynamics from the real world", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Learning to divide and conquer for online multi-target tracking", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "DeepFace: Clos-ing the gap to human-level performance in face veri\ufb01cation", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Cas-caded ensemble of convolutional neural networks and handcrafted features for mitosis detection", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Transferring rich feature hierarchies for robust visual tracking", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Learning optimal parameters for multi-target tracking", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Stacked generalization", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Ef\ufb01cient track linking methods for track graphs using network-\ufb02ow and set-cover techniques", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Learning to track: Online multi-object tracking by decision making", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Who are you with and where are you going? CVPR", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "An online learned crf model for multi-target tracking", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Bayesian multi-object track-ing using motion context from multiple objects", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Multiple target tracking using spatio-temporal Markov chain Monte Carlo data association", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Learning to compare image patches via convolutional neural networks", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Gmcp-tracker: Global multi-object tracking using generalized minimum clique graphs", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Computing the stereo matching cost with a convolutional neural network", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Improving multiview face detection with multi-task deep convolutional neural networks", "weight": 1}, {"from": "Learning by tracking: siamese cnn for robust target association", "to": "Global data association for multi-object tracking using network \ufb02ows", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding", "to": "Mesh segmentation-a comparative study", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding", "to": "A framework for the objective evaluation of segmentation algorithms using a ground-truth of human segmented 3D-models", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding", "to": "T", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding", "to": "Linking WordNet to 3D shapes", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding", "to": "A benchmark for 3D mesh segmentation", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding", "to": "3D se-mantic segmentation with submanifold sparse convolutional networks", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding", "to": "Parts of recognition", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding", "to": "Co-segmentation of 3D shapes via subspace clustering", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding", "to": "Learning to predict part mobility from a sin-gle static snapshot", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding", "to": "Learning how objects function via co-analysis of interactions", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding", "to": "Predictive and generative neural networks for object functionality", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding", "to": "Robust watertight mani-fold surface generation method for shapenet models", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding", "to": "Explor-ing shape variations by 3d-model decomposition and part-In Computer Graphics Forum", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding", "to": "Learning 3D mesh segmentation and labeling", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding", "to": "Shape2pose: Human-centric shape analysis", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding", "to": "Escape from cells: Deep kd-networks for the recognition of 3D point cloud models", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding", "to": "Ai2-thor: An interactive 3d environment for vi-sual ai", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding", "to": "Parameter learning and con-vergent inference for dense random \ufb01elds", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding", "to": "The hungarian method for the assignment prob-lem", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding", "to": "PointGrid: A deep network for 3D shape understanding", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding", "to": "SO-Net: Self-organizing network for point cloud analysis", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding", "to": "Grass: Generative recursive autoencoders for shape structures", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding", "to": "PointCNN: Convolution on X -transformed points", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding", "to": "Physical primitive decomposition", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding", "to": "Explo-ration of continuous variability in collections of 3d shapes", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding", "to": "Virtualhome: Simulating household activities via programs", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding", "to": "PointNet: Deep learning on point sets for 3D classi\ufb01cation and segmentation", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding", "to": "PointNet++: Deep hierarchical feature learning on point sets in a metric space", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding", "to": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Con-point cloud processing", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding", "to": "Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding", "to": "SGPN: Sim-ilarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding", "to": "Learning to group and label \ufb01ne-grained shape components", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding", "to": "Active co-analysis of a set of shapes", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding", "to": "Dynamic graph cnn for learning on point clouds", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding", "to": "VoxSegNet: Volumetric CNNs for semantic part segmentation of 3D shapes", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding", "to": "Structure-aware generative network for 3d-shape modeling", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding", "to": "Spider-CNN: Deep learning on point sets with parameterized con-volutional \ufb01lters", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding", "to": "Chalet: Cornell house agent learning environment", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding", "to": "Learning hierarchical shape segmentation and labeling from online repositories", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding", "to": "V", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding", "to": "SyncSpecCNN: Syn-chronized spectral CNN for 3D shape segmentation", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding", "to": "Visual semantic plan-ning using deep successor representations", "weight": 1}, {"from": "Squeezenet: Alexnet-level accuracy with 50x fewer parameters and\u00a1 1mb model size", "to": "", "weight": 1}, {"from": "Incremental network quantization: Towards lossless cnns with lowprecision weights", "to": "", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "Learn-ing to compose neural networks for question answering", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "Neural module networks", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "VQA: Visual question answering", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "Deepcoder: Learning to write programs", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "Making neural programming architectures generalize via recursion", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "Visual dialog", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "Exploring nearest neighbor approaches for image cap-tioning", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "Multimodal compact bilinear pooling for visual question answering and visual grounding", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "Compact bilinear pooling", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "Fast R-CNN", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "Making the V in VQA matter: Elevating the role of image understanding in visual question answering", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "Neural turing ma-chines", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "G", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "Deep residual learning for image recognition", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "Long short-term memory", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "Modeling relationships in referential expressions with com-positional modular networks", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "Revisiting visual question answering baselines", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "CLEVR: A diagnostic dataset for compositional language and elementary visual reasoning", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "Inferring algorithmic patterns with stack-augmented recurrent nets", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "Visual question answering: Datasets", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "Adam: A method for stochastic opti-mization", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "Accurate unlexicalized parsing", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "Y", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "classi\ufb01cation with deep convolutional neural networks", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "Neural random-access machines", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "Building machines that learn and think like people", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "Neural symbolic machines: Learning semantic parsers on freebase with weak supervision", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "Learning dependency-based compositional semantics", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "Hierarchical question-image co-attention for visual question answering", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "A multi-world approach to question answering about real-world scenes based on uncer-tain input", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "Ask your neu-rons: A neural-based approach to answering questions about images", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "Learning models for actions and person-object interactions with transfer to question answer-ing", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "Neural pro-grammer: Inducing latent programs with gradient descent", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "Neural programmer-interpreters", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "J", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "End-to-end memory networks", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "Sequence to sequence learning with neural networks", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "Movieqa: Understanding stories in movies through question-answering", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "Memory networks", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "Simple statistical gradient-following algo-rithms for connectionist reinforcement learning", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "Understanding Natural Language", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "Visual question answering: A survey of methods and datasets", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "Dynamic memory net-ICML", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "Stacked attention networks for image question answering", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "Learning simple algorithms from examples", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "Learning to execute", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "Reinforcement learning neural turing machines", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "Yin and yang: Balancing and answering binary visual questions", "weight": 1}, {"from": "Inferring and executing programs for visual reasoning", "to": "Visual7W: Grounded question answering in images", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "Tensor-\ufb02ow: Large-scale machine learning on heteroge-neous distributed systems", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "G", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "Pedestrian detection with a large-\ufb01eld-of-view deep network", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "Multiple ob-ject recognition with visual attention", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "vin", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "Web 1T 5-gram version 1", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "The Chubby lock service for loosely-In Proceedings of coupled distributed systems", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "Sample size selection in optimization methods for machine learning", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "One billion word bench-mark for measuring progress in statistical lan-CoRR", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "In Inter-Revisiting distributed synchronous SGD", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "MXNet: A \ufb02exible and ef\ufb01cient machine learning library for heterogeneous dis-In Proceedings of the Workshop tributed systems", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "cuDNN: Ef\ufb01cient primitives for deep learning", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "Project Adam: Building an ef\ufb01cient and scalable deep learning train-In 11th USENIX Symposium ing system", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "convnet-benchmarks", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "LIN-In Proceed-Qits: Big data on little clients", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "S", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "The missing piece in complex analytics: Low latency", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "GeePS: Scalable deep learning on distributed GPUs with a GPU-specialized parameter server", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "Document em-arXiv preprint bedding with paragraph vectors", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "Large scale distributed deep networks", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "Mapreduce: Simpli\ufb01ed In Proceedings data processing on large clusters", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "I", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "Generative adversarial nets", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "Deep residual learning for image recognition", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "Multilin-gual acoustic models using distributed deep neural In Acoustics", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "Mesos: A platform for \ufb01ne-grained resource In Proceedings of the sharing in the data center", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "Learning distributed representa-In Proceedings of the Eighth tions of concepts", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "Deep neural networks for acoustic modeling in speech recognition: The shared views of four research IEEE Signal Process", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "ZooKeeper: Wait-free coordination for internet-the 2010 scale systems", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "Batch normalization: Ac-celerating deep network training by reducing inter-nal covariate shift", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "a small self-contained low-precision GEMM library", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "On using very large target vocabulary for neural In Proceedings of the 53rd machine translation", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "Caffe: Convolutional architecture for fast fea-ture embedding", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "Serial order: A parallel dis-ICS report Institute for Cognitive Science", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "Google supercharges machine learning tasks with TPU custom chip", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "Large-scale video classi\ufb01cation with convolutional neural networks", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "One weird trick for paralleliz-ing convolutional neural networks", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "Ima-geNet classi\ufb01cation with deep convolutional neural networks", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "Exploring strategies for training deep Journal of Machine Learn-neural networks", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "Fast algorithms for convo-lutional neural networks", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "Building high-level features using large scale unsupervised learn-ing", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "Scaling distributed machine learn-In 11th USENIX ing with the Parameter Server", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "Ef\ufb01cient mini-batch training for stochastic opti-the 20th ACM mization", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "lan-guage modeling", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "Move evaluation in Go using deep convolutional neural networks", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "Scal-In Proceedings ability! But at what COST? of the 15th USENIX Conference on Hot Top-ics in Operating Systems", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "Ef\ufb01cient estimation of word representations in In International Conference on vector space", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "Human-level control through deep reinforcement learning", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "SparkNet: Training deep networks in Spark", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "Naiad: a timely data\ufb02ow system", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "P", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "Toward acceler-ating deep learning at scale using specialized In Hot Chips: A Symposium on High logic", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "On the dif\ufb01culty of training recurrent neural net-In ICML (3)", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "Nvidia devtech blog post", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "Hogwild: A lock-free approach to parallelizing stochastic In Advances in Neural In-gradient descent", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "Dandelion: a compiler and runtime In Proceedings of for heterogeneous systems", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "ImageNet Large Scale Visual International Journal of Recognition Challenge", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "chitecture for parallel topic models", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "On recti\ufb01ed lin-ear units for speech processing", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "On the importance of initialization and In Proceedings momentum in deep learning", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "Sequence to sequence learning with neural networks", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "Going deeper with convolutions", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "Rethinking the inception architecture for computer vision", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "Large-scale clus-In Pro-ter management at Google with Borg", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "Grammar as a foreign lan-guage", "weight": 1}, {"from": "TensorFlow: Large-scale machine learning on heterogeneous systems", "to": "DryadLINQ: A system for general-purpose distributed data-parallel lan-the 8th USENIX guage", "weight": 1}, {"from": "Deep convolutional ranking for multilabel image annotation", "to": "Learning the semantics of words and pictures", "weight": 1}, {"from": "Deep convolutional ranking for multilabel image annotation", "to": "Animals on the web", "weight": 1}, {"from": "Deep convolutional ranking for multilabel image annotation", "to": "", "weight": 1}, {"from": "Deep convolutional ranking for multilabel image annotation", "to": "hierarchical image database", "weight": 1}, {"from": "Deep convolutional ranking for multilabel image annotation", "to": "Decaf: A deep convolutional activation feature for generic visual recognition", "weight": 1}, {"from": "Deep convolutional ranking for multilabel image annotation", "to": "Object recognition as machine translation: Learning a lexicon for a \ufb01xed image vocabulary", "weight": 1}, {"from": "Deep convolutional ranking for multilabel image annotation", "to": "Semi-supervised learning in gigantic image collections", "weight": 1}, {"from": "Deep convolutional ranking for multilabel image annotation", "to": "A multi-view embedding space for internet images, tags, and their semantics", "weight": 1}, {"from": "Deep convolutional ranking for multilabel image annotation", "to": "learning binary codes", "weight": 1}, {"from": "Deep convolutional ranking for multilabel image annotation", "to": "Maxout networks", "weight": 1}, {"from": "Deep convolutional ranking for multilabel image annotation", "to": "Multimodal semi-supervised learning for image classi\ufb01cation", "weight": 1}, {"from": "Deep convolutional ranking for multilabel image annotation", "to": "Improving neural networks by preventing co-adaptation of feature detectors", "weight": 1}, {"from": "Deep convolutional ranking for multilabel image annotation", "to": "Imagenet classi\ufb01cation with deep convolutional neural networks", "weight": 1}, {"from": "Deep convolutional ranking for multilabel image annotation", "to": "Beyond bags of features: Spatial pyra-mid matching for recognizing natural scene categories", "weight": 1}, {"from": "Deep convolutional ranking for multilabel image annotation", "to": "A new baseline for image annotation", "weight": 1}, {"from": "Deep convolutional ranking for multilabel image annotation", "to": "Modeling the shape of the scene: a holistic representation of the spatial envelope", "weight": 1}, {"from": "Deep convolutional ranking for multilabel image annotation", "to": "Fisher kernels on visual vocabularies for image categorization", "weight": 1}, {"from": "Deep convolutional ranking for multilabel image annotation", "to": "Evaluating color descriptors for object and scene recognition", "weight": 1}, {"from": "Deep convolutional ranking for multilabel image annotation", "to": "Regularization of neural networks using dropconnect", "weight": 1}, {"from": "Deep convolutional ranking for multilabel image annotation", "to": "Locality-constrained linear coding for image classi\ufb01cation", "weight": 1}, {"from": "Deep convolutional ranking for multilabel image annotation", "to": "Wsabie: Scaling up to large vocabulary image annotation", "weight": 1}, {"from": "Deep convolutional ranking for multilabel image annotation", "to": "Sun database: Large-scale scene recognition from abbey to zoo", "weight": 1}, {"from": "Deep convolutional ranking for multilabel image annotation", "to": "Linear spatial pyramid matching uisng sparse coding for image classi\ufb01cation", "weight": 1}, {"from": "Deep convolutional ranking for multilabel image annotation", "to": "Stochastic pooling for regularization of deep convolutional neural networks", "weight": 1}, {"from": "Circulant binary embedding", "to": "", "weight": 1}, {"from": "Deep structure inference network for facial action unit recognition", "to": "Personalised gam-ing", "weight": 1}, {"from": "Deep structure inference network for facial action unit recognition", "to": "W", "weight": 1}, {"from": "Deep structure inference network for facial action unit recognition", "to": "Structure inference machines: Recurrent neural networks for an-alyzing relations in group activity recognition", "weight": 1}, {"from": "Deep structure inference network for facial action unit recognition", "to": "A virtual human inter-viewer for healthcare decision support", "weight": 1}, {"from": "Deep structure inference network for facial action unit recognition", "to": "Facial action unit event detection by cas-cade of tasks", "weight": 1}, {"from": "Deep structure inference network for facial action unit recognition", "to": "Facs manual", "weight": 1}, {"from": "Deep structure inference network for facial action unit recognition", "to": "Multi-conditional latent variable model for joint facial action unit detection", "weight": 1}, {"from": "Deep structure inference network for facial action unit recognition", "to": "Recognition of action units in the wild with deep nets and a new global-local loss", "weight": 1}, {"from": "Deep structure inference network for facial action unit recognition", "to": "Role of facial expressions in social interac-tions", "weight": 1}, {"from": "Deep structure inference network for facial action unit recognition", "to": "Deep learning the dynamic appearance and shape of facial action units", "weight": 1}, {"from": "Deep structure inference network for facial action unit recognition", "to": "Continu-ous pain intensity estimation from facial expressions", "weight": 1}, {"from": "Deep structure inference network for facial action unit recognition", "to": "Auto-matic prediction of frustration", "weight": 1}, {"from": "Deep structure inference network for facial action unit recognition", "to": "One millisecond face align-ment with an ensemble of regression trees", "weight": 1}, {"from": "Deep structure inference network for facial action unit recognition", "to": "Automatic recognition of deceptive facial expressions of emotion", "weight": 1}, {"from": "Deep structure inference network for facial action unit recognition", "to": "Bp4d-spontaneous: a high-resolution spontaneous 3d dy-namic facial expression database", "weight": 1}, {"from": "Deep structure inference network for facial action unit recognition", "to": "Joint patch and multi-label learning for fa-cial action unit detection", "weight": 1}, {"from": "Deep structure inference network for facial action unit recognition", "to": "Deep region and multi-label learning for facial action unit detection", "weight": 1}, {"from": "Deep structure inference network for facial action unit recognition", "to": "Condi-tional random \ufb01elds as recurrent neural networks", "weight": 1}, {"from": "Deep structure inference network for facial action unit recognition", "to": "Learning multiscale active facial patches for expression analysis", "weight": 1}, {"from": "Deep structure inference network for facial action unit recognition", "to": "Action unit de-tection with region adaptation", "weight": 1}, {"from": "Deep structure inference network for facial action unit recognition", "to": "Automatically detecting pain in video through facial action units", "weight": 1}, {"from": "Deep structure inference network for facial action unit recognition", "to": "Disfa: A spontaneous facial action intensity database", "weight": 1}, {"from": "Deep structure inference network for facial action unit recognition", "to": "Deep face In British Machine Vision Conference", "weight": 1}, {"from": "Deep structure inference network for facial action unit recognition", "to": "Grad-cam: Visual explana-tions from deep networks via gradient-based localiza-tion", "weight": 1}, {"from": "Deep structure inference network for facial action unit recognition", "to": "Very deep convo-lutional networks for large-scale image recognition", "weight": 1}, {"from": "Deep structure inference network for facial action unit recognition", "to": "Ex-ploiting sparsity and co-occurrence structure for ac-tion unit recognition", "weight": 1}, {"from": "Deep structure inference network for facial action unit recognition", "to": "Deep-face: Closing the gap to human-level performance in face veri\ufb01cation", "weight": 1}, {"from": "Deep structure inference network for facial action unit recognition", "to": "Social sig-nal processing: Survey of an emerging domain", "weight": 1}, {"from": "Deep structure inference network for facial action unit recognition", "to": "V", "weight": 1}, {"from": "Deep structure inference network for facial action unit recognition", "to": "Capturing global semantic relationships for facial action unit recogni-tion", "weight": 1}, {"from": "Deep structure inference network for facial action unit recognition", "to": "Constrained joint cascade regression framework for simultaneous facial action unit recogni-tion and facial landmark detection", "weight": 1}, {"from": "Deep structure inference network for facial action unit recognition", "to": "Con\ufb01dence preserving machine for facial ac-tion unit detection", "weight": 1}, {"from": "Deep structure inference network for facial action unit recognition", "to": "Task-dependent multi-task multiple kernel learning for facial action unit de-tection", "weight": 1}, {"from": "Extending the openai gym for robotics: a toolkit for reinforcearXiv preprint ment learning using ros and gazebo", "to": "", "weight": 1}, {"from": "Extending the openai gym for robotics: a toolkit for reinforcearXiv preprint ment learning using ros and gazebo", "to": "On-line Q-learning using connectionist systems", "weight": 1}, {"from": "SqueezeNet: AlexNetlevel accuracy with 50x fewer parameters and\u003c 0", "to": "", "weight": 1}, {"from": "Squeezenet: Alexnet-level accuracy with 50x fewer parameters and\u00a1 0", "to": "", "weight": 1}]);

        // adding nodes and edges to the graph
        data = {nodes: nodes, edges: edges};

        var options = {
    "configure": {
        "enabled": false
    },
    "edges": {
        "color": {
            "inherit": true
        },
        "smooth": {
            "enabled": false,
            "type": "continuous"
        }
    },
    "interaction": {
        "dragNodes": true,
        "hideEdgesOnDrag": false,
        "hideNodesOnDrag": false
    },
    "physics": {
        "enabled": true,
        "stabilization": {
            "enabled": true,
            "fit": true,
            "iterations": 1000,
            "onlyDynamicEdges": false,
            "updateInterval": 50
        }
    }
};
        
        

        

        network = new vis.Network(container, data, options);
	 
        


        
        network.on("stabilizationProgress", function(params) {
      		document.getElementById('loadingBar').removeAttribute("style");
	        var maxWidth = 496;
	        var minWidth = 20;
	        var widthFactor = params.iterations/params.total;
	        var width = Math.max(minWidth,maxWidth * widthFactor);

	        document.getElementById('bar').style.width = width + 'px';
	        document.getElementById('text').innerHTML = Math.round(widthFactor*100) + '%';
	    });
	    network.once("stabilizationIterationsDone", function() {
	        document.getElementById('text').innerHTML = '100%';
	        document.getElementById('bar').style.width = '496px';
	        document.getElementById('loadingBar').style.opacity = 0;
	        // really clean the dom element
	        setTimeout(function () {document.getElementById('loadingBar').style.display = 'none';}, 500);
	    });
        

        return network;

    }

    drawGraph();

</script>
</body>
</html>