,authors,title,journal,publisher,volume,year,pages,full_ref,source_file,source_title
0,,,,,,,,"helps users to identify candidate queries when only prefixes are input. It significantly improves the efficiency of query generation since users are only required to input a few characters. In Fashionista, the server maintains a trie for all item identifiers in its main memory. Every time a new character is entered, an Ajax request is sent to the server which looks up the trie and returns a list of candidate items with a matching prefix. In addition, the server also returns the corresponding icon images for the candidate items to provide a preview in the item id input text box.  2.2.2  Fashion Trend Exhibitor  The fashion trend exhibitor surfaces a plot of the fashionability scores of the query image from the year of 2006",./refs/download/Fashionista: A fashion-aware graphical system for exploring visually similar items.pdf,
0,,,,,,,,"J. J. McAuley, C. Targett, Q. Shi, and A. van den Hengel, “Image-based recommendations on styles and substitutes,” in SIGIR, 2015",./refs/download/Fashionista: A fashion-aware graphical system for exploring visually similar items.pdf,
0,,,,,,,,"R. He and J. McAuley, “Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative filtering,” in WWW, 2016",./refs/download/Fashionista: A fashion-aware graphical system for exploring visually similar items.pdf,
0,,,,,,,,"R. He and J. McAuley, “VBPR: visual bayesian personalized ranking from implicit feedback,” in AAAI, 2016",./refs/download/Fashionista: A fashion-aware graphical system for exploring visually similar items.pdf,
0,,,,,,,,"C. Lin, J. Lu, T. W. Ling, and B. Cautis, “Lotusx: a position-aware xml graphical search system with auto-completion,” in ICDE, 2012",./refs/download/Fashionista: A fashion-aware graphical system for exploring visually similar items.pdf,
0,,,,,,,,"A. Krizhevsky, I. Sutskever, and G. E. Hinton, “Imagenet classification with deep convolutional neural networks,” in NIPS, 2012",./refs/download/Fashionista: A fashion-aware graphical system for exploring visually similar items.pdf,
0,,,,,,,,"R. Pan, Y. Zhou, B. Cao, N. N. Liu, R. Lukose, M. Scholz, and Q. Yang, “One-class collaborative filtering,” in ICDM, 2008",./refs/download/Fashionista: A fashion-aware graphical system for exploring visually similar items.pdf,
0,,,,,,,,"L. van der Maaten, “Accelerating t-SNE using tree-based algorithms,” JMLR, 2014",./refs/download/Fashionista: A fashion-aware graphical system for exploring visually similar items.pdf,
0,"Han, X., Wu, Z., Wu, Z., Yu, R., Davis, L. S.",Viton: An image-based virtual try-on network,arXiv preprint arXiv:1711.08447,,,2017,,"Han, X., Wu, Z., Wu, Z., Yu, R., and Davis, L. S. Viton: An image-based virtual try-on network. arXiv preprint arXiv:1711.08447, 2017.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,"Huang, X., Li, Y., Poursaeed, O., Hopcroft, J., Belongie, S.",Stacked generative adversarial networks,In IEEE Conference on Computer Vision and Pattern Recognition (CVPR),,,2017,"volume 2, pp. 4","Huang, X., Li, Y., Poursaeed, O., Hopcroft, J., and Belongie, S. Stacked generative adversarial networks. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), volume 2, pp. 4, 2017.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,"Isola, P., Zhu, J.-Y., Zhou, T., Efros, A. A.",Image-toimage translation with conditional adversarial networks,arXiv preprint,,,2017,,"Isola, P., Zhu, J.-Y., Zhou, T., and Efros, A. A. Image-toimage translation with conditional adversarial networks. arXiv preprint, 2017.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,"Kalantidis, Y., Kennedy, L., Li, L.-J.",Getting the look: clothing recognition and segmentation for automatic product suggestions in everyday photos,In Proceedings of the 3rd ACM conference on International conference on multimedia retrieval,. ACM,,2013,pp. 105–112,"Kalantidis, Y., Kennedy, L., and Li, L.-J. Getting the look: clothing recognition and segmentation for automatic product suggestions in everyday photos. In Proceedings of the 3rd ACM conference on International conference on multimedia retrieval, pp. 105–112. ACM, 2013.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,"Karras, T., Aila, T., Laine, S., Lehtinen, J.","Progressive growing of gans for improved quality, stability, and variation",arXiv preprint arXiv:1710.10196,,,2017,,"Karras, T., Aila, T., Laine, S., and Lehtinen, J. Progressive growing of gans for improved quality, stability, and variation. arXiv preprint arXiv:1710.10196, 2017.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,"Barratt, S., Sharma, R.",A note on the inception score,arXiv preprint arXiv:1801.01973,,,2018,,"Barratt, S. and Sharma, R. A note on the inception score. arXiv preprint arXiv:1801.01973, 2018.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,"Kiapour, M. H., Han, X., Lazebnik, S., Berg, A. C., Berg, T. L.",Where to buy it: Matching street clothing photos in online shops,In ICCV,,,2015,pp. 3343–3351,"Kiapour, M. H., Han, X., Lazebnik, S., Berg, A. C., and Berg, T. L. Where to buy it: Matching street clothing photos in online shops. In ICCV, pp. 3343–3351, 2015.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,"Belghazi, M. I., Rajeswar, S., Mastropietro, O., Rostamzadeh, N., Mitrovic, J., Courville, A.",Hierarchical adversarially learned inference,arXiv preprint arXiv:1802.01071,,,2018,,"Belghazi, M. I., Rajeswar, S., Mastropietro, O., Rostamzadeh, N., Mitrovic, J., and Courville, A. Hierarchical adversarially learned inference. arXiv preprint arXiv:1802.01071, 2018.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,"Bossard, L., Dantone, M., Leistner, C., Wengert, C., Quack, T.",", and Van Gool, L",Apparel classification with style. In Asian conference on computer vision,. Springer,,2012,pp. 321–335,"Bossard, L., Dantone, M., Leistner, C., Wengert, C., Quack, T., and Van Gool, L. Apparel classification with style. In Asian conference on computer vision, pp. 321–335. Springer, 2012.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,"Liang, X., Lin, L., Yang, W., Luo, P., Huang, J., Yan, S.",Clothes co-parsing via joint image segmentation and labeling with application to clothing retrieval,IEEE Transactions on Multimedia,,,2016,18(6):1175–1186,"Liang, X., Lin, L., Yang, W., Luo, P., Huang, J., and Yan, S. Clothes co-parsing via joint image segmentation and labeling with application to clothing retrieval. IEEE Transactions on Multimedia, 18(6):1175–1186, 2016.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,"Chen, H., Gallagher, A., Girod, B.",Describing clothing by semantic attributes,In European conference on computer vision,. Springer,,2012,pp. 609–623,"Chen, H., Gallagher, A., and Girod, B. Describing clothing by semantic attributes. In European conference on computer vision, pp. 609–623. Springer, 2012.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,"Lin, T.-Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Dollár, P., Zitnick, C. L.",Microsoft coco: Common objects in context,In European conference on computer vision,. Springer,,2014,pp. 740–755,"Lin, T.-Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Dollár, P., and Zitnick, C. L. Microsoft coco: Common objects in context. In European conference on computer vision, pp. 740–755. Springer, 2014.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,"Chen, Q., Huang, J., Feris, R., Brown, L. M., Dong, J., Yan, S.",Deep domain adaptation for describing people based on fine-grained clothing attributes,In Computer Vision and Pattern Recognition (CVPR),. IEEE,,2015,"2015 IEEE Conference on, pp. 5315–5324","Chen, Q., Huang, J., Feris, R., Brown, L. M., Dong, J., and Yan, S. Deep domain adaptation for describing people based on fine-grained clothing attributes. In Computer Vision and Pattern Recognition (CVPR), 2015 IEEE Conference on, pp. 5315–5324. IEEE, 2015.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,"Denton, E., Fergus, R.",Stochastic video generation with a learned prior,arXiv preprint arXiv:1802.07687,,,2018,,"Denton, E. and Fergus, R. Stochastic video generation with a learned prior. arXiv preprint arXiv:1802.07687, 2018.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,"Liu, S., Song, Z., Liu, G., Xu, C., Lu, H., Yan, S.",Street-to-shop: Cross-scenario clothing retrieval via parts alignment and auxiliary set,In Computer Vision and Pattern Recognition (CVPR),. IEEE,,2012,"2012 IEEE Conference on, pp. 3330–3337","Liu, S., Song, Z., Liu, G., Xu, C., Lu, H., and Yan, S. Street-to-shop: Cross-scenario clothing retrieval via parts alignment and auxiliary set. In Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on, pp. 3330–3337. IEEE, 2012.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,"Liu, Z., Luo, P., Wang, X., Tang, X.",Deep learning face attributes in the wild,In Proceedings of the IEEE International Conference on Computer Vision,,,2015,pp. 3730– 3738,"Liu, Z., Luo, P., Wang, X., and Tang, X. Deep learning face attributes in the wild. In Proceedings of the IEEE International Conference on Computer Vision, pp. 3730– 3738, 2015.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,"Liu, Z., Luo, P., Qiu, S., Wang, X., Tang, X.",Deepfashion: Powering robust clothes recognition and retrieval  Fashion-Gen: The Generative Fashion Dataset and Challenge  with rich annotations,In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,,,2016,pp. 1096–1104,"Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., and Bengio,  Liu, Z., Luo, P., Qiu, S., Wang, X., and Tang, X. Deepfashion: Powering robust clothes recognition and retrieval  Fashion-Gen: The Generative Fashion Dataset and Challenge  with rich annotations. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1096–1104, 2016.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,,,,,,,,"Nilsback, M.-E. and Zisserman, A. Automated flower classification over a large number of classes. In Computer Vision, Graphics & Image Processing, 2008.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,"Reed, S., Akata, Z., Yan, X., Logeswaran, L., Schiele, B., Lee, H.",Generative adversarial text to image synthesis,arXiv preprint arXiv:1605.05396,,,2016,"2016a. Reed, S., Akata, Z., Lee, H., and Schiele, B. Learning deep representations of fine-grained visual descriptions. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 49–58, 2016b. Reed, S. E., Akata, Z., Schiele, B., and Lee, H. Learning deep representations of fine-grained visual descriptions. CoRR, abs/1605.05395","Reed, S., Akata, Z., Yan, X., Logeswaran, L., Schiele, B., and Lee, H. Generative adversarial text to image synthesis. arXiv preprint arXiv:1605.05396, 2016a. Reed, S., Akata, Z., Lee, H., and Schiele, B. Learning deep representations of fine-grained visual descriptions. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 49–58, 2016b. Reed, S. E., Akata, Z., Schiele, B., and Lee, H. Learning deep representations of fine-grained visual descriptions. CoRR, abs/1605.05395, 2016.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,"Salimans, T., Goodfellow, I., Zaremba, W., Cheung, V., Radford, A., Chen, X.",Improved techniques for training gans,In Advances in Neural Information Processing Systems,,,2016,pp. 2234–2242,"Salimans, T., Goodfellow, I., Zaremba, W., Cheung, V., Radford, A., and Chen, X. Improved techniques for training gans. In Advances in Neural Information Processing Systems, pp. 2234–2242, 2016.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,"Schuster, M., Paliwal, K. K., General, A.",Bidirectional recurrent neural networks,IEEE Transactions on Signal Processing,,,1997,,"Schuster, M., Paliwal, K. K., and General, A. Bidirectional recurrent neural networks. IEEE Transactions on Signal Processing, 1997.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,"Simo-Serra, E., Fidler, S., Moreno-Noguer, F., Urtasun, R.",Neuroaesthetics in fashion: Modeling the perception of fashionability,In CVPR,,,2015,"volume 2, pp. 6","Simo-Serra, E., Fidler, S., Moreno-Noguer, F., and Urtasun, R. Neuroaesthetics in fashion: Modeling the perception of fashionability. In CVPR, volume 2, pp. 6, 2015.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,"Sønderby, C. K., Caballero, J., Theis, L., Shi, W., Huszár, F.",Amortised map inference for image superresolution,arXiv preprint arXiv:1610.04490,,,2016,,"Sønderby, C. K., Caballero, J., Theis, L., Shi, W., and Huszár, F. Amortised map inference for image superresolution. arXiv preprint arXiv:1610.04490, 2016.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,"Taigman, Y., Polyak, A., Wolf, L.",Unsupervised cross-domain image generation,arXiv preprint arXiv:1611.02200,,,2016,,"Taigman, Y., Polyak, A., and Wolf, L. Unsupervised cross-domain image generation. arXiv preprint arXiv:1611.02200, 2016.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,"Maaten, L., Hinton, G.",Visualizing data using t-SNE,Journal of Machine Learning Research,,,2008,9: 2579–2605,"Maaten, L. and Hinton, G. Visualizing data using t-SNE. Journal of Machine Learning Research, 9: 2579–2605, 2008.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,"Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., Polosukhin, I.",Attention is all you need,CoRR,,,2017,abs/1706.03762,"Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., and Polosukhin, I. Attention is all you need. CoRR, abs/1706.03762, 2017.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,"Veit, A., Kovacs, B., Bell, S., McAuley, J., Bala, K., Belongie, S.",Learning visual clothing style with heterogeneous dyadic co-occurrences,In Computer Vision (ICCV),. IEEE,,2015,"2015 IEEE International Conference on, pp. 4642–4650","Veit, A., Kovacs, B., Bell, S., McAuley, J., Bala, K., and Belongie, S. Learning visual clothing style with heterogeneous dyadic co-occurrences. In Computer Vision (ICCV), 2015 IEEE International Conference on, pp. 4642–4650. IEEE, 2015.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,"Xiao, T., Xia, T., Yang, Y., Huang, C., Wang, X.",Learning from massive noisy labeled data for image classification,In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,,,2015,pp. 2691–2699,"Xiao, T., Xia, T., Yang, Y., Huang, C., and Wang, X. Learning from massive noisy labeled data for image classification. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2691–2699, 2015.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,"Zhang, H., Xu, T., Li, H., Zhang, S., Huang, X., Wang, X., Metaxas, D.",Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks,In IEEE Int. Conf. Comput. Vision (ICCV),,,2018,"pp. 5907–5915, 2017a. Zhang, H., Xu, T., Li, H., Zhang, S., Wang, X., Huang, X., and Metaxas, D. N. Stackgan++: Realistic image synthesis with stacked generative adversarial networks. CoRR, abs/1710.10916, 2017b. URL http://arxiv. org/abs/1710.10916. Zhang, Z., Xie, Y., and Yang, L. Photographic text-toimage synthesis with a hierarchically-nested adversarial network. arXiv preprint arXiv:1802.09178","Zhang, H., Xu, T., Li, H., Zhang, S., Huang, X., Wang, X., and Metaxas, D. Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks. In IEEE Int. Conf. Comput. Vision (ICCV), pp. 5907–5915, 2017a. Zhang, H., Xu, T., Li, H., Zhang, S., Wang, X., Huang, X., and Metaxas, D. N. Stackgan++: Realistic image synthesis with stacked generative adversarial networks. CoRR, abs/1710.10916, 2017b. URL http://arxiv. org/abs/1710.10916. Zhang, Z., Xie, Y., and Yang, L. Photographic text-toimage synthesis with a hierarchically-nested adversarial network. arXiv preprint arXiv:1802.09178, 2018.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,,,,,,,,"Y. Cao, M. Long, B. Liu, and J. Wang. Deep cauchy hashing for hamming space retrieval. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1229",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,,,,,,,,"Z. Cao, M. Long, J. Wang, and S. Y. Philip. Hashnet: Deep learning to hash by continuation. In ICCV, pages 5609",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,,,,,,,,"Y.-W. Chao, S. Vijayanarasimhan, B. Seybold, D. A. Ross, J. Deng, and R. Sukthankar. Rethinking the faster r-cnn architecture for temporal action localization. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1130",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,"Y. Chen, Y. Kalantidis, J. Li, S. Yan",and J. Feng. Multi-fiber networks for video recognition. arXiv preprint arXiv:1807.11195,,,,2018,,"Y. Chen, Y. Kalantidis, J. Li, S. Yan, and J. Feng. Multi-fiber networks for video recognition. arXiv preprint arXiv:1807.11195, 2018",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,"T.-S. Chua, J. Tang, R. Hong, H. Li, Z. Luo, and Y. Zheng. Nus-wide: a real-world web image database from national university of singapore. In Proceedings of the ACM international conference on image and video retrieval",page 48. ACM,,,,2009,,"T.-S. Chua, J. Tang, R. Hong, H. Li, Z. Luo, and Y. Zheng. Nus-wide: a real-world web image database from national university of singapore. In Proceedings of the ACM international conference on image and video retrieval, page 48. ACM, 2009",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,,,,,,,,"J. Donahue, L. Anne Hendricks, S. Guadarrama, M. Rohrbach, S. Venugopalan, K. Saenko, and T. Darrell. Long-term recurrent convolutional networks for visual recognition and description. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 2625",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,,,,,,,,"Y. Gong, S. Lazebnik, A. Gordo, and F. Perronnin. Iterative quantization: A procrustean approach to learning binary codes for large-scale image retrieval. IEEE Transactions on Pattern Analysis and Machine Intelligence, 35(12):2916– 2929",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,,,,,,,,"Y. Gu, C. Ma, and J. Yang. Supervised recurrent hashing for large scale video retrieval. In Proceedings of the 2016",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,"K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition",pages 770–778,,,,2016,,"K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770–778, 2016",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,,,,,,,,"L. Karlinsky, J. Shtok, S. Harary, E. Schwartz, A. Aides, R. Feris, R. Giryes, and A. M. Bronstein. Repmet: Representative-based metric learning for classification and few-shot object detection. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 5197",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,"H. Kuehne, H. Jhuang, R. Stiefelhagen, and T. Serre. Hmdb51: A large video database for human motion recognition. In High Performance Computing in Science and Engineering 12",pages 571–582. Springer,,,,2013,,"H. Kuehne, H. Jhuang, R. Stiefelhagen, and T. Serre. Hmdb51: A large video database for human motion recognition. In High Performance Computing in Science and Engineering 12, pages 571–582. Springer, 2013",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,,,,,,,,"B. Kulis and T. Darrell. Learning to hash with binary reconstructive embeddings. In Advances in neural information processing systems, pages 1042",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,,,,,,,," ceedings of the IEEE conference on computer vision and pattern recognition, pages 3270",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,"F. Shen, C. Shen, W. Liu, and H. Tao Shen. Supervised discrete hashing. In Proceedings of the IEEE conference on computer vision and pattern recognition",pages 37–45,,,,2015,,"F. Shen, C. Shen, W. Liu, and H. Tao Shen. Supervised discrete hashing. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 37–45, 2015",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,K. Simonyan and A. Zisserman. Two-stream convolutional networks for action recognition in videos. In Advances in neural information processing systems,pages 568–576,,,,2014,,"K. Simonyan and A. Zisserman. Two-stream convolutional networks for action recognition in videos. In Advances in neural information processing systems, pages 568–576, 2014",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,,,,,,,,"D. Song, W. Liu, R. Ji, D. A. Meyer, and J. R. Smith. Top rank supervised binary coding for visual search. In Proceedings of the IEEE International Conference on Computer Vision, pages 1922",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,"K. Soomro, A. R. Zamir",and M. Shah. Ucf101: A dataset of 101 human actions classes from videos in the wild. arXiv preprint arXiv:1212.0402,,,,2012,,"K. Soomro, A. R. Zamir, and M. Shah. Ucf101: A dataset of 101 human actions classes from videos in the wild. arXiv preprint arXiv:1212.0402, 2012",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,"G. Varol, I. Laptev, and C. Schmid. Long-term temporal convolutions for action recognition. IEEE transactions on pattern analysis and machine intelligence",40(6):1510–1517,,,,2017,,"G. Varol, I. Laptev, and C. Schmid. Long-term temporal convolutions for action recognition. IEEE transactions on pattern analysis and machine intelligence, 40(6):1510–1517, 2017",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,"J. Wang, W. Liu, S. Kumar, and S.-F. Chang. Learning to hash for indexing big dataa survey. Proceedings of the IEEE",104(1):34–57,,,,2016,,"J. Wang, W. Liu, S. Kumar, and S.-F. Chang. Learning to hash for indexing big dataa survey. Proceedings of the IEEE, 104(1):34–57, 2016",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,,,,,,,,"J. Wang, W. Liu, A. X. Sun, and Y.-G. Jiang. Learning hash codes with listwise supervision. In Proceedings of the IEEE International Conference on Computer Vision, pages 3032",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,"L. Wang, Y. Xiong, Z. Wang, Y. Qiao, D. Lin, X. Tang, and L. Van Gool. Temporal segment networks: Towards good practices for deep action recognition. In European conference on computer vision",pages 20–36. Springer,,,,2016,,"L. Wang, Y. Xiong, Z. Wang, Y. Qiao, D. Lin, X. Tang, and L. Van Gool. Temporal segment networks: Towards good practices for deep action recognition. In European conference on computer vision, pages 20–36. Springer, 2016",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,"T. Weise, M. Zapf, R. Chiong, and A. J. Nebro. Why is optimization difficult? In Nature-Inspired Algorithms for Optimisation",pages 1–50. Springer,,,,2009,,"T. Weise, M. Zapf, R. Chiong, and A. J. Nebro. Why is optimization difficult? In Nature-Inspired Algorithms for Optimisation, pages 1–50. Springer, 2009",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,,,,,,,,"Y. Weiss, A. Torralba, and R. Fergus. Spectral hashing. In Advances in neural information processing systems, pages 1753",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,,,,,,,,E. W. Weisstein. Hadamard matrix. 2002,./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,"Y. Wen, K. Zhang, Z. Li, and Y. Qiao. A discriminative feature learning approach for deep face recognition. In European Conference on Computer Vision",pages 499–515. Springer,,,,2016,,"Y. Wen, K. Zhang, Z. Li, and Y. Qiao. A discriminative feature learning approach for deep face recognition. In European Conference on Computer Vision, pages 499–515. Springer, 2016",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,"R. Xia, Y. Pan, H. Lai, C. Liu, and S. Yan. Supervised hashing for image retrieval via image representation learning. In AAAI",volume 1,page 2,,,2014,,"R. Xia, Y. Pan, H. Lai, C. Liu, and S. Yan. Supervised hashing for image retrieval via image representation learning. In AAAI, volume 1, page 2, 2014",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,,,,,,,,"E. Yang, T. Liu, C. Deng, W. Liu, and D. Tao. Distillhash: Unsupervised deep hashing by distilling data pairs. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2946",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,"L. Yuan, E. H. F. Tay",P. Li,and J. Feng. Unsupervised video summarization with cycle-consistent adversarial lstm networks. IEEE Transactions on Multimedia,,,2019,,"L. Yuan, E. H. F. Tay, P. Li, and J. Feng. Unsupervised video summarization with cycle-consistent adversarial lstm networks. IEEE Transactions on Multimedia, 2019",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,,,,,,,,"L. Yuan, F. E. Tay, P. Li, L. Zhou, and J. Feng. Cycle-sum: cycle-consistent adversarial lstm networks for unsupervised video summarization. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 33, pages 9143",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,,,,,,,,"H. Zhu, M. Long, J. Wang, and Y. Cao. Deep hashing network for efficient similarity retrieval. In AAAI, pages 2415",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,"N. Zhuang, J. Ye",and K. A. Hua. Dlstm approach to video modeling with hashing for large-scale video retrieval. In Pattern Recognition (ICPR),,,,2016,,"N. Zhuang, J. Ye, and K. A. Hua. Dlstm approach to video modeling with hashing for large-scale video retrieval. In Pattern Recognition (ICPR), 2016",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,,,,,,,,"proposed multi-component labeling benchmark containing  • We introduce PartNet, consisting of 573,585 finegrained part annotations for 26,671 shapes across 24 object categories. To the best of our knowledge, it is the first large-scale dataset with fine-grained, hierarchical, instance-level part annotations; • We propose three part-level object understanding tasks to demonstrate the usefulness of this data: fine-grained semantic segmentation, hierarchical semantic segmentation, and instance segmentation. 2  Bag  Keyboard  Bed  Bowl  Knife  Laptop  Clock  Lamp  Dishwasher  Microwave  Display  Mug  Door  Refrigerator  Earphone  Chair  Scissors  Faucet  Table  Hat  Trash Can  Storage Furniture  Vase  Bottle  Figure 2. PartNet dataset. We visualize example shapes with fine-grained part annotations for the 24 object categories in PartNet. #A #S #M #PS #PI Pmed Pmax Dmed Dmax  All Bag 3253",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"R. Hu, W. Li, O. Van Kaick, A. Shamir, H. Zhang, and H. Huang. Learning to predict part mobility from a single static snapshot. ACM Transactions on Graphics (TOG)",36(6):227,,,,2017,,"R. Hu, W. Li, O. Van Kaick, A. Shamir, H. Zhang, and H. Huang. Learning to predict part mobility from a single static snapshot. ACM Transactions on Graphics (TOG), 36(6):227, 2017",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"R. Hu, O. van Kaick, B. Wu, H. Huang, A. Shamir, and H. Zhang. Learning how objects function via co-analysis of interactions. ACM Transactions on Graphics (TOG)",35(4):47,,,,2016,,"R. Hu, O. van Kaick, B. Wu, H. Huang, A. Shamir, and H. Zhang. Learning how objects function via co-analysis of interactions. ACM Transactions on Graphics (TOG), 35(4):47, 2016",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"R. Hu, Z. Yan, J. Zhang, O. van Kaick, A. Shamir, H. Zhang, and H. Huang. Predictive and generative neural networks for object functionality. In Computer Graphics Forum (Eurographics State-of-the-art report)",volume 37,pages 603– 624,,,2018,,"R. Hu, Z. Yan, J. Zhang, O. van Kaick, A. Shamir, H. Zhang, and H. Huang. Predictive and generative neural networks for object functionality. In Computer Graphics Forum (Eurographics State-of-the-art report), volume 37, pages 603– 624, 2018",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"J. Huang, H. Su",and L. Guibas. Robust watertight manifold surface generation method for shapenet models. arXiv preprint arXiv:1802.01698,,,,2018,,"J. Huang, H. Su, and L. Guibas. Robust watertight manifold surface generation method for shapenet models. arXiv preprint arXiv:1802.01698, 2018",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"T. Ritschel, and H.-P. Seidel. Exploring shape variations by 3d-model decomposition and partbased recombination. In Computer Graphics Forum",volume 31,pages 631–640. Wiley Online Library,,,2012,,"A. Jain, T. Thormählen, T. Ritschel, and H.-P. Seidel. Exploring shape variations by 3d-model decomposition and partbased recombination. In Computer Graphics Forum, volume 31, pages 631–640. Wiley Online Library, 2012",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"E. Kalogerakis, A. Hertzmann, and K. Singh. Learning 3D mesh segmentation and labeling. ACM Transactions on Graphics (TOG)",29(4):102,,,,2010,,"E. Kalogerakis, A. Hertzmann, and K. Singh. Learning 3D mesh segmentation and labeling. ACM Transactions on Graphics (TOG), 29(4):102, 2010",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"G. Kim, S. Chaudhuri, L. Guibas, and T. Funkhouser. Shape2pose: Human-centric shape analysis. ACM Transactions on Graphics (TOG)",33(4):120,,,,2014,,"V. G. Kim, S. Chaudhuri, L. Guibas, and T. Funkhouser. Shape2pose: Human-centric shape analysis. ACM Transactions on Graphics (TOG), 33(4):120, 2014",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,,,,,,,,"R. Klokov and V. Lempitsky. Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models. In Computer Vision (ICCV), 2017",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"E. Kolve, R. Mottaghi, D. Gordon, Y. Zhu, A. Gupta",and A. Farhadi. Ai2-thor: An interactive 3d environment for visual ai. arXiv preprint arXiv:1712.05474,,,,2017,,"E. Kolve, R. Mottaghi, D. Gordon, Y. Zhu, A. Gupta, and A. Farhadi. Ai2-thor: An interactive 3d environment for visual ai. arXiv preprint arXiv:1712.05474, 2017",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,P. Krähenbühl and V. Koltun. Parameter learning and convergent inference for dense random fields. In International Conference on Machine Learning,pages 513–521,,,,2013,,"P. Krähenbühl and V. Koltun. Parameter learning and convergent inference for dense random fields. In International Conference on Machine Learning, pages 513–521, 2013",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,H. W. Kuhn. The hungarian method for the assignment problem. Naval research logistics quarterly,2(1-2):83–97,,,,1955,,"H. W. Kuhn. The hungarian method for the assignment problem. Naval research logistics quarterly, 2(1-2):83–97, 1955",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,,,,,,,,"T. Le and Y. Duan. PointGrid: A deep network for 3D shape understanding. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 9204",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,,,,,,,,"J. Li, B. M. Chen, and G. H. Lee. SO-Net: Self-organizing network for point cloud analysis. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 9397",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"J. Li, K. Xu, S. Chaudhuri, E. Yumer, H. Zhang, and L. Guibas. Grass: Generative recursive autoencoders for shape structures. ACM Transactions on Graphics (TOG)",36(4):52,,,,2017,,"J. Li, K. Xu, S. Chaudhuri, E. Yumer, H. Zhang, and L. Guibas. Grass: Generative recursive autoencoders for shape structures. ACM Transactions on Graphics (TOG), 36(4):52, 2017",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"Y. Li, R. Bu, M. Sun",and B. Chen. PointCNN: Convolution on X -transformed points. Advances in neural information processing systems (NIPS),,,,2018,,"Y. Li, R. Bu, M. Sun, and B. Chen. PointCNN: Convolution on X -transformed points. Advances in neural information processing systems (NIPS), 2018",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"Z. Liu, W. T. Freeman",J. B. Tenenbaum,and J. Wu. Physical primitive decomposition. arXiv preprint arXiv:1809.05070,,,2018,,"Z. Liu, W. T. Freeman, J. B. Tenenbaum, and J. Wu. Physical primitive decomposition. arXiv preprint arXiv:1809.05070, 2018",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"M. Attene, S. Katz, M. Mortara, G. Patané",M. Spagnuolo,and A. Tal. Mesh segmentation-a comparative study. In Shape Modeling and Applications,,,2006,,"M. Attene, S. Katz, M. Mortara, G. Patané, M. Spagnuolo, and A. Tal. Mesh segmentation-a comparative study. In Shape Modeling and Applications, 2006",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"H. Benhabiles, J.-P. Vandeborre, G. Lavoué",and M. Daoudi. A framework for the objective evaluation of segmentation algorithms using a ground-truth of human segmented 3Dmodels. In IEEE International Conference on Shape Modeling and Applications (SMI),pages Session–5,,,2009,,"H. Benhabiles, J.-P. Vandeborre, G. Lavoué, and M. Daoudi. A framework for the objective evaluation of segmentation algorithms using a ground-truth of human segmented 3Dmodels. In IEEE International Conference on Shape Modeling and Applications (SMI), pages Session–5, 2009",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"X. Chang, T. Funkhouser, L. Guibas, P. Hanrahan, Q. Huang, Z. Li, S. Savarese, M. Savva, S. Song, H. Su",et al. ShapeNet: An information-rich 3D model repository. arXiv preprint arXiv:1512.03012,,,,2015,,"A. X. Chang, T. Funkhouser, L. Guibas, P. Hanrahan, Q. Huang, Z. Li, S. Savarese, M. Savva, S. Song, H. Su, et al. ShapeNet: An information-rich 3D model repository. arXiv preprint arXiv:1512.03012, 2015",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"X. Chang, R. Mago, P. Krishna, M. Savva",and C. Fellbaum. Linking WordNet to 3D shapes. In Global WordNet Conference,,,,2018,,"A. X. Chang, R. Mago, P. Krishna, M. Savva, and C. Fellbaum. Linking WordNet to 3D shapes. In Global WordNet Conference, 2018",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"X. Chen, A. Golovinskiy",and T. Funkhouser. A benchmark for 3D mesh segmentation. ACM Transactions on Graphics (Proc. SIGGRAPH),,,,2009,,"X. Chen, A. Golovinskiy, and T. Funkhouser. A benchmark for 3D mesh segmentation. ACM Transactions on Graphics (Proc. SIGGRAPH), 2009",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"B. Graham, M. Engelcke, and L. van der Maaten. 3D semantic segmentation with submanifold sparse convolutional networks. Proceedings of the IEEE Computer Vision and Pattern Recognition (CVPR)",pages 18–22,,,,2018,,"B. Graham, M. Engelcke, and L. van der Maaten. 3D semantic segmentation with submanifold sparse convolutional networks. Proceedings of the IEEE Computer Vision and Pattern Recognition (CVPR), pages 18–22, 2018",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"P. Hermosilla, T. Ritschel, P.-P. Vázquez",À. Vinacua,and T. Ropinski. Monte carlo convolution for learning on non-uniformly sampled point clouds. arXiv preprint arXiv:1806.01759,,,2018,,"P. Hermosilla, T. Ritschel, P.-P. Vázquez, À. Vinacua, and T. Ropinski. Monte carlo convolution for learning on non-uniformly sampled point clouds. arXiv preprint arXiv:1806.01759, 2018",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,D. D. Hoffman and W. A. Richards. Parts of recognition. Cognition,18(1-3):65–96,,,,1984,,"D. D. Hoffman and W. A. Richards. Parts of recognition. Cognition, 18(1-3):65–96, 1984",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,,,,,,,,"R. Hu, L. Fan, and L. Liu. Co-segmentation of 3D shapes via subspace clustering. In Computer graphics forum, volume 31, pages 1703",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"C. Yan, D. Misra, A. Bennnett, A. Walsman, Y. Bisk",and Y. Artzi. Chalet: Cornell house agent learning environment. arXiv preprint arXiv:1801.07357,,,,2018,,"C. Yan, D. Misra, A. Bennnett, A. Walsman, Y. Bisk, and Y. Artzi. Chalet: Cornell house agent learning environment. arXiv preprint arXiv:1801.07357, 2018",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"L. Yi, L. Guibas, A. Hertzmann, V. G. Kim",H. Su,and E. Yumer. Learning hierarchical shape segmentation and labeling from online repositories. ACM Transactions on Graphics (Proc. SIGGRAPH Asia),,,2017,,"L. Yi, L. Guibas, A. Hertzmann, V. G. Kim, H. Su, and E. Yumer. Learning hierarchical shape segmentation and labeling from online repositories. ACM Transactions on Graphics (Proc. SIGGRAPH Asia), 2017",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"G. Kim, D. Ceylan, I. Shen, M. Yan, H. Su, C. Lu, Q. Huang, A. Sheffer, L. Guibas, et al. A scalable active framework for region annotation in 3D shape collections. ACM Transactions on Graphics (TOG)",35(6):210,,,,2016,,"L. Yi, V. G. Kim, D. Ceylan, I. Shen, M. Yan, H. Su, C. Lu, Q. Huang, A. Sheffer, L. Guibas, et al. A scalable active framework for region annotation in 3D shape collections. ACM Transactions on Graphics (TOG), 35(6):210, 2016",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,,,,,,,,"L. Yi, H. Su, X. Guo, and L. J. Guibas. SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 6584",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"Y. Zhu, D. Gordon, E. Kolve, D. Fox, L. Fei-Fei, A. Gupta, R. Mottaghi, and A. Farhadi. Visual semantic planning using deep successor representations. arXiv preprint ArXiv:1705.08080",pages 1–13,,,,2017,,"Y. Zhu, D. Gordon, E. Kolve, D. Fox, L. Fei-Fei, A. Gupta, R. Mottaghi, and A. Farhadi. Visual semantic planning using deep successor representations. arXiv preprint ArXiv:1705.08080, pages 1–13, 2017",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,L. v. d. Maaten and G. Hinton. Visualizing data using t-sne. Journal of machine learning research,9(Nov):2579–2605,,,,2008,,"L. v. d. Maaten and G. Hinton. Visualizing data using t-sne. Journal of machine learning research, 9(Nov):2579–2605, 2008",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"M. Ovsjanikov, W. Li, L. Guibas, and N. J. Mitra. Exploration of continuous variability in collections of 3d shapes. In ACM Transactions on Graphics (TOG)",volume 30,page 33. ACM,,,2011,,"M. Ovsjanikov, W. Li, L. Guibas, and N. J. Mitra. Exploration of continuous variability in collections of 3d shapes. In ACM Transactions on Graphics (TOG), volume 30, page 33. ACM, 2011",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"X. Puig, K. Ra, M. Boben, J. Li, T. Wang, S. Fidler",and A. Torralba. Virtualhome: Simulating household activities via programs. In CVPR,,,,2018,,"X. Puig, K. Ra, M. Boben, J. Li, T. Wang, S. Fidler, and A. Torralba. Virtualhome: Simulating household activities via programs. In CVPR, 2018",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,IEEE,volume 1,page 4,,,2017,,"C. R. Qi, H. Su, K. Mo, and L. J. Guibas. PointNet: Deep learning on point sets for 3D classification and segmentation. In Proc. Computer Vision and Pattern Recognition (CVPR), IEEE, volume 1, page 4, 2017",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,,,,,,,,"C. R. Qi, L. Yi, H. Su, and L. J. Guibas. PointNet++: Deep hierarchical feature learning on point sets in a metric space. In Advances in Neural Information Processing Systems, pages 5099",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,,,,,,,,"H. Su, V. Jampani, D. Sun, S. Maji, E. Kalogerakis, M.-H. Yang, and J. Kautz. SplatNet: Sparse lattice networks for point cloud processing. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2530",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"M. Sung, H. Su, R. Yu",and L. Guibas. Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions. Advances in neural information processing systems (NIPS),,,,2018,,"M. Sung, H. Su, R. Yu, and L. Guibas. Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions. Advances in neural information processing systems (NIPS), 2018",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"P.-S. Wang, Y. Liu, Y.-X. Guo, C.-Y. Sun, and X. Tong. OCNN: Octree-based convolutional neural networks for 3D shape analysis. ACM Transactions on Graphics (TOG)",36(4):72,,,,2017,,"P.-S. Wang, Y. Liu, Y.-X. Guo, C.-Y. Sun, and X. Tong. OCNN: Octree-based convolutional neural networks for 3D shape analysis. ACM Transactions on Graphics (TOG), 36(4):72, 2017",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,,,,,,,,"W. Wang, R. Yu, Q. Huang, and U. Neumann. SGPN: Similarity group proposal network for 3D point cloud instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 2569",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,,,,,,,,"X. Wang, B. Zhou, H. Fang, X. Chen, Q. Zhao, and K. Xu. Learning to group and label fine-grained shape components. ACM Transactions on Graphics (SIGGRAPH Asia 2018)",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"Y. Wang, S. Asafi, O. Van Kaick, H. Zhang, D. Cohen-Or, and B. Chen. Active co-analysis of a set of shapes. ACM Transactions on Graphics (TOG)",31(6):165,,,,2012,,"Y. Wang, S. Asafi, O. Van Kaick, H. Zhang, D. Cohen-Or, and B. Chen. Active co-analysis of a set of shapes. ACM Transactions on Graphics (TOG), 31(6):165, 2012",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"Y. Wang, Y. Sun, Z. Liu, S. E. Sarma",M. M. Bronstein,and J. M. Solomon. Dynamic graph cnn for learning on point clouds. arXiv preprint arXiv:1801.07829,,,2018,,"Y. Wang, Y. Sun, Z. Liu, S. E. Sarma, M. M. Bronstein, and J. M. Solomon. Dynamic graph cnn for learning on point clouds. arXiv preprint arXiv:1801.07829, 2018",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,,,,,,,,"Z. Wang and F. Lu. VoxSegNet: Volumetric CNNs for semantic part segmentation of 3D shapes. arXiv preprint arXiv:1809.00226, 2018",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"Z. Wu, X. Wang, D. Lin, D. Lischinski, D. Cohen-Or",and H. Huang. Structure-aware generative network for 3d-shape modeling. arXiv preprint arXiv:1808.03981,,,,2018,,"Z. Wu, X. Wang, D. Lin, D. Lischinski, D. Cohen-Or, and H. Huang. Structure-aware generative network for 3d-shape modeling. arXiv preprint arXiv:1808.03981, 2018",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"Y. Xu, T. Fan, M. Xu, L. Zeng",and Y. Qiao. SpiderCNN: Deep learning on point sets with parameterized convolutional filters. European Conference on Computer Vision (ECCV),,,,2018,,"Y. Xu, T. Fan, M. Xu, L. Zeng, and Y. Qiao. SpiderCNN: Deep learning on point sets with parameterized convolutional filters. European Conference on Computer Vision (ECCV), 2018",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"Lee, S., Alexander, M. L., Jacobs, D. W., Belhumeur, P. N.",Birdsnap: Large-scale fine-grained visual categorization of birds,CVPR,,,2014,pp. 2011–2018,"Lee, S., Alexander, M. L., Jacobs, D. W., and Belhumeur, P. N. Birdsnap: Large-scale fine-grained visual categorization of birds. CVPR, pp. 2011–2018, 2014.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"Bossard, L., Guillaumin, M.",", and Van Gool, L",Food-101– mining discriminative components with random forests. ECCV,,,2014,pp. 446–461,"Bossard, L., Guillaumin, M., and Van Gool, L. Food-101– mining discriminative components with random forests. ECCV, pp. 446–461, 2014.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"Cai, H., Zhu, L., Han, S.",Proxylessnas: Direct neural architecture search on target task and hardware,ICLR,,,2019,,"Cai, H., Zhu, L., and Han, S. Proxylessnas: Direct neural architecture search on target task and hardware. ICLR, 2019.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"Cubuk, E. D., Zoph, B., Mane, D., Vasudevan, V., Le, Q. V.",Autoaugment: Learning augmentation policies from data,CVPR,,,2019,,"Cubuk, E. D., Zoph, B., Mane, D., Vasudevan, V., and Le, Q. V. Autoaugment: Learning augmentation policies from data. CVPR, 2019.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"Elfwing, S., Uchibe, E., Doya, K.",Sigmoid-weighted linear units for neural network function approximation in reinforcement learning,Neural Networks,,,2018,107:3–11,"Elfwing, S., Uchibe, E., and Doya, K. Sigmoid-weighted linear units for neural network function approximation in reinforcement learning. Neural Networks, 107:3–11, 2018.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"Gholami, A., Kwon, K., Wu, B., Tai, Z., Yue, X., Jin, P., Zhao, S., Keutzer, K.",Squeezenext: Hardware-aware neural network design,ECV Workshop at CVPR’18,,,2018,,"Gholami, A., Kwon, K., Wu, B., Tai, Z., Yue, X., Jin, P., Zhao, S., and Keutzer, K. Squeezenext: Hardware-aware neural network design. ECV Workshop at CVPR’18, 2018.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"Han, S., Mao, H., Dally, W. J.","Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding",ICLR,,,2016,,"Han, S., Mao, H., and Dally, W. J. Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding. ICLR, 2016.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"He, K., Zhang, X., Ren, S., Sun, J.",Deep residual learning for image recognition,CVPR,,,2016,pp. 770–778,"He, K., Zhang, X., Ren, S., and Sun, J. Deep residual learning for image recognition. CVPR, pp. 770–778, 2016.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"He, K., Gkioxari, G., Dollár, P., Girshick, R.",Mask r-cnn,ICCV,,,2017,pp. 2980–2988,"He, K., Gkioxari, G., Dollár, P., and Girshick, R. Mask r-cnn. ICCV, pp. 2980–2988, 2017.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"He, Y., Lin, J., Liu, Z., Wang, H., Li, L.-J., Han, S.",Amc: Automl for model compression and acceleration on mobile devices,ECCV,,,2018,,"He, Y., Lin, J., Liu, Z., Wang, H., Li, L.-J., and Han, S. Amc: Automl for model compression and acceleration on mobile devices. ECCV, 2018.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"Hendrycks, D., Gimpel, K.",Gaussian error linear units (gelus),arXiv preprint arXiv:1606.08415,,,2016,,"Hendrycks, D. and Gimpel, K. Gaussian error linear units (gelus). arXiv preprint arXiv:1606.08415, 2016.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"Howard, A. G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M., Adam, H.",Mobilenets: Efficient convolutional neural networks for mobile vision applications,arXiv preprint arXiv:1704.04861,,,2017,,"Howard, A. G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M., and Adam, H. Mobilenets: Efficient convolutional neural networks for mobile vision applications. arXiv preprint arXiv:1704.04861, 2017.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"Hu, J., Shen, L., Sun, G.",Squeeze-and-excitation networks,CVPR,,,2018,,"Hu, J., Shen, L., and Sun, G. Squeeze-and-excitation networks. CVPR, 2018.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"Huang, G., Sun, Y., Liu, Z., Sedra, D., Weinberger, K. Q.",Deep networks with stochastic depth,ECCV,,,2016,pp. 646–661,"Huang, G., Sun, Y., Liu, Z., Sedra, D., and Weinberger, K. Q. Deep networks with stochastic depth. ECCV, pp. 646–661, 2016.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"Maaten, L., Weinberger, K. Q.",Densely connected convolutional networks,CVPR,,,2017,,"Maaten, L., and Weinberger, K. Q. Densely connected convolutional networks. CVPR, 2017.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"Huang, Y., Cheng, Y., Chen, D., Lee, H., Ngiam, J., Le, Q. V., Chen, Z.",Gpipe: Efficient training of giant neural networks using pipeline parallelism,arXiv preprint arXiv:1808.07233,,,2018,,"Huang, Y., Cheng, Y., Chen, D., Lee, H., Ngiam, J., Le, Q. V., and Chen, Z. Gpipe: Efficient training of giant neural networks using pipeline parallelism. arXiv preprint arXiv:1808.07233, 2018.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"Iandola, F. N., Han, S., Moskewicz, M. W., Ashraf, K., Dally, W. J.",", and Keutzer, K",Squeezenet: Alexnet-level accuracy with 50x fewer parameters and <0.5 mb model size. arXiv preprint arXiv:1602.07360,,,2016,,"Iandola, F. N., Han, S., Moskewicz, M. W., Ashraf, K., Dally, W. J., and Keutzer, K. Squeezenet: Alexnet-level accuracy with 50x fewer parameters and <0.5 mb model size. arXiv preprint arXiv:1602.07360, 2016.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"Ioffe, S., Szegedy, C.",Batch normalization: Accelerating deep network training by reducing internal covariate shift,ICML,,,2015,pp. 448–456,"Ioffe, S. and Szegedy, C. Batch normalization: Accelerating deep network training by reducing internal covariate shift. ICML, pp. 448–456, 2015.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"Raghu, M., Poole, B., Kleinberg, J., Ganguli, S., SohlDickstein, J.",On the expressive power of deep neural networks,ICML,,,2017,,"Raghu, M., Poole, B., Kleinberg, J., Ganguli, S., and SohlDickstein, J. On the expressive power of deep neural networks. ICML, 2017.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"Kornblith, S., Shlens, J., Le, Q.",V,Do better imagenet models transfer better? CVPR,,,2019,,"Kornblith, S., Shlens, J., and Le, Q. V. Do better imagenet models transfer better? CVPR, 2019.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"Ramachandran, P., Zoph, B., Le, Q. V.",Searching for activation functions,arXiv preprint arXiv:1710.05941,,,2018,,"Ramachandran, P., Zoph, B., and Le, Q. V. Searching for activation functions. arXiv preprint arXiv:1710.05941, 2018.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"Krause, J., Deng, J., Stark, M., Fei-Fei, L.",Collecting a large-scale dataset of fine-grained cars,Second Workshop on Fine-Grained Visual Categorizatio,,,2013,,"Krause, J., Deng, J., Stark, M., and Fei-Fei, L. Collecting a large-scale dataset of fine-grained cars. Second Workshop on Fine-Grained Visual Categorizatio, 2013.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"Krizhevsky, A., Hinton, G.",Learning multiple layers of features from tiny images,Technical Report,,,2009,,"Krizhevsky, A. and Hinton, G. Learning multiple layers of features from tiny images. Technical Report, 2009.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"Real, E., Aggarwal, A., Huang, Y., Le, Q. V.",Regularized evolution for image classifier architecture search,AAAI,,,2019,,"Real, E., Aggarwal, A., Huang, Y., and Le, Q. V. Regularized evolution for image classifier architecture search. AAAI, 2019.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"Krizhevsky, A., Sutskever, I., Hinton, G. E.",Imagenet classification with deep convolutional neural networks,In NIPS,,,2012,pp. 1097–1105,"Krizhevsky, A., Sutskever, I., and Hinton, G. E. Imagenet classification with deep convolutional neural networks. In NIPS, pp. 1097–1105, 2012.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"Lin, H., Jegelka, S.",Resnet with one-neuron hidden layers is a universal approximator,NeurIPS,,,2018,pp. 6172– 6181,"Lin, H. and Jegelka, S. Resnet with one-neuron hidden layers is a universal approximator. NeurIPS, pp. 6172– 6181, 2018.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., Chen, L.-C.",Mobilenetv2: Inverted residuals and linear bottlenecks,CVPR,,,2018,,"Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., and Chen, L.-C. Mobilenetv2: Inverted residuals and linear bottlenecks. CVPR, 2018.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"Lin, T.-Y., Dollár, P., Girshick, R., He, K., Hariharan, B., Belongie, S.",Feature pyramid networks for object detection,CVPR,,,2017,,"Lin, T.-Y., Dollár, P., Girshick, R., He, K., Hariharan, B., and Belongie, S. Feature pyramid networks for object detection. CVPR, 2017.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"Sharir, O., Shashua, A.",On the expressive power of overlapping architectures of deep learning,ICLR,,,2018,,"Sharir, O. and Shashua, A. On the expressive power of overlapping architectures of deep learning. ICLR, 2018.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"Liu, C., Zoph, B., Shlens, J., Hua, W., Li, L.-J., Fei-Fei, L., Yuille, A., Huang, J., Murphy, K.",Progressive neural architecture search,ECCV,,,2018,,"Liu, C., Zoph, B., Shlens, J., Hua, W., Li, L.-J., Fei-Fei, L., Yuille, A., Huang, J., and Murphy, K. Progressive neural architecture search. ECCV, 2018.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., Salakhutdinov, R.",Dropout: a simple way to prevent neural networks from overfitting,The Journal of Machine Learning Research,,,2014,15(1):1929–1958,"Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., and Salakhutdinov, R. Dropout: a simple way to prevent neural networks from overfitting. The Journal of Machine Learning Research, 15(1):1929–1958, 2014.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"Lu, Z., Pu, H., Wang, F., Hu, Z., Wang, L.",The expressive power of neural networks: A view from the width,NeurIPS,,,2018,,"Lu, Z., Pu, H., Wang, F., Hu, Z., and Wang, L. The expressive power of neural networks: A view from the width. NeurIPS, 2018.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"Ma, N., Zhang, X., Zheng, H.-T., Sun, J.",Shufflenet v2: Practical guidelines for efficient cnn architecture design,ECCV,,,2018,,"Ma, N., Zhang, X., Zheng, H.-T., and Sun, J. Shufflenet v2: Practical guidelines for efficient cnn architecture design. ECCV, 2018.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"Mahajan, D., Girshick, R., Ramanathan, V., He, K., Paluri, M., Li, Y., Bharambe, A.",", and van der Maaten, L",Exploring the limits of weakly supervised pretraining. arXiv preprint arXiv:1805.00932,,,2018,,"Mahajan, D., Girshick, R., Ramanathan, V., He, K., Paluri, M., Li, Y., Bharambe, A., and van der Maaten, L. Exploring the limits of weakly supervised pretraining. arXiv preprint arXiv:1805.00932, 2018.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Vanhoucke, V., Rabinovich, A.",Going deeper with convolutions,CVPR,,,2015,pp. 1–9,"Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Vanhoucke, V., and Rabinovich, A. Going deeper with convolutions. CVPR, pp. 1–9, 2015.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z.",Rethinking the inception architecture for computer vision,CVPR,,,2016,pp. 2818–2826,"Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., and Wojna, Z. Rethinking the inception architecture for computer vision. CVPR, pp. 2818–2826, 2016.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A. A.","Inception-v4, inception-resnet and the impact of residual connections on learning",AAAI,,,2017,4:12,"Szegedy, C., Ioffe, S., Vanhoucke, V., and Alemi, A. A. Inception-v4, inception-resnet and the impact of residual connections on learning. AAAI, 4:12, 2017.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"Maji, S., Rahtu, E., Kannala, J., Blaschko, M., Vedaldi, A.",Fine-grained visual classification of aircraft,arXiv preprint arXiv:1306.5151,,,2013,,"Maji, S., Rahtu, E., Kannala, J., Blaschko, M., and Vedaldi, A. Fine-grained visual classification of aircraft. arXiv preprint arXiv:1306.5151, 2013.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"Tan, M., Chen, B., Pang, R., Vasudevan, V., Sandler, M., Howard, A., Le, Q. V.",MnasNet: Platform-aware neural architecture search for mobile,CVPR,,,2019,,"Tan, M., Chen, B., Pang, R., Vasudevan, V., Sandler, M., Howard, A., and Le, Q. V. MnasNet: Platform-aware neural architecture search for mobile. CVPR, 2019.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"Ngiam, J., Peng, D., Vasudevan, V., Kornblith, S., Le, Q. V., Pang, R.",Domain adaptive transfer learning with specialist models,arXiv preprint arXiv:1811.07056,,,2018,,"Ngiam, J., Peng, D., Vasudevan, V., Kornblith, S., Le, Q. V., and Pang, R. Domain adaptive transfer learning with specialist models. arXiv preprint arXiv:1811.07056, 2018.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"Xie, S., Girshick, R., Dollár, P., Tu, Z., He, K.",Aggregated residual transformations for deep neural networks,CVPR,,,2017,pp. 5987–5995,"Xie, S., Girshick, R., Dollár, P., Tu, Z., and He, K. Aggregated residual transformations for deep neural networks. CVPR, pp. 5987–5995, 2017.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"Nilsback, M.-E., Zisserman, A.",Automated flower classification over a large number of classes,ICVGIP,,,2008,pp. 722–729,"Nilsback, M.-E. and Zisserman, A. Automated flower classification over a large number of classes. ICVGIP, pp. 722–729, 2008.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"Yang, T.-J., Howard, A., Chen, B., Zhang, X., Go, A., Sze, V., Adam, H.",Netadapt: Platform-aware neural network adaptation for mobile applications,ECCV,,,2018,,"Yang, T.-J., Howard, A., Chen, B., Zhang, X., Go, A., Sze, V., and Adam, H. Netadapt: Platform-aware neural network adaptation for mobile applications. ECCV, 2018.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"Parkhi, O. M., Vedaldi, A., Zisserman, A., Jawahar, C.",Cats and dogs,CVPR,,,2012,pp. 3498–3505,"Parkhi, O. M., Vedaldi, A., Zisserman, A., and Jawahar, C. Cats and dogs. CVPR, pp. 3498–3505, 2012.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"Zagoruyko, S., Komodakis, N.",Wide residual networks,BMVC,,,2016,,"Zagoruyko, S. and Komodakis, N. Wide residual networks. BMVC, 2016.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"Zhang, X., Li, Z., Loy, C. C., Lin, D.",Polynet: A pursuit of structural diversity in very deep networks,CVPR,,,2017,pp. 3900–3908,"Zhang, X., Li, Z., Loy, C. C., and Lin, D. Polynet: A pursuit of structural diversity in very deep networks. CVPR, pp. 3900–3908, 2017.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"Zhang, X., Zhou, X., Lin, M., Sun, J.",Shufflenet: An extremely efficient convolutional neural network for mobile devices,CVPR,,,2018,,"Zhang, X., Zhou, X., Lin, M., and Sun, J. Shufflenet: An extremely efficient convolutional neural network for mobile devices. CVPR, 2018.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"Zhou, B., Khosla, A., Lapedriza, A., Oliva, A., Torralba, A.",Learning deep features for discriminative localization,CVPR,,,2016,pp. 2921–2929,"Zhou, B., Khosla, A., Lapedriza, A., Oliva, A., and Torralba, A. Learning deep features for discriminative localization. CVPR, pp. 2921–2929, 2016.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"Zoph, B., Le, Q. V.",Neural architecture search with reinforcement learning,ICLR,,,2017,,"Zoph, B. and Le, Q. V. Neural architecture search with reinforcement learning. ICLR, 2017.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"Zoph, B., Vasudevan, V., Shlens, J., Le, Q. V.",Learning transferable architectures for scalable image recognition,CVPR,,,2018,,"Zoph, B., Vasudevan, V., Shlens, J., and Le, Q. V. Learning transferable architectures for scalable image recognition. CVPR, 2018.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,,,,,,,,up to the inception (4e) block 3 whose output is a 7 × 7 feature map with 1024,./refs/download/A compact embedding for facial expression similarity.pdf,
0,"Y. Guo, L. Zhang, Y. Hu, X. He",and J. Gao. MS-Celeb-1M: A dataset and benchmark for large scale face recognition. In ECCV,,,,2016,,"Y. Guo, L. Zhang, Y. Hu, X. He, and J. Gao. MS-Celeb-1M: A dataset and benchmark for large scale face recognition. In ECCV, 2016",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"X. He, Y. Zhou, Z. Zhou, S. Bai",and X. Bai. Triplet-center loss for multi-view 3D object retrieval. In CVPR,,,,2018,,"X. He, Y. Zhou, Z. Zhou, S. Bai, and X. Bai. Triplet-center loss for multi-view 3D object retrieval. In CVPR, 2018",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"A. Hermans, L. Beyer, and B. Leibe. In defense of the triplet loss for person re-identification. CoRR",abs/1703.07737,,,,2017,,"A. Hermans, L. Beyer, and B. Leibe. In defense of the triplet loss for person re-identification. CoRR, abs/1703.07737, 2017",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"G. Huang, Z. Liu, L. van der Maaten",and K. Q. Weinberger. Densely connected convolutional networks. In CVPR,,,,2017,,"G. Huang, Z. Liu, L. van der Maaten, and K. Q. Weinberger. Densely connected convolutional networks. In CVPR, 2017",./refs/download/A compact embedding for facial expression similarity.pdf,
0,,,,,,,,"S. Ioffe and C. Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. In ICML, 2015",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"I. Kemelmacher-Shlizerman, S. M. Seitz",D. Miller,and E. Brossard. The MegaFace benchmark: 1 million faces for recognition at scale. In CVPR,,,2016,,"I. Kemelmacher-Shlizerman, S. M. Seitz, D. Miller, and E. Brossard. The MegaFace benchmark: 1 million faces for recognition at scale. In CVPR, 2016",./refs/download/A compact embedding for facial expression similarity.pdf,
0,D. P. Kingma and J. Ba. Adam: A method for stochastic optimization. CoRR,abs/1412.6980,,,,2014,,"D. P. Kingma and J. Ba. Adam: A method for stochastic optimization. CoRR, abs/1412.6980, 2014",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"M. Soleymani, J. Lee, A. Yazdani, T. Ebrahimi, T. Pun, A. Nijholt, and I. Patras. DEAP: A database for emotion analysis using physiological signals. IEEE Transactions on Affective Computing",3(1):18– 31,,,,2012,,"S. Koelstra, C. Mühl, M. Soleymani, J. Lee, A. Yazdani, T. Ebrahimi, T. Pun, A. Nijholt, and I. Patras. DEAP: A database for emotion analysis using physiological signals. IEEE Transactions on Affective Computing, 3(1):18– 31, 2012",./refs/download/A compact embedding for facial expression similarity.pdf,
0,A. S. Koepke,O. Wiles,and A. Zisserman. Self-supervised learning of a facial attribute embedding from video. In BMVC,,,2018,,"A. S. Koepke, O. Wiles, and A. Zisserman. Self-supervised learning of a facial attribute embedding from video. In BMVC, 2018",./refs/download/A compact embedding for facial expression similarity.pdf,
0,deep architectures,and beyond. CoRR,abs/1804.10938,,,2018,,"D. Kollias, P. Tzirakis, M. A. Nicolaou, A. Papaioannou, G. Zhao, B. W. Schuller, I. Kotsia, and S. Zafeiriou. Deep affect prediction in-the-wild: Aff-wild database and challenge, deep architectures, and beyond. CoRR, abs/1804.10938, 2018",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"J. Kossaifi, G. Tzimiropoulos, S. Todorovic, and M. Pantic. AFEW-VA database for valence and arousal estimation inthe-wild. Image and Vision Computing",65:23–36,,,,2017,,"J. Kossaifi, G. Tzimiropoulos, S. Todorovic, and M. Pantic. AFEW-VA database for valence and arousal estimation inthe-wild. Image and Vision Computing, 65:23–36, 2017",./refs/download/A compact embedding for facial expression similarity.pdf,
0,,,,,,,,"A. Krizhevsky. Convolutional deep belief networks on CIFAR-10. Unpublished manuscript, 2010",./refs/download/A compact embedding for facial expression similarity.pdf,
0,S. Li and W. Deng. Deep facial expression recognition: A survey. CoRR,abs/1804.08348,,,,2018,,"S. Li and W. Deng. Deep facial expression recognition: A survey. CoRR, abs/1804.08348, 2018",./refs/download/A compact embedding for facial expression similarity.pdf,
0,S. Li and W. Deng. Reliable crowdsourcing and deep locality-preserving learning for unconstrained facial expression recognition. IEEE Transactions on Image Processing,28(1):356–370,,,,2019,,"S. Li and W. Deng. Reliable crowdsourcing and deep locality-preserving learning for unconstrained facial expression recognition. IEEE Transactions on Image Processing, 28(1):356–370, 2019",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"H. Liu, Y. Tian, Y. Wang, L. Pang",and T. Huang. Deep relative distance learning: Tell the difference between similar vehicles. In CVPR,,,,2016,,"H. Liu, Y. Tian, Y. Wang, L. Pang, and T. Huang. Deep relative distance learning: Tell the difference between similar vehicles. In CVPR, 2016",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"Z. Liu, P. Luo, X. Wang",and X. Tang. Deep learning face attributes in the wild. In ICCV,,,,2015,,"Z. Liu, P. Luo, X. Wang, and X. Tang. Deep learning face attributes in the wild. In ICCV, 2015",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"F. Cohn, T. Kanade, J. M. Saragih",Z. Ambadar,and I. A. Matthews. The extended Cohn-Kanade dataset (CK+): A complete dataset for action unit and emotionspecified expression. In CVPR Workshops,,,2010,,"P. Lucey, J. F. Cohn, T. Kanade, J. M. Saragih, Z. Ambadar, and I. A. Matthews. The extended Cohn-Kanade dataset (CK+): A complete dataset for action unit and emotionspecified expression. In CVPR Workshops, 2010",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"B. Martinez, M. F. Valstar",B. Jiang,and M. Pantic. Automatic analysis of facial actions: A survey. IEEE Transactions on Affective Computing,,,2017,,"B. Martinez, M. F. Valstar, B. Jiang, and M. Pantic. Automatic analysis of facial actions: A survey. IEEE Transactions on Affective Computing, 2017",./refs/download/A compact embedding for facial expression similarity.pdf,
0,Visualizing data using t-SNE. Journal of Machine Learning Research,9:2579–2605,,,,2008,,"Visualizing data using t-SNE. Journal of Machine Learning Research, 9:2579–2605, 2008",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"F. Benitez-Quiroz, R. Srinivasan, and A. M. Martı́nez. Emotionet: An accurate",real-time algorithm for the automatic annotation of a million facial expressions in the wild. In CVPR,,,,2016,,"C. F. Benitez-Quiroz, R. Srinivasan, and A. M. Martı́nez. Emotionet: An accurate, real-time algorithm for the automatic annotation of a million facial expressions in the wild. In CVPR, 2016",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"G. Chechik, V. Sharma, U. Shalit, and S. Bengio. Large scale online learning of image similarity through ranking. Journal of Machine Learning Research",11:1109–1135,,,,2010,,"G. Chechik, V. Sharma, U. Shalit, and S. Bengio. Large scale online learning of image similarity through ranking. Journal of Machine Learning Research, 11:1109–1135, 2010",./refs/download/A compact embedding for facial expression similarity.pdf,
0,C. A. Corneanu,M. Madadi,and S. Escalera. Deep structure inference network for facial action unit recognition. In ECCV,,,2018,,"C. A. Corneanu, M. Madadi, and S. Escalera. Deep structure inference network for facial action unit recognition. In ECCV, 2018",./refs/download/A compact embedding for facial expression similarity.pdf,
0,A. S. Cowen and D. Keltner. Self-report captures 27 distinct categories of emotion bridged by continuous gradients. Proceedings of the National Academy of Sciences,114(38):E7900E7909,,,,2017,,"A. S. Cowen and D. Keltner. Self-report captures 27 distinct categories of emotion bridged by continuous gradients. Proceedings of the National Academy of Sciences, 114(38):E7900E7909, 2017",./refs/download/A compact embedding for facial expression similarity.pdf,
0,dimensionality,and structure of emotion. Trends in Cognitive Sciences,22(4):274–276,,,2018,,"A. S. Cowen and D. Keltner. Clarifying the conceptualization, dimensionality, and structure of emotion. Trends in Cognitive Sciences, 22(4):274–276, 2018",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"A. Dhall, R. Goecke, S. Ghosh, J. Joshi, J. Hoey",and T. Gedeon. From individual to group-level emotion recognition: Emotiw 5.0. In ICMI,,,,2017,,"A. Dhall, R. Goecke, S. Ghosh, J. Joshi, J. Hoey, and T. Gedeon. From individual to group-level emotion recognition: Emotiw 5.0. In ICMI, 2017",./refs/download/A compact embedding for facial expression similarity.pdf,
0,,,,,,,,"A. Dhall, R. Goecke, J. Joshi, M. Wagner, and T. Gedeon. Emotion recognition in the wild challenge 2013",./refs/download/A compact embedding for facial expression similarity.pdf,
0,,,,,,,,"A. Dhall, O. V. R. Murthy, R. Goecke, J. Joshi, and T. Gedeon. Video and image based emotion recognition challenges in the wild: Emotiw 2015",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"P. Ekman, W. V. Friesen",and J. C. Hager. Facial Action Coding System - Manual. A Human Face,,,,2002,,"P. Ekman, W. V. Friesen, and J. C. Hager. Facial Action Coding System - Manual. A Human Face, 2002",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"J. Fiss, A. Agarwala, and B. Curless. Candid portrait selection from video. ACM Transactions on Graphics",30(6):128:1–128:8,,,,2011,,"J. Fiss, A. Agarwala, and B. Curless. Candid portrait selection from video. ACM Transactions on Graphics, 30(6):128:1–128:8, 2011",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"W. Ge, W. Huang, D. Dong",and M. R. Scott. Deep metric learning with hierarchical triplet loss. In ECCV,,,,2018,,"W. Ge, W. Huang, D. Dong, and M. R. Scott. Deep metric learning with hierarchical triplet loss. In ECCV, 2018",./refs/download/A compact embedding for facial expression similarity.pdf,
0,,,,,,,,"X. Glorot and Y. Bengio. Understanding the difficulty of training deep feedforward neural networks. In AISTATS, 2010",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"T. Ionescu, M. Popescu, C. Grozea, J. Bergstra, J. Xie, L. Romaszko, B. Xu, Z. Chuang, and Y. Bengio. Challenges in representation learning: A report on three machine learning contests. Neural Networks",64:59–63,,,,2015,,"I. J. Goodfellow, D. Erhan, P. L. Carrier, A. C. Courville, M. Mirza, B. Hamner, W. Cukierski, Y. Tang, D. Thaler, D. Lee, Y. Zhou, C. Ramaiah, F. Feng, R. Li, X. Wang, D. Athanasakis, J. Shawe-Taylor, M. Milakov, J. Park, R. T. Ionescu, M. Popescu, C. Grozea, J. Bergstra, J. Xie, L. Romaszko, B. Xu, Z. Chuang, and Y. Bengio. Challenges in representation learning: A report on three machine learning contests. Neural Networks, 64:59–63, 2015",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"F. Cohn, T. Kanade, and S. Baker. Multi-PIE. Image and Vision Computing",28(5):807–813,,,,2010,,"R. Gross, I. A. Matthews, J. F. Cohn, T. Kanade, and S. Baker. Multi-PIE. Image and Vision Computing, 28(5):807–813, 2010",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"G. Zhao, X. Huang, M. Taini, S. Z. Li",and M. Pietikäinen. Facial expression recognition from near-infrared videos. Image and Vision Computing,29(9):607–619,,,2011,,"G. Zhao, X. Huang, M. Taini, S. Z. Li, and M. Pietikäinen. Facial expression recognition from near-infrared videos. Image and Vision Computing, 29(9):607–619, 2011",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"B. Zhuang, G. Lin, C. Shen",and I. D. Reid. Fast training of triplet-based deep binary embedding networks. In CVPR,,,,2016,,"B. Zhuang, G. Lin, C. Shen, and I. D. Reid. Fast training of triplet-based deep binary embedding networks. In CVPR, 2016",./refs/download/A compact embedding for facial expression similarity.pdf,
0,,,,,,,,in 1998,./refs/download/Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms.pdf,
0,making it immediately compatible with any machine learning package capable of working with the original MNIST dataset.  References D. Ciregan,U. Meier,and J. Schmidhuber. Multi-column deep neural networks for image classification. In Computer Vision and Pattern Recognition (CVPR),,,2012,," PassiveAggressiveClassifier  C=1 C=100 C=10  Perceptron  penalty=l1 penalty=l2 penalty=elasticnet  RandomForestClassifier  n_estimators=100 criterion=entropy max_depth=100 n_estimators=100 criterion=gini max_depth=100 n_estimators=50 criterion=entropy max_depth=100 n_estimators=100 criterion=entropy max_depth=50 n_estimators=50 criterion=entropy max_depth=50 n_estimators=100 criterion=gini max_depth=50 n_estimators=50 criterion=gini max_depth=50 n_estimators=50 criterion=gini max_depth=100 n_estimators=10 criterion=entropy max_depth=50 n_estimators=10 criterion=entropy max_depth=100 n_estimators=10 criterion=gini max_depth=50 n_estimators=10 criterion=gini max_depth=100 n_estimators=50 criterion=entropy max_depth=10 n_estimators=100 criterion=entropy max_depth=10 n_estimators=100 criterion=gini max_depth=10 n_estimators=50 criterion=gini max_depth=10 n_estimators=10 criterion=entropy max_depth=10 n_estimators=10 criterion=gini max_depth=10  SGDClassifier  loss=hinge penalty=l2 loss=perceptron penalty=l1 loss=modified_huber penalty=l1 loss=modified_huber penalty=l2 loss=log penalty=elasticnet loss=hinge penalty=elasticnet  Fashion  MNIST  0.751 0.749 0.748 0.736 0.516 0.496 0.492 0.484  0.783 0.816 0.829 0.829 0.759 0.753 0.746 0.737  0.842 0.841 0.839 0.839 0.836  0.917 0.917 0.916 0.909 0.916  0.871 0.870 0.868 0.863 0.850 0.848 0.841 0.840  0.972 0.972 0.962 0.957 0.936 0.933 0.921 0.921  0.776 0.775 0.773  0.877 0.875 0.880  0.782 0.754 0.726  0.887 0.845 0.845  0.873 0.872 0.872 0.872 0.871 0.871 0.870 0.869 0.853 0.852 0.848 0.847 0.838 0.838 0.835 0.834 0.828 0.825  0.970 0.970 0.968 0.969 0.967 0.971 0.968 0.967 0.949 0.949 0.948 0.948 0.947 0.950 0.949 0.945 0.933 0.930  0.819 0.818 0.817 0.816 0.816 0.816  0.914 0.912 0.910 0.913 0.912 0.913  Continued on next page 5  Table 3 – continued from previous page Test Accuracy Classifier  Parameter loss=squared_hinge penalty=elasticnet loss=hinge penalty=l1 loss=log penalty=l1 loss=perceptron penalty=l2 loss=perceptron penalty=elasticnet loss=squared_hinge penalty=l2 loss=modified_huber penalty=elasticnet loss=log penalty=l2 loss=squared_hinge penalty=l1  SVC  C=10 kernel=rbf C=10 kernel=poly C=100 kernel=poly C=100 kernel=rbf C=1 kernel=rbf C=1 kernel=poly C=1 kernel=linear C=10 kernel=linear C=100 kernel=linear C=1 kernel=sigmoid C=10 kernel=sigmoid C=100 kernel=sigmoid  Fashion  MNIST  0.815 0.815 0.815 0.814 0.814 0.814 0.813 0.813 0.813  0.914 0.911 0.910 0.913 0.912 0.912 0.914 0.913 0.911  0.897 0.891 0.890 0.890 0.879 0.873 0.839 0.829 0.827 0.678 0.671 0.664  0.973 0.976 0.978 0.972 0.966 0.957 0.929 0.927 0.926 0.898 0.873 0.868  4 Conclusions This paper introduced Fashion-MNIST, a fashion product images dataset intended to be a dropin replacement of MNIST and whilst providing a more challenging alternative for benchmarking machine learning algorithm. The images in Fashion-MNIST are converted to a format that matches that of the MNIST dataset, making it immediately compatible with any machine learning package capable of working with the original MNIST dataset.  References D. Ciregan, U. Meier, and J. Schmidhuber. Multi-column deep neural networks for image classification. In Computer Vision and Pattern Recognition (CVPR), 2012",./refs/download/Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms.pdf,
0,,,,,,,,"is a large scale image ontology database. The investigators of this project, namely Pr. Li Fei-Fei and her colleagues at Princeton University, have started their efforts in 2009",./refs/download/Imagenet: A large-scale hierarchical image database.pdf,
0,,,,,,,,"ontology. It is a “large lexical database of English. Nouns, verbs, adjectives and adverbs are grouped into sets of cognitive synonyms (synsets), each expressing a distinct concept”. Hence, ImageNet can be viewed as a tree where each node corresponds to a synset. Each node contains 500 to 1000",./refs/download/Imagenet: A large-scale hierarchical image database.pdf,
0,,,,,,,,"based features or object attributes, but only for images of small subsets of the 21,841 synsets (1000",./refs/download/Imagenet: A large-scale hierarchical image database.pdf,
0,,,,,,,,"J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei, “ImageNet: A Large-Scale Hierarchical Image Database,” in CVPR09, 2009",./refs/download/Imagenet: A large-scale hierarchical image database.pdf,
0,C. Fellbaum,WordNet: An Electronic Lexical Database. Bradford Books,,,,1998,,"C. Fellbaum, WordNet: An Electronic Lexical Database. Bradford Books, 1998",./refs/download/Imagenet: A large-scale hierarchical image database.pdf,
0,vol. 60,no. 2,pp. 91–110,,,2004,,"D. G. Lowe, “Distinctive image features from scale-invariant keypoints,” International Journal of Computer Vision, vol. 60, no. 2, pp. 91–110, 2004",./refs/download/Imagenet: A large-scale hierarchical image database.pdf,
0,NY,USA: John Wiley & Sons,Inc.,,,2002,,"P. Salembier and T. Sikora, Introduction to MPEG-7: Multimedia Content Description Interface, B. Manjunath, Ed. New York, NY, USA: John Wiley & Sons, Inc., 2002",./refs/download/Imagenet: A large-scale hierarchical image database.pdf,
0,,,,,,,,"T. Sikora, “The mpeg-7 visual standard for content description-an overview,” IEEE Transactions on Circuits and Systems for Video Technology, vol. 11, no. 6, pp. 696–702, Jun 2001",./refs/download/Imagenet: A large-scale hierarchical image database.pdf,
0,,,,,,,,"B. S. Manjunath, J. R. Ohm, V. V. Vasudevan, and A. Yamada, “Color and texture descriptors,” IEEE Transactions on Circuits and Systems for Video Technology, vol. 11, no. 6, pp. 703–715, Jun 2001",./refs/download/Imagenet: A large-scale hierarchical image database.pdf,
0,,,,,,,,"M. Bober, “Mpeg-7 visual shape descriptors,” IEEE Transactions on Circuits and Systems for Video Technology, vol. 11, no. 6, pp. 716–719, Jun 2001",./refs/download/Imagenet: A large-scale hierarchical image database.pdf,
0,,,,,,,,"S. Jeannin and A. Divakaran, “Mpeg-7 visual motion descriptors,” IEEE Transactions on Circuits and Systems for Video Technology, vol. 11, no. 6, pp. 720–724, Jun 2001",./refs/download/Imagenet: A large-scale hierarchical image database.pdf,
0,vol. 24,no. 1,pp. 23–30,,,2002,,"C. S. Won, D. K. Park, and Y. S. Jeon, “Efficient use of mpeg-7 edge histogram descriptor,” ETRI Journal, vol. 24, no. 1, pp. 23–30, 2002",./refs/download/Imagenet: A large-scale hierarchical image database.pdf,
0,” Moving Picture Experts Group,Tech. Rep.,,,,2000,,"MPEG, “Iso/iec/jtc1/sc29/wg11 - core experiment results for edge histogram descriptor (ct4)), mpeg document m6174,” Moving Picture Experts Group, Tech. Rep., 2000",./refs/download/Imagenet: A large-scale hierarchical image database.pdf,
0,,,,,,,,0.1007  0.4 0.3  64 bits 0.6835 0.5732 0.5645 0.5538 0.5852 0.3943 0.5764 0.5520 0.3578 0.4191 0.3596  NUS-WIDE 32 bits 48 bits 0.6988 0.7114 0.6637 0.6692 0.6158 0.6345 0.5827 0.5926 0.5545 0.5786 0.3327 0.3124 0.4052 0.3732 0.5425 0.5580 0.5290 0.5475 0.4209 0.4211 0.4227 0.4333  16 bits 0.6623 0.6374 0.5976 0.5696 0.4756 0.3561 0.4598 0.5086 0.5027 0.4058 0.3283  64 bits 0.7163 0.6714 0.6388 0.5996 0.5812 0.3368 0.3467 0.5611 0.5546 0.4104 0.5009  16 bits 0.6873 0.6774 0.5932 0.5642 0.5545 0.5212 0.5659 0.5818 0.5920 0.4951 0.4592  MS COCO 32 bits 48 bits 0.7184 0.7301 0.7013 0.6948 0.6034 0.6045 0.5744 0.5711 0.5642 0.5723 0.5343 0.5343 0.5624 0.5297 0.6243 0.6460 0.6224 0.6300 0.5071 0.5099 0.4856 0.5440  64 bits 0.7362 0.6944 0.6099 0.5671 0.5799 0.5361 0.5019 0.6574 0.6336 0.5101 0.5849  0.7  HashNet DHN DNNH CNNH ITQ-CCA KSH ITQ SH  0.6  Precision  Method  0.4 0.3  0.5  0.4 0.2  0.2  0.1  0.1  0  0 20  25  30  35  40  45  50  55  0  60  0.3 0.1  0.2  0.3  0.4  Number of bits  0.5  0.6  0.7  0.8  0.9  100  1  200  (a) Precision within Hamming radius 2  300  400  500  600  700  800  900 1000,./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,E. L. Allgower and K. Georg. Numerical continuation methods: an introduction,volume 13. Springer Science & Business Media,,,,2012,,"E. L. Allgower and K. Georg. Numerical continuation methods: an introduction, volume 13. Springer Science & Business Media, 2012",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,,,,,,,,"Y. Bengio, A. Courville, and P. Vincent. Representation learning: A review and new perspectives. IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 35(8):1798–1828, Aug 2013",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"T. Hoffman, editors",NIPS,pages 153–160. MIT Press,,,2007,,"Y. Bengio, P. Lamblin, D. Popovici, and H. Larochelle. Greedy layer-wise training of deep networks. In B. Schölkopf, J. C. Platt, and T. Hoffman, editors, NIPS, pages 153–160. MIT Press, 2007",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"T.-S. Chua, J. Tang, R. Hong, H. Li, Z. Luo",and Y.-T. Zheng. Nus-wide: A real-world web image database from national university of singapore. In ICMR. ACM,,,,2009,,"T.-S. Chua, J. Tang, R. Hong, H. Li, Z. Luo, and Y.-T. Zheng. Nus-wide: A real-world web image database from national university of singapore. In ICMR. ACM, 2009",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,,,,,,,,"M. Courbariaux and Y. Bengio. Binarynet: Training deep neural networks with weights and activations constrained to +1 or -1. In NIPS, 2016",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"H. Lai, Y. Pan, Y. Liu",and S. Yan. Simultaneous feature learning and hash coding with deep neural networks. In CVPR. IEEE,,,,2015,,"H. Lai, Y. Pan, Y. Liu, and S. Yan. Simultaneous feature learning and hash coding with deep neural networks. In CVPR. IEEE, 2015",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,approximations,and upper bounds. Journal of Machine Learning Research (JMLR),11(Dec):3313–3332,,,2010,,"J. P. Dmochowski, P. Sajda, and L. C. Parra. Maximum likelihood in cost-sensitive learning: Model specification, approximations, and upper bounds. Journal of Machine Learning Research (JMLR), 11(Dec):3313–3332, 2010",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,,,,,,,,"M. S. Lew, N. Sebe, C. Djeraba, and R. Jain. Contentbased multimedia information retrieval: State of the art and challenges. ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM), 2(1):1–19, Feb. 2006",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"J. Donahue, Y. Jia, O. Vinyals, J. Hoffman, N. Zhang, E. Tzeng",and T. Darrell. Decaf: A deep convolutional activation feature for generic visual recognition. In ICML,,,,2014,,"J. Donahue, Y. Jia, O. Vinyals, J. Hoffman, N. Zhang, E. Tzeng, and T. Darrell. Decaf: A deep convolutional activation feature for generic visual recognition. In ICML, 2014",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"W.-J. Li, S. Wang",and W.-C. Kang. Feature learning based deep supervised hashing with pairwise labels. In IJCAI,,,,2016,,"W.-J. Li, S. Wang, and W.-C. Kang. Feature learning based deep supervised hashing with pairwise labels. In IJCAI, 2016",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,,,,,,,,"V. Erin Liong, J. Lu, G. Wang, P. Moulin, and J. Zhou. Deep hashing for compact binary codes learning. In CVPR, pages 2475",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan, P. Dollár",and C. L. Zitnick. Microsoft coco: Common objects in context. In ECCV,pages 740–755. Springer,,,2014,,"T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan, P. Dollár, and C. L. Zitnick. Microsoft coco: Common objects in context. In ECCV, pages 740–755. Springer, 2014",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,D. J. Fleet,A. Punjani,and M. Norouzi. Fast search in hamming space with multi-index hashing. In CVPR. IEEE,,,2012,,"D. J. Fleet, A. Punjani, and M. Norouzi. Fast search in hamming space with multi-index hashing. In CVPR. IEEE, 2012",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,,,,,,,,"H. Liu, R. Wang, S. Shan, and X. Chen. Deep supervised hashing for fast image retrieval. In CVPR, pages 2064",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"A. Gionis, P. Indyk, R. Motwani, et al. Similarity search in high dimensions via hashing. In VLDB",volume 99,pages 518–529. ACM,,,1999,,"A. Gionis, P. Indyk, R. Motwani, et al. Similarity search in high dimensions via hashing. In VLDB, volume 99, pages 518–529. ACM, 1999",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"Y. Gong, S. Kumar, H. Rowley, S. Lazebnik, et al. Learning binary codes for high-dimensional data using bilinear projections. In CVPR",pages 484–491. IEEE,,,,2013,,"Y. Gong, S. Kumar, H. Rowley, S. Lazebnik, et al. Learning binary codes for high-dimensional data using bilinear projections. In CVPR, pages 484–491. IEEE, 2013",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,Y. Gong and S. Lazebnik. Iterative quantization: A procrustean approach to learning binary codes. In CVPR,pages 817–824,,,,2011,,"Y. Gong and S. Lazebnik. Iterative quantization: A procrustean approach to learning binary codes. In CVPR, pages 817–824, 2011",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"K. He, X. Zhang, S. Ren",and J. Sun. Deep residual learning for image recognition. CVPR,,,,2016,,"K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. CVPR, 2016",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"E. Hinton, S. Osindero, and Y.-W. Teh. A fast learning algorithm for deep belief nets. Neural Computation",18(7):1527–1554,,,,2006,,"G. E. Hinton, S. Osindero, and Y.-W. Teh. A fast learning algorithm for deep belief nets. Neural Computation, 18(7):1527–1554, 2006",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,,,,,,,,"S. Ioffe and C. Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. In ICML, 2015",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,,,,,,,,"H. Jegou, M. Douze, and C. Schmid. Product quantization for nearest neighbor search. IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 33(1):117–128, Jan 2011",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Girshick, S. Guadarrama",and T. Darrell. Caffe: Convolutional architecture for fast feature embedding. In ACM Multimedia Conference. ACM,,,,2014,,"Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Girshick, S. Guadarrama, and T. Darrell. Caffe: Convolutional architecture for fast feature embedding. In ACM Multimedia Conference. ACM, 2014",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"W. Liu, J. Wang, R. Ji, Y.-G. Jiang",and S.-F. Chang. Supervised hashing with kernels. In CVPR. IEEE,,,,2012,,"W. Liu, J. Wang, R. Ji, Y.-G. Jiang, and S.-F. Chang. Supervised hashing with kernels. In CVPR. IEEE, 2012",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"W. Liu, J. Wang, S. Kumar",and S.-F. Chang. Hashing with graphs. In ICML. ACM,,,,2011,,"W. Liu, J. Wang, S. Kumar, and S.-F. Chang. Hashing with graphs. In ICML. ACM, 2011",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,,,,,,,,"X. Liu, J. He, B. Lang, and S.-F. Chang. Hash bit selection: a unified solution for selection problems in hashing. In CVPR, pages 1570",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"W. Tsang, F. Peng, and C. Liu. Partial hash update via hamming subspace learning. IEEE Transactions on Image Processing (TIP)",26(4):1939–1951,,,,2017,,"C. Ma, I. W. Tsang, F. Peng, and C. Liu. Partial hash update via hamming subspace learning. IEEE Transactions on Image Processing (TIP), 26(4):1939–1951, 2017",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"T. Joachims, editors",ICML,pages 807–814. Omnipress,,,2010,,"V. Nair and G. E. Hinton. Rectified linear units improve restricted boltzmann machines. In J. Fürnkranz and T. Joachims, editors, ICML, pages 807–814. Omnipress, 2010",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,M. Norouzi and D. M. Blei. Minimal loss hashing for compact binary codes. In ICML,pages 353–360. ACM,,,,2011,,"M. Norouzi and D. M. Blei. Minimal loss hashing for compact binary codes. In ICML, pages 353–360. ACM, 2011",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,,,,,,,,"M. Norouzi, D. M. Blei, and R. R. Salakhutdinov. Hamming distance metric learning. In NIPS, pages 1061",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"A. Krizhevsky, I. Sutskever",and G. E. Hinton. Imagenet classification with deep convolutional neural networks. In NIPS,,,,2012,,"A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classification with deep convolutional neural networks. In NIPS, 2012",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, A. C. Berg",and L. Fei-Fei. ImageNet Large Scale Visual Recognition Challenge. International Journal of Computer Vision (IJCV),115(3):211–252,,,2015,,"O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, A. C. Berg, and L. Fei-Fei. ImageNet Large Scale Visual Recognition Challenge. International Journal of Computer Vision (IJCV), 115(3):211–252, 2015",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,,,,,,,,"B. Kulis and T. Darrell. Learning to hash with binary reconstructive embeddings. In NIPS, pages 1042",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,R. Salakhutdinov and G. E. Hinton. Learning a nonlinear embedding by preserving class neighbourhood structure. In AISTATS,pages 412–419,,,,2007,,"R. Salakhutdinov and G. E. Hinton. Learning a nonlinear embedding by preserving class neighbourhood structure. In AISTATS, pages 412–419, 2007",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,,,,,,,,"F. Shen, C. Shen, W. Liu, and H. Tao Shen. Supervised discrete hashing. In CVPR. IEEE, June 2015",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,,,,,,,,"A. W. Smeulders, M. Worring, S. Santini, A. Gupta, and R. Jain. Content-based image retrieval at the end of the early years. IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 22(12):1349– 1380",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,,,,,,,,"N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, and R. Salakhutdinov. Dropout: A simple way to prevent neural networks from overfitting. Journal of Machine Learning Research (JMLR), 15(1):1929–1958, Jan. 2014",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"J. Wang, S. Kumar, and S.-F. Chang. Semi-supervised hashing for large-scale search. IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)",34(12):2393–2406,,,,2012,,"J. Wang, S. Kumar, and S.-F. Chang. Semi-supervised hashing for large-scale search. IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 34(12):2393–2406, 2012",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"J. Wang, H. T. Shen",J. Song,and J. Ji. Hashing for similarity search: A survey. Arxiv,,,2014,,"J. Wang, H. T. Shen, J. Song, and J. Ji. Hashing for similarity search: A survey. Arxiv, 2014",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"Y. Weiss, A. Torralba",and R. Fergus. Spectral hashing. In NIPS,,,,2009,,"Y. Weiss, A. Torralba, and R. Fergus. Spectral hashing. In NIPS, 2009",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,,,,,,,,"R. Xia, Y. Pan, H. Lai, C. Liu, and S. Yan. Supervised hashing for image retrieval via image representation learning. In AAAI, pages 2156",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"X. Yu, S. Kumar, Y. Gong, and S.-F. Chang. Circulant binary embedding. In ICML",pages 353–360. ACM,,,,2014,,"F. X. Yu, S. Kumar, Y. Gong, and S.-F. Chang. Circulant binary embedding. In ICML, pages 353–360. ACM, 2014",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"P. Zhang, W. Zhang, W.-J. Li, and M. Guo. Supervised hashing with latent factor models. In SIGIR",pages 173–182. ACM,,,,2014,,"P. Zhang, W. Zhang, W.-J. Li, and M. Guo. Supervised hashing with latent factor models. In SIGIR, pages 173–182. ACM, 2014",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,,,,,,,,"F. Zhao, Y. Huang, L. Wang, and T. Tan. Deep semantic ranking based hashing for multi-label image retrieval. In CVPR, pages 1556",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"H. Zhu, M. Long, J. Wang",and Y. Cao. Deep hashing network for efficient similarity retrieval. In AAAI. AAAI,,,,2016,,"H. Zhu, M. Long, J. Wang, and Y. Cao. Deep hashing network for efficient similarity retrieval. In AAAI. AAAI, 2016",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,,,,,,,,"contains a “large” dataset with around 9,000 models consisting of models from a variety of sources organized into 171 categories (Table 1).  3. ShapeNet: An Information-Rich 3D Model Repository ShapeNet is a large, information-rich repository of 3D models. It contains models spanning a multitude of semantic categories. Unlike previous 3D model repositories, it provides extensive sets of annotations for every model and links between models in the repository and other multimedia data outside the repository. Like ImageNet, ShapeNet provides a view of the contained data in a hierarchical categorization according to WordNet synsets (Figure 1). Unlike other model repositories, ShapeNet also provides a rich set of annotations for 2  Benchmarks SHREC14LSGTB  Types  # models  # classes  Avg # models per class  Generic  8,987  171  53  PSB Generic 907+907 (train+test) 90+92 (train+test) 10+10 (train+test) SHREC12GTB Generic 1200",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,Ilya N Shindyalov,and Philip E Bourne. The protein data bank. Nucleic Acids Res,28:235–242,,,2000,,"Helen M Berman, John Westbrook, Zukang Feng, Gary Gilliland, TN Bhat, Helge Weissig, Ilya N Shindyalov, and Philip E Bourne. The protein data bank. Nucleic Acids Res, 28:235–242, 2000",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,,,,,,,,"Xiaobai Chen, Aleksey Golovinskiy, and Thomas Funkhouser. A benchmark for 3D mesh segmentation. ACM TOG, 28(3):73:1–73:12, July 2009",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,,,,,,,,"Xiaobai Chen, Abulhair Saparov, Bill Pang, and Thomas Funkhouser. Schelling points on 3D surface meshes. ACM TOG, August 2012",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,,,,,,,,"Joerg Liebelt and Cordelia Schmid. Multi-view object class detection with a 3D geometric model. In CVPR, pages 1688",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,Li-Jia Li,Kai Li,and Li Fei-Fei. ImageNet: A large-scale hierarchical image database. In CVPR,,,2009,,"Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. ImageNet: A large-scale hierarchical image database. In CVPR, 2009",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,,,,,,,,"Tianqiang Liu, Siddhartha Chaudhuri, Vladimir G. Kim, QiXing Huang, Niloy J. Mitra, and Thomas Funkhouser. Creating consistent scene graphs using a probabilistic grammar. ACM TOG, December 2014",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,,,,,,,,"Bianca Falcidieno. Aim@shape. http://www. aimatshape.net/ontologies/shapes/, 2005",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,Thomas Funkhouser,and Pat Hanrahan. Example-based synthesis of 3D object arrangements. ACM TOG,31(6):135,,,2012,,"Matthew Fisher, Daniel Ritchie, Manolis Savva, Thomas Funkhouser, and Pat Hanrahan. Example-based synthesis of 3D object arrangements. ACM TOG, 31(6):135, 2012",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,Mary Ann Marcinkiewicz,and Beatrice Santorini. Building a large annotated corpus of english: The Penn Treebank. Computational linguistics,19(2):313–330,,,1993,,"Mitchell P Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. Building a large annotated corpus of english: The Penn Treebank. Computational linguistics, 19(2):313–330, 1993",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,,,,,,,,"Paul-Louis George. Gamma. http://www.rocq. inria.fr/gamma/download/download.php, 2007",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,,,,,,,,"George A. Miller. WordNet: a lexical database for English. CACM, 1995",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,Hao Su,and Leonidas Guibas. Fine-grained semi-supervised labeling of large shape collections. ACM TOG,32:190:1–190:10,,,2013,,"Qixing Huang, Hao Su, and Leonidas Guibas. Fine-grained semi-supervised labeling of large shape collections. ACM TOG, 32:190:1–190:10, 2013",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,and Duygu Ceylan. Symmetry in 3D geometry: Extraction and applications. In Computer Graphics Forum,volume 32,pages 1–23,,,2013,,"Niloy J Mitra, Mark Pauly, Michael Wand, and Duygu Ceylan. Symmetry in 3D geometry: Extraction and applications. In Computer Graphics Forum, volume 32, pages 1–23, 2013",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,Yagnanarayanan Kalyanaraman,Natraj Iyer,and Karthik Ramani. Developing an engineering shape benchmark for CAD models. Computer-Aided Design,,,2006,,"Subramaniam Jayanti, Yagnanarayanan Kalyanaraman, Natraj Iyer, and Karthik Ramani. Developing an engineering shape benchmark for CAD models. Computer-Aided Design, 2006",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,Fakir S. Nooruddin and Greg Turk. Simplification and repair of polygonal models using volumetric techniques. Visualization and Computer Graphics,IEEE Transactions on,,,,2003,,"Fakir S. Nooruddin and Greg Turk. Simplification and repair of polygonal models using volumetric techniques. Visualization and Computer Graphics, IEEE Transactions on, 2003",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,Daphne Koller,and Vladlen Koltun. A probabilistic model for component-based shape synthesis. ACM TOG,31:55,,,2012,,"Evangelos Kalogerakis, Siddhartha Chaudhuri, Daphne Koller, and Vladlen Koltun. A probabilistic model for component-based shape synthesis. ACM TOG, 31:55, 2012",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,,,,,,,,"Bryan C Russell and Antonio Torralba. Building a database of 3D scenes from user annotations. In CVPR, 2009",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,,,,,,,,"Vladimir Kim, Yaron Lipman, Xiaobai Chen, and Thomas Funkhouser. Mobius transformations for global intrinsic symmetry analysis. Symposium on Geometry Processing, July 2010",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,,,,,,,,"Manolis Savva, Angel X. Chang, Gilbert Bernstein, Christopher D. Manning, and Pat Hanrahan. On being the right scale: Sizing large collections of 3D models. In SIGGRAPH Asia 2014",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,,,,,,,,"Vladimir G. Kim, Wilmot Li, Niloy J. Mitra, Siddhartha Chaudhuri, Stephen DiVerdi, and Thomas Funkhouser. Learning part-based templates from large collections of 3D shapes. ACM TOG, 32(4):70:1–70:12, July 2013",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,,,,,,,,"Manolis Savva, Angel X. Chang, and Pat Hanrahan. Semantically-Enriched 3D Models for Common-sense Knowledge. CVPR 2015",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,,,,,,,,"Vladimir G. Kim, Wilmot Li, Niloy J. Mitra, Stephen DiVerdi, and Thomas Funkhouser. Exploring collections of 3D models using fuzzy correspondences. ACM TOG, 31(4):54:1–54:11, July 2012",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,Patrick Min,Michael Kazhdan,and Thomas Funkhouser. The Princeton shape benchmark. In Shape Modeling Applications. IEEE,,,2004,,"Philip Shilane, Patrick Min, Michael Kazhdan, and Thomas Funkhouser. The Princeton shape benchmark. In Shape Modeling Applications. IEEE, 2004",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,and Li Fei-Fei. 3D object representations for fine-grained categorization. In 4th International IEEE Workshop on 3D Representation and Recognition (3dRR-13),Sydney,Australia,,,2013,,"Jonathan Krause, Michael Stark, Jia Deng, and Li Fei-Fei. 3D object representations for fine-grained categorization. In 4th International IEEE Workshop on 3D Representation and Recognition (3dRR-13), Sydney, Australia, 2013",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,,,,,,,,"Shuran Song and Jianxiong Xiao. Sliding shapes for 3D object detection in depth images. In ECCV, 2014",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,Martin L Jones,and Janet M Thornton. PDBsum: A web-based database of summaries and analyses of all PDB structures. Trends Biochem. Sci.,22:488–490,,,1997,,"Roman A Laskowski, E Gail Hutchinson, Alex D Michie, Andrew C Wallace, Martin L Jones, and Janet M Thornton. PDBsum: A web-based database of summaries and analyses of all PDB structures. Trends Biochem. Sci., 22:488–490, 1997",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,Atsushi Tatsuma,Hitoshi Koyanagi,and Masaki Aono. A large-scale shape benchmark for 3D object retrieval: Toyohashi shape benchmark. In Asia Pacific Signal and Information Processing Association,,,2012,,"Atsushi Tatsuma, Hitoshi Koyanagi, and Masaki Aono. A large-scale shape benchmark for 3D object retrieval: Toyohashi shape benchmark. In Asia Pacific Signal and Information Processing Association, 2012",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,Bryan C Russell,and Jenny Yuen. LabelMe: Online image annotation and applications. Proceedings of the IEEE,98(8):1467–1484,,,2010,,"Antonio Torralba, Bryan C Russell, and Jenny Yuen. LabelMe: Online image annotation and applications. Proceedings of the IEEE, 98(8):1467–1484, 2010",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,Ryutarou Ohbuchi,Carolina Redondo-Cabrera,et al. SHREC’12 track: generic 3D shape retrieval. In 5th Eurographics Conference on 3D Object Retrieval,,,2012,,"Bo Li, Afzal Godil, Masaki Aono, X Bai, Takahiko Furuya, L Li, R López-Sastre, Henry Johan, Ryutarou Ohbuchi, Carolina Redondo-Cabrera, et al. SHREC’12 track: generic 3D shape retrieval. In 5th Eurographics Conference on 3D Object Retrieval, 2012",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,,,,,,,,Remco C. Veltkamp and FB ter Harr. SHREC 2007,./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,Dejan V Vranić. 3D model retrieval. University of Leipzig,Germany,PhD thesis,,,2004,,"Dejan V Vranić. 3D model retrieval. University of Leipzig, Germany, PhD thesis, 2004",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,,,,,,,,"Raoul Wessel, Ina Blümel, and Reinhard Klein. A 3D shape benchmark for retrieval and automatic classification of architectural data. In Eurographics 2009",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,Linguang Zhang,Xiaoou Tang,and Jianxiong Xiao. 3D ShapeNets: A Deep Representation for Volumetric Shapes. CVPR,,,2015,,"Zhirong Wu, Shuran Song, Aditya Khosla, Fisher Yu, Linguang Zhang, Xiaoou Tang, and Jianxiong Xiao. 3D ShapeNets: A Deep Representation for Volumetric Shapes. CVPR, 2015",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,Yu Xiang,Roozbeh Mottaghi,and Silvio Savarese. Beyond PASCAL: A benchmark for 3D object detection in the wild. In WACV,,,2014,,"Yu Xiang, Roozbeh Mottaghi, and Silvio Savarese. Beyond PASCAL: A benchmark for 3D object detection in the wild. In WACV, 2014",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,,,,,,,,"Jianxiong Xiao, Andrew Owens, and Antonio Torralba. SUN3D: A database of big spaces reconstructed using SfM and object labels. In ICCV, pages 1625",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,Diego Macrini,Ali Shokoufandeh,and Sven Dickinson. Retrieving articulated 3-D models using medial surfaces and their graph spectra. In Energy minimization methods in computer vision and pattern recognition,,,2005,,"Juan Zhang, Kaleem Siddiqi, Diego Macrini, Ali Shokoufandeh, and Sven Dickinson. Retrieving articulated 3-D models using medial surfaces and their graph spectra. In Energy minimization methods in computer vision and pattern recognition, 2005",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
