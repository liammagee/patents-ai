,authors,title,journal,publisher,volume,year,pages,full_ref,source_file,source_title
0,"Y. Guo, Y. Liu, A. Oerlemans, S. Lao, S. Wu, M.S. Lew",Deep learning for visual understanding: A review, Neurocomputing,, 187 ,2016, 27-48.,"Y. Guo, Y. Liu, A. Oerlemans, S. Lao, S. Wu, M.S. Lew, Deep learning for visual understanding: A review, Neurocomputing, 187 (2016) 27-48.",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"W. Rawat, Z. Wang",Deep convolutional neural networks for image classification: A comprehensive review, Neural computation,, 29 ,2017, 2352-2449.,"W. Rawat, Z. Wang, Deep convolutional neural networks for image classification: A comprehensive review, Neural computation, 29 (2017) 2352-2449.",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, L. Fei-Fei",Imagenet: A large-scale hierarchical image database, 2009 IEEE conference on computer vision and pattern recognition, Ieee,, 2009, pp. 248-255.,"J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, L. Fei-Fei, Imagenet: A large-scale hierarchical image database, 2009 IEEE conference on computer vision and pattern recognition, Ieee, 2009, pp. 248-255.",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan, P. Dollár, C.L. Zitnick",Microsoft coco: Common objects in context, European conference on computer vision, Springer,, 2014, pp. 740-755.,"T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan, P. Dollár, C.L. Zitnick, Microsoft coco: Common objects in context, European conference on computer vision, Springer, 2014, pp. 740-755.",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"Z. Liu, P. Luo, S. Qiu, X. Wang, X. Tang",Deepfashion: Powering robust clothes recognition and retrieval with rich annotations, Proceedings of the IEEE conference on computer vision and pattern recognition,,, 2016, pp. 10961104.,"Z. Liu, P. Luo, S. Qiu, X. Wang, X. Tang, Deepfashion: Powering robust clothes recognition and retrieval with rich annotations, Proceedings of the IEEE conference on computer vision and pattern recognition, 2016, pp. 10961104.",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"Y. Ge, R. Zhang, X. Wang, X. Tang, P. Luo",Deepfashion2: A versatile benchmark for detection, pose estimation,,,,,"Y. Ge, R. Zhang, X. Wang, X. Tang, P. Luo, Deepfashion2: A versatile benchmark for detection, pose estimation, segmentation and re-identification of clothing images, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2019, pp. 5337-5345.",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"Z. Wu, S. Song, A. Khosla, F. Yu, L. Zhang, X. Tang, J. Xiao",3d shapenets: A deep representation for volumetric shapes, Proceedings of the IEEE conference on computer vision and pattern recognition,,, 2015, pp. 1912-1920.,"Z. Wu, S. Song, A. Khosla, F. Yu, L. Zhang, X. Tang, J. Xiao, 3d shapenets: A deep representation for volumetric shapes, Proceedings of the IEEE conference on computer vision and pattern recognition, 2015, pp. 1912-1920.",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"A.X. Chang, T. Funkhouser, L. Guibas, P. Hanrahan, Q. Huang, Z. Li, S. Savarese, M. Savva, S. Song, H. Su",Shapenet: An information-rich 3d model repository,,, ,2015,.,"A.X. Chang, T. Funkhouser, L. Guibas, P. Hanrahan, Q. Huang, Z. Li, S. Savarese, M. Savva, S. Song, H. Su, Shapenet: An information-rich 3d model repository, arXiv preprint arXiv:1512.03012, (2015).",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"M. Aubry, D. Maturana, A.A. Efros, B.C. Russell, J. Sivic",Seeing 3d chairs: exemplar part-based 2d-3d alignment using a large dataset of cad models, Proceedings of the IEEE conference on computer vision and pattern recognition,,, 2014, pp. 3762-3769.,"M. Aubry, D. Maturana, A.A. Efros, B.C. Russell, J. Sivic, Seeing 3d chairs: exemplar part-based 2d-3d alignment using a large dataset of cad models, Proceedings of the IEEE conference on computer vision and pattern recognition, 2014, pp. 3762-3769.",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"B. de Bruijn, T.A. Nguyen, D. Bucur, K. Tei",Benchmark Datasets for Fault Detection and Classification in Sensor Data, SENSORNETS,,, 2016, pp. 185-195.,"B. de Bruijn, T.A. Nguyen, D. Bucur, K. Tei, Benchmark Datasets for Fault Detection and Classification in Sensor Data, SENSORNETS, 2016, pp. 185-195.",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"T. Karras, S. Laine, T. Aila",A style-based generator architecture for generative adversarial networks, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,,, 2019, pp. 4401-4410.,"T. Karras, S. Laine, T. Aila, A style-based generator architecture for generative adversarial networks, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2019, pp. 4401-4410.",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"R. Vemulapalli, A. Agarwala",A compact embedding for facial expression similarity, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,,, 2019, pp. 5683-5692.,"R. Vemulapalli, A. Agarwala, A compact embedding for facial expression similarity, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2019, pp. 5683-5692.",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"K. Mo, S. Zhu, A.X. Chang, L. Yi, S. Tripathi, L.J. Guibas, H. Su",Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding,  Proceedings of the IEEE/CVF Conference on  Computer Vision and Pattern Recognition,,, 2019, pp. 909-918.,"K. Mo, S. Zhu, A.X. Chang, L. Yi, S. Tripathi, L.J. Guibas, H. Su, Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding,  Proceedings of the IEEE/CVF Conference on  Computer Vision and Pattern Recognition, 2019, pp. 909-918.",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"J. Krause, M. Stark, J. Deng, L. Fei-Fei",3d object representations for fine-grained categorization, Proceedings of the IEEE international conference on computer vision workshops,,, 2013, pp. 554-561.,"J. Krause, M. Stark, J. Deng, L. Fei-Fei, 3d object representations for fine-grained categorization, Proceedings of the IEEE international conference on computer vision workshops, 2013, pp. 554-561.",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"R. He, C. Lin, J. McAuley",Fashionista: A fashion-aware graphical system for exploring visually similar items, Proceedings of the 25th International Conference Companion on World Wide Web,,, 2016, pp. 199-202.,"R. He, C. Lin, J. McAuley, Fashionista: A fashion-aware graphical system for exploring visually similar items, Proceedings of the 25th International Conference Companion on World Wide Web, 2016, pp. 199-202.",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"X. Zou, X. Kong, W. Wong, C. Wang, Y. Liu, Y. Cao",Fashionai: A hierarchical dataset for fashion understanding,  Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition  Workshops,,, 2019, pp. 0-0.,"X. Zou, X. Kong, W. Wong, C. Wang, Y. Liu, Y. Cao, Fashionai: A hierarchical dataset for fashion understanding,  Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition  Workshops, 2019, pp. 0-0.",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"H. Xiao, K. Rasul, R. Vollgraf",Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms,,, ,2017,.,"H. Xiao, K. Rasul, R. Vollgraf, Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms, arXiv preprint arXiv:1708.07747, (2017).",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"B. Loni, L.Y. Cheung, M. Riegler, A. Bozzon, L. Gottlieb, M. Larson",Fashion 10000: an enriched social image dataset for fashion and clothing, Proceedings of the 5th acm multimedia systems conference,,, 2014, pp. 4146. ,"B. Loni, L.Y. Cheung, M. Riegler, A. Bozzon, L. Gottlieb, M. Larson, Fashion 10000: an enriched social image dataset for fashion and clothing, Proceedings of the 5th acm multimedia systems conference, 2014, pp. 4146. ",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"N. Rostamzadeh, S. Hosseini, T. Boquet, W. Stokowiec, Y. Zhang, C. Jauvin, C. Pal",Fashion-gen: The generative fashion dataset and challenge,,, ,2018,.,"N. Rostamzadeh, S. Hosseini, T. Boquet, W. Stokowiec, Y. Zhang, C. Jauvin, C. Pal, Fashion-gen: The generative fashion dataset and challenge, arXiv preprint arXiv:1806.08317, (2018).",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"K. Simonyan, A. Zisserman",Very deep convolutional networks for large-scale image recognition,,, ,2014,.,"K. Simonyan, A. Zisserman, Very deep convolutional networks for large-scale image recognition, arXiv preprint arXiv:1409.1556, (2014).",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, A. Rabinovich",Going deeper with convolutions, Proceedings of the IEEE conference on computer vision and pattern recognition,,, 2015, pp. 1-9.,"C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, A. Rabinovich, Going deeper with convolutions, Proceedings of the IEEE conference on computer vision and pattern recognition, 2015, pp. 1-9.",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"K. He, X. Zhang, S. Ren, J. Sun",Deep residual learning for image recognition, Proceedings of the IEEE conference on computer vision and pattern recognition,,, 2016, pp. 770-778.,"K. He, X. Zhang, S. Ren, J. Sun, Deep residual learning for image recognition, Proceedings of the IEEE conference on computer vision and pattern recognition, 2016, pp. 770-778.",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"G. Huang, Z. Liu, L. Van Der Maaten, K.Q. Weinberger",Densely connected convolutional networks, Proceedings of the IEEE conference on computer vision and pattern recognition,,, 2017, pp. 4700-4708.,"G. Huang, Z. Liu, L. Van Der Maaten, K.Q. Weinberger, Densely connected convolutional networks, Proceedings of the IEEE conference on computer vision and pattern recognition, 2017, pp. 4700-4708.",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"M. Tan, Q. Le",Efficientnet: Rethinking model scaling for convolutional neural networks, International Conference on Machine Learning, PMLR,, 2019, pp. 6105-6114.,"M. Tan, Q. Le, Efficientnet: Rethinking model scaling for convolutional neural networks, International Conference on Machine Learning, PMLR, 2019, pp. 6105-6114.",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"L. Yuan, T. Wang, X. Zhang, F.E. Tay, Z. Jie, W. Liu, J. Feng",Central similarity quantization for efficient image and video retrieval,  Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern  Recognition,,, 2020, pp. 3083-3092.,"L. Yuan, T. Wang, X. Zhang, F.E. Tay, Z. Jie, W. Liu, J. Feng, Central similarity quantization for efficient image and video retrieval,  Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern  Recognition, 2020, pp. 3083-3092.",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"Z. Cao, M. Long, J. Wang, P.S. Yu",Hashnet: Deep learning to hash by continuation, Proceedings of the IEEE international conference on computer vision,,, 2017, pp. 5608-5617.,"Z. Cao, M. Long, J. Wang, P.S. Yu, Hashnet: Deep learning to hash by continuation, Proceedings of the IEEE international conference on computer vision, 2017, pp. 5608-5617.",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"A. Ng, M. Jordan, Y. Weiss",On Spectral Clustering: Analysis and an algorithm,,,,,,"A. Ng, M. Jordan, Y. Weiss, On Spectral Clustering: Analysis and an algorithm, in: T. Dietterich, S. Becker, Z. Ghahramani (Eds.) Advances in Neural Information Processing Systems, MIT Press, 2002.",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"H. Zhao, H. Liu, Y. Fu",Incomplete multi-modal visual data grouping, Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence,,, 2016, pp. 2392-2398.,"H. Zhao, H. Liu, Y. Fu, Incomplete multi-modal visual data grouping, Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence, 2016, pp. 2392-2398.",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"M. Hu, S. Chen",Doubly Aligned Incomplete Multi-view Clustering, International Joint Conference on Artificial Intelligence,,, 2018, pp. 2262-2268.,"M. Hu, S. Chen, Doubly Aligned Incomplete Multi-view Clustering, International Joint Conference on Artificial Intelligence, 2018, pp. 2262-2268.",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"J. Wen, Y. Xu, H. Liu",Incomplete Multiview Spectral Clustering With Adaptive Graph Learning, IEEE Transactions on Cybernetics,, 50 ,2020, 1418-1429.,"J. Wen, Y. Xu, H. Liu, Incomplete Multiview Spectral Clustering With Adaptive Graph Learning, IEEE Transactions on Cybernetics, 50 (2020) 1418-1429.",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"J. Guo, J. Ye",Anchors bring ease: An embarrassingly simple approach to partial multi-view clustering, Proceedings of the AAAI Conference on Artificial Intelligence,,, 2019, pp. 118-125.,"J. Guo, J. Ye, Anchors bring ease: An embarrassingly simple approach to partial multi-view clustering, Proceedings of the AAAI Conference on Artificial Intelligence, 2019, pp. 118-125.",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"E. Amigó, J. Gonzalo, J. Artiles, F. Verdejo",A comparison of extrinsic clustering evaluation metrics based on formal constraints, Information retrieval,, 12 ,2009, 461-486.,"E. Amigó, J. Gonzalo, J. Artiles, F. Verdejo, A comparison of extrinsic clustering evaluation metrics based on formal constraints, Information retrieval, 12 (2009) 461-486.",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"K. Zhan, X. Chang, J. Guan, L. Chen, Z. Ma, Y. Yang",Adaptive structure discovery for multimedia analysis using multiple features, IEEE transactions on cybernetics,, 49 ,2018, 1826-1834. ,"K. Zhan, X. Chang, J. Guan, L. Chen, Z. Ma, Y. Yang, Adaptive structure discovery for multimedia analysis using multiple features, IEEE transactions on cybernetics, 49 (2018) 1826-1834. ",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"J. J. McAuley, C. Targett, Q. Shi, and A. van den Hengel",“Image-based recommendations on styles and substitutes,” in SIGIR,,,,,"J. J. McAuley, C. Targett, Q. Shi, and A. van den Hengel, “Image-based recommendations on styles and substitutes,” in SIGIR, 2015.",./refs/download/Fashionista: A fashion-aware graphical system for exploring visually similar items.pdf,
0,R. He and J. McAuley,“Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative filtering,” in WWW,,,,,"R. He and J. McAuley, “Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative filtering,” in WWW, 2016.",./refs/download/Fashionista: A fashion-aware graphical system for exploring visually similar items.pdf,
0,R. He and J. McAuley,“VBPR: visual bayesian personalized ranking from implicit feedback,” in AAAI,,,,,"R. He and J. McAuley, “VBPR: visual bayesian personalized ranking from implicit feedback,” in AAAI, 2016.",./refs/download/Fashionista: A fashion-aware graphical system for exploring visually similar items.pdf,
0,"C. Lin, J. Lu, T. W. Ling, and B. Cautis",“Lotusx: a position-aware xml graphical search system with auto-completion,” in ICDE,,,,,"C. Lin, J. Lu, T. W. Ling, and B. Cautis, “Lotusx: a position-aware xml graphical search system with auto-completion,” in ICDE, 2012.",./refs/download/Fashionista: A fashion-aware graphical system for exploring visually similar items.pdf,
0,"A. Krizhevsky, I. Sutskever, and G. E. Hinton",“Imagenet classification with deep convolutional neural networks,” in NIPS,,,,,"A. Krizhevsky, I. Sutskever, and G. E. Hinton, “Imagenet classification with deep convolutional neural networks,” in NIPS, 2012.",./refs/download/Fashionista: A fashion-aware graphical system for exploring visually similar items.pdf,
0,"R. Pan, Y. Zhou, B. Cao, N. N. Liu, R. Lukose, M. Scholz, and Q. Yang",“One-class collaborative filtering,” in ICDM,,,,,"R. Pan, Y. Zhou, B. Cao, N. N. Liu, R. Lukose, M. Scholz, and Q. Yang, “One-class collaborative filtering,” in ICDM, 2008.",./refs/download/Fashionista: A fashion-aware graphical system for exploring visually similar items.pdf,
0,L. van der Maaten,“Accelerating t-SNE using tree-based algorithms,” JMLR,,,,,"L. van der Maaten, “Accelerating t-SNE using tree-based algorithms,” JMLR, 2014.  4 5  http://www.ebay.com/ http://www.walmart.com/ ",./refs/download/Fashionista: A fashion-aware graphical system for exploring visually similar items.pdf,
0,,Han,,,,,,"Han, X., Wu, Z., Wu, Z., Yu, R., and Davis, L. S. Viton: An image-based virtual try-on network. arXiv preprint arXiv:1711.08447, 2017.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,,Huang,,,,,,"Huang, X., Li, Y., Poursaeed, O., Hopcroft, J., and Belongie, S. Stacked generative adversarial networks. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), volume 2, pp. 4, 2017.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,,Isola,,,,,,"Isola, P., Zhu, J.-Y., Zhou, T., and Efros, A. A. Image-toimage translation with conditional adversarial networks. arXiv preprint, 2017.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,,Kalantidis,,,,,,"Kalantidis, Y., Kennedy, L., and Li, L.-J. Getting the look: clothing recognition and segmentation for automatic product suggestions in everyday photos. In Proceedings of the 3rd ACM conference on International conference on multimedia retrieval, pp. 105–112. ACM, 2013.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,,Karras,,,,,,"Karras, T., Aila, T., Laine, S., and Lehtinen, J. Progressive growing of gans for improved quality, stability, and variation. arXiv preprint arXiv:1710.10196, 2017.  Barratt, S. and Sharma, R. A note on the inception score. arXiv preprint arXiv:1801.01973, 2018.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,,Kiapour,,,,,,"Kiapour, M. H., Han, X., Lazebnik, S., Berg, A. C., and Berg, T. L. Where to buy it: Matching street clothing photos in online shops. In ICCV, pp. 3343–3351, 2015.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,,Belghazi,,,,,,"Belghazi, M. I., Rajeswar, S., Mastropietro, O., Rostamzadeh, N., Mitrovic, J., and Courville, A. Hierarchical adversarially learned inference. arXiv preprint arXiv:1802.01071, 2018.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,,Ledig,,,,,,"Ledig, C., Theis, L., Huszár, F., Caballero, J., Cunningham, A., Acosta, A., Aitken, A., Tejani, A., Totz, J., Wang, Z., et al. Photo-realistic single image super-resolution using a generative adversarial network. arXiv preprint, 2016.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,,Bossard,,,,,,"Bossard, L., Dantone, M., Leistner, C., Wengert, C., Quack, T., and Van Gool, L. Apparel classification with style. In Asian conference on computer vision, pp. 321–335. Springer, 2012.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,,Liang,,,,,,"Liang, X., Lin, L., Yang, W., Luo, P., Huang, J., and Yan, S. Clothes co-parsing via joint image segmentation and labeling with application to clothing retrieval. IEEE Transactions on Multimedia, 18(6):1175–1186, 2016.  Chen, H., Gallagher, A., and Girod, B. Describing clothing by semantic attributes. In European conference on computer vision, pp. 609–623. Springer, 2012.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,,Lin,,,,,,"Lin, T.-Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Dollár, P., and Zitnick, C. L. Microsoft coco: Common objects in context. In European conference on computer vision, pp. 740–755. Springer, 2014.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,,Chen,,,,,,"Chen, Q., Huang, J., Feris, R., Brown, L. M., Dong, J., and Yan, S. Deep domain adaptation for describing people based on fine-grained clothing attributes. In Computer Vision and Pattern Recognition (CVPR), 2015 IEEE Conference on, pp. 5315–5324. IEEE, 2015.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,,Denton,,,, R. Stochastic video generation with a learned prior. arXiv preprint arXiv:1802.07687, 2018.,"Denton, E. and Fergus, R. Stochastic video generation with a learned prior. arXiv preprint arXiv:1802.07687, 2018.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,,Liu,,,,,,"Liu, S., Song, Z., Liu, G., Xu, C., Lu, H., and Yan, S. Street-to-shop: Cross-scenario clothing retrieval via parts alignment and auxiliary set. In Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on, pp. 3330–3337. IEEE, 2012.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,,Denton,,,, pp. 4417–4426, 2017.,"Denton, E. L. et al. Unsupervised learning of disentangled representations from video. In Advances in Neural Information Processing Systems, pp. 4417–4426, 2017.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,,Liu,,,,,,"Liu, Z., Luo, P., Wang, X., and Tang, X. Deep learning face attributes in the wild. In Proceedings of the IEEE International Conference on Computer Vision, pp. 3730– 3738, 2015.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,,Nilsback,,,,,,"Nilsback, M.-E. and Zisserman, A. Automated flower classification over a large number of classes. In Computer Vision, Graphics & Image Processing, 2008. ICVGIP’08. Sixth Indian Conference on, pp. 722–729. IEEE, 2008.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,,Reed,,,,,,"Reed, S., Akata, Z., Yan, X., Logeswaran, L., Schiele, B., and Lee, H. Generative adversarial text to image synthesis. arXiv preprint arXiv:1605.05396, 2016a.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,,Reed,,,,,,"Reed, S., Akata, Z., Lee, H., and Schiele, B. Learning deep representations of fine-grained visual descriptions. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 49–58, 2016b.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,,Reed,,,,,,"Reed, S. E., Akata, Z., Schiele, B., and Lee, H. Learning deep representations of fine-grained visual descriptions. CoRR, abs/1605.05395, 2016.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,,Salimans,,,,,,"Salimans, T., Goodfellow, I., Zaremba, W., Cheung, V., Radford, A., and Chen, X. Improved techniques for training gans. In Advances in Neural Information Processing Systems, pp. 2234–2242, 2016.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,,Schuster,,,,,,"Schuster, M., Paliwal, K. K., and General, A. Bidirectional recurrent neural networks. IEEE Transactions on Signal Processing, 1997.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,,Simo-Serra,,,,,,"Simo-Serra, E., Fidler, S., Moreno-Noguer, F., and Urtasun, R. Neuroaesthetics in fashion: Modeling the perception of fashionability. In CVPR, volume 2, pp. 6, 2015. Sønderby, C. K., Caballero, J., Theis, L., Shi, W., and Huszár, F. Amortised map inference for image superresolution. arXiv preprint arXiv:1610.04490, 2016.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,,Taigman,,,,,,"Taigman, Y., Polyak, A., and Wolf, L. Unsupervised cross-domain image generation. arXiv preprint arXiv:1611.02200, 2016. van der Maaten, L. and Hinton, G. Visualizing data using t-SNE. Journal of Machine Learning Research, 9: 2579–2605, 2008.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,,Vaswani,,,,,,"Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., and Polosukhin, I. Attention is all you need. CoRR, abs/1706.03762, 2017.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,,Veit,,,,,,"Veit, A., Kovacs, B., Bell, S., McAuley, J., Bala, K., and Belongie, S. Learning visual clothing style with heterogeneous dyadic co-occurrences. In Computer Vision (ICCV), 2015 IEEE International Conference on, pp. 4642–4650. IEEE, 2015.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,,Xiao,,,,,,"Xiao, T., Xia, T., Yang, Y., Huang, C., and Wang, X. Learning from massive noisy labeled data for image classification. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2691–2699, 2015.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,,Zhang,,,,,,"Zhang, H., Xu, T., Li, H., Zhang, S., Wang, X., Huang, X., and Metaxas, D. N. Stackgan++: Realistic image synthesis with stacked generative adversarial networks. CoRR, abs/1710.10916, 2017b.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,,Zhang,,,,,,"Zhang, Z., Xie, Y., and Yang, L. Photographic text-toimage synthesis with a hierarchically-nested adversarial network. arXiv preprint arXiv:1802.09178, 2018. Zhu, J.-Y., Park, T., Isola, P., and Efros, A. A. Unpaired image-to-image translation using cycle-consistent adversarial networks. arXiv preprint arXiv:1703.10593, 2017a.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,,Zhu,,,,,,"Zhu, S., Fidler, S., Urtasun, R., Lin, D., and Loy, C. C. Be your own prada: Fashion synthesis with structural coherence. arXiv preprint arXiv:1710.07346, 2017b.",./refs/download/Fashion-gen: The generative fashion dataset and challenge.pdf,
0,"Y. Cao, M. Long, B. Liu, and J. Wang. Deep cauchy hashing for hamming space retrieval. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",pages 1229–1237,,,,,,"Y. Cao, M. Long, B. Liu, and J. Wang. Deep cauchy hashing for hamming space retrieval. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1229–1237, 2018.",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,"Z. Cao, M. Long, J. Wang, and S. Y. Philip. Hashnet: Deep learning to hash by continuation. In ICCV",pages 5609–5618,,,,,,"Z. Cao, M. Long, J. Wang, and S. Y. Philip. Hashnet: Deep learning to hash by continuation. In ICCV, pages 5609–5618, 2017.",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,"Y.-W. Chao, S. Vijayanarasimhan, B. Seybold, D. A. Ross, J. Deng, and R. Sukthankar. Rethinking the faster r-cnn architecture for temporal action localization. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",pages 1130–1139,,,,,,"Y.-W. Chao, S. Vijayanarasimhan, B. Seybold, D. A. Ross, J. Deng, and R. Sukthankar. Rethinking the faster r-cnn architecture for temporal action localization. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1130–1139, 2018.",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,"Y. Chen, Y. Kalantidis, J. Li, S. Yan, and J. Feng. Multi-fiber networks for video recognition. arXiv preprint arXiv:1807.11195, 2018.",,,,,,,"Y. Chen, Y. Kalantidis, J. Li, S. Yan, and J. Feng. Multi-fiber networks for video recognition. arXiv preprint arXiv:1807.11195, 2018.",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,"T.-S. Chua, J. Tang, R. Hong, H. Li, Z. Luo, and Y. Zheng. Nus-wide: a real-world web image database from national university of singapore. In Proceedings of the ACM international conference on image and video retrieval, page 48. ACM, 2009.",,,,,,,"T.-S. Chua, J. Tang, R. Hong, H. Li, Z. Luo, and Y. Zheng. Nus-wide: a real-world web image database from national university of singapore. In Proceedings of the ACM international conference on image and video retrieval, page 48. ACM, 2009.",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,"J. Donahue, L. Anne Hendricks, S. Guadarrama, M. Rohrbach, S. Venugopalan, K. Saenko, and T. Darrell. Long-term recurrent convolutional networks for visual recognition and description. In Proceedings of the IEEE conference on computer vision and pattern recognition",pages 2625–2634,,,,,,"J. Donahue, L. Anne Hendricks, S. Guadarrama, M. Rohrbach, S. Venugopalan, K. Saenko, and T. Darrell. Long-term recurrent convolutional networks for visual recognition and description. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 2625–2634, 2015.",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,"Y. Gong, S. Lazebnik, A. Gordo, and F. Perronnin. Iterative quantization: A procrustean approach to learning binary codes for large-scale image retrieval. IEEE Transactions on Pattern Analysis and Machine Intelligence",35(12):2916– 2929,,,,,,"Y. Gong, S. Lazebnik, A. Gordo, and F. Perronnin. Iterative quantization: A procrustean approach to learning binary codes for large-scale image retrieval. IEEE Transactions on Pattern Analysis and Machine Intelligence, 35(12):2916– 2929, 2013.",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,"Y. Gu, C. Ma, and J. Yang. Supervised recurrent hashing for large scale video retrieval. In Proceedings of the 2016 ACM on Multimedia Conference, pages 272–276. ACM, 2016.",,,,,,,"Y. Gu, C. Ma, and J. Yang. Supervised recurrent hashing for large scale video retrieval. In Proceedings of the 2016 ACM on Multimedia Conference, pages 272–276. ACM, 2016.",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,"K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition",pages 770–778,,,,,,"K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770–778, 2016.",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,"A. Hyvärinen, J. Hurri, and P. O. Hoyer. Natural image statistics: a probabilistic approach to early computational vision. Springer.",,,,,,,"A. Hyvärinen, J. Hurri, and P. O. Hoyer. Natural image statistics: a probabilistic approach to early computational vision. Springer.",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,"L. Karlinsky, J. Shtok, S. Harary, E. Schwartz, A. Aides, R. Feris, R. Giryes, and A. M. Bronstein. Repmet: Representative-based metric learning for classification and few-shot object detection. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",pages 5197–5206,,,,,,"L. Karlinsky, J. Shtok, S. Harary, E. Schwartz, A. Aides, R. Feris, R. Giryes, and A. M. Bronstein. Repmet: Representative-based metric learning for classification and few-shot object detection. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 5197–5206, 2019.",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,"H. Kuehne, H. Jhuang, R. Stiefelhagen, and T. Serre. Hmdb51: A large video database for human motion recognition. In High Performance Computing in Science and Engineering 12, pages 571–582. Springer, 2013.",,,,,,,"H. Kuehne, H. Jhuang, R. Stiefelhagen, and T. Serre. Hmdb51: A large video database for human motion recognition. In High Performance Computing in Science and Engineering 12, pages 571–582. Springer, 2013.",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,B. Kulis and T. Darrell. Learning to hash with binary reconstructive embeddings. In Advances in neural information processing systems,pages 1042–1050,,,,,,"B. Kulis and T. Darrell. Learning to hash with binary reconstructive embeddings. In Advances in neural information processing systems, pages 1042–1050, 2009.",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,"H. Lai, Y. Pan, Y. Liu, and S. Yan. Simultaneous feature learning and hash coding with deep neural networks. In Pro-",,,,,,,"H. Lai, Y. Pan, Y. Liu, and S. Yan. Simultaneous feature learning and hash coding with deep neural networks. In Pro- ",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,"F. Shen, C. Shen, W. Liu, and H. Tao Shen. Supervised discrete hashing. In Proceedings of the IEEE conference on computer vision and pattern recognition",pages 37–45,,,,,,"F. Shen, C. Shen, W. Liu, and H. Tao Shen. Supervised discrete hashing. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 37–45, 2015.",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,K. Simonyan and A. Zisserman. Two-stream convolutional networks for action recognition in videos. In Advances in neural information processing systems,pages 568–576,,,,,,"K. Simonyan and A. Zisserman. Two-stream convolutional networks for action recognition in videos. In Advances in neural information processing systems, pages 568–576, 2014.",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,"D. Song, W. Liu, R. Ji, D. A. Meyer, and J. R. Smith. Top rank supervised binary coding for visual search. In Proceedings of the IEEE International Conference on Computer Vision",pages 1922–1930,,,,,,"D. Song, W. Liu, R. Ji, D. A. Meyer, and J. R. Smith. Top rank supervised binary coding for visual search. In Proceedings of the IEEE International Conference on Computer Vision, pages 1922–1930, 2015.",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,"K. Soomro, A. R. Zamir, and M. Shah. Ucf101: A dataset of 101 human actions classes from videos in the wild. arXiv preprint arXiv:1212.0402, 2012.",,,,,,,"K. Soomro, A. R. Zamir, and M. Shah. Ucf101: A dataset of 101 human actions classes from videos in the wild. arXiv preprint arXiv:1212.0402, 2012.",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,"G. Varol, I. Laptev, and C. Schmid. Long-term temporal convolutions for action recognition. IEEE transactions on pattern analysis and machine intelligence",40(6):1510–1517,,,,,,"G. Varol, I. Laptev, and C. Schmid. Long-term temporal convolutions for action recognition. IEEE transactions on pattern analysis and machine intelligence, 40(6):1510–1517, 2017.",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,"J. Wang, W. Liu, S. Kumar, and S.-F. Chang. Learning to hash for indexing big dataa survey. Proceedings of the IEEE",104(1):34–57,,,,,,"J. Wang, W. Liu, S. Kumar, and S.-F. Chang. Learning to hash for indexing big dataa survey. Proceedings of the IEEE, 104(1):34–57, 2016.",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,"J. Wang, W. Liu, A. X. Sun, and Y.-G. Jiang. Learning hash codes with listwise supervision. In Proceedings of the IEEE International Conference on Computer Vision",pages 3032– 3039,,,,,,"J. Wang, W. Liu, A. X. Sun, and Y.-G. Jiang. Learning hash codes with listwise supervision. In Proceedings of the IEEE International Conference on Computer Vision, pages 3032– 3039, 2013.",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,"L. Wang, Y. Xiong, Z. Wang, Y. Qiao, D. Lin, X. Tang, and L. Van Gool. Temporal segment networks: Towards good practices for deep action recognition. In European conference on computer vision, pages 20–36. Springer, 2016.",,,,,,,"L. Wang, Y. Xiong, Z. Wang, Y. Qiao, D. Lin, X. Tang, and L. Van Gool. Temporal segment networks: Towards good practices for deep action recognition. In European conference on computer vision, pages 20–36. Springer, 2016.",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,"T. Weise, M. Zapf, R. Chiong, and A. J. Nebro. Why is optimization difficult? In Nature-Inspired Algorithms for Optimisation, pages 1–50. Springer, 2009.",,,,,,,"T. Weise, M. Zapf, R. Chiong, and A. J. Nebro. Why is optimization difficult? In Nature-Inspired Algorithms for Optimisation, pages 1–50. Springer, 2009.",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,"Y. Weiss, A. Torralba, and R. Fergus. Spectral hashing. In Advances in neural information processing systems",pages 1753–1760,,,,,,"Y. Weiss, A. Torralba, and R. Fergus. Spectral hashing. In Advances in neural information processing systems, pages 1753–1760, 2009.",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,E. W. Weisstein. Hadamard matrix. 2002.,,,,,,,E. W. Weisstein. Hadamard matrix. 2002.,./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,"Y. Wen, K. Zhang, Z. Li, and Y. Qiao. A discriminative feature learning approach for deep face recognition. In European Conference on Computer Vision, pages 499–515. Springer, 2016.",,,,,,,"Y. Wen, K. Zhang, Z. Li, and Y. Qiao. A discriminative feature learning approach for deep face recognition. In European Conference on Computer Vision, pages 499–515. Springer, 2016.",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,"R. Xia, Y. Pan, H. Lai, C. Liu, and S. Yan. Supervised hashing for image retrieval via image representation learning. In AAAI",volume 1, page 2,,,,,"R. Xia, Y. Pan, H. Lai, C. Liu, and S. Yan. Supervised hashing for image retrieval via image representation learning. In AAAI, volume 1, page 2, 2014.",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,"E. Yang, T. Liu, C. Deng, W. Liu, and D. Tao. Distillhash: Unsupervised deep hashing by distilling data pairs. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",pages 2946–2955,,,,,,"E. Yang, T. Liu, C. Deng, W. Liu, and D. Tao. Distillhash: Unsupervised deep hashing by distilling data pairs. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2946–2955, 2019.",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,"L. Yuan, E. H. F. Tay, P. Li, and J. Feng. Unsupervised video summarization with cycle-consistent adversarial lstm networks. IEEE Transactions on Multimedia, 2019.",,,,,,,"L. Yuan, E. H. F. Tay, P. Li, and J. Feng. Unsupervised video summarization with cycle-consistent adversarial lstm networks. IEEE Transactions on Multimedia, 2019.",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,"L. Yuan, F. E. Tay, P. Li, L. Zhou, and J. Feng. Cycle-sum: cycle-consistent adversarial lstm networks for unsupervised video summarization. In Proceedings of the AAAI Conference on Artificial Intelligence",volume 33, pages 9143–9150,,,,,"L. Yuan, F. E. Tay, P. Li, L. Zhou, and J. Feng. Cycle-sum: cycle-consistent adversarial lstm networks for unsupervised video summarization. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 33, pages 9143–9150, 2019.",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,"H. Zhu, M. Long, J. Wang, and Y. Cao. Deep hashing network for efficient similarity retrieval. In AAAI",pages 2415– 2421,,,,,,"H. Zhu, M. Long, J. Wang, and Y. Cao. Deep hashing network for efficient similarity retrieval. In AAAI, pages 2415– 2421, 2016. ",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,"N. Zhuang, J. Ye, and K. A. Hua. Dlstm approach to video modeling with hashing for large-scale video retrieval. In Pattern Recognition (ICPR)",2016 23rd International Conference on,,,,,,"N. Zhuang, J. Ye, and K. A. Hua. Dlstm approach to video modeling with hashing for large-scale video retrieval. In Pattern Recognition (ICPR), 2016 23rd International Conference on, pages 3222–3227. IEEE, 2016. ",./refs/download/Central similarity quantization for efficient image and video retrieval.pdf,
0,,[Bickel and Scheffer,,,, pages 19–26. IEEE Computer Society, 2004.,"[Bickel and Scheffer, 2004] Steffen Bickel and Tobias Scheffer. Multi-view clustering. In IEEE International Conference on Data Mining (ICDM), pages 19–26. IEEE Computer Society, 2004.",./refs/download/Doubly Aligned Incomplete Multi-view Clustering.pdf,
0,,[Bishop and Nasrabadi,,,, 16(4):049901, 2007.,"[Bishop and Nasrabadi, 2007] Christopher M Bishop and Nasser M Nasrabadi. Pattern recognition and machine learning. Journal of Electronic Imaging, 16(4):049901, 2007.",./refs/download/Doubly Aligned Incomplete Multi-view Clustering.pdf,
0,,[Blum and Mitchell,,,, pages 92–100. ACM, 1998.,"[Blum and Mitchell, 1998] Avrim Blum and Tom Mitchell. Combining labeled and unlabeled data with co-training. In Annual Conference on Computational Learning Theory (COLT), pages 92–100. ACM, 1998.",./refs/download/Doubly Aligned Incomplete Multi-view Clustering.pdf,
0,[Chao et al.,2017] Guoqing Chao, Shiliang Sun,,, and Jinbo Bi. A survey on multi-view clustering. arXiv preprint arXiv:1712.06246, 2017.,"[Chao et al., 2017] Guoqing Chao, Shiliang Sun, and Jinbo Bi. A survey on multi-view clustering. arXiv preprint arXiv:1712.06246, 2017.",./refs/download/Doubly Aligned Incomplete Multi-view Clustering.pdf,
0,[Ding et al.,2010] Chris HQ Ding, Tao Li, and Michael I Jordan. Convex and semi-nonnegative matrix factorizations. IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI),, 32(1):45–55, 2010.,"[Ding et al., 2010] Chris HQ Ding, Tao Li, and Michael I Jordan. Convex and semi-nonnegative matrix factorizations. IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 32(1):45–55, 2010.",./refs/download/Doubly Aligned Incomplete Multi-view Clustering.pdf,
0,[Fan et al.,2017] Yanbo Fan, Jian Liang,,,,,"[Fan et al., 2017] Yanbo Fan, Jian Liang, Ran He, Bao-Gang Hu, and Siwei Lyu. Robust localized multi-view subspace clustering. arXiv preprint arXiv:1705.07777, 2017.",./refs/download/Doubly Aligned Incomplete Multi-view Clustering.pdf,
0,[Jing et al.,2017] Xiao-Yuan Jing, Fei Wu,,,,,"[Jing et al., 2017] Xiao-Yuan Jing, Fei Wu, Xiwei Dong, Shiguang Shan, and Songcan Chen. Semi-supervised multi-view correlation feature learning with application to webpage classification. In AAAI Conference on Artificial Intelligence (AAAI), pages 1374–1381, 2017.",./refs/download/Doubly Aligned Incomplete Multi-view Clustering.pdf,
0,[Kong et al.,2011] Deguang Kong, Chris Ding, and Heng Huang. Robust nonnegative matrix factorization using l21norm. In ACM International Conference on Information and Knowledge Managementn (CIKM),, pages 673–682. ACM, 2011.,"[Kong et al., 2011] Deguang Kong, Chris Ding, and Heng Huang. Robust nonnegative matrix factorization using l21norm. In ACM International Conference on Information and Knowledge Managementn (CIKM), pages 673–682. ACM, 2011.",./refs/download/Doubly Aligned Incomplete Multi-view Clustering.pdf,
0,,[Lee and Seung,,,,,,"[Lee and Seung, 1999] Daniel D Lee and H Sebastian Seung. Learning the parts of objects by non-negative matrix factorization. Nature, 401(6755):788–791, 1999. [Li et al., 2014] Shao-Yuan Li, Yuan Jiang, and Zhi-Hua Zhou. Partial multi-view clustering. In AAAI Conference on Artificial Intelligence (AAAI), pages 1968–1974, 2014.",./refs/download/Doubly Aligned Incomplete Multi-view Clustering.pdf,
0,,[Li,,,, pages 3793–3800. IEEE, 2016.,"[Li, 2016] Yifeng Li. Advances in multi-view matrix factorizations. In International Joint Conference on Neural Networks (IJCNN), pages 3793–3800. IEEE, 2016.",./refs/download/Doubly Aligned Incomplete Multi-view Clustering.pdf,
0,[Liu et al.,2013] Jialu Liu, Chi Wang,,,,,"[Liu et al., 2013] Jialu Liu, Chi Wang, Jing Gao, and Jiawei Han. Multi-view clustering via joint nonnegative matrix factorization. In SIAM International Conference on Data Mining (SDM), pages 252–260. SIAM, 2013.",./refs/download/Doubly Aligned Incomplete Multi-view Clustering.pdf,
0,[Nie et al.,2017] Feiping Nie, Guohao Cai, and Xuelong Li. Multi-view clustering and semi-supervised classification with adaptive neighbours. In AAAI Conference on Artificial Intelligence (AAAI),, pages 2408–2414, 2017.,"[Nie et al., 2017] Feiping Nie, Guohao Cai, and Xuelong Li. Multi-view clustering and semi-supervised classification with adaptive neighbours. In AAAI Conference on Artificial Intelligence (AAAI), pages 2408–2414, 2017.",./refs/download/Doubly Aligned Incomplete Multi-view Clustering.pdf,
0,[Nie et al.,2018] Feiping Nie, Guohao Cai,,,,,"[Nie et al., 2018] Feiping Nie, Guohao Cai, Jing Li, and Xuelong Li. Auto-weighted multi-view learning for image clustering and semi-supervised classification. IEEE Transactions on Image Processing, 27(3):1501–1511, 2018. [Potthast et al., 2018] Christian Potthast, Andreas Breitenmoser, Fei Sha, and Gaurav S Sukhatme. Active multiview object recognition and online feature selection. In Robotics Research, pages 471–488. Springer, 2018.",./refs/download/Doubly Aligned Incomplete Multi-view Clustering.pdf,
0,[Romero et al.,2017] Andrés Romero, Juan León,,, and Pablo Arbeláez. Multi-view dynamic facial action unit detection. arXiv preprint arXiv:1704.07863, 2017.,"[Romero et al., 2017] Andrés Romero, Juan León, and Pablo Arbeláez. Multi-view dynamic facial action unit detection. arXiv preprint arXiv:1704.07863, 2017.",./refs/download/Doubly Aligned Incomplete Multi-view Clustering.pdf,
0,[Schechter et al.,2017] Ian Schechter, Tim Wakeling,,, and Ann M Wollrath. Processing data from multiple sources, March 28 2017.,"[Schechter et al., 2017] Ian Schechter, Tim Wakeling, and Ann M Wollrath. Processing data from multiple sources, March 28 2017.",./refs/download/Doubly Aligned Incomplete Multi-view Clustering.pdf,
0,[Shao et al.,2015] Weixiang Shao, Lifang He,,,,,"[Shao et al., 2015] Weixiang Shao, Lifang He, and S Yu Philip. Multiple incomplete views clustering via weighted nonnegative matrix factorization with l2,1 regularization. In Machine Learning and Knowledge Discovery in Databases - European Conference, ECML PKDD, pages 318–334, 2015.",./refs/download/Doubly Aligned Incomplete Multi-view Clustering.pdf,
0,,[Sun,,,, pages 2031–2038, 2013.,"[Sun, 2013] Shiliang Sun. A survey of multi-view machine learning. Neural Computing and Applications, pages 2031–2038, 2013.",./refs/download/Doubly Aligned Incomplete Multi-view Clustering.pdf,
0,[Wu et al.,2018] Baolei Wu, Enyuan Wang,,,,,"[Wu et al., 2018] Baolei Wu, Enyuan Wang, Zhen Zhu, Wei Chen, and Pengcheng Xiao. Manifold nmf with l21 norm for clustering. Neurocomputing, 273:78–88, 2018.",./refs/download/Doubly Aligned Incomplete Multi-view Clustering.pdf,
0,[Xing et al.,2017] Junliang Xing, Zhiheng Niu,,,,,"[Xing et al., 2017] Junliang Xing, Zhiheng Niu, Junshi Huang, Weiming Hu, Xi Zhou, and Shuicheng Yan. Towards robust and accurate multi-view and partiallyoccluded face alignment. IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2017.",./refs/download/Doubly Aligned Incomplete Multi-view Clustering.pdf,
0,[Zhao et al.,2016] Handong Zhao, Hongfu Liu, and Yun Fu. Incomplete multi-modal visual data grouping. In International Joint Conference on Artificial Intelligence (IJCAI),, pages 2392–2398, 2016.,"[Zhao et al., 2016] Handong Zhao, Hongfu Liu, and Yun Fu. Incomplete multi-modal visual data grouping. In International Joint Conference on Artificial Intelligence (IJCAI), pages 2392–2398, 2016.",./refs/download/Doubly Aligned Incomplete Multi-view Clustering.pdf,
0,[Zhao et al.,2017] Handong Zhao, Zhengming Ding, and Yun Fu. Multi-view clustering via deep matrix factorization. In AAAI Conference on Artificial Intelligence (AAAI),, pages 2921–2927, 2017.,"[Zhao et al., 2017] Handong Zhao, Zhengming Ding, and Yun Fu. Multi-view clustering via deep matrix factorization. In AAAI Conference on Artificial Intelligence (AAAI), pages 2921–2927, 2017.",./refs/download/Doubly Aligned Incomplete Multi-view Clustering.pdf,
0,[Zong et al.,2017] Linlin Zong, Xianchao Zhang,,,,,"[Zong et al., 2017] Linlin Zong, Xianchao Zhang, Long Zhao, Hong Yu, and Qianli Zhao. Multi-view clustering  via multi-manifold regularized non-negative matrix factorization. Neural Networks, 88:74–89, 2017.",./refs/download/Doubly Aligned Incomplete Multi-view Clustering.pdf,
0,"R. Hu, W. Li, O. Van Kaick, A. Shamir, H. Zhang, and H. Huang. Learning to predict part mobility from a single static snapshot. ACM Transactions on Graphics (TOG)",36(6):227,,,,,,"R. Hu, W. Li, O. Van Kaick, A. Shamir, H. Zhang, and H. Huang. Learning to predict part mobility from a single static snapshot. ACM Transactions on Graphics (TOG), 36(6):227, 2017. 3",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"R. Hu, O. van Kaick, B. Wu, H. Huang, A. Shamir, and H. Zhang. Learning how objects function via co-analysis of interactions. ACM Transactions on Graphics (TOG)",35(4):47,,,,,,"R. Hu, O. van Kaick, B. Wu, H. Huang, A. Shamir, and H. Zhang. Learning how objects function via co-analysis of interactions. ACM Transactions on Graphics (TOG), 35(4):47, 2016. 1, 3",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"R. Hu, Z. Yan, J. Zhang, O. van Kaick, A. Shamir, H. Zhang, and H. Huang. Predictive and generative neural networks for object functionality. In Computer Graphics Forum (Eurographics State-of-the-art report)",volume 37, pages 603– 624,,,,,"R. Hu, Z. Yan, J. Zhang, O. van Kaick, A. Shamir, H. Zhang, and H. Huang. Predictive and generative neural networks for object functionality. In Computer Graphics Forum (Eurographics State-of-the-art report), volume 37, pages 603– 624, 2018. 1",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"J. Huang, H. Su, and L. Guibas. Robust watertight manifold surface generation method for shapenet models. arXiv preprint arXiv:1802.01698, 2018. 4",,,,,,,"J. Huang, H. Su, and L. Guibas. Robust watertight manifold surface generation method for shapenet models. arXiv preprint arXiv:1802.01698, 2018. 4",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"A. Jain, T. Thormählen, T. Ritschel, and H.-P. Seidel. Exploring shape variations by 3d-model decomposition and partbased recombination. In Computer Graphics Forum",volume 31,,,,,,"A. Jain, T. Thormählen, T. Ritschel, and H.-P. Seidel. Exploring shape variations by 3d-model decomposition and partbased recombination. In Computer Graphics Forum, volume 31, pages 631–640. Wiley Online Library, 2012. 1",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"E. Kalogerakis, A. Hertzmann, and K. Singh. Learning 3D mesh segmentation and labeling. ACM Transactions on Graphics (TOG)",29(4):102,,,,,,"E. Kalogerakis, A. Hertzmann, and K. Singh. Learning 3D mesh segmentation and labeling. ACM Transactions on Graphics (TOG), 29(4):102, 2010. 2",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"V. G. Kim, S. Chaudhuri, L. Guibas, and T. Funkhouser. Shape2pose: Human-centric shape analysis. ACM Transactions on Graphics (TOG)",33(4):120,,,,,,"V. G. Kim, S. Chaudhuri, L. Guibas, and T. Funkhouser. Shape2pose: Human-centric shape analysis. ACM Transactions on Graphics (TOG), 33(4):120, 2014. 1",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,R. Klokov and V. Lempitsky. Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models. In Computer Vision (ICCV),2017 IEEE International Conference on,,,, 2017. 1, 5,"R. Klokov and V. Lempitsky. Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models. In Computer Vision (ICCV), 2017 IEEE International Conference on, pages 863–872. IEEE, 2017. 1, 5",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"E. Kolve, R. Mottaghi, D. Gordon, Y. Zhu, A. Gupta, and A. Farhadi. Ai2-thor: An interactive 3d environment for visual ai. arXiv preprint arXiv:1712.05474, 2017. 1",,,,,,,"E. Kolve, R. Mottaghi, D. Gordon, Y. Zhu, A. Gupta, and A. Farhadi. Ai2-thor: An interactive 3d environment for visual ai. arXiv preprint arXiv:1712.05474, 2017. 1",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,P. Krähenbühl and V. Koltun. Parameter learning and convergent inference for dense random fields. In International Conference on Machine Learning,pages 513–521,,,,,,"P. Krähenbühl and V. Koltun. Parameter learning and convergent inference for dense random fields. In International Conference on Machine Learning, pages 513–521, 2013. 8",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,H. W. Kuhn. The hungarian method for the assignment problem. Naval research logistics quarterly,2(1-2):83–97,,,,,,"H. W. Kuhn. The hungarian method for the assignment problem. Naval research logistics quarterly, 2(1-2):83–97, 1955. 7",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,T. Le and Y. Duan. PointGrid: A deep network for 3D shape understanding. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,pages 9204– 9214,,,,,,"T. Le and Y. Duan. PointGrid: A deep network for 3D shape understanding. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 9204– 9214, 2018. 1, 5",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"J. Li, B. M. Chen, and G. H. Lee. SO-Net: Self-organizing network for point cloud analysis. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",pages 9397–9406,,,,,,"J. Li, B. M. Chen, and G. H. Lee. SO-Net: Self-organizing network for point cloud analysis. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 9397–9406, 2018. 1, 5",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"J. Li, K. Xu, S. Chaudhuri, E. Yumer, H. Zhang, and L. Guibas. Grass: Generative recursive autoencoders for shape structures. ACM Transactions on Graphics (TOG)",36(4):52,,,,,,"J. Li, K. Xu, S. Chaudhuri, E. Yumer, H. Zhang, and L. Guibas. Grass: Generative recursive autoencoders for shape structures. ACM Transactions on Graphics (TOG), 36(4):52, 2017. 1",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"Y. Li, R. Bu, M. Sun, and B. Chen. PointCNN: Convolution on X -transformed points. Advances in neural information processing systems (NIPS), 2018. 1",5, 6,,, 13, 14,"Y. Li, R. Bu, M. Sun, and B. Chen. PointCNN: Convolution on X -transformed points. Advances in neural information processing systems (NIPS), 2018. 1, 5, 6, 13, 14",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"Z. Liu, W. T. Freeman, J. B. Tenenbaum, and J. Wu. Physical primitive decomposition. arXiv preprint arXiv:1809.05070, 2018. 1  Acknowledgements This research was supported by NSF grants CRI1729205 and IIS-1763268",a Vannevar Bush Faculty Fellowship, a Google fellowship, and gifts from Autodesk,, Google and Intel AI Lab. We especially thank Zhe Hu from Hikvision for the help on data annotation and Linfeng Zhao for the help on preparing hierarchical templates. We appreciate the 66 annotators from Hikvision, Ytuuu and Data++ on data annotation.  References,"Z. Liu, W. T. Freeman, J. B. Tenenbaum, and J. Wu. Physical primitive decomposition. arXiv preprint arXiv:1809.05070, 2018. 1  Acknowledgements This research was supported by NSF grants CRI1729205 and IIS-1763268, a Vannevar Bush Faculty Fellowship, a Google fellowship, and gifts from Autodesk, Google and Intel AI Lab. We especially thank Zhe Hu from Hikvision for the help on data annotation and Linfeng Zhao for the help on preparing hierarchical templates. We appreciate the 66 annotators from Hikvision, Ytuuu and Data++ on data annotation.  References",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"M. Attene, S. Katz, M. Mortara, G. Patané, M. Spagnuolo, and A. Tal. Mesh segmentation-a comparative study. In Shape Modeling and Applications, 2006. SMI 2006. IEEE International Conference on, pages 7–7. IEEE, 2006. 2",,,,,,,"M. Attene, S. Katz, M. Mortara, G. Patané, M. Spagnuolo, and A. Tal. Mesh segmentation-a comparative study. In Shape Modeling and Applications, 2006. SMI 2006. IEEE International Conference on, pages 7–7. IEEE, 2006. 2",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"H. Benhabiles, J.-P. Vandeborre, G. Lavoué, and M. Daoudi. A framework for the objective evaluation of segmentation algorithms using a ground-truth of human segmented 3Dmodels. In IEEE International Conference on Shape Modeling and Applications (SMI)",pages Session–5,,,,,,"H. Benhabiles, J.-P. Vandeborre, G. Lavoué, and M. Daoudi. A framework for the objective evaluation of segmentation algorithms using a ground-truth of human segmented 3Dmodels. In IEEE International Conference on Shape Modeling and Applications (SMI), pages Session–5, 2009. 2",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"A. X. Chang, T. Funkhouser, L. Guibas, P. Hanrahan, Q. Huang, Z. Li, S. Savarese, M. Savva, S. Song, H. Su, et al. ShapeNet: An information-rich 3D model repository. arXiv preprint arXiv:1512.03012, 2015. 1",2, 5, 9,, 12, 13,"A. X. Chang, T. Funkhouser, L. Guibas, P. Hanrahan, Q. Huang, Z. Li, S. Savarese, M. Savva, S. Song, H. Su, et al. ShapeNet: An information-rich 3D model repository. arXiv preprint arXiv:1512.03012, 2015. 1, 2, 5, 9, 12, 13",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"A. X. Chang, R. Mago, P. Krishna, M. Savva, and C. Fellbaum. Linking WordNet to 3D shapes. In Global WordNet Conference, 2018. 2",3, 4,,,,,"A. X. Chang, R. Mago, P. Krishna, M. Savva, and C. Fellbaum. Linking WordNet to 3D shapes. In Global WordNet Conference, 2018. 2, 3, 4, 11",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"X. Chen, A. Golovinskiy, and T. Funkhouser. A benchmark for 3D mesh segmentation. ACM Transactions on Graphics (Proc. SIGGRAPH), 2009. 1",2, 4,,,,,"X. Chen, A. Golovinskiy, and T. Funkhouser. A benchmark for 3D mesh segmentation. ACM Transactions on Graphics (Proc. SIGGRAPH), 2009. 1, 2, 4, 12",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"B. Graham, M. Engelcke, and L. van der Maaten. 3D semantic segmentation with submanifold sparse convolutional networks. Proceedings of the IEEE Computer Vision and Pattern Recognition (CVPR)",pages 18–22,,,,,,"B. Graham, M. Engelcke, and L. van der Maaten. 3D semantic segmentation with submanifold sparse convolutional networks. Proceedings of the IEEE Computer Vision and Pattern Recognition (CVPR), pages 18–22, 2018. 1, 5",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"P. Hermosilla, T. Ritschel, P.-P. Vázquez, À. Vinacua, and T. Ropinski. Monte carlo convolution for learning on non-uniformly sampled point clouds. arXiv preprint arXiv:1806.01759, 2018. 1",5,,,,,,"P. Hermosilla, T. Ritschel, P.-P. Vázquez, À. Vinacua, and T. Ropinski. Monte carlo convolution for learning on non-uniformly sampled point clouds. arXiv preprint arXiv:1806.01759, 2018. 1, 5",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,D. D. Hoffman and W. A. Richards. Parts of recognition. Cognition,18(1-3):65–96,,,,,,"D. D. Hoffman and W. A. Richards. Parts of recognition. Cognition, 18(1-3):65–96, 1984. 1",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"R. Hu, L. Fan, and L. Liu. Co-segmentation of 3D shapes via subspace clustering. In Computer graphics forum",volume 31,,,,,,"R. Hu, L. Fan, and L. Liu. Co-segmentation of 3D shapes via subspace clustering. In Computer graphics forum, volume 31, pages 1703–1713. Wiley Online Library, 2012. 2  9 ",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"C. Yan, D. Misra, A. Bennnett, A. Walsman, Y. Bisk, and Y. Artzi. Chalet: Cornell house agent learning environment. arXiv preprint arXiv:1801.07357, 2018. 1",,,,,,,"C. Yan, D. Misra, A. Bennnett, A. Walsman, Y. Bisk, and Y. Artzi. Chalet: Cornell house agent learning environment. arXiv preprint arXiv:1801.07357, 2018. 1",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"L. Yi, L. Guibas, A. Hertzmann, V. G. Kim, H. Su, and E. Yumer. Learning hierarchical shape segmentation and labeling from online repositories. ACM Transactions on Graphics (Proc. SIGGRAPH Asia), 2017. 1",2,,,,,,"L. Yi, L. Guibas, A. Hertzmann, V. G. Kim, H. Su, and E. Yumer. Learning hierarchical shape segmentation and labeling from online repositories. ACM Transactions on Graphics (Proc. SIGGRAPH Asia), 2017. 1, 2",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"L. Yi, V. G. Kim, D. Ceylan, I. Shen, M. Yan, H. Su, C. Lu, Q. Huang, A. Sheffer, L. Guibas, et al. A scalable active framework for region annotation in 3D shape collections. ACM Transactions on Graphics (TOG)",35(6):210,,,,,,"L. Yi, V. G. Kim, D. Ceylan, I. Shen, M. Yan, H. Su, C. Lu, Q. Huang, A. Sheffer, L. Guibas, et al. A scalable active framework for region annotation in 3D shape collections. ACM Transactions on Graphics (TOG), 35(6):210, 2016. 1, 2, 4, 5, 6, 12, 13, 14",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"L. Yi, H. Su, X. Guo, and L. J. Guibas. SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",pages 6584–6592,,,,,,"L. Yi, H. Su, X. Guo, and L. J. Guibas. SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 6584–6592, 2017. 1, 5",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"Y. Zhu, D. Gordon, E. Kolve, D. Fox, L. Fei-Fei, A. Gupta, R. Mottaghi, and A. Farhadi. Visual semantic planning using deep successor representations. arXiv preprint ArXiv:1705.08080",pages 1–13,,,,,,"Y. Zhu, D. Gordon, E. Kolve, D. Fox, L. Fei-Fei, A. Gupta, R. Mottaghi, and A. Farhadi. Visual semantic planning using deep successor representations. arXiv preprint ArXiv:1705.08080, pages 1–13, 2017. 1 ",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,L. v. d. Maaten and G. Hinton. Visualizing data using t-sne. Journal of machine learning research,9(Nov):2579–2605,,,,,,"L. v. d. Maaten and G. Hinton. Visualizing data using t-sne. Journal of machine learning research, 9(Nov):2579–2605, 2008. 11",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"M. Ovsjanikov, W. Li, L. Guibas, and N. J. Mitra. Exploration of continuous variability in collections of 3d shapes. In ACM Transactions on Graphics (TOG)",volume 30,,,,,,"M. Ovsjanikov, W. Li, L. Guibas, and N. J. Mitra. Exploration of continuous variability in collections of 3d shapes. In ACM Transactions on Graphics (TOG), volume 30, page 33. ACM, 2011. 1",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"X. Puig, K. Ra, M. Boben, J. Li, T. Wang, S. Fidler, and A. Torralba. Virtualhome: Simulating household activities via programs. In CVPR, 2018. 1",,,,,,,"X. Puig, K. Ra, M. Boben, J. Li, T. Wang, S. Fidler, and A. Torralba. Virtualhome: Simulating household activities via programs. In CVPR, 2018. 1",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"C. R. Qi, H. Su, K. Mo, and L. J. Guibas. PointNet: Deep learning on point sets for 3D classification and segmentation. In Proc. Computer Vision and Pattern Recognition (CVPR)",IEEE, volume 1,,,,,"C. R. Qi, H. Su, K. Mo, and L. J. Guibas. PointNet: Deep learning on point sets for 3D classification and segmentation. In Proc. Computer Vision and Pattern Recognition (CVPR), IEEE, volume 1, page 4, 2017. 1, 5, 6, 13, 14",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"C. R. Qi, L. Yi, H. Su, and L. J. Guibas. PointNet++: Deep hierarchical feature learning on point sets in a metric space. In Advances in Neural Information Processing Systems",pages 5099–5108,,,,,,"C. R. Qi, L. Yi, H. Su, and L. J. Guibas. PointNet++: Deep hierarchical feature learning on point sets in a metric space. In Advances in Neural Information Processing Systems, pages 5099–5108, 2017. 1, 5, 6, 7, 13, 14, 15",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"H. Su, V. Jampani, D. Sun, S. Maji, E. Kalogerakis, M.-H. Yang, and J. Kautz. SplatNet: Sparse lattice networks for point cloud processing. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition",pages 2530–2539,,,,,,"H. Su, V. Jampani, D. Sun, S. Maji, E. Kalogerakis, M.-H. Yang, and J. Kautz. SplatNet: Sparse lattice networks for point cloud processing. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2530–2539, 2018. 1, 5",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"M. Sung, H. Su, R. Yu, and L. Guibas. Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions. Advances in neural information processing systems (NIPS), 2018. 8",,,,,,,"M. Sung, H. Su, R. Yu, and L. Guibas. Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions. Advances in neural information processing systems (NIPS), 2018. 8",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"P.-S. Wang, Y. Liu, Y.-X. Guo, C.-Y. Sun, and X. Tong. OCNN: Octree-based convolutional neural networks for 3D shape analysis. ACM Transactions on Graphics (TOG)",36(4):72,,,,,,"P.-S. Wang, Y. Liu, Y.-X. Guo, C.-Y. Sun, and X. Tong. OCNN: Octree-based convolutional neural networks for 3D shape analysis. ACM Transactions on Graphics (TOG), 36(4):72, 2017. 1, 5",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"W. Wang, R. Yu, Q. Huang, and U. Neumann. SGPN: Similarity group proposal network for 3D point cloud instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)",pages 2569–2578,,,,,,"W. Wang, R. Yu, Q. Huang, and U. Neumann. SGPN: Similarity group proposal network for 3D point cloud instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 2569–2578, 2018. 8, 15",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"X. Wang, B. Zhou, H. Fang, X. Chen, Q. Zhao, and K. Xu. Learning to group and label fine-grained shape components. ACM Transactions on Graphics (SIGGRAPH Asia 2018)",37(6),,,,,,"X. Wang, B. Zhou, H. Fang, X. Chen, Q. Zhao, and K. Xu. Learning to group and label fine-grained shape components. ACM Transactions on Graphics (SIGGRAPH Asia 2018), 37(6), 2018. 2",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"Y. Wang, S. Asafi, O. Van Kaick, H. Zhang, D. Cohen-Or, and B. Chen. Active co-analysis of a set of shapes. ACM Transactions on Graphics (TOG)",31(6):165,,,,,,"Y. Wang, S. Asafi, O. Van Kaick, H. Zhang, D. Cohen-Or, and B. Chen. Active co-analysis of a set of shapes. ACM Transactions on Graphics (TOG), 31(6):165, 2012. 2",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"Y. Wang, Y. Sun, Z. Liu, S. E. Sarma, M. M. Bronstein, and J. M. Solomon. Dynamic graph cnn for learning on point clouds. arXiv preprint arXiv:1801.07829, 2018. 1",5,,,,,,"Y. Wang, Y. Sun, Z. Liu, S. E. Sarma, M. M. Bronstein, and J. M. Solomon. Dynamic graph cnn for learning on point clouds. arXiv preprint arXiv:1801.07829, 2018. 1, 5",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"Z. Wang and F. Lu. VoxSegNet: Volumetric CNNs for semantic part segmentation of 3D shapes. arXiv preprint arXiv:1809.00226, 2018. 1",5,,,,,,"Z. Wang and F. Lu. VoxSegNet: Volumetric CNNs for semantic part segmentation of 3D shapes. arXiv preprint arXiv:1809.00226, 2018. 1, 5",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"Z. Wu, X. Wang, D. Lin, D. Lischinski, D. Cohen-Or, and H. Huang. Structure-aware generative network for 3d-shape modeling. arXiv preprint arXiv:1808.03981, 2018. 1",,,,,,,"Z. Wu, X. Wang, D. Lin, D. Lischinski, D. Cohen-Or, and H. Huang. Structure-aware generative network for 3d-shape modeling. arXiv preprint arXiv:1808.03981, 2018. 1",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,"Y. Xu, T. Fan, M. Xu, L. Zeng, and Y. Qiao. SpiderCNN: Deep learning on point sets with parameterized convolutional filters. European Conference on Computer Vision (ECCV), 2018. 1",5, 6,,,,,"Y. Xu, T. Fan, M. Xu, L. Zeng, and Y. Qiao. SpiderCNN: Deep learning on point sets with parameterized convolutional filters. European Conference on Computer Vision (ECCV), 2018. 1, 5, 6, 13, 14  A. Overview This document provides additional dataset visualization and statistics (Sec B), hierarchical template design details and visualization (Sec C), and the architectures and training details for the three shape segmentation tasks (Sec D), to the main paper.  B. More Dataset Visualization and Statistics We present more visualization and statistics over the proposed PartNet dataset.  B.1. More Fine-grained Segmentation Visualization Figure 13 and 14 show more visualization for finegrained instance-level segmentation annotations in PartNet. We observe the complexity of the annotated segmentation and the heterogeneous variation of shapes within each object category.  B.2. More Hierarchical Segmentation Visualization Figure 15, 16 and 17 show more visualization for example hierarchical instance-level segmentation annotations in PartNet. We visualize the tree-structure of the hierarchical segmentation annotation with the 2D part renderings associated to the tree nodes.  B.3. Shape Statistics We report the statistics for the number of annotations, unique shapes and shapes that we collect multiple human annotations in Figure 9.  B.4. Part Statistics We report the statistics for the number of part semantics for each object category in Figure 10. We also present the 10  Figure 9. PartNet shape statistics. We report the statistics for the number of annotations, unique shapes and shapes that we collect multiple human annotations.  Figure 11. PartNet part instance statistics. We report the statistics for the maximum and median number of part instances per shape for each object category.  Figure 10. PartNet part semantics statistics. We report the statistics for the number of part semantics for each object category.  Figure 12. PartNet tree depth statistics. We report the statistics for the maximum and median tree depth for each object category.  statistics for the maximum and median number of part instances per shape for each object category in Figure 11. We report the statistics for the maximum and median tree depth for each object category in Figure 12. ",./refs/download/Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding.pdf,
0,,Berg,,,,,,"Berg, T., Liu, J., Woo Lee, S., Alexander, M. L., Jacobs, D. W., and Belhumeur, P. N. Birdsnap: Large-scale fine-grained visual categorization of birds. CVPR, pp. 2011–2018, 2014.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,,Bossard,,,,,,"Bossard, L., Guillaumin, M., and Van Gool, L. Food-101– mining discriminative components with random forests. ECCV, pp. 446–461, 2014.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,,Cai,,,,,,"Cai, H., Zhu, L., and Han, S. Proxylessnas: Direct neural architecture search on target task and hardware. ICLR, 2019. Chollet, F. Xception: Deep learning with depthwise separable convolutions. CVPR, pp. 1610–02357, 2017.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,,Cubuk,,,,,,"Cubuk, E. D., Zoph, B., Mane, D., Vasudevan, V., and Le, Q. V. Autoaugment: Learning augmentation policies from data. CVPR, 2019.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,,Han,,,,,,"Han, S., Mao, H., and Dally, W. J. Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding. ICLR, 2016.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,,He,,,,,,"He, K., Zhang, X., Ren, S., and Sun, J. Deep residual learning for image recognition. CVPR, pp. 770–778, 2016. He, K., Gkioxari, G., Dollár, P., and Girshick, R. Mask r-cnn. ICCV, pp. 2980–2988, 2017.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,,He,,,,,,"He, Y., Lin, J., Liu, Z., Wang, H., Li, L.-J., and Han, S. Amc: Automl for model compression and acceleration on mobile devices. ECCV, 2018. Hendrycks, D. and Gimpel, K. Gaussian error linear units (gelus). arXiv preprint arXiv:1606.08415, 2016.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,,Howard,,,,,,"Howard, A. G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M., and Adam, H. Mobilenets: Efficient convolutional neural networks for mobile vision applications. arXiv preprint arXiv:1704.04861, 2017. Hu, J., Shen, L., and Sun, G. Squeeze-and-excitation networks. CVPR, 2018.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,,Huang,,,,,,"Huang, G., Sun, Y., Liu, Z., Sedra, D., and Weinberger, K. Q. Deep networks with stochastic depth. ECCV, pp. 646–661, 2016.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,,Huang,,,,,,"Huang, Y., Cheng, Y., Chen, D., Lee, H., Ngiam, J., Le, Q. V., and Chen, Z. Gpipe: Efficient training of giant neural networks using pipeline parallelism. arXiv preprint arXiv:1808.07233, 2018.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,,Iandola,,,,,,"Iandola, F. N., Han, S., Moskewicz, M. W., Ashraf, K., Dally, W. J., and Keutzer, K. Squeezenet: Alexnet-level accuracy with 50x fewer parameters and <0.5 mb model size. arXiv preprint arXiv:1602.07360, 2016.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,,Ioffe,, C. Batch normalization: Accelerating deep network training by reducing internal covariate shift. ICML,, pp. 448–456, 2015.,"Ioffe, S. and Szegedy, C. Batch normalization: Accelerating deep network training by reducing internal covariate shift. ICML, pp. 448–456, 2015.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,,Raghu,,,,,,"Raghu, M., Poole, B., Kleinberg, J., Ganguli, S., and SohlDickstein, J. On the expressive power of deep neural networks. ICML, 2017.  Kornblith, S., Shlens, J., and Le, Q. V. Do better imagenet models transfer better? CVPR, 2019.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,,Krause,,,,,,"Krause, J., Deng, J., Stark, M., and Fei-Fei, L. Collecting a large-scale dataset of fine-grained cars. Second Workshop on Fine-Grained Visual Categorizatio, 2013. Krizhevsky, A. and Hinton, G. Learning multiple layers of features from tiny images. Technical Report, 2009.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,,Real,,,,,,"Real, E., Aggarwal, A., Huang, Y., and Le, Q. V. Regularized evolution for image classifier architecture search. AAAI, 2019.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,,Krizhevsky,,,,,,"Krizhevsky, A., Sutskever, I., and Hinton, G. E. Imagenet classification with deep convolutional neural networks. In NIPS, pp. 1097–1105, 2012.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,,Russakovsky,,,,,,"Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Karpathy, A., Khosla, A., Bernstein, M., et al. Imagenet large scale visual recognition challenge. International Journal of Computer Vision, 115(3): 211–252, 2015.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,,Lin,, S. Resnet with one-neuron hidden layers is a universal approximator. NeurIPS,, pp. 6172– 6181, 2018.,"Lin, H. and Jegelka, S. Resnet with one-neuron hidden layers is a universal approximator. NeurIPS, pp. 6172– 6181, 2018.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,,Sandler,,,,,,"Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., and Chen, L.-C. Mobilenetv2: Inverted residuals and linear bottlenecks. CVPR, 2018.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,,Lin,,,,,,"Lin, T.-Y., Dollár, P., Girshick, R., He, K., Hariharan, B., and Belongie, S. Feature pyramid networks for object detection. CVPR, 2017.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,,Sharir,,,, A. On the expressive power of overlapping architectures of deep learning. ICLR, 2018.,"Sharir, O. and Shashua, A. On the expressive power of overlapping architectures of deep learning. ICLR, 2018.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,,Liu,,,,,,"Liu, C., Zoph, B., Shlens, J., Hua, W., Li, L.-J., Fei-Fei, L., Yuille, A., Huang, J., and Murphy, K. Progressive neural architecture search. ECCV, 2018.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,,Srivastava,,,,,,"Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., and Salakhutdinov, R. Dropout: a simple way to prevent neural networks from overfitting. The Journal of Machine Learning Research, 15(1):1929–1958, 2014.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,,Lu,,,,,,"Lu, Z., Pu, H., Wang, F., Hu, Z., and Wang, L. The expressive power of neural networks: A view from the width. NeurIPS, 2018. Ma, N., Zhang, X., Zheng, H.-T., and Sun, J. Shufflenet v2: Practical guidelines for efficient cnn architecture design. ECCV, 2018.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,,Mahajan,,,,,,"Mahajan, D., Girshick, R., Ramanathan, V., He, K., Paluri, M., Li, Y., Bharambe, A., and van der Maaten, L. Exploring the limits of weakly supervised pretraining. arXiv preprint arXiv:1805.00932, 2018.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,,Szegedy,,,,,,"Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., and Wojna, Z. Rethinking the inception architecture for computer vision. CVPR, pp. 2818–2826, 2016.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,,Szegedy,,,,,,"Szegedy, C., Ioffe, S., Vanhoucke, V., and Alemi, A. A. Inception-v4, inception-resnet and the impact of residual connections on learning. AAAI, 4:12, 2017.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,,Maji,,,,,,"Maji, S., Rahtu, E., Kannala, J., Blaschko, M., and Vedaldi, A. Fine-grained visual classification of aircraft. arXiv preprint arXiv:1306.5151, 2013.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,,Tan,,,,,,"Tan, M., Chen, B., Pang, R., Vasudevan, V., Sandler, M., Howard, A., and Le, Q. V. MnasNet: Platform-aware neural architecture search for mobile. CVPR, 2019.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,,Ngiam,,,,,,"Ngiam, J., Peng, D., Vasudevan, V., Kornblith, S., Le, Q. V., and Pang, R. Domain adaptive transfer learning with specialist models. arXiv preprint arXiv:1811.07056, 2018.  Xie, S., Girshick, R., Dollár, P., Tu, Z., and He, K. Aggregated residual transformations for deep neural networks. CVPR, pp. 5987–5995, 2017.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,,Nilsback,,,,,,"Nilsback, M.-E. and Zisserman, A. Automated flower classification over a large number of classes. ICVGIP, pp. 722–729, 2008.  Yang, T.-J., Howard, A., Chen, B., Zhang, X., Go, A., Sze, V., and Adam, H. Netadapt: Platform-aware neural network adaptation for mobile applications. ECCV, 2018.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,,Parkhi,,,,,,"Parkhi, O. M., Vedaldi, A., Zisserman, A., and Jawahar, C. Cats and dogs. CVPR, pp. 3498–3505, 2012.  Zagoruyko, S. and Komodakis, N. Wide residual networks. BMVC, 2016.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,,Zhang,,,,,,"Zhang, X., Li, Z., Loy, C. C., and Lin, D. Polynet: A pursuit of structural diversity in very deep networks. CVPR, pp. 3900–3908, 2017. Zhang, X., Zhou, X., Lin, M., and Sun, J. Shufflenet: An extremely efficient convolutional neural network for mobile devices. CVPR, 2018.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,,Zhou,,,,,,"Zhou, B., Khosla, A., Lapedriza, A., Oliva, A., and Torralba, A. Learning deep features for discriminative localization. CVPR, pp. 2921–2929, 2016. Zoph, B. and Le, Q. V. Neural architecture search with reinforcement learning. ICLR, 2017.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,,Zoph,,,,,,"Zoph, B., Vasudevan, V., Shlens, J., and Le, Q. V. Learning transferable architectures for scalable image recognition. CVPR, 2018.",./refs/download/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,
0,"Y. Guo, L. Zhang, Y. Hu, X. He, and J. Gao. MS-Celeb-1M: A dataset and benchmark for large scale face recognition. In ECCV, 2016. 4",,,,,,,"Y. Guo, L. Zhang, Y. Hu, X. He, and J. Gao. MS-Celeb-1M: A dataset and benchmark for large scale face recognition. In ECCV, 2016. 4",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"X. He, Y. Zhou, Z. Zhou, S. Bai, and X. Bai. Triplet-center loss for multi-view 3D object retrieval. In CVPR, 2018. 2",,,,,,,"X. He, Y. Zhou, Z. Zhou, S. Bai, and X. Bai. Triplet-center loss for multi-view 3D object retrieval. In CVPR, 2018. 2",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"A. Hermans, L. Beyer, and B. Leibe. In defense of the triplet loss for person re-identification. CoRR, abs/1703.07737, 2017. 2",,,,,,,"A. Hermans, L. Beyer, and B. Leibe. In defense of the triplet loss for person re-identification. CoRR, abs/1703.07737, 2017. 2",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"G. Huang, Z. Liu, L. van der Maaten, and K. Q. Weinberger. Densely connected convolutional networks. In CVPR, 2017. 4",,,,,,,"G. Huang, Z. Liu, L. van der Maaten, and K. Q. Weinberger. Densely connected convolutional networks. In CVPR, 2017. 4",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"S. Ioffe and C. Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. In ICML, 2015. 4",,,,,,,"S. Ioffe and C. Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. In ICML, 2015. 4",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"I. Kemelmacher-Shlizerman, S. M. Seitz, D. Miller, and E. Brossard. The MegaFace benchmark: 1 million faces for recognition at scale. In CVPR, 2016. 4",,,,,,,"I. Kemelmacher-Shlizerman, S. M. Seitz, D. Miller, and E. Brossard. The MegaFace benchmark: 1 million faces for recognition at scale. In CVPR, 2016. 4",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"D. P. Kingma and J. Ba. Adam: A method for stochastic optimization. CoRR, abs/1412.6980, 2014. 5",,,,,,,"D. P. Kingma and J. Ba. Adam: A method for stochastic optimization. CoRR, abs/1412.6980, 2014. 5",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"S. Koelstra, C. Mühl, M. Soleymani, J. Lee, A. Yazdani, T. Ebrahimi, T. Pun, A. Nijholt, and I. Patras. DEAP: A database for emotion analysis using physiological signals. IEEE Transactions on Affective Computing",3(1):18– 31,,,,,,"S. Koelstra, C. Mühl, M. Soleymani, J. Lee, A. Yazdani, T. Ebrahimi, T. Pun, A. Nijholt, and I. Patras. DEAP: A database for emotion analysis using physiological signals. IEEE Transactions on Affective Computing, 3(1):18– 31, 2012. 2",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"A. S. Koepke, O. Wiles, and A. Zisserman. Self-supervised learning of a facial attribute embedding from video. In BMVC, 2018. 2",,,,,,,"A. S. Koepke, O. Wiles, and A. Zisserman. Self-supervised learning of a facial attribute embedding from video. In BMVC, 2018. 2",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"D. Kollias, P. Tzirakis, M. A. Nicolaou, A. Papaioannou, G. Zhao, B. W. Schuller, I. Kotsia, and S. Zafeiriou. Deep affect prediction in-the-wild: Aff-wild database and challenge",deep architectures,,,, abs/1804.10938, 2018. 2,"D. Kollias, P. Tzirakis, M. A. Nicolaou, A. Papaioannou, G. Zhao, B. W. Schuller, I. Kotsia, and S. Zafeiriou. Deep affect prediction in-the-wild: Aff-wild database and challenge, deep architectures, and beyond. CoRR, abs/1804.10938, 2018. 2",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"J. Kossaifi, G. Tzimiropoulos, S. Todorovic, and M. Pantic. AFEW-VA database for valence and arousal estimation inthe-wild. Image and Vision Computing",65:23–36,,,,,,"J. Kossaifi, G. Tzimiropoulos, S. Todorovic, and M. Pantic. AFEW-VA database for valence and arousal estimation inthe-wild. Image and Vision Computing, 65:23–36, 2017. 2",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"A. Krizhevsky. Convolutional deep belief networks on CIFAR-10. Unpublished manuscript, 2010. 4",,,,,,,"A. Krizhevsky. Convolutional deep belief networks on CIFAR-10. Unpublished manuscript, 2010. 4",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"S. Li and W. Deng. Deep facial expression recognition: A survey. CoRR, abs/1804.08348, 2018. 1",2,,,,,,"S. Li and W. Deng. Deep facial expression recognition: A survey. CoRR, abs/1804.08348, 2018. 1, 2",./refs/download/A compact embedding for facial expression similarity.pdf,
0,S. Li and W. Deng. Reliable crowdsourcing and deep locality-preserving learning for unconstrained facial expression recognition. IEEE Transactions on Image Processing,28(1):356–370,,,,,,"S. Li and W. Deng. Reliable crowdsourcing and deep locality-preserving learning for unconstrained facial expression recognition. IEEE Transactions on Image Processing, 28(1):356–370, 2019. 2",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"H. Liu, Y. Tian, Y. Wang, L. Pang, and T. Huang. Deep relative distance learning: Tell the difference between similar vehicles. In CVPR, 2016. 2",,,,,,,"H. Liu, Y. Tian, Y. Wang, L. Pang, and T. Huang. Deep relative distance learning: Tell the difference between similar vehicles. In CVPR, 2016. 2",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"Z. Liu, P. Luo, X. Wang, and X. Tang. Deep learning face attributes in the wild. In ICCV, 2015. 6",,,,,,,"Z. Liu, P. Luo, X. Wang, and X. Tang. Deep learning face attributes in the wild. In ICCV, 2015. 6",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"P. Lucey, J. F. Cohn, T. Kanade, J. M. Saragih, Z. Ambadar, and I. A. Matthews. The extended Cohn-Kanade dataset (CK+): A complete dataset for action unit and emotionspecified expression. In CVPR Workshops, 2010. 2",,,,,,,"P. Lucey, J. F. Cohn, T. Kanade, J. M. Saragih, Z. Ambadar, and I. A. Matthews. The extended Cohn-Kanade dataset (CK+): A complete dataset for action unit and emotionspecified expression. In CVPR Workshops, 2010. 2",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"B. Martinez, M. F. Valstar, B. Jiang, and M. Pantic. Automatic analysis of facial actions: A survey. IEEE Transactions on Affective Computing, 2017. 1",2,,,,,,"B. Martinez, M. F. Valstar, B. Jiang, and M. Pantic. Automatic analysis of facial actions: A survey. IEEE Transactions on Affective Computing, 2017. 1, 2",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"S. M. Mavadati, M. H. Mahoor, K. Bartlett, P. Trinh, and J. F. Cohn. DISFA: A spontaneous facial action inten-",,,,,,,"S. M. Mavadati, M. H. Mahoor, K. Bartlett, P. Trinh, and J. F. Cohn. DISFA: A spontaneous facial action inten- ",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"C. F. Benitez-Quiroz, R. Srinivasan, and A. M. Martı́nez. Emotionet: An accurate, real-time algorithm for the automatic annotation of a million facial expressions in the wild. In CVPR, 2016. 2",,,,,,,"C. F. Benitez-Quiroz, R. Srinivasan, and A. M. Martı́nez. Emotionet: An accurate, real-time algorithm for the automatic annotation of a million facial expressions in the wild. In CVPR, 2016. 2",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"G. Chechik, V. Sharma, U. Shalit, and S. Bengio. Large scale online learning of image similarity through ranking. Journal of Machine Learning Research",11:1109–1135,,,,,,"G. Chechik, V. Sharma, U. Shalit, and S. Bengio. Large scale online learning of image similarity through ranking. Journal of Machine Learning Research, 11:1109–1135, 2010. 2",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"C. A. Corneanu, M. Madadi, and S. Escalera. Deep structure inference network for facial action unit recognition. In ECCV, 2018. 5",,,,,,,"C. A. Corneanu, M. Madadi, and S. Escalera. Deep structure inference network for facial action unit recognition. In ECCV, 2018. 5",./refs/download/A compact embedding for facial expression similarity.pdf,
0,A. S. Cowen and D. Keltner. Self-report captures 27 distinct categories of emotion bridged by continuous gradients. Proceedings of the National Academy of Sciences,114(38):E7900E7909,,,,,,"A. S. Cowen and D. Keltner. Self-report captures 27 distinct categories of emotion bridged by continuous gradients. Proceedings of the National Academy of Sciences, 114(38):E7900E7909, 2017. 3",./refs/download/A compact embedding for facial expression similarity.pdf,
0,A. S. Cowen and D. Keltner. Clarifying the conceptualization,dimensionality,,,, 22(4):274–276, 2018. 3,"A. S. Cowen and D. Keltner. Clarifying the conceptualization, dimensionality, and structure of emotion. Trends in Cognitive Sciences, 22(4):274–276, 2018. 3",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"A. Dhall, R. Goecke, S. Ghosh, J. Joshi, J. Hoey, and T. Gedeon. From individual to group-level emotion recognition: Emotiw 5.0. In ICMI, 2017. 2",,,,,,,"A. Dhall, R. Goecke, S. Ghosh, J. Joshi, J. Hoey, and T. Gedeon. From individual to group-level emotion recognition: Emotiw 5.0. In ICMI, 2017. 2",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"A. Dhall, R. Goecke, J. Joshi, M. Wagner, and T. Gedeon. Emotion recognition in the wild challenge 2013. In ICMI, 2013. 2",,,,,,,"A. Dhall, R. Goecke, J. Joshi, M. Wagner, and T. Gedeon. Emotion recognition in the wild challenge 2013. In ICMI, 2013. 2",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"A. Dhall, O. V. R. Murthy, R. Goecke, J. Joshi, and T. Gedeon. Video and image based emotion recognition challenges in the wild: Emotiw 2015. In ICMI, 2015. 2",,,,,,,"A. Dhall, O. V. R. Murthy, R. Goecke, J. Joshi, and T. Gedeon. Video and image based emotion recognition challenges in the wild: Emotiw 2015. In ICMI, 2015. 2",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"P. Ekman, W. V. Friesen, and J. C. Hager. Facial Action Coding System - Manual. A Human Face, 2002. 1",2,,,,,,"P. Ekman, W. V. Friesen, and J. C. Hager. Facial Action Coding System - Manual. A Human Face, 2002. 1, 2",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"J. Fiss, A. Agarwala, and B. Curless. Candid portrait selection from video. ACM Transactions on Graphics",30(6):128:1–128:8,,,,,,"J. Fiss, A. Agarwala, and B. Curless. Candid portrait selection from video. ACM Transactions on Graphics, 30(6):128:1–128:8, 2011. 1",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"W. Ge, W. Huang, D. Dong, and M. R. Scott. Deep metric learning with hierarchical triplet loss. In ECCV, 2018. 2",,,,,,,"W. Ge, W. Huang, D. Dong, and M. R. Scott. Deep metric learning with hierarchical triplet loss. In ECCV, 2018. 2",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"X. Glorot and Y. Bengio. Understanding the difficulty of training deep feedforward neural networks. In AISTATS, 2010. 5",,,,,,,"X. Glorot and Y. Bengio. Understanding the difficulty of training deep feedforward neural networks. In AISTATS, 2010. 5",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"I. J. Goodfellow, D. Erhan, P. L. Carrier, A. C. Courville, M. Mirza, B. Hamner, W. Cukierski, Y. Tang, D. Thaler, D. Lee, Y. Zhou, C. Ramaiah, F. Feng, R. Li, X. Wang, D. Athanasakis, J. Shawe-Taylor, M. Milakov, J. Park, R. T. Ionescu, M. Popescu, C. Grozea, J. Bergstra, J. Xie, L. Romaszko, B. Xu, Z. Chuang, and Y. Bengio. Challenges in representation learning: A report on three machine learning contests. Neural Networks",64:59–63,,,,,,"I. J. Goodfellow, D. Erhan, P. L. Carrier, A. C. Courville, M. Mirza, B. Hamner, W. Cukierski, Y. Tang, D. Thaler, D. Lee, Y. Zhou, C. Ramaiah, F. Feng, R. Li, X. Wang, D. Athanasakis, J. Shawe-Taylor, M. Milakov, J. Park, R. T. Ionescu, M. Popescu, C. Grozea, J. Bergstra, J. Xie, L. Romaszko, B. Xu, Z. Chuang, and Y. Bengio. Challenges in representation learning: A report on three machine learning contests. Neural Networks, 64:59–63, 2015. 2",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"R. Gross, I. A. Matthews, J. F. Cohn, T. Kanade, and S. Baker. Multi-PIE. Image and Vision Computing",28(5):807–813,,,,,,"R. Gross, I. A. Matthews, J. F. Cohn, T. Kanade, and S. Baker. Multi-PIE. Image and Vision Computing, 28(5):807–813, 2010. 2  16 ",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"G. Zhao, X. Huang, M. Taini, S. Z. Li, and M. Pietikäinen. Facial expression recognition from near-infrared videos. Image and Vision Computing",29(9):607–619,,,,,,"G. Zhao, X. Huang, M. Taini, S. Z. Li, and M. Pietikäinen. Facial expression recognition from near-infrared videos. Image and Vision Computing, 29(9):607–619, 2011. 2",./refs/download/A compact embedding for facial expression similarity.pdf,
0,"B. Zhuang, G. Lin, C. Shen, and I. D. Reid. Fast training of triplet-based deep binary embedding networks. In CVPR, 2016. 2  sity database. IEEE Transactions on Affective Computing",4(2):151–160,,,,,,"B. Zhuang, G. Lin, C. Shen, and I. D. Reid. Fast training of triplet-based deep binary embedding networks. In CVPR, 2016. 2  sity database. IEEE Transactions on Affective Computing, 4(2):151–160, 2013. 2, 5 D. McDuff, R. E. Kaliouby, T. Senechal, M. Amr, J. F. Cohn, and R. W. Picard. Affectiva-MIT facial expression dataset (AM-FED): Naturalistic and spontaneous facial expressions collected in-the-wild. In CVPR Workshops, 2013. 2 A. Mehrabian. Basic dimensions for a general psychological theory: Implications for personality, social, environmental, and developmental studies. Oelgeschlager, Gunn & Hain, 1980. 2 H. Meng, T. Lin, X. Jiang, Y. Lu, and J. Wen. LSTMbased facial performance capture using embedding between expressions. CoRR, abs/1805.03874, 2018. 2 A. Mollahosseini, B. Hassani, and M. H. Mahoor. AffectNet: A database for facial expression, valence, and arousal computing in the wild. CoRR, abs/1708.03985, 2017. 2, 3, 5, 8 A. Mollahosseini, B. Hassani, M. J. Salvador, H. Abdollahi, D. Chan, and M. H. Mahoor. Facial expression recognition from world wild web. In CVPR Workshops, 2016. 2 A. Nech and I. Kemelmacher-Shlizerman. Level playing field for million scale face recognition. In CVPR, 2017. 4 M. Pantic, M. F. Valstar, R. Rademaker, and L. Maat. Webbased database for facial expression analysis. In ICME, 2005. 2 F. Ringeval, A. Sonderegger, J. S. Sauer, and D. Lalanne. Introducing the RECOLA multimodal corpus of remote collaborative and affective interactions. In FG, 2013. 2 J. A. Russell. A circumplex model of affect. Journal of Personality and Social Psychology, 39(6):1161–1178, 1980. 2 F. Schroff, D. Kalenichenko, and J. Philbin. FaceNet: A unified embedding for face recognition and clustering. In CVPR, 2015. 1, 2, 3, 4, 5 Z. Shao, Z. Liu, J. Cai, and L. Ma. Deep adaptive attention for joint facial action unit detection and face alignment. In ECCV, 2018. 5 H. O. Song, Y. Xiang, S. Jegelka, and S. Savarese. Deep metric learning via lifted structured feature embedding. In CVPR, 2016. 2 Y. Taigman, M. Yang, M. Ranzato, and L. Wolf. DeepFace: Closing the gap to human-level performance in face verification. In CVPR, 2014. 4 J. Wang, Y. Song, T. Leung, C. Rosenberg, J. Wang, J. Philbin, B. Chen, and Y. Wu. Learning fine-grained image similarity with deep ranking. In CVPR, 2014. 2 J. Wang, F. Zhou, S. Wen, X. Liu, and Y. Lin. Deep metric learning with angular loss. In ICCV, 2017. 2 K. Q. Weinberger and L. K. Saul. Distance metric learning for large margin nearest neighbor classification. Journal of Machine Learning Research, 10:207–244, 2009. 3 O. Wiles, A. S. Koepke, and A. Zisserman. Self-supervised learning of a facial attribute embedding from video. In BMVC, 2018. 5, 8 Z. Zhang, P. Luo, C. C. Loy, and X. Tang. From facial expression recognition to interpersonal relation prediction. International Journal of Computer Vision, 126(5):550–569, 2018. 2  17 ",./refs/download/A compact embedding for facial expression similarity.pdf,
0,,Ciregan,,,,,,"Ciregan, U. Meier, and J. Schmidhuber. Multi-column deep neural networks for image classification. In Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on, pages 3642–3649. IEEE, 2012. G. Cohen, S. Afshar, J. Tapson, and A. van Schaik. Emnist: an extension of mnist to handwritten letters. arXiv preprint arXiv:1702.05373, 2017. J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. Imagenet: A large-scale hierarchical image database. In Computer Vision and Pattern Recognition, 2009.",./refs/download/Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms.pdf,
0,,LeCun,,,,,,"LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278–2324, 1998. L. Wan, M. Zeiler, S. Zhang, Y. L. Cun, and R. Fergus. Regularization of neural networks using dropconnect. In Proceedings of the 30th international conference on machine learning (ICML13), pages 1058–1066, 2013.",./refs/download/Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms.pdf,
0,"J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei",“ImageNet: A Large-Scale Hierarchical Image Database,” in CVPR09,,,,,"J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei, “ImageNet: A Large-Scale Hierarchical Image Database,” in CVPR09, 2009.",./refs/download/Imagenet: A large-scale hierarchical image database.pdf,
0,"C. Fellbaum, WordNet: An Electronic Lexical Database. Bradford Books, 1998.",,,,,,,"C. Fellbaum, WordNet: An Electronic Lexical Database. Bradford Books, 1998.",./refs/download/Imagenet: A large-scale hierarchical image database.pdf,
0,D. G. Lowe,“Distinctive image features from scale-invariant keypoints,” International Journal of Computer Vision,,,,,"D. G. Lowe, “Distinctive image features from scale-invariant keypoints,” International Journal of Computer Vision, vol. 60, no. 2, pp. 91–110, 2004.",./refs/download/Imagenet: A large-scale hierarchical image database.pdf,
0,P. Salembier and T. Sikora,Introduction to MPEG-7: Multimedia Content Description Interface,,,,,,"P. Salembier and T. Sikora, Introduction to MPEG-7: Multimedia Content Description Interface, B. Manjunath, Ed. New York, NY, USA: John Wiley & Sons, Inc., 2002.",./refs/download/Imagenet: A large-scale hierarchical image database.pdf,
0,T. Sikora,“The mpeg-7 visual standard for content description-an overview,” IEEE Transactions on Circuits and Systems for Video Technology,,,,,"T. Sikora, “The mpeg-7 visual standard for content description-an overview,” IEEE Transactions on Circuits and Systems for Video Technology, vol. 11, no. 6, pp. 696–702, Jun 2001.",./refs/download/Imagenet: A large-scale hierarchical image database.pdf,
0,"B. S. Manjunath, J. R. Ohm, V. V. Vasudevan, and A. Yamada",“Color and texture descriptors,” IEEE Transactions on Circuits and Systems for Video Technology,,,,,"B. S. Manjunath, J. R. Ohm, V. V. Vasudevan, and A. Yamada, “Color and texture descriptors,” IEEE Transactions on Circuits and Systems for Video Technology, vol. 11, no. 6, pp. 703–715, Jun 2001.",./refs/download/Imagenet: A large-scale hierarchical image database.pdf,
0,M. Bober,“Mpeg-7 visual shape descriptors,” IEEE Transactions on Circuits and Systems for Video Technology,,,,,"M. Bober, “Mpeg-7 visual shape descriptors,” IEEE Transactions on Circuits and Systems for Video Technology, vol. 11, no. 6, pp. 716–719, Jun 2001.",./refs/download/Imagenet: A large-scale hierarchical image database.pdf,
0,S. Jeannin and A. Divakaran,“Mpeg-7 visual motion descriptors,” IEEE Transactions on Circuits and Systems for Video Technology,,,,,"S. Jeannin and A. Divakaran, “Mpeg-7 visual motion descriptors,” IEEE Transactions on Circuits and Systems for Video Technology, vol. 11, no. 6, pp. 720–724, Jun 2001.",./refs/download/Imagenet: A large-scale hierarchical image database.pdf,
0,"C. S. Won, D. K. Park, and Y. S. Jeon",“Efficient use of mpeg-7 edge histogram descriptor,” ETRI Journal,,,,,"C. S. Won, D. K. Park, and Y. S. Jeon, “Efficient use of mpeg-7 edge histogram descriptor,” ETRI Journal, vol. 24, no. 1, pp. 23–30, 2002.",./refs/download/Imagenet: A large-scale hierarchical image database.pdf,
0,"E. L. Allgower and K. Georg. Numerical continuation methods: an introduction, volume 13. Springer Science & Business Media, 2012. 2",4   1 = gik − ηwij α − sij gjk, 1 + exp (−α hgi ,,,,,"E. L. Allgower and K. Georg. Numerical continuation methods: an introduction, volume 13. Springer Science & Business Media, 2012. 2, 4   1 = gik − ηwij α − sij gjk , 1 + exp (−α hgi , gj i) (8) where η is the learning rate and gj0 is computed similarly. ",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"Y. Bengio, A. Courville, and P. Vincent. Representation learning: A review and new perspectives. IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)",35(8):1798–1828,,,,,,"Y. Bengio, A. Courville, and P. Vincent. Representation learning: A review and new perspectives. IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 35(8):1798–1828, Aug 2013. 1  Lemma 1. Denote by hi = sgn(gi ), h0i = sgn(gi0 ), then ( h0i , h0j > hhi , hj i , sij = 1, (9) h0i , h0j 6 hhi , hj i , sij = 0. ",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"Y. Bengio, P. Lamblin, D. Popovici, and H. Larochelle. Greedy layer-wise training of deep networks. In B. Schölkopf, J. C. Platt, and T. Hoffman",editors, NIPS,,,,,"Y. Bengio, P. Lamblin, D. Popovici, and H. Larochelle. Greedy layer-wise training of deep networks. In B. Schölkopf, J. C. Platt, and T. Hoffman, editors, NIPS, pages 153–160. MIT Press, 2007. 4  PK Proof. Since hhi , hj i = k=1 hik hjk , Lemma 1 can be proved by verifying that h0ik h0jk > hik hjk if sij = 1 and h0ik h0jk 6 hik hjk if sij = 0, ∀k = 1, 2, . . . , K. ",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"T.-S. Chua, J. Tang, R. Hong, H. Li, Z. Luo, and Y.-T. Zheng. Nus-wide: A real-world web image database from national university of singapore. In ICMR. ACM, 2009. 5  ",,,,,,,"T.-S. Chua, J. Tang, R. Hong, H. Li, Z. Luo, and Y.-T. Zheng. Nus-wide: A real-world web image database from national university of singapore. In ICMR. ACM, 2009. 5   ",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"M. Courbariaux and Y. Bengio. Binarynet: Training deep neural networks with weights and activations constrained to +1 or -1. In NIPS, 2016. 4",,,,,,,"M. Courbariaux and Y. Bengio. Binarynet: Training deep neural networks with weights and activations constrained to +1 or -1. In NIPS, 2016. 4 ",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"H. Lai, Y. Pan, Y. Liu, and S. Yan. Simultaneous feature learning and hash coding with deep neural networks. In CVPR. IEEE, 2015. 1",2, 5,,,,,"H. Lai, Y. Pan, Y. Liu, and S. Yan. Simultaneous feature learning and hash coding with deep neural networks. In CVPR. IEEE, 2015. 1, 2, 5, 6 ",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"J. P. Dmochowski, P. Sajda, and L. C. Parra. Maximum likelihood in cost-sensitive learning: Model specification",approximations,,,, 11(Dec):3313–3332, 2010. 3 ,"J. P. Dmochowski, P. Sajda, and L. C. Parra. Maximum likelihood in cost-sensitive learning: Model specification, approximations, and upper bounds. Journal of Machine Learning Research (JMLR), 11(Dec):3313–3332, 2010. 3 ",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"M. S. Lew, N. Sebe, C. Djeraba, and R. Jain. Contentbased multimedia information retrieval: State of the art and challenges. ACM Transactions on Multimedia Computing",Communications, and Applications (TOMM),,, 2(1):1–19, Feb. 2006. 1 ,"M. S. Lew, N. Sebe, C. Djeraba, and R. Jain. Contentbased multimedia information retrieval: State of the art and challenges. ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM), 2(1):1–19, Feb. 2006. 1 ",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"J. Donahue, Y. Jia, O. Vinyals, J. Hoffman, N. Zhang, E. Tzeng, and T. Darrell. Decaf: A deep convolutional activation feature for generic visual recognition. In ICML, 2014. 5",7,,,,,,"J. Donahue, Y. Jia, O. Vinyals, J. Hoffman, N. Zhang, E. Tzeng, and T. Darrell. Decaf: A deep convolutional activation feature for generic visual recognition. In ICML, 2014. 5, 7 ",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"W.-J. Li, S. Wang, and W.-C. Kang. Feature learning based deep supervised hashing with pairwise labels. In IJCAI, 2016. 1",2, 8 ,,,,,"W.-J. Li, S. Wang, and W.-C. Kang. Feature learning based deep supervised hashing with pairwise labels. In IJCAI, 2016. 1, 2, 8 ",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"V. Erin Liong, J. Lu, G. Wang, P. Moulin, and J. Zhou. Deep hashing for compact binary codes learning. In CVPR, pages 2475–2483. IEEE, 2015. 1",,,,,,,"V. Erin Liong, J. Lu, G. Wang, P. Moulin, and J. Zhou. Deep hashing for compact binary codes learning. In CVPR, pages 2475–2483. IEEE, 2015. 1 ",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan, P. Dollár, and C. L. Zitnick. Microsoft coco: Common objects in context. In ECCV, pages 740–755. Springer, 2014. 5",,,,,,,"T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan, P. Dollár, and C. L. Zitnick. Microsoft coco: Common objects in context. In ECCV, pages 740–755. Springer, 2014. 5 ",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"D. J. Fleet, A. Punjani, and M. Norouzi. Fast search in hamming space with multi-index hashing. In CVPR. IEEE, 2012. 1",7,,,,,,"D. J. Fleet, A. Punjani, and M. Norouzi. Fast search in hamming space with multi-index hashing. In CVPR. IEEE, 2012. 1, 7 ",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"H. Liu, R. Wang, S. Shan, and X. Chen. Deep supervised hashing for fast image retrieval. In CVPR",pages 2064–2072,,,, 2, 8 ,"H. Liu, R. Wang, S. Shan, and X. Chen. Deep supervised hashing for fast image retrieval. In CVPR, pages 2064–2072, 2016. 1, 2, 8 ",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"A. Gionis, P. Indyk, R. Motwani, et al. Similarity search in high dimensions via hashing. In VLDB",volume 99,, 1999. 1,, 5, 6,"A. Gionis, P. Indyk, R. Motwani, et al. Similarity search in high dimensions via hashing. In VLDB, volume 99, pages 518–529. ACM, 1999. 1, 5, 6",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"Y. Gong, S. Kumar, H. Rowley, S. Lazebnik, et al. Learning binary codes for high-dimensional data using bilinear projections. In CVPR, pages 484–491. IEEE, 2013. 1",,,,,,,"Y. Gong, S. Kumar, H. Rowley, S. Lazebnik, et al. Learning binary codes for high-dimensional data using bilinear projections. In CVPR, pages 484–491. IEEE, 2013. 1",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,Y. Gong and S. Lazebnik. Iterative quantization: A procrustean approach to learning binary codes. In CVPR,pages 817–824,, 2,, 5, 6,"Y. Gong and S. Lazebnik. Iterative quantization: A procrustean approach to learning binary codes. In CVPR, pages 817–824, 2011. 1, 2, 5, 6",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. CVPR, 2016. 2",4,,,,,,"K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. CVPR, 2016. 2, 4",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"G. E. Hinton, S. Osindero, and Y.-W. Teh. A fast learning algorithm for deep belief nets. Neural Computation",18(7):1527–1554,,,,,,"G. E. Hinton, S. Osindero, and Y.-W. Teh. A fast learning algorithm for deep belief nets. Neural Computation, 18(7):1527–1554, 2006. 1, 4",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"S. Ioffe and C. Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. In ICML, 2015. 4",,,,,,,"S. Ioffe and C. Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. In ICML, 2015. 4",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"H. Jegou, M. Douze, and C. Schmid. Product quantization for nearest neighbor search. IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)",33(1):117–128,,,,,,"H. Jegou, M. Douze, and C. Schmid. Product quantization for nearest neighbor search. IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 33(1):117–128, Jan 2011. 2",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Girshick, S. Guadarrama, and T. Darrell. Caffe: Convolutional architecture for fast feature embedding. In ACM Multimedia Conference. ACM, 2014. 5",,,,,,,"Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Girshick, S. Guadarrama, and T. Darrell. Caffe: Convolutional architecture for fast feature embedding. In ACM Multimedia Conference. ACM, 2014. 5 ",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"W. Liu, J. Wang, R. Ji, Y.-G. Jiang, and S.-F. Chang. Supervised hashing with kernels. In CVPR. IEEE, 2012. 1",2, 5,,,,,"W. Liu, J. Wang, R. Ji, Y.-G. Jiang, and S.-F. Chang. Supervised hashing with kernels. In CVPR. IEEE, 2012. 1, 2, 5, 6",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"W. Liu, J. Wang, S. Kumar, and S.-F. Chang. Hashing with graphs. In ICML. ACM, 2011. 2",,,,,,,"W. Liu, J. Wang, S. Kumar, and S.-F. Chang. Hashing with graphs. In ICML. ACM, 2011. 2",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"X. Liu, J. He, B. Lang, and S.-F. Chang. Hash bit selection: a unified solution for selection problems in hashing. In CVPR, pages 1570–1577. IEEE, 2013. 1",,,,,,,"X. Liu, J. He, B. Lang, and S.-F. Chang. Hash bit selection: a unified solution for selection problems in hashing. In CVPR, pages 1570–1577. IEEE, 2013. 1",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"C. Ma, I. W. Tsang, F. Peng, and C. Liu. Partial hash update via hamming subspace learning. IEEE Transactions on Image Processing (TIP)",26(4):1939–1951,,,,,,"C. Ma, I. W. Tsang, F. Peng, and C. Liu. Partial hash update via hamming subspace learning. IEEE Transactions on Image Processing (TIP), 26(4):1939–1951, 2017. 7",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,V. Nair and G. E. Hinton. Rectified linear units improve restricted boltzmann machines. In J. Fürnkranz and T. Joachims,editors, ICML,,, pages 807–814. Omnipress, 2010. 4,"V. Nair and G. E. Hinton. Rectified linear units improve restricted boltzmann machines. In J. Fürnkranz and T. Joachims, editors, ICML, pages 807–814. Omnipress, 2010. 4",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"M. Norouzi and D. M. Blei. Minimal loss hashing for compact binary codes. In ICML, pages 353–360. ACM, 2011. 1",2,,,,,,"M. Norouzi and D. M. Blei. Minimal loss hashing for compact binary codes. In ICML, pages 353–360. ACM, 2011. 1, 2",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"M. Norouzi, D. M. Blei, and R. R. Salakhutdinov. Hamming distance metric learning. In NIPS",pages 1061–1069,,,,,,"M. Norouzi, D. M. Blei, and R. R. Salakhutdinov. Hamming distance metric learning. In NIPS, pages 1061–1069, 2012. 2 ",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classification with deep convolutional neural networks. In NIPS, 2012. 1",2, 5 ,,,,,"A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classification with deep convolutional neural networks. In NIPS, 2012. 1, 2, 5 ",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, A. C. Berg, and L. Fei-Fei. ImageNet Large Scale Visual Recognition Challenge. International Journal of Computer Vision (IJCV)",115(3):211–252,,,,,,"O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, A. C. Berg, and L. Fei-Fei. ImageNet Large Scale Visual Recognition Challenge. International Journal of Computer Vision (IJCV), 115(3):211–252, 2015. 5 ",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,B. Kulis and T. Darrell. Learning to hash with binary reconstructive embeddings. In NIPS,pages 1042– 1050,, 2,, 5, 6 ,"B. Kulis and T. Darrell. Learning to hash with binary reconstructive embeddings. In NIPS, pages 1042– 1050, 2009. 1, 2, 5, 6 ",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,R. Salakhutdinov and G. E. Hinton. Learning a nonlinear embedding by preserving class neighbourhood structure. In AISTATS,pages 412–419,,,,,,"R. Salakhutdinov and G. E. Hinton. Learning a nonlinear embedding by preserving class neighbourhood structure. In AISTATS, pages 412–419, 2007. 2 ",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"F. Shen, C. Shen, W. Liu, and H. Tao Shen. Supervised discrete hashing. In CVPR. IEEE, June 2015. 1",5, 6,,,,,"F. Shen, C. Shen, W. Liu, and H. Tao Shen. Supervised discrete hashing. In CVPR. IEEE, June 2015. 1, 5, 6, 8",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"A. W. Smeulders, M. Worring, S. Santini, A. Gupta, and R. Jain. Content-based image retrieval at the end of the early years. IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)",22(12):1349– 1380,,,,,,"A. W. Smeulders, M. Worring, S. Santini, A. Gupta, and R. Jain. Content-based image retrieval at the end of the early years. IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 22(12):1349– 1380, 2000. 2",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, and R. Salakhutdinov. Dropout: A simple way to prevent neural networks from overfitting. Journal of Machine Learning Research (JMLR)",15(1):1929–1958,,,,,,"N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, and R. Salakhutdinov. Dropout: A simple way to prevent neural networks from overfitting. Journal of Machine Learning Research (JMLR), 15(1):1929–1958, Jan. 2014. 4",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"J. Wang, S. Kumar, and S.-F. Chang. Semi-supervised hashing for large-scale search. IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)",34(12):2393–2406,,,,,,"J. Wang, S. Kumar, and S.-F. Chang. Semi-supervised hashing for large-scale search. IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 34(12):2393–2406, 2012. 1",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"J. Wang, H. T. Shen, J. Song, and J. Ji. Hashing for similarity search: A survey. Arxiv, 2014. 1",2,,,,,,"J. Wang, H. T. Shen, J. Song, and J. Ji. Hashing for similarity search: A survey. Arxiv, 2014. 1, 2",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"Y. Weiss, A. Torralba, and R. Fergus. Spectral hashing. In NIPS, 2009. 2",5, 6,,,,,"Y. Weiss, A. Torralba, and R. Fergus. Spectral hashing. In NIPS, 2009. 2, 5, 6",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"R. Xia, Y. Pan, H. Lai, C. Liu, and S. Yan. Supervised hashing for image retrieval via image representation learning. In AAAI, pages 2156–2162. AAAI, 2014. 1",2, 5,,, 6, 7,"R. Xia, Y. Pan, H. Lai, C. Liu, and S. Yan. Supervised hashing for image retrieval via image representation learning. In AAAI, pages 2156–2162. AAAI, 2014. 1, 2, 5, 6, 7",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"F. X. Yu, S. Kumar, Y. Gong, and S.-F. Chang. Circulant binary embedding. In ICML, pages 353–360. ACM, 2014. 1",,,,,,,"F. X. Yu, S. Kumar, Y. Gong, and S.-F. Chang. Circulant binary embedding. In ICML, pages 353–360. ACM, 2014. 1",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"P. Zhang, W. Zhang, W.-J. Li, and M. Guo. Supervised hashing with latent factor models. In SIGIR, pages 173–182. ACM, 2014. 1",,,,,,,"P. Zhang, W. Zhang, W.-J. Li, and M. Guo. Supervised hashing with latent factor models. In SIGIR, pages 173–182. ACM, 2014. 1",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"F. Zhao, Y. Huang, L. Wang, and T. Tan. Deep semantic ranking based hashing for multi-label image retrieval. In CVPR",pages 1556–1564,,,,,,"F. Zhao, Y. Huang, L. Wang, and T. Tan. Deep semantic ranking based hashing for multi-label image retrieval. In CVPR, pages 1556–1564, 2015. 1",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,"H. Zhu, M. Long, J. Wang, and Y. Cao. Deep hashing network for efficient similarity retrieval. In AAAI. AAAI, 2016. 1",2, 5,,, 6, 7 ,"H. Zhu, M. Long, J. Wang, and Y. Cao. Deep hashing network for efficient similarity retrieval. In AAAI. AAAI, 2016. 1, 2, 5, 6, 7 ",./refs/download/Hashnet: Deep learning to hash by continuation.pdf,
0,,[1] Helen M Berman, John Westbrook,,,,,"[1] Helen M Berman, John Westbrook, Zukang Feng, Gary Gilliland, TN Bhat, Helge Weissig, Ilya N Shindyalov, and Philip E Bourne. The protein data bank. Nucleic Acids Res, 28:235–242, 2000.",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,,[2] Xiaobai Chen, Aleksey Golovinskiy, and Thomas Funkhouser. A benchmark for 3D mesh segmentation. ACM TOG,, 28(3):73:1–73:12, July 2009.,"[2] Xiaobai Chen, Aleksey Golovinskiy, and Thomas Funkhouser. A benchmark for 3D mesh segmentation. ACM TOG, 28(3):73:1–73:12, July 2009.",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,,[3] Xiaobai Chen, Abulhair Saparov, Bill Pang,, and Thomas Funkhouser. Schelling points on 3D surface meshes. ACM TOG, August 2012.,"[3] Xiaobai Chen, Abulhair Saparov, Bill Pang, and Thomas Funkhouser. Schelling points on 3D surface meshes. ACM TOG, August 2012.",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,"[18] Joerg Liebelt and Cordelia Schmid. Multi-view object class detection with a 3D geometric model. In CVPR, pages 1688– 1695. IEEE, 2010.",,,,,,,"[18] Joerg Liebelt and Cordelia Schmid. Multi-view object class detection with a 3D geometric model. In CVPR, pages 1688– 1695. IEEE, 2010.",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,,[4] Jia Deng, Wei Dong,,,,,"[4] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. ImageNet: A large-scale hierarchical image database. In CVPR, 2009.",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,,[19] Tianqiang Liu, Siddhartha Chaudhuri,,,,,"[19] Tianqiang Liu, Siddhartha Chaudhuri, Vladimir G. Kim, QiXing Huang, Niloy J. Mitra, and Thomas Funkhouser. Creating consistent scene graphs using a probabilistic grammar. ACM TOG, December 2014.",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,"[5] Bianca Falcidieno. Aim@shape. http://www. aimatshape.net/ontologies/shapes/, 2005.",,,,,,,"[5] Bianca Falcidieno. Aim@shape. http://www. aimatshape.net/ontologies/shapes/, 2005.",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,,[6] Matthew Fisher, Daniel Ritchie,,,,,"[6] Matthew Fisher, Daniel Ritchie, Manolis Savva, Thomas Funkhouser, and Pat Hanrahan. Example-based synthesis of 3D object arrangements. ACM TOG, 31(6):135, 2012.",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,,[20] Mitchell P Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. Building a large annotated corpus of english: The Penn Treebank. Computational linguistics,, 19(2):313–330, 1993.,"[20] Mitchell P Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. Building a large annotated corpus of english: The Penn Treebank. Computational linguistics, 19(2):313–330, 1993.",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,"[7] Paul-Louis George. Gamma. http://www.rocq. inria.fr/gamma/download/download.php, 2007.",,,,,,,"[7] Paul-Louis George. Gamma. http://www.rocq. inria.fr/gamma/download/download.php, 2007.",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,"[21] George A. Miller. WordNet: a lexical database for English. CACM, 1995.",,,,,,,"[21] George A. Miller. WordNet: a lexical database for English. CACM, 1995.",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,,[8] Qixing Huang, Hao Su, and Leonidas Guibas. Fine-grained semi-supervised labeling of large shape collections. ACM TOG,, 32:190:1–190:10, 2013.,"[8] Qixing Huang, Hao Su, and Leonidas Guibas. Fine-grained semi-supervised labeling of large shape collections. ACM TOG, 32:190:1–190:10, 2013.",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,,[22] Niloy J Mitra, Mark Pauly,,,,,"[22] Niloy J Mitra, Mark Pauly, Michael Wand, and Duygu Ceylan. Symmetry in 3D geometry: Extraction and applications. In Computer Graphics Forum, volume 32, pages 1–23, 2013.",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,,[9] Subramaniam Jayanti, Yagnanarayanan Kalyanaraman, Natraj Iyer,, and Karthik Ramani. Developing an engineering shape benchmark for CAD models. Computer-Aided Design, 2006.,"[9] Subramaniam Jayanti, Yagnanarayanan Kalyanaraman, Natraj Iyer, and Karthik Ramani. Developing an engineering shape benchmark for CAD models. Computer-Aided Design, 2006.",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,[23] Fakir S. Nooruddin and Greg Turk. Simplification and repair of polygonal models using volumetric techniques. Visualization and Computer Graphics,IEEE Transactions on,,,,,,"[23] Fakir S. Nooruddin and Greg Turk. Simplification and repair of polygonal models using volumetric techniques. Visualization and Computer Graphics, IEEE Transactions on, 2003.",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,,[10] Evangelos Kalogerakis, Siddhartha Chaudhuri,,,,,"[10] Evangelos Kalogerakis, Siddhartha Chaudhuri, Daphne Koller, and Vladlen Koltun. A probabilistic model for component-based shape synthesis. ACM TOG, 31:55, 2012.",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,"[24] Bryan C Russell and Antonio Torralba. Building a database of 3D scenes from user annotations. In CVPR, 2009.",,,,,,,"[24] Bryan C Russell and Antonio Torralba. Building a database of 3D scenes from user annotations. In CVPR, 2009.",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,,[11] Vladimir Kim, Yaron Lipman, Xiaobai Chen,, and Thomas Funkhouser. Mobius transformations for global intrinsic symmetry analysis. Symposium on Geometry Processing, July 2010.,"[11] Vladimir Kim, Yaron Lipman, Xiaobai Chen, and Thomas Funkhouser. Mobius transformations for global intrinsic symmetry analysis. Symposium on Geometry Processing, July 2010.",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,,[25] Manolis Savva,,,,,,"[25] Manolis Savva, Angel X. Chang, Gilbert Bernstein, Christopher D. Manning, and Pat Hanrahan. On being the right scale: Sizing large collections of 3D models. In SIGGRAPH Asia 2014 Workshop on Indoor Scene Understanding: Where Graphics meets Vision, 2014.",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,[12] Vladimir G. Kim,Wilmot Li,,,,,,"[12] Vladimir G. Kim, Wilmot Li, Niloy J. Mitra, Siddhartha Chaudhuri, Stephen DiVerdi, and Thomas Funkhouser. Learning part-based templates from large collections of 3D shapes. ACM TOG, 32(4):70:1–70:12, July 2013.",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,,[26] Manolis Savva,,,,,,"[26] Manolis Savva, Angel X. Chang, and Pat Hanrahan. Semantically-Enriched 3D Models for Common-sense Knowledge. CVPR 2015 Workshop on Functionality, Physics, Intentionality and Causality, 2015.",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,[13] Vladimir G. Kim,Wilmot Li,,,,,,"[13] Vladimir G. Kim, Wilmot Li, Niloy J. Mitra, Stephen DiVerdi, and Thomas Funkhouser. Exploring collections of 3D models using fuzzy correspondences. ACM TOG, 31(4):54:1–54:11, July 2012.",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,,[27] Philip Shilane, Patrick Min, Michael Kazhdan,, and Thomas Funkhouser. The Princeton shape benchmark. In Shape Modeling Applications. IEEE, 2004.,"[27] Philip Shilane, Patrick Min, Michael Kazhdan, and Thomas Funkhouser. The Princeton shape benchmark. In Shape Modeling Applications. IEEE, 2004.",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,,[14] Jonathan Krause, Michael Stark,,,,,"[14] Jonathan Krause, Michael Stark, Jia Deng, and Li Fei-Fei. 3D object representations for fine-grained categorization. In 4th International IEEE Workshop on 3D Representation and Recognition (3dRR-13), Sydney, Australia, 2013.",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,,[15] Roman A Laskowski, E Gail Hutchinson,,,,,"[15] Roman A Laskowski, E Gail Hutchinson, Alex D Michie, Andrew C Wallace, Martin L Jones, and Janet M Thornton. PDBsum: A web-based database of summaries and analyses of all PDB structures. Trends Biochem. Sci., 22:488–490, 1997.",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,,[29] Atsushi Tatsuma, Hitoshi Koyanagi,,,,,"[29] Atsushi Tatsuma, Hitoshi Koyanagi, and Masaki Aono. A large-scale shape benchmark for 3D object retrieval: Toyohashi shape benchmark. In Asia Pacific Signal and Information Processing Association, 2012. 3 [30] Antonio Torralba, Bryan C Russell, and Jenny Yuen. LabelMe: Online image annotation and applications. Proceedings of the IEEE, 98(8):1467–1484, 2010.",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,,[16] Bo Li, Afzal Godil,,,,,"[16] Bo Li, Afzal Godil, Masaki Aono, X Bai, Takahiko Furuya, L Li, R López-Sastre, Henry Johan, Ryutarou Ohbuchi, Carolina Redondo-Cabrera, et al. SHREC’12 track: generic 3D shape retrieval. In 5th Eurographics Conference on 3D Object Retrieval, 2012.",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,[31] Remco C. Veltkamp and FB ter Harr. SHREC 2007 3D shape retrieval contest. Technical report,Utrecht University Technical Report UU-CS-2007-015,,,,,,"[31] Remco C. Veltkamp and FB ter Harr. SHREC 2007 3D shape retrieval contest. Technical report, Utrecht University Technical Report UU-CS-2007-015, 2007.",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,,[17] Bo Li, Yijuan Lu,,,,,"[17] Bo Li, Yijuan Lu, Chunyuan Li, Afzal Godil, Tobias Schreck, Masaki Aono, Qiang Chen, Nihad Karim Chowdhury, Bin Fang, Takahiko Furuya, et al. SHREC’14 track:  [32] Dejan V Vranić. 3D model retrieval. University of Leipzig, Germany, PhD thesis, 2004.",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,,[33] Raoul Wessel, Ina Blümel, and Reinhard Klein. A 3D shape benchmark for retrieval and automatic classification of architectural data. In Eurographics 2009 Workshop on 3D Object Retrieval,, pages 53–56. The Eurographics Association, 2009.,"[33] Raoul Wessel, Ina Blümel, and Reinhard Klein. A 3D shape benchmark for retrieval and automatic classification of architectural data. In Eurographics 2009 Workshop on 3D Object Retrieval, pages 53–56. The Eurographics Association, 2009.",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,,[34] Zhirong Wu, Shuran Song,,,,,"[34] Zhirong Wu, Shuran Song, Aditya Khosla, Fisher Yu, Linguang Zhang, Xiaoou Tang, and Jianxiong Xiao. 3D ShapeNets: A Deep Representation for Volumetric Shapes. CVPR, 2015.",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,,[35] Yu Xiang, Roozbeh Mottaghi,,, and Silvio Savarese. Beyond PASCAL: A benchmark for 3D object detection in the wild. In WACV, 2014.,"[35] Yu Xiang, Roozbeh Mottaghi, and Silvio Savarese. Beyond PASCAL: A benchmark for 3D object detection in the wild. In WACV, 2014.",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
0,,[36] Jianxiong Xiao, Andrew Owens,,,,,"[36] Jianxiong Xiao, Andrew Owens, and Antonio Torralba. SUN3D: A database of big spaces reconstructed using SfM and object labels. In ICCV, pages 1625–1632, 2013. 2 [37] Juan Zhang, Kaleem Siddiqi, Diego Macrini, Ali Shokoufandeh, and Sven Dickinson. Retrieving articulated 3-D models using medial surfaces and their graph spectra. In Energy minimization methods in computer vision and pattern recognition, 2005.",./refs/download/Shapenet: An information-rich 3d model repository.pdf,
