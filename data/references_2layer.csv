,authors,title,journal,publisher,volume,year,pages,full_ref,source_file,source_title
0,"Fangyuan Leia, Da Huanga, Jianjian Jianga, Ruijun Ma, Senhong Wang, Jiangzhong Cao, Yusen Lin, Qingyun Dai","PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database",arXiv,,,2021,,,2106.12139.pdf,
0,"Y. Guo, Y. Liu, A. Oerlemans, S. Lao, S. Wu, M.S. Lew",Deep learning for visual understanding: A review,"Neurocomputing, ",,187 ,2016,27-48,"Y. Guo, Y. Liu, A. Oerlemans, S. Lao, S. Wu, M.S. Lew, Deep learning for visual understanding: A review, Neurocomputing, 187 (2016) 27-48",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"W. Rawat, Z. Wang",Deep convolutional neural networks for image classification: A comprehensive review,"Neural computation, ",,29 ,2017,2352-2449,"W. Rawat, Z. Wang, Deep convolutional neural networks for image classification: A comprehensive review, Neural computation, 29 (2017) 2352-2449",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, L. Fei-Fei",Imagenet: A large-scale hierarchical image database,,,,2009,,"J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, L. Fei-Fei, Imagenet: A large-scale hierarchical image database, 2009",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"Z. Liu, P. Luo, S. Qiu, X. Wang, X. Tang",Deepfashion: Powering robust clothes recognition and retrieval with rich annotations,"Proceedings of the IEEE conference on computer vision and pattern recognition, ",,,2016,,"Z. Liu, P. Luo, S. Qiu, X. Wang, X. Tang, Deepfashion: Powering robust clothes recognition and retrieval with rich annotations, Proceedings of the IEEE conference on computer vision and pattern recognition, 2016",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,,,,,,,,"Y. Ge, R. Zhang, X. Wang, X. Tang, P. Luo, Deepfashion2: A versatile benchmark for detection, pose estimation, segmentation and re-identification of clothing images, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2019",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"Z. Wu, S. Song, A. Khosla, F. Yu, L. Zhang, X. Tang, J. Xiao",3d shapenets: A deep representation for volumetric shapes,"Proceedings of the IEEE conference on computer vision and pattern recognition, ",,,2015,,"Z. Wu, S. Song, A. Khosla, F. Yu, L. Zhang, X. Tang, J. Xiao, 3d shapenets: A deep representation for volumetric shapes, Proceedings of the IEEE conference on computer vision and pattern recognition, 2015",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"M. Aubry, D. Maturana, A.A. Efros, B.C. Russell, J. Sivic",Seeing 3d chairs: exemplar part-based 2d-3d alignment using a large dataset of cad models,"Proceedings of the IEEE conference on computer vision and pattern recognition, ",,,2014,,"M. Aubry, D. Maturana, A.A. Efros, B.C. Russell, J. Sivic, Seeing 3d chairs: exemplar part-based 2d-3d alignment using a large dataset of cad models, Proceedings of the IEEE conference on computer vision and pattern recognition, 2014",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"B. de Bruijn, T.A. Nguyen, D. Bucur, K. Tei",Benchmark Datasets for Fault Detection and Classification in Sensor Data,"SENSORNETS, ",,,2016,,"B. de Bruijn, T.A. Nguyen, D. Bucur, K. Tei, Benchmark Datasets for Fault Detection and Classification in Sensor Data, SENSORNETS, 2016",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"T. Karras, S. Laine, T. Aila",A style-based generator architecture for generative adversarial networks,"Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, ",,,2019,,"T. Karras, S. Laine, T. Aila, A style-based generator architecture for generative adversarial networks, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2019",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"R. Vemulapalli, A. Agarwala",A compact embedding for facial expression similarity,"Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, ",,,2019,,"R. Vemulapalli, A. Agarwala, A compact embedding for facial expression similarity, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2019",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"K. Mo, S. Zhu, A.X. Chang, L. Yi, S. Tripathi, L.J. Guibas, H. Su",Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding,"Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, ",,,2019,,"K. Mo, S. Zhu, A.X. Chang, L. Yi, S. Tripathi, L.J. Guibas, H. Su, Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2019",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"J. Krause, M. Stark, J. Deng, L. Fei-Fei",3d object representations for fine-grained categorization,"Proceedings of the IEEE international conference on computer vision workshops, ",,,2013,,"J. Krause, M. Stark, J. Deng, L. Fei-Fei, 3d object representations for fine-grained categorization, Proceedings of the IEEE international conference on computer vision workshops, 2013",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"R. He, C. Lin, J. McAuley",Fashionista: A fashion-aware graphical system for exploring visually similar items,"Proceedings of the 25th International Conference Companion on World Wide Web, ",,,2016,,"R. He, C. Lin, J. McAuley, Fashionista: A fashion-aware graphical system for exploring visually similar items, Proceedings of the 25th International Conference Companion on World Wide Web, 2016",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"X. Zou, X. Kong, W. Wong, C. Wang, Y. Liu, Y. Cao",Fashionai: A hierarchical dataset for fashion understanding,"Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops, ",,,2019,,"X. Zou, X. Kong, W. Wong, C. Wang, Y. Liu, Y. Cao, Fashionai: A hierarchical dataset for fashion understanding, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops, 2019",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"H. Xiao, K. Rasul, R. Vollgraf",Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms,"arXiv preprint arXiv:1708.07747, ",,,2017,,"H. Xiao, K. Rasul, R. Vollgraf, Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms, arXiv preprint arXiv:1708.07747, (2017)",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,,,,,,,,"B. Loni, L.Y. Cheung, M. Riegler, A. Bozzon, L. Gottlieb, M. Larson, Fashion 1000",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"N. Rostamzadeh, S. Hosseini, T. Boquet, W. Stokowiec, Y. Zhang, C. Jauvin, C. Pal",Fashion-gen: The generative fashion dataset and challenge,"arXiv preprint arXiv:1806.08317, ",,,2018,,"N. Rostamzadeh, S. Hosseini, T. Boquet, W. Stokowiec, Y. Zhang, C. Jauvin, C. Pal, Fashion-gen: The generative fashion dataset and challenge, arXiv preprint arXiv:1806.08317, (2018)",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"K. Simonyan, A. Zisserman",Very deep convolutional networks for large-scale image recognition,"arXiv preprint arXiv:1409.1556, ",,,2014,,"K. Simonyan, A. Zisserman, Very deep convolutional networks for large-scale image recognition, arXiv preprint arXiv:1409.1556, (2014)",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, A. Rabinovich",Going deeper with convolutions,"Proceedings of the IEEE conference on computer vision and pattern recognition, ",,,2015,,"C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, A. Rabinovich, Going deeper with convolutions, Proceedings of the IEEE conference on computer vision and pattern recognition, 2015",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"K. He, X. Zhang, S. Ren, J. Sun",Deep residual learning for image recognition,"Proceedings of the IEEE conference on computer vision and pattern recognition, ",,,2016,,"K. He, X. Zhang, S. Ren, J. Sun, Deep residual learning for image recognition, Proceedings of the IEEE conference on computer vision and pattern recognition, 2016",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"G. Huang, Z. Liu, L. Van Der Maaten, K.Q. Weinberger",Densely connected convolutional networks,"Proceedings of the IEEE conference on computer vision and pattern recognition, ",,,2017,,"G. Huang, Z. Liu, L. Van Der Maaten, K.Q. Weinberger, Densely connected convolutional networks, Proceedings of the IEEE conference on computer vision and pattern recognition, 2017",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"M. Tan, Q. Le",Efficientnet: Rethinking model scaling for convolutional neural networks,"International Conference on Machine Learning, ","PMLR, ",,2019,,"M. Tan, Q. Le, Efficientnet: Rethinking model scaling for convolutional neural networks, International Conference on Machine Learning, PMLR, 2019",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"L. Yuan, T. Wang, X. Zhang, F.E. Tay, Z. Jie, W. Liu, J. Feng",Central similarity quantization for efficient image and video retrieval,"Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, ",,,2020,,"L. Yuan, T. Wang, X. Zhang, F.E. Tay, Z. Jie, W. Liu, J. Feng, Central similarity quantization for efficient image and video retrieval, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2020",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"Z. Cao, M. Long, J. Wang, P.S. Yu",Hashnet: Deep learning to hash by continuation,"Proceedings of the IEEE international conference on computer vision, ",,,2017,,"Z. Cao, M. Long, J. Wang, P.S. Yu, Hashnet: Deep learning to hash by continuation, Proceedings of the IEEE international conference on computer vision, 2017",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,,,,,,,,"A. Ng, M. Jordan, Y. Weiss, On Spectral Clustering: Analysis and an algorithm, in: T. Dietterich, S. Becker, Z. Ghahramani (Eds.) Advances in Neural Information Processing Systems, MIT Press, 2002",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"H. Zhao, H. Liu, Y. Fu",Incomplete multi-modal visual data grouping,"Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence, ",,,2016,,"H. Zhao, H. Liu, Y. Fu, Incomplete multi-modal visual data grouping, Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence, 2016",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"M. Hu, S. Chen",Doubly Aligned Incomplete Multi-view Clustering,"International Joint Conference on Artificial Intelligence, ",,,2018,,"M. Hu, S. Chen, Doubly Aligned Incomplete Multi-view Clustering, International Joint Conference on Artificial Intelligence, 2018",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"J. Wen, Y. Xu, H. Liu",Incomplete Multiview Spectral Clustering With Adaptive Graph Learning,"IEEE Transactions on Cybernetics, ",,50 ,2020,1418-1429,"J. Wen, Y. Xu, H. Liu, Incomplete Multiview Spectral Clustering With Adaptive Graph Learning, IEEE Transactions on Cybernetics, 50 (2020) 1418-1429",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"J. Guo, J. Ye",Anchors bring ease: An embarrassingly simple approach to partial multi-view clustering,"Proceedings of the AAAI Conference on Artificial Intelligence, ",,,2019,,"J. Guo, J. Ye, Anchors bring ease: An embarrassingly simple approach to partial multi-view clustering, Proceedings of the AAAI Conference on Artificial Intelligence, 2019",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"E. Amigó, J. Gonzalo, J. Artiles, F. Verdejo",A comparison of extrinsic clustering evaluation metrics based on formal constraints,"Information retrieval, ",,12 ,2009,461-486,"E. Amigó, J. Gonzalo, J. Artiles, F. Verdejo, A comparison of extrinsic clustering evaluation metrics based on formal constraints, Information retrieval, 12 (2009) 461-486",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"K. Zhan, X. Chang, J. Guan, L. Chen, Z. Ma, Y. Yang",Adaptive structure discovery for multimedia analysis using multiple features,"IEEE transactions on cybernetics, ",,49 ,2018,1826-1834,"K. Zhan, X. Chang, J. Guan, L. Chen, Z. Ma, Y. Yang, Adaptive structure discovery for multimedia analysis using multiple features, IEEE transactions on cybernetics, 49 (2018) 1826-1834",2106.12139.pdf,"PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"J. J. McAuley, C. Targett, Q. Shi, A. van den Hengel",Image-based recommendations on styles and substitutes,SIGIR,,,2015,,"J. J. McAuley, C. Targett, Q. Shi, and A. van den Hengel, “Image-based recommendations on styles and substitutes,” in SIGIR, 2015.",./refs/download/2/Fashionista: A fashion-aware graphical system for exploring visually similar items.pdf,Fashionista: A fashion-aware graphical system for exploring visually similar items
0,"R. He and , J. McAuley",Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative filtering,WWW,,,2016,,"R. He and J. McAuley, “Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative filtering,” in WWW, 2016.",./refs/download/2/Fashionista: A fashion-aware graphical system for exploring visually similar items.pdf,Fashionista: A fashion-aware graphical system for exploring visually similar items
0,"R. He and , J. McAuley",VBPR: visual bayesian personalized ranking from implicit feedback,AAAI,,,2016,,"R. He and J. McAuley, “VBPR: visual bayesian personalized ranking from implicit feedback,” in AAAI, 2016.",./refs/download/2/Fashionista: A fashion-aware graphical system for exploring visually similar items.pdf,Fashionista: A fashion-aware graphical system for exploring visually similar items
0,"C. Lin, J. Lu, T. W. Ling, B. Cautis",Lotusx: a position-aware xml graphical search system with auto-completion,ICDE,,,2012,,"C. Lin, J. Lu, T. W. Ling, and B. Cautis, “Lotusx: a position-aware xml graphical search system with auto-completion,” in ICDE, 2012.",./refs/download/2/Fashionista: A fashion-aware graphical system for exploring visually similar items.pdf,Fashionista: A fashion-aware graphical system for exploring visually similar items
0,"A. Krizhevsky, I. Sutskever, G. E. Hinton",Imagenet classification with deep convolutional neural networks,NIPS,,,2012,,"A. Krizhevsky, I. Sutskever, and G. E. Hinton, “Imagenet classification with deep convolutional neural networks,” in NIPS, 2012.",./refs/download/2/Fashionista: A fashion-aware graphical system for exploring visually similar items.pdf,Fashionista: A fashion-aware graphical system for exploring visually similar items
0,"R. Pan, Y. Zhou, B. Cao, N. N. Liu, R. Lukose, M. Scholz, Q. Yang",One-class collaborative filtering,ICDM,,,2008,,"R. Pan, Y. Zhou, B. Cao, N. N. Liu, R. Lukose, M. Scholz, and Q. Yang, “One-class collaborative filtering,” in ICDM, 2008.",./refs/download/2/Fashionista: A fashion-aware graphical system for exploring visually similar items.pdf,Fashionista: A fashion-aware graphical system for exploring visually similar items
0,L. van der Maaten,Accelerating t-SNE using tree-based algorithms, JMLR,,,2014,,"L. van der Maaten, “Accelerating t-SNE using tree-based algorithms,” JMLR, 2014.",./refs/download/2/Fashionista: A fashion-aware graphical system for exploring visually similar items.pdf,Fashionista: A fashion-aware graphical system for exploring visually similar items
0,"Han, X., Wu, Z., Wu, Z., Yu, R., Davis, L. S.",Viton: An image-based virtual try-on network,arXiv preprint arXiv:1711.08447,,,2017,,"Han, X., Wu, Z., Wu, Z., Yu, R., and Davis, L. S. Viton: An image-based virtual try-on network. arXiv preprint arXiv:1711.08447, 2017.",./refs/download/2/Fashion-gen: The generative fashion dataset and challenge.pdf,Fashion-gen: The generative fashion dataset and challenge
0,"Huang, X., Li, Y., Poursaeed, O., Hopcroft, J., Belongie, S.",Stacked generative adversarial networks,In IEEE Conference on Computer Vision and Pattern Recognition (CVPR),,,2017,"volume 2, pp. 4","Huang, X., Li, Y., Poursaeed, O., Hopcroft, J., and Belongie, S. Stacked generative adversarial networks. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), volume 2, pp. 4, 2017.",./refs/download/2/Fashion-gen: The generative fashion dataset and challenge.pdf,Fashion-gen: The generative fashion dataset and challenge
0,"Isola, P., Zhu, J.-Y., Zhou, T., Efros, A. A.",Image-toimage translation with conditional adversarial networks,arXiv preprint,,,2017,,"Isola, P., Zhu, J.-Y., Zhou, T., and Efros, A. A. Image-toimage translation with conditional adversarial networks. arXiv preprint, 2017.",./refs/download/2/Fashion-gen: The generative fashion dataset and challenge.pdf,Fashion-gen: The generative fashion dataset and challenge
0,"Kalantidis, Y., Kennedy, L., Li, L.-J.",Getting the look: clothing recognition and segmentation for automatic product suggestions in everyday photos,In Proceedings of the 3rd ACM conference on International conference on multimedia retrieval,. ACM,,2013,pp. 105–112,"Kalantidis, Y., Kennedy, L., and Li, L.-J. Getting the look: clothing recognition and segmentation for automatic product suggestions in everyday photos. In Proceedings of the 3rd ACM conference on International conference on multimedia retrieval, pp. 105–112. ACM, 2013.",./refs/download/2/Fashion-gen: The generative fashion dataset and challenge.pdf,Fashion-gen: The generative fashion dataset and challenge
0,"Karras, T., Aila, T., Laine, S., Lehtinen, J.","Progressive growing of gans for improved quality, stability, and variation",arXiv preprint arXiv:1710.10196,,,2017,,"Karras, T., Aila, T., Laine, S., and Lehtinen, J. Progressive growing of gans for improved quality, stability, and variation. arXiv preprint arXiv:1710.10196, 2017.",./refs/download/2/Fashion-gen: The generative fashion dataset and challenge.pdf,Fashion-gen: The generative fashion dataset and challenge
0,"Barratt, S., Sharma, R.",A note on the inception score,arXiv preprint arXiv:1801.01973,,,2018,,"Barratt, S. and Sharma, R. A note on the inception score. arXiv preprint arXiv:1801.01973, 2018.",./refs/download/2/Fashion-gen: The generative fashion dataset and challenge.pdf,Fashion-gen: The generative fashion dataset and challenge
0,"Kiapour, M. H., Han, X., Lazebnik, S., Berg, A. C., Berg, T. L.",Where to buy it: Matching street clothing photos in online shops,In ICCV,,,2015,pp. 3343–3351,"Kiapour, M. H., Han, X., Lazebnik, S., Berg, A. C., and Berg, T. L. Where to buy it: Matching street clothing photos in online shops. In ICCV, pp. 3343–3351, 2015.",./refs/download/2/Fashion-gen: The generative fashion dataset and challenge.pdf,Fashion-gen: The generative fashion dataset and challenge
0,"Belghazi, M. I., Rajeswar, S., Mastropietro, O., Rostamzadeh, N., Mitrovic, J., Courville, A.",Hierarchical adversarially learned inference,arXiv preprint arXiv:1802.01071,,,2018,,"Belghazi, M. I., Rajeswar, S., Mastropietro, O., Rostamzadeh, N., Mitrovic, J., and Courville, A. Hierarchical adversarially learned inference. arXiv preprint arXiv:1802.01071, 2018.",./refs/download/2/Fashion-gen: The generative fashion dataset and challenge.pdf,Fashion-gen: The generative fashion dataset and challenge
0,"Ledig, C., Theis, L., Huszár, F., Caballero, J., Cunningham, A., Acosta, A., Aitken, A., Tejani, A., Totz, J., Wang, Z.",", et al",Photo-realistic single image super-resolution using a generative adversarial network. arXiv preprint,,,2016,,"Ledig, C., Theis, L., Huszár, F., Caballero, J., Cunningham, A., Acosta, A., Aitken, A., Tejani, A., Totz, J., Wang, Z., et al. Photo-realistic single image super-resolution using a generative adversarial network. arXiv preprint, 2016.",./refs/download/2/Fashion-gen: The generative fashion dataset and challenge.pdf,Fashion-gen: The generative fashion dataset and challenge
0,"Bossard, L., Dantone, M., Leistner, C., Wengert, C., Quack, T., Van Gool, L.",Apparel classification with style,In Asian conference on computer vision,. Springer,,2012,pp. 321–335,"Bossard, L., Dantone, M., Leistner, C., Wengert, C., Quack, T., and Van Gool, L. Apparel classification with style. In Asian conference on computer vision, pp. 321–335. Springer, 2012.",./refs/download/2/Fashion-gen: The generative fashion dataset and challenge.pdf,Fashion-gen: The generative fashion dataset and challenge
0,"Liang, X., Lin, L., Yang, W., Luo, P., Huang, J., Yan, S.",Clothes co-parsing via joint image segmentation and labeling with application to clothing retrieval,IEEE Transactions on Multimedia,,,2016,18(6):1175–1186,"Liang, X., Lin, L., Yang, W., Luo, P., Huang, J., and Yan, S. Clothes co-parsing via joint image segmentation and labeling with application to clothing retrieval. IEEE Transactions on Multimedia, 18(6):1175–1186, 2016.",./refs/download/2/Fashion-gen: The generative fashion dataset and challenge.pdf,Fashion-gen: The generative fashion dataset and challenge
0,"Chen, H., Gallagher, A., Girod, B.",Describing clothing by semantic attributes,In European conference on computer vision,. Springer,,2012,pp. 609–623,"Chen, H., Gallagher, A., and Girod, B. Describing clothing by semantic attributes. In European conference on computer vision, pp. 609–623. Springer, 2012.",./refs/download/2/Fashion-gen: The generative fashion dataset and challenge.pdf,Fashion-gen: The generative fashion dataset and challenge
0,"Lin, T.-Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Dollár, P., Zitnick, C. L.",Microsoft coco: Common objects in context,In European conference on computer vision,. Springer,,2014,pp. 740–755,"Lin, T.-Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Dollár, P., and Zitnick, C. L. Microsoft coco: Common objects in context. In European conference on computer vision, pp. 740–755. Springer, 2014.",./refs/download/2/Fashion-gen: The generative fashion dataset and challenge.pdf,Fashion-gen: The generative fashion dataset and challenge
0,"Chen, Q., Huang, J., Feris, R., Brown, L. M., Dong, J., Yan, S.",Deep domain adaptation for describing people based on fine-grained clothing attributes,In Computer Vision and Pattern Recognition (CVPR),. IEEE,,2015,"2015 IEEE Conference on, pp. 5315–5324","Chen, Q., Huang, J., Feris, R., Brown, L. M., Dong, J., and Yan, S. Deep domain adaptation for describing people based on fine-grained clothing attributes. In Computer Vision and Pattern Recognition (CVPR), 2015 IEEE Conference on, pp. 5315–5324. IEEE, 2015.",./refs/download/2/Fashion-gen: The generative fashion dataset and challenge.pdf,Fashion-gen: The generative fashion dataset and challenge
0,"Denton, E., Fergus, R.",Stochastic video generation with a learned prior,arXiv preprint arXiv:1802.07687,,,2018,,"Denton, E. and Fergus, R. Stochastic video generation with a learned prior. arXiv preprint arXiv:1802.07687, 2018.",./refs/download/2/Fashion-gen: The generative fashion dataset and challenge.pdf,Fashion-gen: The generative fashion dataset and challenge
0,"Liu, S., Song, Z., Liu, G., Xu, C., Lu, H., Yan, S.",Street-to-shop: Cross-scenario clothing retrieval via parts alignment and auxiliary set,In Computer Vision and Pattern Recognition (CVPR),. IEEE,,2012,"2012 IEEE Conference on, pp. 3330–3337","Liu, S., Song, Z., Liu, G., Xu, C., Lu, H., and Yan, S. Street-to-shop: Cross-scenario clothing retrieval via parts alignment and auxiliary set. In Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on, pp. 3330–3337. IEEE, 2012.",./refs/download/2/Fashion-gen: The generative fashion dataset and challenge.pdf,Fashion-gen: The generative fashion dataset and challenge
0,"Denton, E. L.",et al,Unsupervised learning of disentangled representations from video. In Advances in Neural Information Processing Systems,,,2017,pp. 4417–4426,"Denton, E. L. et al. Unsupervised learning of disentangled representations from video. In Advances in Neural Information Processing Systems, pp. 4417–4426, 2017.",./refs/download/2/Fashion-gen: The generative fashion dataset and challenge.pdf,Fashion-gen: The generative fashion dataset and challenge
0,"Liu, Z., Luo, P., Wang, X., Tang, X.",Deep learning face attributes in the wild,In Proceedings of the IEEE International Conference on Computer Vision,,,2015,pp. 3730– 3738,"Liu, Z., Luo, P., Wang, X., and Tang, X. Deep learning face attributes in the wild. In Proceedings of the IEEE International Conference on Computer Vision, pp. 3730– 3738, 2015.",./refs/download/2/Fashion-gen: The generative fashion dataset and challenge.pdf,Fashion-gen: The generative fashion dataset and challenge
0,"Liu, Z., Luo, P., Qiu, S., Wang, X., Tang, X.",Deepfashion: Powering robust clothes recognition and retrieval Fashion-Gen: The Generative Fashion Dataset and Challenge with rich annotations,In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,,,2016,pp. 1096–1104,"Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., and Bengio, Liu, Z., Luo, P., Qiu, S., Wang, X., and Tang, X. Deepfashion: Powering robust clothes recognition and retrieval Fashion-Gen: The Generative Fashion Dataset and Challenge with rich annotations. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1096–1104, 2016.",./refs/download/2/Fashion-gen: The generative fashion dataset and challenge.pdf,Fashion-gen: The generative fashion dataset and challenge
0,,,,,,,,"Nilsback, M.-E. and Zisserman, A. Automated flower classification over a large number of classes. In Computer Vision, Graphics & Image Processing, 2008.",./refs/download/2/Fashion-gen: The generative fashion dataset and challenge.pdf,Fashion-gen: The generative fashion dataset and challenge
0,"Reed, S., Akata, Z., Yan, X., Logeswaran, L., Schiele, B., Lee, H.",Generative adversarial text to image synthesis,arXiv preprint arXiv:1605.05396,,,2016,"2016a. Reed, S., Akata, Z., Lee, H., and Schiele, B. Learning deep representations of fine-grained visual descriptions. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 49–58, 2016b. Reed, S. E., Akata, Z., Schiele, B., and Lee, H. Learning deep representations of fine-grained visual descriptions. CoRR, abs/1605.05395","Reed, S., Akata, Z., Yan, X., Logeswaran, L., Schiele, B., and Lee, H. Generative adversarial text to image synthesis. arXiv preprint arXiv:1605.05396, 2016a. Reed, S., Akata, Z., Lee, H., and Schiele, B. Learning deep representations of fine-grained visual descriptions. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 49–58, 2016b. Reed, S. E., Akata, Z., Schiele, B., and Lee, H. Learning deep representations of fine-grained visual descriptions. CoRR, abs/1605.05395, 2016.",./refs/download/2/Fashion-gen: The generative fashion dataset and challenge.pdf,Fashion-gen: The generative fashion dataset and challenge
0,"Salimans, T., Goodfellow, I., Zaremba, W., Cheung, V., Radford, A., Chen, X.",Improved techniques for training gans,In Advances in Neural Information Processing Systems,,,2016,pp. 2234–2242,"Salimans, T., Goodfellow, I., Zaremba, W., Cheung, V., Radford, A., and Chen, X. Improved techniques for training gans. In Advances in Neural Information Processing Systems, pp. 2234–2242, 2016.",./refs/download/2/Fashion-gen: The generative fashion dataset and challenge.pdf,Fashion-gen: The generative fashion dataset and challenge
0,"Schuster, M., Paliwal, K. K., General, A.",Bidirectional recurrent neural networks,IEEE Transactions on Signal Processing,,,1997,,"Schuster, M., Paliwal, K. K., and General, A. Bidirectional recurrent neural networks. IEEE Transactions on Signal Processing, 1997.",./refs/download/2/Fashion-gen: The generative fashion dataset and challenge.pdf,Fashion-gen: The generative fashion dataset and challenge
0,"Simo-Serra, E., Fidler, S., Moreno-Noguer, F., Urtasun, R.",Neuroaesthetics in fashion: Modeling the perception of fashionability,In CVPR,,,2015,"volume 2, pp. 6","Simo-Serra, E., Fidler, S., Moreno-Noguer, F., and Urtasun, R. Neuroaesthetics in fashion: Modeling the perception of fashionability. In CVPR, volume 2, pp. 6, 2015.",./refs/download/2/Fashion-gen: The generative fashion dataset and challenge.pdf,Fashion-gen: The generative fashion dataset and challenge
0,"Sønderby, C. K., Caballero, J., Theis, L., Shi, W., Huszár, F.",Amortised map inference for image superresolution,arXiv preprint arXiv:1610.04490,,,2016,,"Sønderby, C. K., Caballero, J., Theis, L., Shi, W., and Huszár, F. Amortised map inference for image superresolution. arXiv preprint arXiv:1610.04490, 2016.",./refs/download/2/Fashion-gen: The generative fashion dataset and challenge.pdf,Fashion-gen: The generative fashion dataset and challenge
0,"Taigman, Y., Polyak, A., Wolf, L.",Unsupervised cross-domain image generation,arXiv preprint arXiv:1611.02200,,,2016,,"Taigman, Y., Polyak, A., and Wolf, L. Unsupervised cross-domain image generation. arXiv preprint arXiv:1611.02200, 2016.",./refs/download/2/Fashion-gen: The generative fashion dataset and challenge.pdf,Fashion-gen: The generative fashion dataset and challenge
0,"Maaten, L., Hinton, G.",Visualizing data using t-SNE,Journal of Machine Learning Research,,,2008,9: 2579–2605,"van der Maaten, L. and Hinton, G. Visualizing data using t-SNE. Journal of Machine Learning Research, 9: 2579–2605, 2008.",./refs/download/2/Fashion-gen: The generative fashion dataset and challenge.pdf,Fashion-gen: The generative fashion dataset and challenge
0,"Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., Polosukhin, I.",Attention is all you need,CoRR,,,2017,abs/1706.03762,"Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., and Polosukhin, I. Attention is all you need. CoRR, abs/1706.03762, 2017.",./refs/download/2/Fashion-gen: The generative fashion dataset and challenge.pdf,Fashion-gen: The generative fashion dataset and challenge
0,"Veit, A., Kovacs, B., Bell, S., McAuley, J., Bala, K., Belongie, S.",Learning visual clothing style with heterogeneous dyadic co-occurrences,In Computer Vision (ICCV),. IEEE,,2015,"2015 IEEE International Conference on, pp. 4642–4650","Veit, A., Kovacs, B., Bell, S., McAuley, J., Bala, K., and Belongie, S. Learning visual clothing style with heterogeneous dyadic co-occurrences. In Computer Vision (ICCV), 2015 IEEE International Conference on, pp. 4642–4650. IEEE, 2015.",./refs/download/2/Fashion-gen: The generative fashion dataset and challenge.pdf,Fashion-gen: The generative fashion dataset and challenge
0,"Xiao, T., Xia, T., Yang, Y., Huang, C., Wang, X.",Learning from massive noisy labeled data for image classification,In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,,,2015,pp. 2691–2699,"Xiao, T., Xia, T., Yang, Y., Huang, C., and Wang, X. Learning from massive noisy labeled data for image classification. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2691–2699, 2015.",./refs/download/2/Fashion-gen: The generative fashion dataset and challenge.pdf,Fashion-gen: The generative fashion dataset and challenge
0,"Zhang, H., Xu, T., Li, H., Zhang, S., Huang, X., Wang, X., Metaxas, D.",Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks,In IEEE Int. Conf. Comput. Vision (ICCV),,,2018,"pp. 5907–5915, 2017a. Zhang, H., Xu, T., Li, H., Zhang, S., Wang, X., Huang, X., and Metaxas, D. N. Stackgan++: Realistic image synthesis with stacked generative adversarial networks. CoRR, abs/1710.10916, 2017b. URL http://arxiv. org/abs/1710.10916. Zhang, Z., Xie, Y., and Yang, L. Photographic text-toimage synthesis with a hierarchically-nested adversarial network. arXiv preprint arXiv:1802.09178","Zhang, H., Xu, T., Li, H., Zhang, S., Huang, X., Wang, X., and Metaxas, D. Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks. In IEEE Int. Conf. Comput. Vision (ICCV), pp. 5907–5915, 2017a. Zhang, H., Xu, T., Li, H., Zhang, S., Wang, X., Huang, X., and Metaxas, D. N. Stackgan++: Realistic image synthesis with stacked generative adversarial networks. CoRR, abs/1710.10916, 2017b. URL http://arxiv. org/abs/1710.10916. Zhang, Z., Xie, Y., and Yang, L. Photographic text-toimage synthesis with a hierarchically-nested adversarial network. arXiv preprint arXiv:1802.09178, 2018.",./refs/download/2/Fashion-gen: The generative fashion dataset and challenge.pdf,Fashion-gen: The generative fashion dataset and challenge
0,"M. Abadi, A. Agarwal, P. Barham, E. Brevdo, Z. Chen, C. Citro, G. S. Corrado, A. Davis, J. Dean, M. Devin, S. Ghemawat, I. Goodfellow, A. Harp, G. Irving, M. Isard, Y. Jia, R. Jozefowicz, L. Kaiser, M. Kudlur, J. Levenberg, D. Mané, R. Monga, S. Moore, D. Murray, C. Olah, M. Schuster, J. Shlens, B. Steiner, I. Sutskever, K. Talwar, P. Tucker, V. Vanhoucke, V. Vasudevan, F. Viégas, O. Vinyals, P. Warden, M. Wattenberg, M. Wicke, Y. Yu, X. Zheng",TensorFlow: Large-scale machine learning on heterogeneous systems, ,,,2015,,"M. Abadi, A. Agarwal, P. Barham, E. Brevdo, Z. Chen, C. Citro, G. S. Corrado, A. Davis, J. Dean, M. Devin, S. Ghemawat, I. Goodfellow, A. Harp, G. Irving, M. Isard, Y. Jia, R. Jozefowicz, L. Kaiser, M. Kudlur, J. Levenberg, D. Mané, R. Monga, S. Moore, D. Murray, C. Olah, M. Schuster, J. Shlens, B. Steiner, I. Sutskever, K. Talwar, P. Tucker, V. Vanhoucke, V. Vasudevan, F. Viégas, O. Vinyals, P. Warden, M. Wattenberg, M. Wicke, Y. Yu, and X. Zheng. TensorFlow: Large-scale machine learning on heterogeneous systems, 2015.",./refs/download/2/Xception: Deep learning with depthwise separable convolutions.pdf,Xception: Deep learning with depthwise separable convolutions
0,F. Chollet,Keras, https://github,.com/fchollet/keras,,2015,,"F. Chollet. Keras. https://github.com/fchollet/keras, 2015.",./refs/download/2/Xception: Deep learning with depthwise separable convolutions.pdf,Xception: Deep learning with depthwise separable convolutions
0,"K. He, X. Zhang, S. Ren, J. Sun",Deep residual learning for image recognition, arXiv preprint arXiv:,,,1512,,"K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. arXiv preprint arXiv:1512.",./refs/download/2/Xception: Deep learning with depthwise separable convolutions.pdf,Xception: Deep learning with depthwise separable convolutions
0,"G. Hinton, O. Vinyals, J. Dean",Distilling the knowledge in a neural network, ,,,2015,,"G. Hinton, O. Vinyals, and J. Dean. Distilling the knowledge in a neural network, 2015.",./refs/download/2/Xception: Deep learning with depthwise separable convolutions.pdf,Xception: Deep learning with depthwise separable convolutions
0,A. Howard,Mobilenets: Efficient convolutional neural networks for mobile vision applications, Forthcoming,. [7] S. Ioffe and C. Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. In Proceedings of The 32nd International Conference on Machine Learning,,2015,,"A. Howard. Mobilenets: Efficient convolutional neural networks for mobile vision applications. Forthcoming. [7] S. Ioffe and C. Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. In Proceedings of The 32nd International Conference on Machine Learning, pages 448–456, 2015.",./refs/download/2/Xception: Deep learning with depthwise separable convolutions.pdf,Xception: Deep learning with depthwise separable convolutions
0,"J. Jin, A. Dundar, E. Culurciello",Flattened convolutional neural networks for feedforward acceleration, arXiv preprint arXiv:,,,1412,,"J. Jin, A. Dundar, and E. Culurciello. Flattened convolutional neural networks for feedforward acceleration. arXiv preprint arXiv:1412.",./refs/download/2/Xception: Deep learning with depthwise separable convolutions.pdf,Xception: Deep learning with depthwise separable convolutions
0,"A. Krizhevsky, I. Sutskever, G. E. Hinton",Imagenet classification with deep convolutional neural networks, In Advances in neural information processing systems,,,2012,,"A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classification with deep convolutional neural networks. In Advances in neural information processing systems, pages 1097–1105, 2012.",./refs/download/2/Xception: Deep learning with depthwise separable convolutions.pdf,Xception: Deep learning with depthwise separable convolutions
0,Y. LeCun,L, Jackel,,,1995,,"Y. LeCun, L. Jackel, L. Bottou, C. Cortes, J. S. Denker, H. Drucker, I. Guyon, U. Muller, E. Sackinger, P. Simard, et al. Learning algorithms for classification: A comparison on handwritten digit recognition. Neural networks: the statistical mechanics perspective, 261:276, 1995.",./refs/download/2/Xception: Deep learning with depthwise separable convolutions.pdf,Xception: Deep learning with depthwise separable convolutions
0,"M. Lin, Q. Chen, S. Yan",Network in network, arXiv preprint arXiv:,,,1312,,"M. Lin, Q. Chen, and S. Yan. Network in network. arXiv preprint arXiv:1312.",./refs/download/2/Xception: Deep learning with depthwise separable convolutions.pdf,Xception: Deep learning with depthwise separable convolutions
0,"F. Mamalet and , C. Garcia",Simplifying ConvNets for Fast Learning, In International Conference on Artificial Neural Networks (ICANN 2012),,,2012,,"F. Mamalet and C. Garcia. Simplifying ConvNets for Fast Learning. In International Conference on Artificial Neural Networks (ICANN 2012), pages 58–65. Springer, 2012.",./refs/download/2/Xception: Deep learning with depthwise separable convolutions.pdf,Xception: Deep learning with depthwise separable convolutions
0,"B. T. Polyak and , A. B. Juditsky",Acceleration of stochastic approximation by averaging, SIAM J,. Control Optim.,,1992,30,"B. T. Polyak and A. B. Juditsky. Acceleration of stochastic approximation by averaging. SIAM J. Control Optim., 30(4):838–855, July 1992.",./refs/download/2/Xception: Deep learning with depthwise separable convolutions.pdf,Xception: Deep learning with depthwise separable convolutions
0,O. Russakovsky,J, Deng,,,2014,,"O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, et al. Imagenet large scale visual recognition challenge. 2014.",./refs/download/2/Xception: Deep learning with depthwise separable convolutions.pdf,Xception: Deep learning with depthwise separable convolutions
0,L. Sifre,Rigid-motion scattering for image classification, ,,,2014,,"L. Sifre. Rigid-motion scattering for image classification, 2014.",./refs/download/2/Xception: Deep learning with depthwise separable convolutions.pdf,Xception: Deep learning with depthwise separable convolutions
0,"L. Sifre and , S. Mallat",Rotation, scaling and deformation invariant scattering for texture discrimination,. In 2013 IEEE Conference on Computer Vision and Pattern Recognition,,2013,,"L. Sifre and S. Mallat. Rotation, scaling and deformation invariant scattering for texture discrimination. In 2013 IEEE Conference on Computer Vision and Pattern Recognition, Portland, OR, USA, June 23-28, 2013, pages 1233–1240, 2013.",./refs/download/2/Xception: Deep learning with depthwise separable convolutions.pdf,Xception: Deep learning with depthwise separable convolutions
0,"N. Silberman and , S. Guadarrama",Tf-slim, ,,,2016,,"N. Silberman and S. Guadarrama. Tf-slim, 2016.",./refs/download/2/Xception: Deep learning with depthwise separable convolutions.pdf,Xception: Deep learning with depthwise separable convolutions
0,"K. Simonyan and , A. Zisserman",Very deep convolutional networks for large-scale image recognition, arXiv preprint arXiv:1409,.1556,,2014,,"K. Simonyan and A. Zisserman. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556, 2014.",./refs/download/2/Xception: Deep learning with depthwise separable convolutions.pdf,Xception: Deep learning with depthwise separable convolutions
0,"C. Szegedy, S. Ioffe, V. Vanhoucke",Inception-v4, inception-resnet and the impact of residual connections on learning,,,1602,,"C. Szegedy, S. Ioffe, and V. Vanhoucke. Inception-v4, inception-resnet and the impact of residual connections on learning. arXiv preprint arXiv:1602.",./refs/download/2/Xception: Deep learning with depthwise separable convolutions.pdf,Xception: Deep learning with depthwise separable convolutions
0,"C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, A. Rabinovich",Going deeper with convolutions, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,,,2015,,"C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, and A. Rabinovich. Going deeper with convolutions. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1–9, 2015.",./refs/download/2/Xception: Deep learning with depthwise separable convolutions.pdf,Xception: Deep learning with depthwise separable convolutions
0,"C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, Z. Wojna",Rethinking the inception architecture for computer vision, arXiv preprint arXiv:,,,1512,,"C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, and Z. Wojna. Rethinking the inception architecture for computer vision. arXiv preprint arXiv:1512.",./refs/download/2/Xception: Deep learning with depthwise separable convolutions.pdf,Xception: Deep learning with depthwise separable convolutions
0,"T. Tieleman and , G. Hinton",Divide the gradient by a running average of its recent magnitude, COURSERA: Neural Networks for Machine Learning,,,2012,,"T. Tieleman and G. Hinton. Divide the gradient by a running average of its recent magnitude. COURSERA: Neural Networks for Machine Learning, 4, 2012.",./refs/download/2/Xception: Deep learning with depthwise separable convolutions.pdf,Xception: Deep learning with depthwise separable convolutions
0,V. Vanhoucke,Learning visual representations at scale, ICLR,,,2014,,"V. Vanhoucke. Learning visual representations at scale. ICLR, 2014.",./refs/download/2/Xception: Deep learning with depthwise separable convolutions.pdf,Xception: Deep learning with depthwise separable convolutions
0,"M. Wang, B. Liu, H. Foroosh",Factorized convolutional neural networks, arXiv preprint arXiv:,,,1608,,"M. Wang, B. Liu, and H. Foroosh. Factorized convolutional neural networks. arXiv preprint arXiv:1608.",./refs/download/2/Xception: Deep learning with depthwise separable convolutions.pdf,Xception: Deep learning with depthwise separable convolutions
0,"M. D. Zeiler and , R. Fergus",Visualizing and understanding convolutional networks, In Computer Vision–ECCV 2014,,,2014,,"M. D. Zeiler and R. Fergus. Visualizing and understanding convolutional networks. In Computer Vision–ECCV 2014, pages 818–833. Springer, 2014.",./refs/download/2/Xception: Deep learning with depthwise separable convolutions.pdf,Xception: Deep learning with depthwise separable convolutions
0,,,,,,,," Y. Bengio, J. Louradour, R. Collobert, and ",./refs/download/2/FaceNet: A In uniﬁed embedding for face recognition and clustering.pdf,FaceNet: A In uniﬁed embedding for face recognition and clustering
0,,,,,,,," D. Chen, X. Cao, L. Wang, F. Wen, and ",./refs/download/2/FaceNet: A In uniﬁed embedding for face recognition and clustering.pdf,FaceNet: A In uniﬁed embedding for face recognition and clustering
0,,,,,,,," D. Chen, S. Ren, Y. Wei, X. Cao, and ",./refs/download/2/FaceNet: A In uniﬁed embedding for face recognition and clustering.pdf,FaceNet: A In uniﬁed embedding for face recognition and clustering
0,,,,,,,," J. Dean, G. Corrado, R. Monga, K. Chen, M. Devin, M. Mao, M. Ranzato, A. Senior, P. Tucker, K. Yang, Q. V. Le, and ",./refs/download/2/FaceNet: A In uniﬁed embedding for face recognition and clustering.pdf,FaceNet: A In uniﬁed embedding for face recognition and clustering
0,,,,,,,," P. Bartlett, F. Pereira, C. Burges, L. Bottou, and ",./refs/download/2/FaceNet: A In uniﬁed embedding for face recognition and clustering.pdf,FaceNet: A In uniﬁed embedding for face recognition and clustering
0,,,,,,,," J. Duchi, E. Hazan, and ",./refs/download/2/FaceNet: A In uniﬁed embedding for face recognition and clustering.pdf,FaceNet: A In uniﬁed embedding for face recognition and clustering
0,,,,,,,," I. J. Goodfellow, D. Warde-farley, M. Mirza, A. Courville, and ",./refs/download/2/FaceNet: A In uniﬁed embedding for face recognition and clustering.pdf,FaceNet: A In uniﬁed embedding for face recognition and clustering
0,,,,,,,," G. B. Huang, M. Ramesh, T. Berg, and ",./refs/download/2/FaceNet: A In uniﬁed embedding for face recognition and clustering.pdf,FaceNet: A In uniﬁed embedding for face recognition and clustering
0,,,,,,,," Y. LeCun, B. Boser, J. S. Denker, D. Henderson, R. E. Howard, W. Hubbard, and ",./refs/download/2/FaceNet: A In uniﬁed embedding for face recognition and clustering.pdf,FaceNet: A In uniﬁed embedding for face recognition and clustering
0,,,,,,,," M. Lin, Q. Chen, and ",./refs/download/2/FaceNet: A In uniﬁed embedding for face recognition and clustering.pdf,FaceNet: A In uniﬁed embedding for face recognition and clustering
0,,,,,,,, C. Lu and ,./refs/download/2/FaceNet: A In uniﬁed embedding for face recognition and clustering.pdf,FaceNet: A In uniﬁed embedding for face recognition and clustering
0,,,,,,,," D. E. Rumelhart, G. E. Hinton, and ",./refs/download/2/FaceNet: A In uniﬁed embedding for face recognition and clustering.pdf,FaceNet: A In uniﬁed embedding for face recognition and clustering
0,,,,,,,, M. Schultz and ,./refs/download/2/FaceNet: A In uniﬁed embedding for face recognition and clustering.pdf,FaceNet: A In uniﬁed embedding for face recognition and clustering
0,,,,,,,," S. Thrun, L. Saul, and ",./refs/download/2/FaceNet: A In uniﬁed embedding for face recognition and clustering.pdf,FaceNet: A In uniﬁed embedding for face recognition and clustering
0,,,,,,,," T. Sim, S. Baker, and ",./refs/download/2/FaceNet: A In uniﬁed embedding for face recognition and clustering.pdf,FaceNet: A In uniﬁed embedding for face recognition and clustering
0,,,,,,,," Y. Sun, X. Wang, and ",./refs/download/2/FaceNet: A In uniﬁed embedding for face recognition and clustering.pdf,FaceNet: A In uniﬁed embedding for face recognition and clustering
0,,,,,,,," Y. Sun, X. Wang, and ",./refs/download/2/FaceNet: A In uniﬁed embedding for face recognition and clustering.pdf,FaceNet: A In uniﬁed embedding for face recognition and clustering
0,,,,,,,," C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, and ",./refs/download/2/FaceNet: A In uniﬁed embedding for face recognition and clustering.pdf,FaceNet: A In uniﬁed embedding for face recognition and clustering
0,,,,,,,," Y. Taigman, M. Yang, M. Ranzato, and ",./refs/download/2/FaceNet: A In uniﬁed embedding for face recognition and clustering.pdf,FaceNet: A In uniﬁed embedding for face recognition and clustering
0,,,,,,,," J. Wang, Y. Song, T. Leung, C. Rosenberg, J. Wang, J. Philbin, B. Chen, and ",./refs/download/2/FaceNet: A In uniﬁed embedding for face recognition and clustering.pdf,FaceNet: A In uniﬁed embedding for face recognition and clustering
0,,,,,,,," K. Q. Weinberger, J. Blitzer, and ",./refs/download/2/FaceNet: A In uniﬁed embedding for face recognition and clustering.pdf,FaceNet: A In uniﬁed embedding for face recognition and clustering
0,,,,,,,, D. R. Wilson and ,./refs/download/2/FaceNet: A In uniﬁed embedding for face recognition and clustering.pdf,FaceNet: A In uniﬁed embedding for face recognition and clustering
0,,,,,,,," L. Wolf, T. Hassner, and ",./refs/download/2/FaceNet: A In uniﬁed embedding for face recognition and clustering.pdf,FaceNet: A In uniﬁed embedding for face recognition and clustering
0,,,,,,,, M. D. Zeiler and ,./refs/download/2/FaceNet: A In uniﬁed embedding for face recognition and clustering.pdf,FaceNet: A In uniﬁed embedding for face recognition and clustering
0,,,,,,,," Z. Zhu, P. Luo, X. Wang, and ",./refs/download/2/FaceNet: A In uniﬁed embedding for face recognition and clustering.pdf,FaceNet: A In uniﬁed embedding for face recognition and clustering
0,"Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander C. Berg, Li Fei-Fei",Imagenet large scale visual recognition challenge,Int. J. Comput. Vision,", ",115(3):,2015,211–252,"Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, Alexander C. Berg, and Li Fei-Fei. Imagenet large scale visual recognition challenge. Int. J. Comput. Vision, 115(3):211–252, December 2015.",./refs/download/2/Mobilenetv2: Inverted residuals and linear bottlenecks.pdf,Mobilenetv2: Inverted residuals and linear bottlenecks
0,,,,,,,,"Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Dollár, and C Lawrence Zitnick. Microsoft COCO: Common objects in context. In ECCV, 2014.",./refs/download/2/Mobilenetv2: Inverted residuals and linear bottlenecks.pdf,Mobilenetv2: Inverted residuals and linear bottlenecks
0,"Ali Eslami, Luc Van Gool, Christopher K. I. Williams, John Winn, Andrew Zisserma",The pascal visual object classes challenge a retrospective,IJCV,,,2014,,"Mark Everingham, S. M. Ali Eslami, Luc Van Gool, Christopher K. I. Williams, John Winn, and Andrew Zisserma. The pascal visual object classes challenge a retrospective. IJCV, 2014.",./refs/download/2/Mobilenetv2: Inverted residuals and linear bottlenecks.pdf,Mobilenetv2: Inverted residuals and linear bottlenecks
0,,,,,,,,"Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. CoRR, abs/1409.1556, 2014.",./refs/download/2/Mobilenetv2: Inverted residuals and linear bottlenecks.pdf,Mobilenetv2: Inverted residuals and linear bottlenecks
0,,,,,,,,"Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott E. Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. Going deeper with convolutions. In IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2015",./refs/download/2/Mobilenetv2: Inverted residuals and linear bottlenecks.pdf,Mobilenetv2: Inverted residuals and linear bottlenecks
0,,,,,,,,"Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. CoRR, abs/1512.03385, 2015.",./refs/download/2/Mobilenetv2: Inverted residuals and linear bottlenecks.pdf,Mobilenetv2: Inverted residuals and linear bottlenecks
0,"James Bergstra , Yoshua Bengio",Random search for hyper-parameter optimization,Journal of Machine Learning Research,", ",13:,2012,281–305,"James Bergstra and Yoshua Bengio. Random search for hyper-parameter optimization. Journal of Machine Learning Research, 13:281–305, 2012.",./refs/download/2/Mobilenetv2: Inverted residuals and linear bottlenecks.pdf,Mobilenetv2: Inverted residuals and linear bottlenecks
0,,,,,,,,"Jasper Snoek, Oren Rippel, Kevin Swersky, Ryan Kiros, Nadathur Satish, Narayanan Sundaram, Md. Mostofa Ali Patwary, Prabhat, and Ryan P. Adams. Scalable bayesian optimization using deep neural networks. In Francis R. Bach and David M. Blei, editors, Proceedings of the 32nd International Conference on Machine Learning, ICML 2015",./refs/download/2/Mobilenetv2: Inverted residuals and linear bottlenecks.pdf,Mobilenetv2: Inverted residuals and linear bottlenecks
0,,,,,,,,"Song Han, Jeff Pool, John Tran, and William J. Dally. Learning both weights and connections for efficient neural network. In Corinna Cortes, Neil D. Lawrence, Daniel D. Lee, Masashi Sugiyama, and Roman Garnett, editors, Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing Systems 2015",./refs/download/2/Mobilenetv2: Inverted residuals and linear bottlenecks.pdf,Mobilenetv2: Inverted residuals and linear bottlenecks
0,,,,,,,,"Song Han, Jeff Pool, Sharan Narang, Huizi Mao, Shijian Tang, Erich Elsen, Bryan Catanzaro, John Tran, and William J. Dally. DSD: regularizing deep neural networks with dense-sparse-dense training flow. CoRR, abs/1607.04381, 2016.",./refs/download/2/Mobilenetv2: Inverted residuals and linear bottlenecks.pdf,Mobilenetv2: Inverted residuals and linear bottlenecks
0,,,,,,,,"Yiwen Guo, Anbang Yao, and Yurong Chen. Dynamic network surgery for efficient dnns. In Daniel D. Lee, Masashi Sugiyama, Ulrike von Luxburg, Isabelle Guyon, and Roman Garnett, editors, Advances in Neural Information Processing Systems 29: Annual Conference on Neural Information Processing Systems 2016",./refs/download/2/Mobilenetv2: Inverted residuals and linear bottlenecks.pdf,Mobilenetv2: Inverted residuals and linear bottlenecks
0,,,,,,,,"Hao Li, Asim Kadav, Igor Durdanovic, Hanan Samet, and Hans Peter Graf. Pruning filters for efficient convnets. CoRR, abs/1608.08710, 2016.",./refs/download/2/Mobilenetv2: Inverted residuals and linear bottlenecks.pdf,Mobilenetv2: Inverted residuals and linear bottlenecks
0,,,,,,,,"Karim Ahmed and Lorenzo Torresani. Connectivity learning in multi-branch networks. CoRR, abs/1709.09582, 2017.",./refs/download/2/Mobilenetv2: Inverted residuals and linear bottlenecks.pdf,Mobilenetv2: Inverted residuals and linear bottlenecks
0,,,,,,,,"Tom Veniat and Ludovic Denoyer. Learning timeefficient deep architectures with budgeted super networks. CoRR, abs/1706.00046, 2017.",./refs/download/2/Mobilenetv2: Inverted residuals and linear bottlenecks.pdf,Mobilenetv2: Inverted residuals and linear bottlenecks
0,,,,,,,,"Xiangyu Zhang, Xinyu Zhou, Mengxiao Lin, and Jian Sun. Shufflenet: An extremely efficient convolutional neural network for mobile devices. CoRR, abs/1707.01083, 2017.",./refs/download/2/Mobilenetv2: Inverted residuals and linear bottlenecks.pdf,Mobilenetv2: Inverted residuals and linear bottlenecks
0,,,,,,,,"Soravit Changpinyo, Mark Sandler, and Andrey Zhmoginov. The power of sparsity in convolutional neural networks. CoRR, abs/1702.06257, 2017.",./refs/download/2/Mobilenetv2: Inverted residuals and linear bottlenecks.pdf,Mobilenetv2: Inverted residuals and linear bottlenecks
0,,,,,,,,"Min Wang, Baoyuan Liu, and Hassan Foroosh. Design of efficient convolutional layers using single intra-channel convolution, topological subdivisioning and spatial ”bottleneck” structure. CoRR, abs/1608.04337, 2016.",./refs/download/2/Mobilenetv2: Inverted residuals and linear bottlenecks.pdf,Mobilenetv2: Inverted residuals and linear bottlenecks
0,,,,,,,,"Barret Zoph, Vijay Vasudevan, Jonathon Shlens, and Quoc V. Le. Learning transferable architectures for scalable image recognition. CoRR, abs/1707.07012, 2017.",./refs/download/2/Mobilenetv2: Inverted residuals and linear bottlenecks.pdf,Mobilenetv2: Inverted residuals and linear bottlenecks
0,,,,,,,,"Lingxi Xie and Alan L. Yuille. CoRR, abs/1703.01513, 2017.",./refs/download/2/Mobilenetv2: Inverted residuals and linear bottlenecks.pdf,Mobilenetv2: Inverted residuals and linear bottlenecks
0,,,,,,,,"Esteban Real, Sherry Moore, Andrew Selle, Saurabh Saxena, Yutaka Leon Suematsu, Jie Tan, Quoc V. Le, and Alexey Kurakin. Large-scale evolution of image classifiers. In Doina Precup and Yee Whye Teh, editors, Proceedings of the 34th International Conference on Machine Learning, ICML 2017",./refs/download/2/Mobilenetv2: Inverted residuals and linear bottlenecks.pdf,Mobilenetv2: Inverted residuals and linear bottlenecks
0,,,,,,,,"Barret Zoph and Quoc V. Le. Neural architecture search with reinforcement learning. CoRR, abs/1611.01578, 2016.",./refs/download/2/Mobilenetv2: Inverted residuals and linear bottlenecks.pdf,Mobilenetv2: Inverted residuals and linear bottlenecks
0,,,,,,,,"Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, and Hartwig Adam. Mobilenets: Efficient convolutional neural networks for mobile vision applications. CoRR, abs/1704.04861, 2017.",./refs/download/2/Mobilenetv2: Inverted residuals and linear bottlenecks.pdf,Mobilenetv2: Inverted residuals and linear bottlenecks
0,,,,,,,,"Francois Chollet. Xception: Deep learning with depthwise separable convolutions. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), July 2017.",./refs/download/2/Mobilenetv2: Inverted residuals and linear bottlenecks.pdf,Mobilenetv2: Inverted residuals and linear bottlenecks
0,,,,,,,,"Dongyoon Han, Jiwhan Kim, and Junmo Kim. Deep pyramidal residual networks. CoRR, abs/1610.02915, 2016.",./refs/download/2/Mobilenetv2: Inverted residuals and linear bottlenecks.pdf,Mobilenetv2: Inverted residuals and linear bottlenecks
0,,,,,,,,"Saining Xie, Ross B. Girshick, Piotr Dollár, Zhuowen Tu, and Kaiming He. Aggregated residual transformations for deep neural networks. CoRR, abs/1611.05431, 2016.",./refs/download/2/Mobilenetv2: Inverted residuals and linear bottlenecks.pdf,Mobilenetv2: Inverted residuals and linear bottlenecks
0,,,,,,,,"Martı́n Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S. Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfellow, Andrew Harp, Geoffrey Irving, Michael Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dan Mané, Rajat Monga, Sherry Moore, Derek Murray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Viégas, Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng. TensorFlow: Large-scale machine learning on heterogeneous systems, 2015.",./refs/download/2/Mobilenetv2: Inverted residuals and linear bottlenecks.pdf,Mobilenetv2: Inverted residuals and linear bottlenecks
0,"Yangqing Jia, Evan Shelhamer, Jeff Donahue, Sergey Karayev, Jonathan Long, Ross Girshick, Sergio Guadarrama, Trevor Darrell",Caffe: Convolutional architecture for fast feature embedding,arXiv preprint arXiv:1408.5093,,,2014,,"Yangqing Jia, Evan Shelhamer, Jeff Donahue, Sergey Karayev, Jonathan Long, Ross Girshick, Sergio Guadarrama, and Trevor Darrell. Caffe: Convolutional architecture for fast feature embedding. arXiv preprint arXiv:1408.5093, 2014.",./refs/download/2/Mobilenetv2: Inverted residuals and linear bottlenecks.pdf,Mobilenetv2: Inverted residuals and linear bottlenecks
0,,,,,,,,"Jonathan Huang, Vivek Rathod, Chen Sun, Menglong Zhu, Anoop Korattikara, Alireza Fathi, Ian Fischer, Zbigniew Wojna, Yang Song, Sergio Guadarrama, et al. Speed/accuracy trade-offs for modern convolutional object detectors. In CVPR, 2017.",./refs/download/2/Mobilenetv2: Inverted residuals and linear bottlenecks.pdf,Mobilenetv2: Inverted residuals and linear bottlenecks
0,"Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott Reed, Cheng-Yang Fu, Alexander C Berg",Ssd: Single shot multibox detector,ECCV,,,2016,,"Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott Reed, Cheng-Yang Fu, and Alexander C Berg. Ssd: Single shot multibox detector. In ECCV, 2016.",./refs/download/2/Mobilenetv2: Inverted residuals and linear bottlenecks.pdf,Mobilenetv2: Inverted residuals and linear bottlenecks
0,"Joseph Redmon , Ali Farhadi","Yolo9000: Better, faster, stronger",arXiv preprint arXiv:1612.08242,,,2016,,"Joseph Redmon and Ali Farhadi. Yolo9000: Better, faster, stronger. arXiv preprint arXiv:1612.08242, 2016.",./refs/download/2/Mobilenetv2: Inverted residuals and linear bottlenecks.pdf,Mobilenetv2: Inverted residuals and linear bottlenecks
0,"Bharath Hariharan, Pablo Arbeláez, Lubomir Bourdev, Subhransu Maji, Jitendra Malik",Semantic contours from inverse detectors,ICCV,,,2011,,"Bharath Hariharan, Pablo Arbeláez, Lubomir Bourdev, Subhransu Maji, and Jitendra Malik. Semantic contours from inverse detectors. In ICCV, 2011.",./refs/download/2/Mobilenetv2: Inverted residuals and linear bottlenecks.pdf,Mobilenetv2: Inverted residuals and linear bottlenecks
0,"Shaoqing Ren, Kaiming He, Ross Girshick, Jian Sun",Faster r-cnn: Towards real-time object detection with region proposal networks,Advances in neural information processing systems,", ",,2015,91–99,"Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun. Faster r-cnn: Towards real-time object detection with region proposal networks. In Advances in neural information processing systems, pages 91–99, 2015.",./refs/download/2/Mobilenetv2: Inverted residuals and linear bottlenecks.pdf,Mobilenetv2: Inverted residuals and linear bottlenecks
0,,,,,,,,"Christian Szegedy, Sergey Ioffe, and Vincent Vanhoucke. Inception-v4, inception-resnet and the impact of residual connections on learning. CoRR, abs/1602.07261, 2016.",./refs/download/2/Mobilenetv2: Inverted residuals and linear bottlenecks.pdf,Mobilenetv2: Inverted residuals and linear bottlenecks
0,"Jifeng Dai, Yi Li, Kaiming He, Jian Sun",Rfcn: Object detection via region-based fully convolutional networks,Advances in neural information processing systems,", ",,2016,379–387,"Jifeng Dai, Yi Li, Kaiming He, and Jian Sun. Rfcn: Object detection via region-based fully convolutional networks. In Advances in neural information processing systems, pages 379–387, 2016.",./refs/download/2/Mobilenetv2: Inverted residuals and linear bottlenecks.pdf,Mobilenetv2: Inverted residuals and linear bottlenecks
0,,,,,,,,"Guido Montúfar, Razvan Pascanu, Kyunghyun Cho, and Yoshua Bengio. On the number of linear regions of deep neural networks. In Proceedings of the 27th International Conference on Neural Information Processing Systems, NIPS’14, pages 2924",./refs/download/2/Mobilenetv2: Inverted residuals and linear bottlenecks.pdf,Mobilenetv2: Inverted residuals and linear bottlenecks
0,,,,,,,,"Jonathan Huang, Vivek Rathod, Derek Chow, Chen Sun, and Menglong Zhu. Tensorflow object detection api, 2017.",./refs/download/2/Mobilenetv2: Inverted residuals and linear bottlenecks.pdf,Mobilenetv2: Inverted residuals and linear bottlenecks
0,,,,,,,,"Liang-Chieh Chen, George Papandreou, Florian Schroff, and Hartwig Adam. Rethinking atrous convolution for semantic image segmentation. CoRR, abs/1706.05587, 2017.",./refs/download/2/Mobilenetv2: Inverted residuals and linear bottlenecks.pdf,Mobilenetv2: Inverted residuals and linear bottlenecks
0,,,,,,,,"Matthias Holschneider, Richard KronlandMartinet, Jean Morlet, and Ph Tchamitchian. A real-time algorithm for signal analysis with the help of the wavelet transform. In Wavelets: Time-Frequency Methods and Phase Space, pages 289–297. 1989.",./refs/download/2/Mobilenetv2: Inverted residuals and linear bottlenecks.pdf,Mobilenetv2: Inverted residuals and linear bottlenecks
0,"Pierre Sermanet, David Eigen, Xiang Zhang, Michaël Mathieu, Rob Fergus, Yann LeCun","Overfeat: Integrated recognition, localization and detection using convolutional networks",arXiv:1312.6229,,,2013,,"Pierre Sermanet, David Eigen, Xiang Zhang, Michaël Mathieu, Rob Fergus, and Yann LeCun. Overfeat: Integrated recognition, localization and detection using convolutional networks. arXiv:1312.6229, 2013.",./refs/download/2/Mobilenetv2: Inverted residuals and linear bottlenecks.pdf,Mobilenetv2: Inverted residuals and linear bottlenecks
0,"George Papandreou, Iasonas Kokkinos, PierreAndre Savalle","Modeling local and global deformations in deep learning: Epitomic convolution, multiple instance learning, and sliding window detection",CVPR,,,2015,,"George Papandreou, Iasonas Kokkinos, and PierreAndre Savalle. Modeling local and global deformations in deep learning: Epitomic convolution, multiple instance learning, and sliding window detection. In CVPR, 2015.",./refs/download/2/Mobilenetv2: Inverted residuals and linear bottlenecks.pdf,Mobilenetv2: Inverted residuals and linear bottlenecks
0,"Liang-Chieh Chen, George Papandreou, Iasonas Kokkinos, Kevin Murphy, Alan L Yuille","Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs",TPAMI,,,2017,,"Liang-Chieh Chen, George Papandreou, Iasonas Kokkinos, Kevin Murphy, and Alan L Yuille. Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs. TPAMI, 2017.",./refs/download/2/Mobilenetv2: Inverted residuals and linear bottlenecks.pdf,Mobilenetv2: Inverted residuals and linear bottlenecks
0,,,,,,,,"Wei Liu, Andrew Rabinovich, and Alexander C. Berg. Parsenet: Looking wider to see better. CoRR, abs/1506.04579, 2015.",./refs/download/2/Mobilenetv2: Inverted residuals and linear bottlenecks.pdf,Mobilenetv2: Inverted residuals and linear bottlenecks
0,,,,,,,,"Peter L. Bartlett, Fernando C. N. Pereira, Christopher J. C. Burges, Léon Bottou, and Kilian Q. Weinberger, editors. Advances in Neural Information Processing Systems 25: 26th Annual Conference on Neural Information Processing Systems 2012.",./refs/download/2/Mobilenetv2: Inverted residuals and linear bottlenecks.pdf,Mobilenetv2: Inverted residuals and linear bottlenecks
0,,,,,,,," Y. Cao, M. Long, B. Liu, and ",./refs/download/2/Central similarity quantization for efficient image and video retrieval.pdf,Central similarity quantization for efficient image and video retrieval
0,,,,,,,," Z. Cao, M. Long, J. Wang, and ",./refs/download/2/Central similarity quantization for efficient image and video retrieval.pdf,Central similarity quantization for efficient image and video retrieval
0,,,,,,,," S. Vijayanarasimhan, B. Seybold, D. A. Ross, J. Deng, and ",./refs/download/2/Central similarity quantization for efficient image and video retrieval.pdf,Central similarity quantization for efficient image and video retrieval
0,,,,,,,," Y. Chen, Y. Kalantidis, J. Li, S. Yan, and ",./refs/download/2/Central similarity quantization for efficient image and video retrieval.pdf,Central similarity quantization for efficient image and video retrieval
0,,,,,,,," J. Tang, R. Hong, H. Li, Z. Luo, and ",./refs/download/2/Central similarity quantization for efficient image and video retrieval.pdf,Central similarity quantization for efficient image and video retrieval
0,,,,,,,," J. Donahue, L. Anne Hendricks, S. Guadarrama, M. Rohrbach, S. Venugopalan, K. Saenko, and ",./refs/download/2/Central similarity quantization for efficient image and video retrieval.pdf,Central similarity quantization for efficient image and video retrieval
0,,,,,,,," Y. Gong, S. Lazebnik, A. Gordo, and ",./refs/download/2/Central similarity quantization for efficient image and video retrieval.pdf,Central similarity quantization for efficient image and video retrieval
0,,,,,,,," Y. Gu, C. Ma, and ",./refs/download/2/Central similarity quantization for efficient image and video retrieval.pdf,Central similarity quantization for efficient image and video retrieval
0,,,,,,,," K. He, X. Zhang, S. Ren, and ",./refs/download/2/Central similarity quantization for efficient image and video retrieval.pdf,Central similarity quantization for efficient image and video retrieval
0,,,,,,,," A. Hyvärinen, J. Hurri, and ",./refs/download/2/Central similarity quantization for efficient image and video retrieval.pdf,Central similarity quantization for efficient image and video retrieval
0,,,,,,,," L. Karlinsky, J. Shtok, S. Harary, E. Schwartz, A. Aides, R. Feris, R. Giryes, and ",./refs/download/2/Central similarity quantization for efficient image and video retrieval.pdf,Central similarity quantization for efficient image and video retrieval
0,,,,,,,," H. Kuehne, H. Jhuang, R. Stiefelhagen, and ",./refs/download/2/Central similarity quantization for efficient image and video retrieval.pdf,Central similarity quantization for efficient image and video retrieval
0,,,,,,,, B. Kulis and ,./refs/download/2/Central similarity quantization for efficient image and video retrieval.pdf,Central similarity quantization for efficient image and video retrieval
0,,,,,,,," H. Lai, Y. Pan, Y. Liu, and ",./refs/download/2/Central similarity quantization for efficient image and video retrieval.pdf,Central similarity quantization for efficient image and video retrieval
0,,,,,,,," C. Li, C. Deng, N. Li, W. Liu, X. Gao, and ",./refs/download/2/Central similarity quantization for efficient image and video retrieval.pdf,Central similarity quantization for efficient image and video retrieval
0,,,,,,,," C. Li, S. Gao, C. Deng, D. Xie, and ",./refs/download/2/Central similarity quantization for efficient image and video retrieval.pdf,Central similarity quantization for efficient image and video retrieval
0,,,,,,,," S. Wang, and ",./refs/download/2/Central similarity quantization for efficient image and video retrieval.pdf,Central similarity quantization for efficient image and video retrieval
0,,,,,,,," Y. Li, W. Liu, and ",./refs/download/2/Central similarity quantization for efficient image and video retrieval.pdf,Central similarity quantization for efficient image and video retrieval
0,,,,,,,," M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan, P. Dollár, and ",./refs/download/2/Central similarity quantization for efficient image and video retrieval.pdf,Central similarity quantization for efficient image and video retrieval
0,,,,,,,," H. Liu, R. Wang, S. Shan, and ",./refs/download/2/Central similarity quantization for efficient image and video retrieval.pdf,Central similarity quantization for efficient image and video retrieval
0,,,,,,,," W. Liu, C. Mu, S. Kumar, and ",./refs/download/2/Central similarity quantization for efficient image and video retrieval.pdf,Central similarity quantization for efficient image and video retrieval
0,,,,,,,," W. Liu, J. Wang, S. Kumar, and ",./refs/download/2/Central similarity quantization for efficient image and video retrieval.pdf,Central similarity quantization for efficient image and video retrieval
0,,,,,,,, W. Liu and ,./refs/download/2/Central similarity quantization for efficient image and video retrieval.pdf,Central similarity quantization for efficient image and video retrieval
0,,,,,,,," M. Norouzi, D. J. Fleet, and ",./refs/download/2/Central similarity quantization for efficient image and video retrieval.pdf,Central similarity quantization for efficient image and video retrieval
0,,,,,,,," J. Qin, L. Liu, M. Yu, Y. Wang, and ",./refs/download/2/Central similarity quantization for efficient image and video retrieval.pdf,Central similarity quantization for efficient image and video retrieval
0,,,,,,,," O. Rippel, M. Paluri, P. Dollar, and ",./refs/download/2/Central similarity quantization for efficient image and video retrieval.pdf,Central similarity quantization for efficient image and video retrieval
0,,,,,,,," F. Shen, W. Liu, S. Zhang, Y. Yang, and ",./refs/download/2/Central similarity quantization for efficient image and video retrieval.pdf,Central similarity quantization for efficient image and video retrieval
0,,,,,,,," F. Shen, C. Shen, W. Liu, and ",./refs/download/2/Central similarity quantization for efficient image and video retrieval.pdf,Central similarity quantization for efficient image and video retrieval
0,,,,,,,, K. Simonyan and ,./refs/download/2/Central similarity quantization for efficient image and video retrieval.pdf,Central similarity quantization for efficient image and video retrieval
0,,,,,,,," D. Song, W. Liu, R. Ji, D. A. Meyer, and ",./refs/download/2/Central similarity quantization for efficient image and video retrieval.pdf,Central similarity quantization for efficient image and video retrieval
0,,,,,,,," K. Soomro, A. R. Zamir, and ",./refs/download/2/Central similarity quantization for efficient image and video retrieval.pdf,Central similarity quantization for efficient image and video retrieval
0,,,,,,,," G. Varol, I. Laptev, and ",./refs/download/2/Central similarity quantization for efficient image and video retrieval.pdf,Central similarity quantization for efficient image and video retrieval
0,,,,,,,," J. Wang, W. Liu, S. Kumar, and ",./refs/download/2/Central similarity quantization for efficient image and video retrieval.pdf,Central similarity quantization for efficient image and video retrieval
0,,,,,,,," J. Wang, W. Liu, A. X. Sun, and ",./refs/download/2/Central similarity quantization for efficient image and video retrieval.pdf,Central similarity quantization for efficient image and video retrieval
0,,,,,,,," L. Wang, Y. Xiong, Z. Wang, Y. Qiao, D. Lin, X. Tang, and ",./refs/download/2/Central similarity quantization for efficient image and video retrieval.pdf,Central similarity quantization for efficient image and video retrieval
0,,,,,,,," T. Weise, M. Zapf, R. Chiong, and ",./refs/download/2/Central similarity quantization for efficient image and video retrieval.pdf,Central similarity quantization for efficient image and video retrieval
0,,,,,,,," Y. Weiss, A. Torralba, and ",./refs/download/2/Central similarity quantization for efficient image and video retrieval.pdf,Central similarity quantization for efficient image and video retrieval
0,,,,,,,," Y. Wen, K. Zhang, Z. Li, and ",./refs/download/2/Central similarity quantization for efficient image and video retrieval.pdf,Central similarity quantization for efficient image and video retrieval
0,,,,,,,," R. Xia, Y. Pan, H. Lai, C. Liu, and ",./refs/download/2/Central similarity quantization for efficient image and video retrieval.pdf,Central similarity quantization for efficient image and video retrieval
0,,,,,,,," E. Yang, T. Liu, C. Deng, W. Liu, and ",./refs/download/2/Central similarity quantization for efficient image and video retrieval.pdf,Central similarity quantization for efficient image and video retrieval
0,,,,,,,," L. Yuan, E. H. F. Tay, P. Li, and ",./refs/download/2/Central similarity quantization for efficient image and video retrieval.pdf,Central similarity quantization for efficient image and video retrieval
0,,,,,,,," L. Yuan, F. E. Tay, P. Li, L. Zhou, and ",./refs/download/2/Central similarity quantization for efficient image and video retrieval.pdf,Central similarity quantization for efficient image and video retrieval
0,,,,,,,," H. Zhu, M. Long, J. Wang, and ",./refs/download/2/Central similarity quantization for efficient image and video retrieval.pdf,Central similarity quantization for efficient image and video retrieval
0,,,,,,,," N. Zhuang, J. Ye, and ",./refs/download/2/Central similarity quantization for efficient image and video retrieval.pdf,Central similarity quantization for efficient image and video retrieval
0,,,,,,,,Yoshua Bengio and Xavier Glorot. Understanding the difficulty of training deep feedforward neural networks. In Proceedings of AISTATS 2010,./refs/download/2/Wide residual networks.pdf,Wide residual networks
0,,,,,,,,"Yoshua Bengio and Yann LeCun. Scaling learning algorithms towards AI. In Léon Bottou, Olivier Chapelle, D. DeCoste, and J. Weston, editors, Large Scale Kernel Machines. MIT Press, 2007.",./refs/download/2/Wide residual networks.pdf,Wide residual networks
0,,,,,,,,"Monica Bianchini and Franco Scarselli. On the complexity of shallow and deep neural network classifiers. In 22th European Symposium on Artificial Neural Networks, ESANN 2014",./refs/download/2/Wide residual networks.pdf,Wide residual networks
0,,,,,,,,"Djork-Arné Clevert, Thomas Unterthiner, and Sepp Hochreiter. Fast and accurate deep network learning by exponential linear units (elus). CoRR, abs/1511.07289, 2015.",./refs/download/2/Wide residual networks.pdf,Wide residual networks
0,,,,,,,,"Spyros Gidaris and Nikos Komodakis. Locnet: Improving localization accuracy for object detection. In Computer Vision and Pattern Recognition (CVPR), 2016",./refs/download/2/Wide residual networks.pdf,Wide residual networks
0,,,,,,,,"Ian J. Goodfellow, David Warde-Farley, Mehdi Mirza, Aaron Courville, and Yoshua Bengio. Maxout networks. In Sanjoy Dasgupta and David McAllester, editors, Proceedings of the 30th International Conference on Machine Learning (ICML’13), pages 1319",./refs/download/2/Wide residual networks.pdf,Wide residual networks
0,,,,,,,,"Benjamin Graham. Fractional max-pooling. arXiv:1412.6071, 2014.",./refs/download/2/Wide residual networks.pdf,Wide residual networks
0,,,,,,,,"Sam Gross and Michael Wilber. Training and investigating residual nets, 2016.",./refs/download/2/Wide residual networks.pdf,Wide residual networks
0,,,,,,,,"Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. CoRR, abs/1512.03385, 2015.",./refs/download/2/Wide residual networks.pdf,Wide residual networks
0,,,,,,,,"Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Delving deep into rectifiers: Surpassing human-level performance on imagenet classification. CoRR, abs/1502.01852, 2015.",./refs/download/2/Wide residual networks.pdf,Wide residual networks
0,,,,,,,,"Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Identity mappings in deep residual networks. CoRR, abs/1603.05027, 2016.",./refs/download/2/Wide residual networks.pdf,Wide residual networks
0,,,,,,,,"Gao Huang, Yu Sun, Zhuang Liu, Daniel Sedra, and Kilian Q. Weinberger. Deep networks with stochastic depth. CoRR, abs/1603.09382, 2016.",./refs/download/2/Wide residual networks.pdf,Wide residual networks
0,"In David Blei , Francis Bach","editors, Proceedings of the 32nd International Conference on Machine Learning (ICML-15), pages 448–456",JMLR Workshop and Conference Proceedings,,,2015,,"Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. In David Blei and Francis Bach, editors, Proceedings of the 32nd International Conference on Machine Learning (ICML-15), pages 448–456. JMLR Workshop and Conference Proceedings, 2015.",./refs/download/2/Wide residual networks.pdf,Wide residual networks
0,,,,,,,,"Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. Cifar-10 (canadian institute for advanced research). 2012.",./refs/download/2/Wide residual networks.pdf,Wide residual networks
0,,,,,,,,"Hugo Larochelle, Dumitru Erhan, Aaron Courville, James Bergstra, and Yoshua Bengio. An empirical evaluation of deep architectures on problems with many factors of variation. In Zoubin Ghahramani, editor, Proceedings of the 24th International Conference on Machine Learning (ICML’07), pages 473–480. ACM, 2007.",./refs/download/2/Wide residual networks.pdf,Wide residual networks
0,,,,,,,,"Min Lin, Qiang Chen, and Shuicheng Yan. Network in network. CoRR, abs/1312.4400, 2013.",./refs/download/2/Wide residual networks.pdf,Wide residual networks
0,,,,,,,,"Francisco Massa. Optnet - reducing memory usage in torch neural networks, 2016.",./refs/download/2/Wide residual networks.pdf,Wide residual networks
0,,,,,,,,"Guido F. Montúfar, Razvan Pascanu, KyungHyun Cho, and Yoshua Bengio. On the number of linear regions of deep neural networks. In Advances in Neural Information Processing Systems 27: Annual Conference on Neural Information Processing Systems 2014",./refs/download/2/Wide residual networks.pdf,Wide residual networks
0,,,,,,,,"Tapani Raiko, Harri Valpola, and Yann Lecun. Deep learning made easier by linear transformations in perceptrons. In Neil D. Lawrence and Mark A. Girolami, editors, Proceedings of the Fifteenth International Conference on Artificial Intelligence and Statistics (AISTATS-12), volume 22, pages 924–932, 2012.",./refs/download/2/Wide residual networks.pdf,Wide residual networks
0,,,,,,,,"Adriana Romero, Nicolas Ballas, Samira Ebrahimi Kahou, Antoine Chassang, Carlo Gatta, and Yoshua Bengio. FitNets: Hints for thin deep nets. Technical Report Arxiv report 1412.",./refs/download/2/Wide residual networks.pdf,Wide residual networks
0,,,,,,,,"Rupesh Kumar Srivastava, Klaus Greff, and Jürgen Schmidhuber. Highway networks. CoRR, abs/1505.00387, 2015.",./refs/download/2/Wide residual networks.pdf,Wide residual networks
0,,,,,,,,"Ilya Sutskever, James Martens, George E. Dahl, and Geoffrey E. Hinton. On the importance of initialization and momentum in deep learning. In Sanjoy Dasgupta and David Mcallester, editors, Proceedings of the 30th International Conference on Machine Learning (ICML-13), volume 28, pages 1139",./refs/download/2/Wide residual networks.pdf,Wide residual networks
0,"Christian Szegedy, Sergey Ioffe, Vincent Vanhoucke","Inception-v4, inceptionresnet and the impact of residual connections on learning",abs/1602.07261,,,2016,,"Christian Szegedy, Sergey Ioffe, and Vincent Vanhoucke. Inception-v4, inceptionresnet and the impact of residual connections on learning. abs/1602.07261, 2016.",./refs/download/2/Wide residual networks.pdf,Wide residual networks
0,,,,,,,," S. Belongie, J. Malik, and ",./refs/download/2/3D semantic segmentation with submanifold sparse convolutional networks.pdf,3D semantic segmentation with submanifold sparse convolutional networks
0,,,,,,,," A. Abdulkadir, S. S. Lienkamp, T. Brox, and ",./refs/download/2/3D semantic segmentation with submanifold sparse convolutional networks.pdf,3D semantic segmentation with submanifold sparse convolutional networks
0,,,,,,,," M. Engelcke, D. Rao, D. Z. Wang, C. H. Tong, and ",./refs/download/2/3D semantic segmentation with submanifold sparse convolutional networks.pdf,3D semantic segmentation with submanifold sparse convolutional networks
0,,,,,,,, B. Graham and ,./refs/download/2/3D semantic segmentation with submanifold sparse convolutional networks.pdf,3D semantic segmentation with submanifold sparse convolutional networks
0,,,,,,,," S. Gupta, P. Arbelaez, and ",./refs/download/2/3D semantic segmentation with submanifold sparse convolutional networks.pdf,3D semantic segmentation with submanifold sparse convolutional networks
0,,,,,,,," K. He, X. Zhang, S. Ren, and ",./refs/download/2/3D semantic segmentation with submanifold sparse convolutional networks.pdf,3D semantic segmentation with submanifold sparse convolutional networks
0,,,,,,,," K. He, X. Zhang, S. Ren, and ",./refs/download/2/3D semantic segmentation with submanifold sparse convolutional networks.pdf,3D semantic segmentation with submanifold sparse convolutional networks
0,,,,,,,," G. Huang, Z. Liu, K. Q. Weinberger, and ",./refs/download/2/3D semantic segmentation with submanifold sparse convolutional networks.pdf,3D semantic segmentation with submanifold sparse convolutional networks
0,,,,,,,, R. Klokov and ,./refs/download/2/3D semantic segmentation with submanifold sparse convolutional networks.pdf,3D semantic segmentation with submanifold sparse convolutional networks
0,,,,,,,," X. G. L. Yi, H. Su and ",./refs/download/2/3D semantic segmentation with submanifold sparse convolutional networks.pdf,3D semantic segmentation with submanifold sparse convolutional networks
0,,,,,,,," Y. LeCun, J. Denker, and ",./refs/download/2/3D semantic segmentation with submanifold sparse convolutional networks.pdf,3D semantic segmentation with submanifold sparse convolutional networks
0,,,,,,,," J. Long, E. Shelhamer, and ",./refs/download/2/3D semantic segmentation with submanifold sparse convolutional networks.pdf,3D semantic segmentation with submanifold sparse convolutional networks
0,,,,,,,, D. Maturana and ,./refs/download/2/3D semantic segmentation with submanifold sparse convolutional networks.pdf,3D semantic segmentation with submanifold sparse convolutional networks
0,,,,,,,," P. K. Nathan Silberman, Derek Hoiem and ",./refs/download/2/3D semantic segmentation with submanifold sparse convolutional networks.pdf,3D semantic segmentation with submanifold sparse convolutional networks
0,,,,,,,," C. R. Qi, H. Su, K. Mo, and ",./refs/download/2/3D semantic segmentation with submanifold sparse convolutional networks.pdf,3D semantic segmentation with submanifold sparse convolutional networks
0,,,,,,,," G. Riegler, A. O. Ulusoys, and ",./refs/download/2/3D semantic segmentation with submanifold sparse convolutional networks.pdf,3D semantic segmentation with submanifold sparse convolutional networks
0,,,,,,,," O. Ronneberger, P. Fischer, and ",./refs/download/2/3D semantic segmentation with submanifold sparse convolutional networks.pdf,3D semantic segmentation with submanifold sparse convolutional networks
0,,,,,,,, K. Simonyan and ,./refs/download/2/3D semantic segmentation with submanifold sparse convolutional networks.pdf,3D semantic segmentation with submanifold sparse convolutional networks
0,,,,,,,," H. Su, S. Maji, E. Kalogerakis, and ",./refs/download/2/3D semantic segmentation with submanifold sparse convolutional networks.pdf,3D semantic segmentation with submanifold sparse convolutional networks
0,,,,,,,, D. Z. Wang and ,./refs/download/2/3D semantic segmentation with submanifold sparse convolutional networks.pdf,3D semantic segmentation with submanifold sparse convolutional networks
0,,,,,,,, F. Yu and ,./refs/download/2/3D semantic segmentation with submanifold sparse convolutional networks.pdf,3D semantic segmentation with submanifold sparse convolutional networks
0,,,,,,,," M. D. Zeiler, D. Krishnan, G. W. Taylor, and ",./refs/download/2/3D semantic segmentation with submanifold sparse convolutional networks.pdf,3D semantic segmentation with submanifold sparse convolutional networks
0,"Q. Liu and , C. Liu",A novel locally linear knn model for visual recognition, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,,,2015,,"Q. Liu and C. Liu. A novel locally linear knn model for visual recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1329– 1337, 2015.",./refs/download/2/Emotionet: An accurate.pdf,Emotionet: An accurate
0,A. M. Martinez,Recognizing imprecisely localized, partially occluded,,,2002,,"A. M. Martinez. Recognizing imprecisely localized, partially occluded, and expression variant faces from a single sample per class. IEEE Transactions on Pattern analysis and machine intelligence, 24(6):748–763, 2002.",./refs/download/2/Emotionet: An accurate.pdf,Emotionet: An accurate
0,A. M. Martinez,Computational models of face perception, Current Directions in Psychological Science,,,2017,,"A. M. Martinez. Computational models of face perception. Current Directions in Psychological Science, 2017.",./refs/download/2/Emotionet: An accurate.pdf,Emotionet: An accurate
0,O. Russakovsky,J, Deng,,,2014,,"O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, et al. Imagenet large scale visual recognition challenge. International Journal of Computer Vision, pages 1–42, 2014.",./refs/download/2/Emotionet: An accurate.pdf,Emotionet: An accurate
0,"R. Srinivasan, J. D. Golomb, A. M. Martine",A neural basis of facial action recognition in humans, The Journal of Neuroscience,,,2016,,"R. Srinivasan, J. D. Golomb, and A. M. Martine. A neural basis of facial action recognition in humans. The Journal of Neuroscience, 2016.",./refs/download/2/Emotionet: An accurate.pdf,Emotionet: An accurate
0,"D. Tome, C. Russell, L. Agapito",Lifting from the deep: Convolutional 3d pose estimation from a single image, arXiv preprint arXiv:,,,1701,,"D. Tome, C. Russell, and L. Agapito. Lifting from the deep: Convolutional 3d pose estimation from a single image. arXiv preprint arXiv:1701.",./refs/download/2/Emotionet: An accurate.pdf,Emotionet: An accurate
0,"Y. Tong, W. Liao, Q. Ji",Facial action unit recognition by exploiting their dynamic and semantic relationships, IEEE transactions on pattern analysis and machine intelligence,,,2007,29,"Y. Tong, W. Liao, and Q. Ji. Facial action unit recognition by exploiting their dynamic and semantic relationships. IEEE transactions on pattern analysis and machine intelligence, 29(10), 2007.",./refs/download/2/Emotionet: An accurate.pdf,Emotionet: An accurate
0,"F. Wang, X. Xiang, C. Liu, T. D. Tran, A. Reiter, G. D. Hager, H. Quon, J. Cheng, A. L. Yuille",Transferring face verification nets to pain and expression regression, arXiv preprint arXiv:,,,1702,,"F. Wang, X. Xiang, C. Liu, T. D. Tran, A. Reiter, G. D. Hager, H. Quon, J. Cheng, and A. L. Yuille. Transferring face verification nets to pain and expression regression. arXiv preprint arXiv:1702.",./refs/download/2/Emotionet: An accurate.pdf,Emotionet: An accurate
0,"D. You, C. F. Benitez-Quiroz, A. M. Martinez",Multiobjective optimization for model selection in kernel methods in regression, IEEE transactions on neural networks and learning systems,,,2014,25,"D. You, C. F. Benitez-Quiroz, and A. M. Martinez. Multiobjective optimization for model selection in kernel methods in regression. IEEE transactions on neural networks and learning systems, 25(10):1879–1893, 2014.",./refs/download/2/Emotionet: An accurate.pdf,Emotionet: An accurate
0,"D. You, O. C. Hamsici, A. M. Martinez",Kernel optimization in discriminant analysis, IEEE Transactions on Pattern Analysis and Machine Intelligence,,,2011,33,"D. You, O. C. Hamsici, and A. M. Martinez. Kernel optimization in discriminant analysis. IEEE Transactions on Pattern Analysis and Machine Intelligence, 33(3):631–638, 2011.",./refs/download/2/Emotionet: An accurate.pdf,Emotionet: An accurate
0,"S. Zafeiriou, A. Papaioannou, I. Kotsia, M. Nicolaou, G. Zhao",Facial affect “in the wild”, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops,,,2016,,"S. Zafeiriou, A. Papaioannou, I. Kotsia, M. Nicolaou, and G. Zhao. Facial affect “in the wild”. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, pages 36–47, 2016.",./refs/download/2/Emotionet: An accurate.pdf,Emotionet: An accurate
0,"K. Zhao, W.-S. Chu, F. De la Torre, J. F. Cohn, H. Zhang",Joint patch and multi-label learning for facial action unit and holistic expression recognition, IEEE Transactions on Image Processing,,,2016,25,"K. Zhao, W.-S. Chu, F. De la Torre, J. F. Cohn, and H. Zhang. Joint patch and multi-label learning for facial action unit and holistic expression recognition. IEEE Transactions on Image Processing, 25(8):3931–3946, 2016.",./refs/download/2/Emotionet: An accurate.pdf,Emotionet: An accurate
0,"R. Zhao, Y. Wang, A. M. Martinez",A simple, fast and highly-accurate algorithm to recover 3d shape from 2d landmarks on a single image,,,1609,,"R. Zhao, Y. Wang, and A. M. Martinez. A simple, fast and highly-accurate algorithm to recover 3d shape from 2d landmarks on a single image. arXiv preprint arXiv:1609.",./refs/download/2/Emotionet: An accurate.pdf,Emotionet: An accurate
0,"C. F. Benitez-Quiroz, R. Srinivasan, A. M. Martinez",Emotionet: An accurate, real-time algorithm for the automatic annotation of a million facial expressions in the wild,. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,,2016,,"C. F. Benitez-Quiroz, R. Srinivasan, and A. M. Martinez. Emotionet: An accurate, real-time algorithm for the automatic annotation of a million facial expressions in the wild. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 5562–5570, 2016.",./refs/download/2/Emotionet: An accurate.pdf,Emotionet: An accurate
0,"C. A. Corneanu, M. O. Simón, J. F. Cohn, S. E. Guerrero",Survey on rgb, 3d,,,2016,,"C. A. Corneanu, M. O. Simón, J. F. Cohn, and S. E. Guerrero. Survey on rgb, 3d, thermal, and multimodal approaches for facial expression recognition: History, trends, and affectrelated applications. IEEE transactions on pattern analysis and machine intelligence, 38(8):1548–1568, 2016.",./refs/download/2/Emotionet: An accurate.pdf,Emotionet: An accurate
0,"A. Dhall, R. Goecke, T. Gedeon, N. Sebe",Emotion recognition in the wild, Journal on Multimodal User Interfaces,,,2016,,"A. Dhall, R. Goecke, T. Gedeon, and N. Sebe. Emotion recognition in the wild. Journal on Multimodal User Interfaces, 2(10):95–97, 2016.",./refs/download/2/Emotionet: An accurate.pdf,Emotionet: An accurate
0,"S. Du, Y. Tao, A. M. Martinez",Compound facial expressions of emotion, Proceedings of the National Academy of Sciences,,,2014,111,"S. Du, Y. Tao, and A. M. Martinez. Compound facial expressions of emotion. Proceedings of the National Academy of Sciences, 111(15):E1454–E1462, 2014.",./refs/download/2/Emotionet: An accurate.pdf,Emotionet: An accurate
0,"P. Ekman and , E. L. Rosenberg",What the Face Reveals: Basic and applied studies of spontaneous expression using the Facial Action Coding System (FACS), 2nd edition,. Oxford University Press,,2006,,"P. Ekman and E. L. Rosenberg. What the Face Reveals: Basic and applied studies of spontaneous expression using the Facial Action Coding System (FACS), 2nd edition. Oxford University Press, USA, 2006.",./refs/download/2/Emotionet: An accurate.pdf,Emotionet: An accurate
0,"M. Everingham, L. Van Gool, C. K. I. Williams, J. Winn, A. Zisserman",The pascal visual object classes (voc) challenge, International Journal of Computer Vision,,,2010,88,"M. Everingham, L. Van Gool, C. K. I. Williams, J. Winn, and A. Zisserman. The pascal visual object classes (voc) challenge. International Journal of Computer Vision, 88(2):303– 338, June 2010.",./refs/download/2/Emotionet: An accurate.pdf,Emotionet: An accurate
0,"L. A. Jeni, S. Tulyakov, L. Yin, N. Sebe, J. F. Cohn",The first 3d face alignment in the wild (3dfaw) challenge, In European Conference on Computer Vision,,,2016,,"L. A. Jeni, S. Tulyakov, L. Yin, N. Sebe, and J. F. Cohn. The first 3d face alignment in the wild (3dfaw) challenge. In European Conference on Computer Vision, pages 511–520. Springer International Publishing, 2016.",./refs/download/2/Emotionet: An accurate.pdf,Emotionet: An accurate
0,"H. Jia and , A. M. Martinez",Support vector machines in face recognition with occlusions, In Computer Vision and Pattern Recognition,,,2009,,"H. Jia and A. M. Martinez. Support vector machines in face recognition with occlusions. In Computer Vision and Pattern Recognition, 2009.",./refs/download/2/Emotionet: An accurate.pdf,Emotionet: An accurate
0,"I. Kemelmacher-Shlizerman, S. M. Seitz, D. Miller, E. Brossard",The megaface benchmark: 1 million faces for recognition at scale, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,,,2016,,"I. Kemelmacher-Shlizerman, S. M. Seitz, D. Miller, and E. Brossard. The megaface benchmark: 1 million faces for recognition at scale. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2016.",./refs/download/2/Emotionet: An accurate.pdf,Emotionet: An accurate
0,"I. Kotsia, I. Buciu, I. Pitas",An analysis of facial expression recognition under partial facial image occlusion, Image and Vision Computing,,,2008,26,"I. Kotsia, I. Buciu, and I. Pitas. An analysis of facial expression recognition under partial facial image occlusion. Image and Vision Computing, 26(7):1052–1067, 2008.",./refs/download/2/Emotionet: An accurate.pdf,Emotionet: An accurate
0,"A. Krizhevsky, I. Sutskever, G. E. Hinton",Imagenet classification with deep convolutional neural networks, In Advances in neural information processing systems,,,2012,,"A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classification with deep convolutional neural networks. In Advances in neural information processing systems, pages 1097–1105, 2012.",./refs/download/2/Emotionet: An accurate.pdf,Emotionet: An accurate
0,,,,,,,," B. Forgeron, and ",./refs/download/2/Squeezenext: Hardware-aware neural network design.pdf,Squeezenext: Hardware-aware neural network design
0,,,,,,,, L. Cavigelli and ,./refs/download/2/Squeezenext: Hardware-aware neural network design.pdf,Squeezenext: Hardware-aware neural network design
0,,,,,,,," T. Krishna, J. S. Emer, and ",./refs/download/2/Squeezenext: Hardware-aware neural network design.pdf,Squeezenext: Hardware-aware neural network design
0,,,,,,,," C. Farabet, B. Martini, B. Corda, P. Akselrod, E. Culurciello, and ",./refs/download/2/Squeezenext: Hardware-aware neural network design.pdf,Squeezenext: Hardware-aware neural network design
0,,,,,,,," C. Farabet, C. Poulet, J. Y. Han, and ",./refs/download/2/Squeezenext: Hardware-aware neural network design.pdf,Squeezenext: Hardware-aware neural network design
0,,,,,,,," A. Gholami, A. Azad, P. Jin, K. Keutzer, and ",./refs/download/2/Squeezenext: Hardware-aware neural network design.pdf,Squeezenext: Hardware-aware neural network design
0,,,,,,,," V. Gokhale, J. Jin, A. Dundar, B. Martini, and ",./refs/download/2/Squeezenext: Hardware-aware neural network design.pdf,Squeezenext: Hardware-aware neural network design
0,,,,,,,," S. Han, H. Mao, and ",./refs/download/2/Squeezenext: Hardware-aware neural network design.pdf,Squeezenext: Hardware-aware neural network design
0,,,,,,,," S. Han, J. Pool, J. Tran, and ",./refs/download/2/Squeezenext: Hardware-aware neural network design.pdf,Squeezenext: Hardware-aware neural network design
0,,,,,,,," K. He, X. Zhang, S. Ren, and ",./refs/download/2/Squeezenext: Hardware-aware neural network design.pdf,Squeezenext: Hardware-aware neural network design
0,,,,,,,, M. G. Hluchyj and ,./refs/download/2/Squeezenext: Hardware-aware neural network design.pdf,Squeezenext: Hardware-aware neural network design
0,,,,,,,," A. G. Howard, M. Zhu, B. Chen, D. Kalenichenko, W. Wang, T. Weyand, M. Andreetto, and ",./refs/download/2/Squeezenext: Hardware-aware neural network design.pdf,Squeezenext: Hardware-aware neural network design
0,,,,,,,," G. Huang, S. Liu, L. van der Maaten, and ",./refs/download/2/Squeezenext: Hardware-aware neural network design.pdf,Squeezenext: Hardware-aware neural network design
0,,,,,,,," G. Huang, Z. Liu, K. Q. Weinberger, and ",./refs/download/2/Squeezenext: Hardware-aware neural network design.pdf,Squeezenext: Hardware-aware neural network design
0,,,,,,,," I. Hubara, M. Courbariaux, D. Soudry, R. El-Yaniv, and ",./refs/download/2/Squeezenext: Hardware-aware neural network design.pdf,Squeezenext: Hardware-aware neural network design
0,,,,,,,," F. N. Iandola, S. Han, M. W. Moskewicz, K. Ashraf, W. J. Dally, and ",./refs/download/2/Squeezenext: Hardware-aware neural network design.pdf,Squeezenext: Hardware-aware neural network design
0,,,,,,,, S. Ioffe and ,./refs/download/2/Squeezenext: Hardware-aware neural network design.pdf,Squeezenext: Hardware-aware neural network design
0,,,,,,,," M. Jaderberg, A. Vedaldi, and ",./refs/download/2/Squeezenext: Hardware-aware neural network design.pdf,Squeezenext: Hardware-aware neural network design
0,,,,,,,," A. Krizhevsky, I. Sutskever, and ",./refs/download/2/Squeezenext: Hardware-aware neural network design.pdf,Squeezenext: Hardware-aware neural network design
0,,,,,,,," E. Park, J. Ahn, and ",./refs/download/2/Squeezenext: Hardware-aware neural network design.pdf,Squeezenext: Hardware-aware neural network design
0,,,,,,,," M. Rastegari, V. Ordonez, J. Redmon, and ",./refs/download/2/Squeezenext: Hardware-aware neural network design.pdf,Squeezenext: Hardware-aware neural network design
0,,,,,,,, K. Simonyan and ,./refs/download/2/Squeezenext: Hardware-aware neural network design.pdf,Squeezenext: Hardware-aware neural network design
0,,,,,,,," S. Williams, A. Waterman, and ",./refs/download/2/Squeezenext: Hardware-aware neural network design.pdf,Squeezenext: Hardware-aware neural network design
0,,,,,,,," B. Wu, F. Iandola, P. H. Jin, and ",./refs/download/2/Squeezenext: Hardware-aware neural network design.pdf,Squeezenext: Hardware-aware neural network design
0,,,,,,,," B. Wu, A. Wan, X. Yue, and ",./refs/download/2/Squeezenext: Hardware-aware neural network design.pdf,Squeezenext: Hardware-aware neural network design
0,,,,,,,," F. Yu, D. Wang, and ",./refs/download/2/Squeezenext: Hardware-aware neural network design.pdf,Squeezenext: Hardware-aware neural network design
0,,,,,,,," C. Zhu, S. Han, H. Mao, and ",./refs/download/2/Squeezenext: Hardware-aware neural network design.pdf,Squeezenext: Hardware-aware neural network design
0,"Anali Alfaro, Domingo Mery, Alvaro Soto",Action recognition in video using sparse coding and relative features,CVPR,,,2016,,"Anali Alfaro, Domingo Mery, and Alvaro Soto. Action recognition in video using sparse coding and relative features. In CVPR, 2016.",./refs/download/2/Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions.pdf,Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions
0,"Federica Bogo, Javier Romero, Matthew Loper, Michael J. Black",FAUST: Dataset and evaluation for 3D mesh registration,CVPR,,,2014,,"Federica Bogo, Javier Romero, Matthew Loper, and Michael J. Black. FAUST: Dataset and evaluation for 3D mesh registration. In CVPR, 2014.",./refs/download/2/Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions.pdf,Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions
0,"Hilton Bristow, Anders Eriksson, Simon Lucey",Fast convolutional sparse coding,CVPR,,,2013,,"Hilton Bristow, Anders Eriksson, and Simon Lucey. Fast convolutional sparse coding. In CVPR, 2013.",./refs/download/2/Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions.pdf,Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions
0,"Joan Bruna, Wojciech Zaremba, Arthur Szlam, Yann Lecun",Spectral networks and locally connected networks on graphs,ICLR,,,2014,,"Joan Bruna, Wojciech Zaremba, Arthur Szlam, and Yann Lecun. Spectral networks and locally connected networks on graphs. In ICLR, 2014.",./refs/download/2/Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions.pdf,Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions
0,,,,,,,,"Angel X. Chang, Thomas A. Funkhouser, Leonidas J. Guibas, Pat Hanrahan, Qi-Xing Huang, Zimo Li, Silvio Savarese, Manolis Savva, Shuran Song, Hao Su, Jianxiong Xiao, Li Yi, and Fisher Yu. Shapenet: An information-rich 3d model repository. CoRR, abs/1512.03012, 2015.",./refs/download/2/Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions.pdf,Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions
0,"Scott Shaobing Chen, David L Donoho, Michael A Saunders",Atomic decomposition by basis pursuit,SIAM review,,,2001,,"Scott Shaobing Chen, David L Donoho, and Michael A Saunders. Atomic decomposition by basis pursuit. SIAM review, 2001.",./refs/download/2/Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions.pdf,Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions
0,"Scott Deerwester, Susan T Dumais, George W Furnas, Thomas K Landauer, Richard Harshman",Indexing by latent semantic analysis,Journal of the American society for information science,,,1990,,"Scott Deerwester, Susan T Dumais, George W Furnas, Thomas K Landauer, and Richard Harshman. Indexing by latent semantic analysis. Journal of the American society for information science, 1990.",./refs/download/2/Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions.pdf,Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions
0,"Davide Eynard, Emanuele Rodola, Klaus Glashoff, Michael M Bronstein",Coupled functional maps,3DV,", ",,2016,399–407,"Davide Eynard, Emanuele Rodola, Klaus Glashoff, and Michael M Bronstein. Coupled functional maps. In 3DV, pages 399–407, 2016.",./refs/download/2/Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions.pdf,Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions
0,,,,,,,,"Thomas Hofmann. Probabilistic latent semantic analysis. In Proceedings of the Fifteenth conference on Uncertainty in artificial intelligence, 1999.",./refs/download/2/Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions.pdf,Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions
0,,,,,,,,"Jan Hosang, Rodrigo Benenson, Piotr Dollar, and Bernt Schiele. What makes for effective detection proposals? IEEE TPAMI, 2016.",./refs/download/2/Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions.pdf,Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions
0,"Qi-Xing Huang, Hao Su, Leonidas Guibas",Fine-grained semi-supervised labeling of large shape collections,SIGGRAPH Asia,,,2013,,"Qi-Xing Huang, Hao Su, and Leonidas Guibas. Fine-grained semi-supervised labeling of large shape collections. In SIGGRAPH Asia, 2013.",./refs/download/2/Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions.pdf,Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions
0,"Qiangui Huang, Weiyue Wang, Ulrich Neumann",Recurrent slice networks for 3d segmentation on point clouds,CVPR,,,2018,,"Qiangui Huang, Weiyue Wang, and Ulrich Neumann. Recurrent slice networks for 3d segmentation on point clouds. In CVPR, 2018.",./refs/download/2/Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions.pdf,Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions
0,"Qixing Huang, Vladlen Koltun, Leonidas Guibas",Joint shape segmentation with linear programming,SIGGRAPH Asia,,,2011,,"Qixing Huang, Vladlen Koltun, and Leonidas Guibas. Joint shape segmentation with linear programming. In SIGGRAPH Asia, 2011.",./refs/download/2/Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions.pdf,Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions
0,"Qixing Huang, Fan Wang, Leonidas Guibas",Functional map networks for analyzing and exploring large shape collections,SIGGRAPH,,,2014,,"Qixing Huang, Fan Wang, and Leonidas Guibas. Functional map networks for analyzing and exploring large shape collections. In SIGGRAPH, 2014.",./refs/download/2/Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions.pdf,Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions
0,"Evangelos Kalogerakis, Melinos Averkiou, Subhransu Maji, Siddhartha Chaudhuri",3D shape segmentation with projective convolutional networks,CVPR,,,2017,,"Evangelos Kalogerakis, Melinos Averkiou, Subhransu Maji, and Siddhartha Chaudhuri. 3D shape segmentation with projective convolutional networks. In CVPR, 2017.",./refs/download/2/Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions.pdf,Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions
0,"Roman Klokov , Victor S. Lempitsky",Escape from cells: Deep kd-networks for the recognition of 3d point cloud models,ICCV,,,2017,,"Roman Klokov and Victor S. Lempitsky. Escape from cells: Deep kd-networks for the recognition of 3d point cloud models. In ICCV, 2017.",./refs/download/2/Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions.pdf,Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions
0,"Artiom Kovnatsky, Michael M Bronstein, Xavier Bresson, Pierre Vandergheynst",Functional correspondence by matrix completion,CVPR,,,2015,,"Artiom Kovnatsky, Michael M Bronstein, Xavier Bresson, and Pierre Vandergheynst. Functional correspondence by matrix completion. In CVPR, 2015.",./refs/download/2/Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions.pdf,Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions
0,"Honglak Lee, Alexis Battle, Rajat Raina, Andrew Y Ng",Efficient sparse coding algorithms,NIPS,,,2007,,"Honglak Lee, Alexis Battle, Rajat Raina, and Andrew Y Ng. Efficient sparse coding algorithms. In NIPS, 2007.",./refs/download/2/Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions.pdf,Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions
0,"Michael S Lewicki , Terrence J Sejnowski",Learning overcomplete representations,Neural computation,,,2000,,"Michael S Lewicki and Terrence J Sejnowski. Learning overcomplete representations. Neural computation, 2000.",./refs/download/2/Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions.pdf,Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions
0,"Or Litany, Tal Remez, Emanuele Rodola, Alex Bronstein, Michael Bronstein",Deep functional maps: Structured prediction for dense shape correspondence,CVPR,,,2017,,"Or Litany, Tal Remez, Emanuele Rodola, Alex Bronstein, and Michael Bronstein. Deep functional maps: Structured prediction for dense shape correspondence. In CVPR, 2017.",./refs/download/2/Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions.pdf,Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions
0,"Dorian Nogneng , Maks Ovsjanikov",Informative descriptor preservation via commutativity for shape matching,Eurographics,,,2017,,"Dorian Nogneng and Maks Ovsjanikov. Informative descriptor preservation via commutativity for shape matching. In Eurographics, 2017.",./refs/download/2/Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions.pdf,Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions
0,,,,,,,,"Bruno A Olshausen. Sparse coding of time-varying natural images. Journal of Vision, 2002.",./refs/download/2/Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions.pdf,Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions
0,"Bruno A Olshausen , David J Field",Emergence of simple-cell receptive field properties by learning a sparse code for natural images,Nature,,,1996,,"Bruno A Olshausen and David J Field. Emergence of simple-cell receptive field properties by learning a sparse code for natural images. Nature, 1996.",./refs/download/2/Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions.pdf,Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions
0,,,,,,,,"Bruno A Olshausen and David J Field. Sparse coding with an overcomplete basis set: A strategy employed by v1? Vision research, 1997.",./refs/download/2/Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions.pdf,Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions
0,"Bruno A Olshausen , David J Field",Sparse coding of sensory inputs,Current opinion in neurobiology,,,2004,,"Bruno A Olshausen and David J Field. Sparse coding of sensory inputs. Current opinion in neurobiology, 2004.",./refs/download/2/Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions.pdf,Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions
0,"Maks Ovsjanikov, Mirela Ben-Chen, Justin Solomon, Adrian Butscher, Leonidas Guibas",Functional maps: a flexible representation of maps between shapes,SIGGRAPH,,,2012,,"Maks Ovsjanikov, Mirela Ben-Chen, Justin Solomon, Adrian Butscher, and Leonidas Guibas. Functional maps: a flexible representation of maps between shapes. In SIGGRAPH, 2012.",./refs/download/2/Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions.pdf,Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions
0,"Jonathan Pokrass, Alexander M Bronstein, Michael M Bronstein, Pablo Sprechmann, Guillermo Sapiro",Sparse modeling of intrinsic correspondences,Eurographics,,,2013,,"Jonathan Pokrass, Alexander M Bronstein, Michael M Bronstein, Pablo Sprechmann, and Guillermo Sapiro. Sparse modeling of intrinsic correspondences. In Eurographics, 2013.",./refs/download/2/Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions.pdf,Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions
0,"Charles R Qi, Wei Liu, Chenxia Wu, Hao Su, Leonidas J Guibas",Frustum pointnets for 3d object detection from rgb-d data,CVPR,,,2018,,"Charles R Qi, Wei Liu, Chenxia Wu, Hao Su, and Leonidas J Guibas. Frustum pointnets for 3d object detection from rgb-d data. In CVPR, 2018.",./refs/download/2/Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions.pdf,Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions
0,"Charles Ruizhongtai Qi, Hao Su, Kaichun Mo, Leonidas J. Guibas",Pointnet: Deep learning on point sets for 3d classification and segmentation,CVPR,,,2017,,"Charles Ruizhongtai Qi, Hao Su, Kaichun Mo, and Leonidas J. Guibas. Pointnet: Deep learning on point sets for 3d classification and segmentation. In CVPR, 2017.",./refs/download/2/Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions.pdf,Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions
0,"Charles Ruizhongtai Qi, Li Yi, Hao Su, Leonidas J. Guibas",Pointnet++: Deep hierarchical feature learning on point sets in a metric space,NIPS,,,2017,,"Charles Ruizhongtai Qi, Li Yi, Hao Su, and Leonidas J. Guibas. Pointnet++: Deep hierarchical feature learning on point sets in a metric space. In NIPS, 2017.",./refs/download/2/Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions.pdf,Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions
0,"Emanuele Rodolà, Luca Cosmo, Michael M Bronstein, Andrea Torsello, Daniel Cremers",Partial functional correspondence,SGP,,,2016,,"Emanuele Rodolà, Luca Cosmo, Michael M Bronstein, Andrea Torsello, and Daniel Cremers. Partial functional correspondence. In SGP, 2016.",./refs/download/2/Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions.pdf,Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions
0,"Jian Sun, Maks Ovsjanikov, Leonidas Guibas",A concise and provably informative multiscale signature based on heat diffusion,SGP,,,2009,,"Jian Sun, Maks Ovsjanikov, and Leonidas Guibas. A concise and provably informative multiscale signature based on heat diffusion. In SGP, 2009.",./refs/download/2/Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions.pdf,Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions
0,"Fan Wang, Qixing Huang, Leonidas J. Guibas",Image co-segmentation via consistent functional maps,ICCV,,,2013,,"Fan Wang, Qixing Huang, and Leonidas J. Guibas. Image co-segmentation via consistent functional maps. In ICCV, 2013.",./refs/download/2/Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions.pdf,Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions
0,"Weiyue Wang, Ronald Yu, Qiangui Huang, Ulrich Neumann",Sgpn: Similarity group proposal network for 3d point cloud instance segmentation,CVPR,,,2018,,"Weiyue Wang, Ronald Yu, Qiangui Huang, and Ulrich Neumann. Sgpn: Similarity group proposal network for 3d point cloud instance segmentation. In CVPR, 2018.",./refs/download/2/Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions.pdf,Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions
0,"Yue Wang, Yongbin Sun, Ziwei Liu, Sanjay E. Sarma, Michael M. Bronstein, Justin M. Solomon",Dynamic graph cnn for learning on point clouds,arXiv,,,2018,,"Yue Wang, Yongbin Sun, Ziwei Liu, Sanjay E. Sarma, Michael M. Bronstein, and Justin M. Solomon. Dynamic graph cnn for learning on point clouds. arXiv, 2018.",./refs/download/2/Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions.pdf,Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions
0,"Li Yi, Vladimir G. Kim, Duygu Ceylan, I-Chao Shen, Mengyan Yan, Hao Su, Cewu Lu, Qixing Huang, Alla Sheffer, Leonidas Guibas",A scalable active framework for region annotation in 3d shape collections,SIGGRAPH Asia,,,2016,,"Li Yi, Vladimir G. Kim, Duygu Ceylan, I-Chao Shen, Mengyan Yan, Hao Su, Cewu Lu, Qixing Huang, Alla Sheffer, and Leonidas Guibas. A scalable active framework for region annotation in 3d shape collections. In SIGGRAPH Asia, 2016.",./refs/download/2/Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions.pdf,Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions
0,"Li Yi, Hao Su, Xingwen Guo, Leonidas J Guibas",Syncspeccnn: Synchronized spectral cnn for 3d shape segmentation,CVPR,,,2017,,"Li Yi, Hao Su, Xingwen Guo, and Leonidas J Guibas. Syncspeccnn: Synchronized spectral cnn for 3d shape segmentation. In CVPR, 2017.",./refs/download/2/Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions.pdf,Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions
0,"Matthew D Zeiler, Dilip Krishnan, Graham W Taylor, Rob Fergus",Deconvolutional networks,CVPR,,,2010,,"Matthew D Zeiler, Dilip Krishnan, Graham W Taylor, and Rob Fergus. Deconvolutional networks. In CVPR, 2010.",./refs/download/2/Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions.pdf,Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions
0,"Berg, T., Liu, J., Lee, S., Alexander, M. L., Jacobs, D. W., Belhumeur, P. N.",Birdsnap: Large-scale fine-grained visual categorization of birds,CVPR,,,2014,pp. 2011–2018,"References Berg, T., Liu, J., Woo Lee, S., Alexander, M. L., Jacobs, D. W., and Belhumeur, P. N. Birdsnap: Large-scale fine-grained visual categorization of birds. CVPR, pp. 2011–2018, 2014.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"Bossard, L., Guillaumin, M., Van Gool, L.",Food-101– mining discriminative components with random forests,ECCV,,,2014,pp. 446–461,"Bossard, L., Guillaumin, M., and Van Gool, L. Food-101– mining discriminative components with random forests. ECCV, pp. 446–461, 2014.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"Cai, H., Zhu, L., Han, S.",Proxylessnas: Direct neural architecture search on target task and hardware,ICLR,,,2019,,"Cai, H., Zhu, L., and Han, S. Proxylessnas: Direct neural architecture search on target task and hardware. ICLR, 2019.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"Chollet, F.",Xception: Deep learning with depthwise separable convolutions,CVPR,,,2017,pp. 1610–02357,"Chollet, F. Xception: Deep learning with depthwise separable convolutions. CVPR, pp. 1610–02357, 2017.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"Cubuk, E. D., Zoph, B., Mane, D., Vasudevan, V., Le, Q. V.",Autoaugment: Learning augmentation policies from data,CVPR,,,2019,,"Cubuk, E. D., Zoph, B., Mane, D., Vasudevan, V., and Le, Q. V. Autoaugment: Learning augmentation policies from data. CVPR, 2019.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"Elfwing, S., Uchibe, E., Doya, K.",Sigmoid-weighted linear units for neural network function approximation in reinforcement learning,Neural Networks,,,2018,107:3–11,"Elfwing, S., Uchibe, E., and Doya, K. Sigmoid-weighted linear units for neural network function approximation in reinforcement learning. Neural Networks, 107:3–11, 2018.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"Gholami, A., Kwon, K., Wu, B., Tai, Z., Yue, X., Jin, P., Zhao, S., Keutzer, K.",Squeezenext: Hardware-aware neural network design,ECV Workshop at CVPR’18,,,2018,,"Gholami, A., Kwon, K., Wu, B., Tai, Z., Yue, X., Jin, P., Zhao, S., and Keutzer, K. Squeezenext: Hardware-aware neural network design. ECV Workshop at CVPR’18, 2018.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"Han, S., Mao, H., Dally, W. J.","Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding",ICLR,,,2016,,"Han, S., Mao, H., and Dally, W. J. Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding. ICLR, 2016.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"He, K., Zhang, X., Ren, S., Sun, J.",Deep residual learning for image recognition,CVPR,,,2016,pp. 770–778,"He, K., Zhang, X., Ren, S., and Sun, J. Deep residual learning for image recognition. CVPR, pp. 770–778, 2016.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"He, K., Gkioxari, G., Dollár, P., Girshick, R.",Mask r-cnn,ICCV,,,2017,pp. 2980–2988,"He, K., Gkioxari, G., Dollár, P., and Girshick, R. Mask r-cnn. ICCV, pp. 2980–2988, 2017.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"He, Y., Lin, J., Liu, Z., Wang, H., Li, L.-J., Han, S.",Amc: Automl for model compression and acceleration on mobile devices,ECCV,,,2018,,"He, Y., Lin, J., Liu, Z., Wang, H., Li, L.-J., and Han, S. Amc: Automl for model compression and acceleration on mobile devices. ECCV, 2018.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"Hendrycks, D., Gimpel, K.",Gaussian error linear units (gelus),arXiv preprint arXiv:1606.08415,,,2016,,"Hendrycks, D. and Gimpel, K. Gaussian error linear units (gelus). arXiv preprint arXiv:1606.08415, 2016.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"Howard, A. G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M., Adam, H.",Mobilenets: Efficient convolutional neural networks for mobile vision applications,arXiv preprint arXiv:1704.04861,,,2017,,"Howard, A. G., Zhu, M., Chen, B., Kalenichenko, D., Wang, W., Weyand, T., Andreetto, M., and Adam, H. Mobilenets: Efficient convolutional neural networks for mobile vision applications. arXiv preprint arXiv:1704.04861, 2017.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"Hu, J., Shen, L., Sun, G.",Squeeze-and-excitation networks,CVPR,,,2018,,"Hu, J., Shen, L., and Sun, G. Squeeze-and-excitation networks. CVPR, 2018.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"Huang, G., Sun, Y., Liu, Z., Sedra, D., Weinberger, K. Q.",Deep networks with stochastic depth,ECCV,,,2016,pp. 646–661,"Huang, G., Sun, Y., Liu, Z., Sedra, D., and Weinberger, K. Q. Deep networks with stochastic depth. ECCV, pp. 646–661, 2016.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"Huang, G., Liu, Z., Maaten, L., Weinberger, K. Q.",Densely connected convolutional networks,CVPR,,,2017,,"Huang, G., Liu, Z., Van Der Maaten, L., and Weinberger, K. Q. Densely connected convolutional networks. CVPR, 2017.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"Huang, Y., Cheng, Y., Chen, D., Lee, H., Ngiam, J., Le, Q. V., Chen, Z.",Gpipe: Efficient training of giant neural networks using pipeline parallelism,arXiv preprint arXiv:1808.07233,,,2018,,"Huang, Y., Cheng, Y., Chen, D., Lee, H., Ngiam, J., Le, Q. V., and Chen, Z. Gpipe: Efficient training of giant neural networks using pipeline parallelism. arXiv preprint arXiv:1808.07233, 2018.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"Iandola, F. N., Han, S., Moskewicz, M. W., Ashraf, K., Dally, W. J.",", and Keutzer, K",Squeezenet: Alexnet-level accuracy with 50x fewer parameters and <0.5 mb model size. arXiv preprint arXiv:1602.07360,,,2016,,"Iandola, F. N., Han, S., Moskewicz, M. W., Ashraf, K., Dally, W. J., and Keutzer, K. Squeezenet: Alexnet-level accuracy with 50x fewer parameters and <0.5 mb model size. arXiv preprint arXiv:1602.07360, 2016.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"Ioffe, S., Szegedy, C.",Batch normalization: Accelerating deep network training by reducing internal covariate shift,ICML,,,2015,pp. 448–456,"Convolutional Neural Networks Ioffe, S. and Szegedy, C. Batch normalization: Accelerating deep network training by reducing internal covariate shift. ICML, pp. 448–456, 2015.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"Raghu, M., Poole, B., Kleinberg, J., Ganguli, S., SohlDickstein, J.",On the expressive power of deep neural networks,ICML,,,2017,,"Raghu, M., Poole, B., Kleinberg, J., Ganguli, S., and SohlDickstein, J. On the expressive power of deep neural networks. ICML, 2017.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"Kornblith, S., Shlens, J., Le, Q.",V,Do better imagenet models transfer better? CVPR,,,2019,,"Kornblith, S., Shlens, J., and Le, Q. V. Do better imagenet models transfer better? CVPR, 2019.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"Ramachandran, P., Zoph, B., Le, Q. V.",Searching for activation functions,arXiv preprint arXiv:1710.05941,,,2018,,"Ramachandran, P., Zoph, B., and Le, Q. V. Searching for activation functions. arXiv preprint arXiv:1710.05941, 2018.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"Krause, J., Deng, J., Stark, M., Fei-Fei, L.",Collecting a large-scale dataset of fine-grained cars,Second Workshop on Fine-Grained Visual Categorizatio,,,2013,,"Krause, J., Deng, J., Stark, M., and Fei-Fei, L. Collecting a large-scale dataset of fine-grained cars. Second Workshop on Fine-Grained Visual Categorizatio, 2013.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"Krizhevsky, A., Hinton, G.",Learning multiple layers of features from tiny images,Technical Report,,,2009,,"Krizhevsky, A. and Hinton, G. Learning multiple layers of features from tiny images. Technical Report, 2009.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"Real, E., Aggarwal, A., Huang, Y., Le, Q. V.",Regularized evolution for image classifier architecture search,AAAI,,,2019,,"Real, E., Aggarwal, A., Huang, Y., and Le, Q. V. Regularized evolution for image classifier architecture search. AAAI, 2019.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"Krizhevsky, A., Sutskever, I., Hinton, G. E.",Imagenet classification with deep convolutional neural networks,In NIPS,,,2012,pp. 1097–1105,"Krizhevsky, A., Sutskever, I., and Hinton, G. E. Imagenet classification with deep convolutional neural networks. In NIPS, pp. 1097–1105, 2012.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Karpathy, A., Khosla, A., Bernstein, M.",", et al",Imagenet large scale visual recognition challenge. International Journal of Computer Vision,,,2015,115(3): 211–252,"Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Karpathy, A., Khosla, A., Bernstein, M., et al. Imagenet large scale visual recognition challenge. International Journal of Computer Vision, 115(3): 211–252, 2015.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"Lin, H., Jegelka, S.",Resnet with one-neuron hidden layers is a universal approximator,NeurIPS,,,2018,pp. 6172– 6181,"Lin, H. and Jegelka, S. Resnet with one-neuron hidden layers is a universal approximator. NeurIPS, pp. 6172– 6181, 2018.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., Chen, L.-C.",Mobilenetv2: Inverted residuals and linear bottlenecks,CVPR,,,2018,,"Sandler, M., Howard, A., Zhu, M., Zhmoginov, A., and Chen, L.-C. Mobilenetv2: Inverted residuals and linear bottlenecks. CVPR, 2018.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"Lin, T.-Y., Dollár, P., Girshick, R., He, K., Hariharan, B., Belongie, S.",Feature pyramid networks for object detection,CVPR,,,2017,,"Lin, T.-Y., Dollár, P., Girshick, R., He, K., Hariharan, B., and Belongie, S. Feature pyramid networks for object detection. CVPR, 2017.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"Sharir, O., Shashua, A.",On the expressive power of overlapping architectures of deep learning,ICLR,,,2018,,"Sharir, O. and Shashua, A. On the expressive power of overlapping architectures of deep learning. ICLR, 2018.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"Liu, C., Zoph, B., Shlens, J., Hua, W., Li, L.-J., Fei-Fei, L., Yuille, A., Huang, J., Murphy, K.",Progressive neural architecture search,ECCV,,,2018,,"Liu, C., Zoph, B., Shlens, J., Hua, W., Li, L.-J., Fei-Fei, L., Yuille, A., Huang, J., and Murphy, K. Progressive neural architecture search. ECCV, 2018.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., Salakhutdinov, R.",Dropout: a simple way to prevent neural networks from overfitting,The Journal of Machine Learning Research,,,2014,15(1):1929–1958,"Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., and Salakhutdinov, R. Dropout: a simple way to prevent neural networks from overfitting. The Journal of Machine Learning Research, 15(1):1929–1958, 2014.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"Lu, Z., Pu, H., Wang, F., Hu, Z., Wang, L.",The expressive power of neural networks: A view from the width,NeurIPS,,,2018,,"Lu, Z., Pu, H., Wang, F., Hu, Z., and Wang, L. The expressive power of neural networks: A view from the width. NeurIPS, 2018.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"Ma, N., Zhang, X., Zheng, H.-T., Sun, J.",Shufflenet v2: Practical guidelines for efficient cnn architecture design,ECCV,,,2018,,"Ma, N., Zhang, X., Zheng, H.-T., and Sun, J. Shufflenet v2: Practical guidelines for efficient cnn architecture design. ECCV, 2018.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"Mahajan, D., Girshick, R., Ramanathan, V., He, K., Paluri, M., Li, Y., Bharambe, A., van der Maaten, L.",Exploring the limits of weakly supervised pretraining,arXiv preprint arXiv:1805.00932,,,2018,,"Mahajan, D., Girshick, R., Ramanathan, V., He, K., Paluri, M., Li, Y., Bharambe, A., and van der Maaten, L. Exploring the limits of weakly supervised pretraining. arXiv preprint arXiv:1805.00932, 2018.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Vanhoucke, V., Rabinovich, A.",Going deeper with convolutions,CVPR,,,2015,pp. 1–9,"Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Vanhoucke, V., and Rabinovich, A. Going deeper with convolutions. CVPR, pp. 1–9, 2015.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z.",Rethinking the inception architecture for computer vision,CVPR,,,2016,pp. 2818–2826,"Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., and Wojna, Z. Rethinking the inception architecture for computer vision. CVPR, pp. 2818–2826, 2016.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A. A.","Inception-v4, inception-resnet and the impact of residual connections on learning",AAAI,,,2017,4:12,"Szegedy, C., Ioffe, S., Vanhoucke, V., and Alemi, A. A. Inception-v4, inception-resnet and the impact of residual connections on learning. AAAI, 4:12, 2017.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"Maji, S., Rahtu, E., Kannala, J., Blaschko, M., Vedaldi, A.",Fine-grained visual classification of aircraft,arXiv preprint arXiv:1306.5151,,,2013,,"Maji, S., Rahtu, E., Kannala, J., Blaschko, M., and Vedaldi, A. Fine-grained visual classification of aircraft. arXiv preprint arXiv:1306.5151, 2013.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"Tan, M., Chen, B., Pang, R., Vasudevan, V., Sandler, M., Howard, A., Le, Q. V.",MnasNet: Platform-aware neural architecture search for mobile,CVPR,,,2019,,"Tan, M., Chen, B., Pang, R., Vasudevan, V., Sandler, M., Howard, A., and Le, Q. V. MnasNet: Platform-aware neural architecture search for mobile. CVPR, 2019.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"Ngiam, J., Peng, D., Vasudevan, V., Kornblith, S., Le, Q. V., Pang, R.",Domain adaptive transfer learning with specialist models,arXiv preprint arXiv:1811.07056,,,2018,,"Ngiam, J., Peng, D., Vasudevan, V., Kornblith, S., Le, Q. V., and Pang, R. Domain adaptive transfer learning with specialist models. arXiv preprint arXiv:1811.07056, 2018.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"Xie, S., Girshick, R., Dollár, P., Tu, Z., He, K.",Aggregated residual transformations for deep neural networks,CVPR,,,2017,pp. 5987–5995,"Xie, S., Girshick, R., Dollár, P., Tu, Z., and He, K. Aggregated residual transformations for deep neural networks. CVPR, pp. 5987–5995, 2017.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"Nilsback, M.-E., Zisserman, A.",Automated flower classification over a large number of classes,ICVGIP,,,2008,pp. 722–729,"Nilsback, M.-E. and Zisserman, A. Automated flower classification over a large number of classes. ICVGIP, pp. 722–729, 2008.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"Yang, T.-J., Howard, A., Chen, B., Zhang, X., Go, A., Sze, V., Adam, H.",Netadapt: Platform-aware neural network adaptation for mobile applications,ECCV,,,2018,,"Yang, T.-J., Howard, A., Chen, B., Zhang, X., Go, A., Sze, V., and Adam, H. Netadapt: Platform-aware neural network adaptation for mobile applications. ECCV, 2018.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"Parkhi, O. M., Vedaldi, A., Zisserman, A., Jawahar, C.",Cats and dogs,CVPR,,,2012,pp. 3498–3505,"Parkhi, O. M., Vedaldi, A., Zisserman, A., and Jawahar, C. Cats and dogs. CVPR, pp. 3498–3505, 2012.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"Zagoruyko, S., Komodakis, N.",Wide residual networks,BMVC,,,2016,,"Zagoruyko, S. and Komodakis, N. Wide residual networks. BMVC, 2016.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"Zhang, X., Li, Z., Loy, C. C., Lin, D.",Polynet: A pursuit of structural diversity in very deep networks,CVPR,,,2017,pp. 3900–3908,"Convolutional Neural Networks Zhang, X., Li, Z., Loy, C. C., and Lin, D. Polynet: A pursuit of structural diversity in very deep networks. CVPR, pp. 3900–3908, 2017.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"Zhang, X., Zhou, X., Lin, M., Sun, J.",Shufflenet: An extremely efficient convolutional neural network for mobile devices,CVPR,,,2018,,"Zhang, X., Zhou, X., Lin, M., and Sun, J. Shufflenet: An extremely efficient convolutional neural network for mobile devices. CVPR, 2018.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"Zhou, B., Khosla, A., Lapedriza, A., Oliva, A., Torralba, A.",Learning deep features for discriminative localization,CVPR,,,2016,pp. 2921–2929,"Zhou, B., Khosla, A., Lapedriza, A., Oliva, A., and Torralba, A. Learning deep features for discriminative localization. CVPR, pp. 2921–2929, 2016.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"Zoph, B., Le, Q. V.",Neural architecture search with reinforcement learning,ICLR,,,2017,,"Zoph, B. and Le, Q. V. Neural architecture search with reinforcement learning. ICLR, 2017.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"Zoph, B., Vasudevan, V., Shlens, J., Le, Q. V.",Learning transferable architectures for scalable image recognition,CVPR,,,2018,,"Zoph, B., Vasudevan, V., Shlens, J., and Le, Q. V. Learning transferable architectures for scalable image recognition. CVPR, 2018.",./refs/download/2/Efficientnet: Rethinking model scaling for convolutional neural networks.pdf,Efficientnet: Rethinking model scaling for convolutional neural networks
0,"S. Bell and , K. Bala",Learning visual similarity for product design with convolutional neural networks, In SIGGRAPH,,,2015,,"S. Bell and K. Bala. Learning visual similarity for product design with convolutional neural networks. In SIGGRAPH, 2015.",./refs/download/2/Deep metric learning via lifted structured feature embedding.pdf,Deep metric learning via lifted structured feature embedding
0,"Y. Bengio, J. Paiement, P. Vincent",Out-of-sample extensions for lle, isomap,,,2004,,"Y. Bengio, J. Paiement, and P. Vincent. Out-of-sample extensions for lle, isomap, mds, eigenmaps, and spectral clustering. In NIPS, 2004.",./refs/download/2/Deep metric learning via lifted structured feature embedding.pdf,Deep metric learning via lifted structured feature embedding
0,"J. Bromley, I. Guyon, Y. Lecun, E. SŁckinger, R. Shah",Signature verification using a “siamese” time delay neural network, In NIPS,,,1994,,"J. Bromley, I. Guyon, Y. Lecun, E. SŁckinger, and R. Shah. Signature verification using a “siamese” time delay neural network. In NIPS, 1994.",./refs/download/2/Deep metric learning via lifted structured feature embedding.pdf,Deep metric learning via lifted structured feature embedding
0,"G. Chechik, V. Sharma, U. Shalit, S. Bengio",Large scale online learning of image similarity through ranking, JMLR,,,2010,11,"G. Chechik, V. Sharma, U. Shalit, and S. Bengio. Large scale online learning of image similarity through ranking. JMLR, 11, 2010.",./refs/download/2/Deep metric learning via lifted structured feature embedding.pdf,Deep metric learning via lifted structured feature embedding
0,"S. Chopra, R. Hadsell, Y. LeCun",Learning a similarity metric discriminatively, with application to face verification,. In CVPR,,2005,,"S. Chopra, R. Hadsell, and Y. LeCun. Learning a similarity metric discriminatively, with application to face verification. In CVPR, June 2005.",./refs/download/2/Deep metric learning via lifted structured feature embedding.pdf,Deep metric learning via lifted structured feature embedding
0,"A. Choromanska, A. Agarwal, J. Langford",Extreme multi class classification, In NIPS,,,2013,,"A. Choromanska, A. Agarwal, and J. Langford. Extreme multi class classification. In NIPS, 2013.",./refs/download/2/Deep metric learning via lifted structured feature embedding.pdf,Deep metric learning via lifted structured feature embedding
0,"T. Cox and , M. Cox",Multidimensional scaling, In London: Chapman and Hill,,,1994,,"T. Cox and M. Cox. Multidimensional scaling. In London: Chapman and Hill, 1994.",./refs/download/2/Deep metric learning via lifted structured feature embedding.pdf,Deep metric learning via lifted structured feature embedding
0,I. S. Data,https://sites,google,.com/site/ imagesimilaritydata/,,2014,,"I. S. Data. https://sites.google.com/site/ imagesimilaritydata/, 2014.",./refs/download/2/Deep metric learning via lifted structured feature embedding.pdf,Deep metric learning via lifted structured feature embedding
0,"B. J. Frey and , D. Dueck",apclusterk,m,. http:// www.psi.toronto.edu/affinitypropagation/ apclusterK.m,,2007,,"B. J. Frey and D. Dueck. apclusterk.m. http:// www.psi.toronto.edu/affinitypropagation/ apclusterK.m, 2007.",./refs/download/2/Deep metric learning via lifted structured feature embedding.pdf,Deep metric learning via lifted structured feature embedding
0,"B. J. Frey and , D. Dueck",Clustering by passing messages between data points, Science,,,2007,,"B. J. Frey and D. Dueck. Clustering by passing messages between data points. Science, 2007.",./refs/download/2/Deep metric learning via lifted structured feature embedding.pdf,Deep metric learning via lifted structured feature embedding
0,"A. Frome, G. S. Corrado, J. Shlens, S. Bengio, J. Dean, M. Ranzato, T. Mikolov",Devise: A deep visual-semantic embedding model, In NIPS,,,2013,,"A. Frome, G. S. Corrado, J. Shlens, S. Bengio, J. Dean, M. Ranzato, and T. Mikolov. Devise: A deep visual-semantic embedding model. In NIPS, 2013.",./refs/download/2/Deep metric learning via lifted structured feature embedding.pdf,Deep metric learning via lifted structured feature embedding
0,"J. Goldberger, S. Roweis, G. Hinton, R. Salakhutdinov",Neighbourhood component analysis, In NIPS,,,2004,,"J. Goldberger, S. Roweis, G. Hinton, and R. Salakhutdinov. Neighbourhood component analysis. In NIPS, 2004.",./refs/download/2/Deep metric learning via lifted structured feature embedding.pdf,Deep metric learning via lifted structured feature embedding
0,"R. Hadsell, S. Chopra, Y. Lecun",Dimensionality reduction by learning an invariant mapping, In CVPR,,,2006,,"R. Hadsell, S. Chopra, and Y. Lecun. Dimensionality reduction by learning an invariant mapping. In CVPR, 2006.",./refs/download/2/Deep metric learning via lifted structured feature embedding.pdf,Deep metric learning via lifted structured feature embedding
0,"H. Jegou, M. Douze, C. Schmid",Product quantization for nearest neighbor search, In PAMI,,,2011,,"H. Jegou, M. Douze, and C. Schmid. Product quantization for nearest neighbor search. In PAMI, 2011.",./refs/download/2/Deep metric learning via lifted structured feature embedding.pdf,Deep metric learning via lifted structured feature embedding
0,"Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Girshick, S. Guadarrama, T. Darrell",Caffe: Convolutional architecture for fast feature embedding, arXiv preprint arXiv:,,,1408,,"Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Girshick, S. Guadarrama, and T. Darrell. Caffe: Convolutional architecture for fast feature embedding. arXiv preprint arXiv:1408.",./refs/download/2/Deep metric learning via lifted structured feature embedding.pdf,Deep metric learning via lifted structured feature embedding
0,"T. Joachims, T. Finley, C.-N. Yu",Cutting-plane training of structural svms, JMLR,,,2009,,"T. Joachims, T. Finley, and C.-N. Yu. Cutting-plane training of structural svms. JMLR, 2009.",./refs/download/2/Deep metric learning via lifted structured feature embedding.pdf,Deep metric learning via lifted structured feature embedding
0,T. I. Jolliffe,Principal component analysis, In New York: Springer-Verlag,,,1986,,"T. I. Jolliffe. Principal component analysis. In New York: Springer-Verlag, 1986.",./refs/download/2/Deep metric learning via lifted structured feature embedding.pdf,Deep metric learning via lifted structured feature embedding
0,"J. Krause, M. Stark, J. Deng, F.-F. Li",3d object representations for fine-grained categorization, ICCV 3dRR-13,,,2013,,"J. Krause, M. Stark, J. Deng, and F.-F. Li. 3d object representations for fine-grained categorization. ICCV 3dRR-13, 2013.",./refs/download/2/Deep metric learning via lifted structured feature embedding.pdf,Deep metric learning via lifted structured feature embedding
0,"A. Krizhevsky, I. Sutskever, G. Hinton",Imagenet classification with deep convolutional neural networks, In NIPS,,,2012,,"A. Krizhevsky, I. Sutskever, and G. Hinton. Imagenet classification with deep convolutional neural networks. In NIPS, 2012.",./refs/download/2/Deep metric learning via lifted structured feature embedding.pdf,Deep metric learning via lifted structured feature embedding
0,"C. H. Lampert, H. Nickisch, S. Harmeling",Attributebased classification for zero-shot visual object categorization, In TPAMI,,,2014,,"C. H. Lampert, H. Nickisch, and S. Harmeling. Attributebased classification for zero-shot visual object categorization. In TPAMI, 2014.",./refs/download/2/Deep metric learning via lifted structured feature embedding.pdf,Deep metric learning via lifted structured feature embedding
0,"Y. Li, H. Su, C. Qi, N. Fish, D. Cohen-Or, L. Guibas",Joint embeddings of shapes and images via cnn image purification, In SIGGRAPH Asia,,,2015,,"Y. Li, H. Su, C. Qi, N. Fish, D. Cohen-Or, and L. Guibas. Joint embeddings of shapes and images via cnn image purification. In SIGGRAPH Asia, 2015.",./refs/download/2/Deep metric learning via lifted structured feature embedding.pdf,Deep metric learning via lifted structured feature embedding
0,"C. D. Manning, P. Raghavan, H. Schtze",Introduction to Information Retrieval, Cambridge university press,,,2008,,"C. D. Manning, P. Raghavan, and H. Schtze. Introduction to Information Retrieval. Cambridge university press, 2008.",./refs/download/2/Deep metric learning via lifted structured feature embedding.pdf,Deep metric learning via lifted structured feature embedding
0,"T. Mensink, J. Verbeek, F. Perronnin, G. Csurk",Metric learning for large scale image classification: Generalizaing to new classes at near-zero cost, In ECCV,,,2012,,"T. Mensink, J. Verbeek, F. Perronnin, and G. Csurk. Metric learning for large scale image classification: Generalizaing to new classes at near-zero cost. In ECCV, 2012.",./refs/download/2/Deep metric learning via lifted structured feature embedding.pdf,Deep metric learning via lifted structured feature embedding
0,"M. Palatucci, D. Pomerleau, G. E. Hinton, T. M. Mitchell",Zero-shot learning with semantic output codes, In NIPS,,,2009,,"M. Palatucci, D. Pomerleau, G. E. Hinton, and T. M. Mitchell. Zero-shot learning with semantic output codes. In NIPS, 2009.",./refs/download/2/Deep metric learning via lifted structured feature embedding.pdf,Deep metric learning via lifted structured feature embedding
0,"Y. Prabhu and , M. Varma",Fastxml: A fast, accurate and stable tree-classifier for extreme multi-label learning,. In SIGKDD,,2014,,"Y. Prabhu and M. Varma. Fastxml: A fast, accurate and stable tree-classifier for extreme multi-label learning. In SIGKDD, 2014.",./refs/download/2/Deep metric learning via lifted structured feature embedding.pdf,Deep metric learning via lifted structured feature embedding
0,"Q. Qian, R. Jin, S. Zhu, Y. Lin",Fine-grained visual categorization via multi-stage metric learning, In CVPR,,,2015,,"Q. Qian, R. Jin, S. Zhu, and Y. Lin. Fine-grained visual categorization via multi-stage metric learning. In CVPR, 2015.",./refs/download/2/Deep metric learning via lifted structured feature embedding.pdf,Deep metric learning via lifted structured feature embedding
0,"M. Rohrbach, M. Stark, B. Schiel",Evaluating knowledge transfer and zero-shot learn-ing in a large-scale setting, In CVPR,,,2011,,"M. Rohrbach, M. Stark, and B. Schiel. Evaluating knowledge transfer and zero-shot learn- ing in a large-scale setting. In CVPR, 2011.",./refs/download/2/Deep metric learning via lifted structured feature embedding.pdf,Deep metric learning via lifted structured feature embedding
0,"O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, A. C. Berg, L. Fei-Fei",ImageNet Large Scale Visual Recognition Challenge, IJCV,,,2015,,"O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, A. C. Berg, and L. Fei-Fei. ImageNet Large Scale Visual Recognition Challenge. IJCV, 2015.",./refs/download/2/Deep metric learning via lifted structured feature embedding.pdf,Deep metric learning via lifted structured feature embedding
0,"F. Schroff, D. Kalenichenko, J. Philbin",Facenet: A unified embedding for face recognition and clustering, In CVPR,,,2015,,"F. Schroff, D. Kalenichenko, and J. Philbin. Facenet: A unified embedding for face recognition and clustering. In CVPR, 2015.",./refs/download/2/Deep metric learning via lifted structured feature embedding.pdf,Deep metric learning via lifted structured feature embedding
0,"R. Socher, C. D. M. M. Ganjoo H, O. Bastani, A. Y. Ng",Zero-shot learning through cross-modal transfer, In ICLR,,,2013,,"R. Socher, C. D. M. M. Ganjoo H. Sridhar, O. Bastani, and A. Y. Ng. Zero-shot learning through cross-modal transfer. In ICLR, 2013.",./refs/download/2/Deep metric learning via lifted structured feature embedding.pdf,Deep metric learning via lifted structured feature embedding
0,"C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, A. Rabinovich",Going deeper with convolutions, In CVPR,,,2015,,"C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, and A. Rabinovich. Going deeper with convolutions. In CVPR, 2015.",./refs/download/2/Deep metric learning via lifted structured feature embedding.pdf,Deep metric learning via lifted structured feature embedding
0,"G. Taylor, R. Fergus, G. Williams, I. Spiro, C. Bregler",Pose-sensitive embedding by nonlinear nca regression, In NIPS,,,2010,,"G. Taylor, R. Fergus, G. Williams, I. Spiro, and C. Bregler. Pose-sensitive embedding by nonlinear nca regression. In NIPS, 2010.",./refs/download/2/Deep metric learning via lifted structured feature embedding.pdf,Deep metric learning via lifted structured feature embedding
0,"I. Tsochantaridis, T. Hofmann, T. Joachims, Y. Altun",Support vector machine learning for interdependent and structured output spaces, In ICML,,,2004,,"I. Tsochantaridis, T. Hofmann, T. Joachims, and Y. Altun. Support vector machine learning for interdependent and structured output spaces. In ICML, 2004.",./refs/download/2/Deep metric learning via lifted structured feature embedding.pdf,Deep metric learning via lifted structured feature embedding
0,L. van der maaten,Accelerating t-sne using tree-based algorithms, In JMLR,,,2014,,"L. van der maaten. Accelerating t-sne using tree-based algorithms. In JMLR, 2014.",./refs/download/2/Deep metric learning via lifted structured feature embedding.pdf,Deep metric learning via lifted structured feature embedding
0,"C. Wah, S. Branson, P. Welinder, P. Perona, S. Belongie",The caltech-ucsd birds-200-2011 dataset, Technical Report CNS-TR-2011-001,,,2011,,"C. Wah, S. Branson, P. Welinder, P. Perona, and S. Belongie. The caltech-ucsd birds-200-2011 dataset. Technical Report CNS-TR-2011-001, California Institute of Technology, 2011.",./refs/download/2/Deep metric learning via lifted structured feature embedding.pdf,Deep metric learning via lifted structured feature embedding
0,"J. Wang, Y. Song, T. Leung, C. Rosenberg, J. Wang, J. Philbin, B. Chen, Y. Wu",Learning fine-grained image similarity with deep ranking, In CVPR,,,2014,,"J. Wang, Y. Song, T. Leung, C. Rosenberg, J. Wang, J. Philbin, B. Chen, and Y. Wu. Learning fine-grained image similarity with deep ranking. In CVPR, 2014.",./refs/download/2/Deep metric learning via lifted structured feature embedding.pdf,Deep metric learning via lifted structured feature embedding
0,"K. Q. Weinberger, J. Blitzer, L. K. Saul",Distance metric learning for large margin nearest neighbor classification, In NIPS,,,2006,,"K. Q. Weinberger, J. Blitzer, and L. K. Saul. Distance metric learning for large margin nearest neighbor classification. In NIPS, 2006.",./refs/download/2/Deep metric learning via lifted structured feature embedding.pdf,Deep metric learning via lifted structured feature embedding
0,"J. Weston, S. Bengio, N. Usurer",Wsabi: Scaling up to large vocabulary image annotation, In IJCAI,,,2011,,"J. Weston, S. Bengio, and N. Usurer. Wsabi: Scaling up to large vocabulary image annotation. In IJCAI, 2011.",./refs/download/2/Deep metric learning via lifted structured feature embedding.pdf,Deep metric learning via lifted structured feature embedding
0,,,,,,,," Y. Guo, L. Zhang, Y. Hu, X. He, and ",./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,," X. He, Y. Zhou, Z. Zhou, S. Bai, and ",./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,," A. Hermans, L. Beyer, and ",./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,," G. Huang, Z. Liu, L. van der Maaten, and ",./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,, S. Ioffe and ,./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,," I. Kemelmacher-Shlizerman, S. M. Seitz, D. Miller, and ",./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,, D. P. Kingma and ,./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,," S. Koelstra, C. Mühl, M. Soleymani, J. Lee, A. Yazdani, T. Ebrahimi, T. Pun, A. Nijholt, and ",./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,," A. S. Koepke, O. Wiles, and ",./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,," D. Kollias, P. Tzirakis, M. A. Nicolaou, A. Papaioannou, G. Zhao, B. W. Schuller, I. Kotsia, and ",./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,," J. Kossaifi, G. Tzimiropoulos, S. Todorovic, and ",./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,, S. Li and ,./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,, S. Li and ,./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,," H. Liu, Y. Tian, Y. Wang, L. Pang, and ",./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,," Z. Liu, P. Luo, X. Wang, and ",./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,," P. Lucey, J. F. Cohn, T. Kanade, J. M. Saragih, Z. Ambadar, and ",./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,," B. Martinez, M. F. Valstar, B. Jiang, and ",./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,," S. M. Mavadati, M. H. Mahoor, K. Bartlett, P. Trinh, and ",./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,," C. F. Benitez-Quiroz, R. Srinivasan, and ",./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,," G. Chechik, V. Sharma, U. Shalit, and ",./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,," C. A. Corneanu, M. Madadi, and ",./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,, A. S. Cowen and ,./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,, A. S. Cowen and ,./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,," A. Dhall, R. Goecke, S. Ghosh, J. Joshi, J. Hoey, and ",./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,," A. Dhall, R. Goecke, J. Joshi, M. Wagner, and ",./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,," A. Dhall, O. V. R. Murthy, R. Goecke, J. Joshi, and ",./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,," P. Ekman, W. V. Friesen, and ",./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,," J. Fiss, A. Agarwala, and ",./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,," W. Ge, W. Huang, D. Dong, and ",./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,, X. Glorot and ,./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,," I. J. Goodfellow, D. Erhan, P. L. Carrier, A. C. Courville, M. Mirza, B. Hamner, W. Cukierski, Y. Tang, D. Thaler, D. Lee, Y. Zhou, C. Ramaiah, F. Feng, R. Li, X. Wang, D. Athanasakis, J. Shawe-Taylor, M. Milakov, J. Park, R. T. Ionescu, M. Popescu, C. Grozea, J. Bergstra, J. Xie, L. Romaszko, B. Xu, Z. Chuang, and ",./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,," R. Gross, I. A. Matthews, J. F. Cohn, T. Kanade, and ",./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,," G. Zhao, X. Huang, M. Taini, S. Z. Li, and ",./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,," B. Zhuang, G. Lin, C. Shen, and ",./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,," D. McDuff, R. E. Kaliouby, T. Senechal, M. Amr, J. F. Cohn, and ",./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,," H. Meng, T. Lin, X. Jiang, Y. Lu, and ",./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,," A. Mollahosseini, B. Hassani, and ",./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,," A. Mollahosseini, B. Hassani, M. J. Salvador, H. Abdollahi, D. Chan, and ",./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,, A. Nech and ,./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,," M. Pantic, M. F. Valstar, R. Rademaker, and ",./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,," F. Ringeval, A. Sonderegger, J. S. Sauer, and ",./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,," F. Schroff, D. Kalenichenko, and ",./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,," Z. Shao, Z. Liu, J. Cai, and ",./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,," H. O. Song, Y. Xiang, S. Jegelka, and ",./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,," Y. Taigman, M. Yang, M. Ranzato, and ",./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,," J. Wang, Y. Song, T. Leung, C. Rosenberg, J. Wang, J. Philbin, B. Chen, and ",./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,," J. Wang, F. Zhou, S. Wen, X. Liu, and ",./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,, K. Q. Weinberger and ,./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,," O. Wiles, A. S. Koepke, and ",./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,," Z. Zhang, P. Luo, C. C. Loy, and ",./refs/download/2/A compact embedding for facial expression similarity.pdf,A compact embedding for facial expression similarity
0,,,,,,,," B. Blaschko, Ross B. Girshick, Juho Kannala, Iasonas Kokkinos, Siddharth Mahendran, Subhransu Maji, Sammy Mohamed, Esa Rahtu, Naomi Saphra, Karen Simonyan, Ben Taskar, Andrea Vedaldi, and ",./refs/download/2/Fine-grained visual classification of aircraft.pdf,Fine-grained visual classification of aircraft
0,,,,,,,," C. Wah, S. Branson, P. Welinder, P. Perona, and ",./refs/download/2/Fine-grained visual classification of aircraft.pdf,Fine-grained visual classification of aircraft
0,,,,,,,," K. Chatfield, V. Lempitsky, A. Vedaldi, and ",./refs/download/2/Fine-grained visual classification of aircraft.pdf,Fine-grained visual classification of aircraft
0,,,,,,,," J. Liu, A. Kanazawa, D. Jacobs, and ",./refs/download/2/Fine-grained visual classification of aircraft.pdf,Fine-grained visual classification of aircraft
0,,,,,,,," O. Parkhi, A. Vedaldi, C. V. Jawahar, and ",./refs/download/2/Fine-grained visual classification of aircraft.pdf,Fine-grained visual classification of aircraft
0,"S. Bai, X. Bai, Z. Zhou, Z. Zhang, L. Jan Latecki",Gift: A real-time and scalable 3d shape search engine, In CVPR,,,2016,,"S. Bai, X. Bai, Z. Zhou, Z. Zhang, and L. Jan Latecki. Gift: A real-time and scalable 3d shape search engine. In CVPR, pages 5023–5032, 2016.",./refs/download/2/Triplet-center loss for multi-view 3D object retrieval.pdf,Triplet-center loss for multi-view 3D object retrieval
0,"S. Bai, X. Bai, Z. Zhou, Z. Zhang, Q. Tian, L. J. Latecki",Gift: Towards scalable 3d shape retrieval, TMM,,,2017,19,"S. Bai, X. Bai, Z. Zhou, Z. Zhang, Q. Tian, and L. J. Latecki. Gift: Towards scalable 3d shape retrieval. TMM, 19(6):1257–1271, 2017.",./refs/download/2/Triplet-center loss for multi-view 3D object retrieval.pdf,Triplet-center loss for multi-view 3D object retrieval
0,"S. Bai, Z. Zhou, J. Wang, X. Bai, L. Jan Latecki, Q. Tian",Ensemble diffusion for retrieval, In ICCV,,,2017,,"S. Bai, Z. Zhou, J. Wang, X. Bai, L. Jan Latecki, and Q. Tian. Ensemble diffusion for retrieval. In ICCV, 2017.",./refs/download/2/Triplet-center loss for multi-view 3D object retrieval.pdf,Triplet-center loss for multi-view 3D object retrieval
0,S. Biasotti,A, Cerri,,,2014,,"S. Biasotti, A. Cerri, M. Abdelrahman, M. Aono, A. B. Hamza, M. El-Melegy, A. Farag, V. Garro, A. Giachetti, D. Giorgi, et al. Shrec14 track: Retrieval and classification on textured 3d models. In 3DOR, pages 111–120, 2014.",./refs/download/2/Triplet-center loss for multi-view 3D object retrieval.pdf,Triplet-center loss for multi-view 3D object retrieval
0,"D. Boscaini, J. Masci, E. Rodolà, M. Bronstein",Learning shape correspondence with anisotropic convolutional neural networks, In NIPS,,,2016,,"D. Boscaini, J. Masci, E. Rodolà, and M. Bronstein. Learning shape correspondence with anisotropic convolutional neural networks. In NIPS, pages 3189–3197, 2016.",./refs/download/2/Triplet-center loss for multi-view 3D object retrieval.pdf,Triplet-center loss for multi-view 3D object retrieval
0,"D. Boscaini, J. Masci, E. Rodolà, M. M. Bronstein, D. Cremers",Anisotropic diffusion descriptors, Computer Graphics Forum,,,2016,35,"D. Boscaini, J. Masci, E. Rodolà, M. M. Bronstein, and D. Cremers. Anisotropic diffusion descriptors. Computer Graphics Forum, 35(2):431–441, 2016.",./refs/download/2/Triplet-center loss for multi-view 3D object retrieval.pdf,Triplet-center loss for multi-view 3D object retrieval
0,"A. X. Chang, T. A. Funkhouser, L. J. Guibas, P. Hanrahan, Q.-X. Huang, Z. Li, S. Savarese, M. Savva, S. Song, H. Su, J. Xiao, L. Yi, F. Yu",Shapenet: An information-rich 3d model repository, arXiv:,,,1512,,"A. X. Chang, T. A. Funkhouser, L. J. Guibas, P. Hanrahan, Q.-X. Huang, Z. Li, S. Savarese, M. Savva, S. Song, H. Su, J. Xiao, L. Yi, and F. Yu. Shapenet: An information-rich 3d model repository. arXiv:1512.",./refs/download/2/Triplet-center loss for multi-view 3D object retrieval.pdf,Triplet-center loss for multi-view 3D object retrieval
0,"S. Chopra, R. Hadsell, Y. LeCun",Learning a similarity metric discriminatively, with application to face verification,. In CVPR,,2005,,"S. Chopra, R. Hadsell, and Y. LeCun. Learning a similarity metric discriminatively, with application to face verification. In CVPR, volume 1, pages 539–546, 2005.",./refs/download/2/Triplet-center loss for multi-view 3D object retrieval.pdf,Triplet-center loss for multi-view 3D object retrieval
0,"G. Dai, J. Xie, F. Zhu, Y. Fang",Deep correlated metric learning for sketch-based 3d shape retrieval, In AAAI,,,2017,,"G. Dai, J. Xie, F. Zhu, and Y. Fang. Deep correlated metric learning for sketch-based 3d shape retrieval. In AAAI, pages 4002–4008, 2017.",./refs/download/2/Triplet-center loss for multi-view 3D object retrieval.pdf,Triplet-center loss for multi-view 3D object retrieval
0,"T. Furuya and , R. Ohbuchi",Ranking on cross-domain manifold for sketch-based 3d model retrieval, In Cyberworlds (CW),,,2013,,"T. Furuya and R. Ohbuchi. Ranking on cross-domain manifold for sketch-based 3d model retrieval. In Cyberworlds (CW), pages 274–281. IEEE, 2013.",./refs/download/2/Triplet-center loss for multi-view 3D object retrieval.pdf,Triplet-center loss for multi-view 3D object retrieval
0,"T. Furuya and , R. Ohbuchi",Deep aggregation of local 3d geometric features for 3d model retrieval, In BMVC,,,2016,,"T. Furuya and R. Ohbuchi. Deep aggregation of local 3d geometric features for 3d model retrieval. In BMVC, 2016.",./refs/download/2/Triplet-center loss for multi-view 3D object retrieval.pdf,Triplet-center loss for multi-view 3D object retrieval
0,"A. Hermans, L. Beyer, B. Leibe",In defense of the triplet loss for person re-identification, arXiv:,,,1703,,"A. Hermans, L. Beyer, and B. Leibe. In defense of the triplet loss for person re-identification. arXiv:1703.",./refs/download/2/Triplet-center loss for multi-view 3D object retrieval.pdf,Triplet-center loss for multi-view 3D object retrieval
0,"A. Ioannidou, E. Chatzilari, S. Nikolopoulos, I. Kompatsiaris",Deep learning advances in computer vision with 3d data: A survey, ACM Computing Surveys (CSUR),,,2017,50,"A. Ioannidou, E. Chatzilari, S. Nikolopoulos, and I. Kompatsiaris. Deep learning advances in computer vision with 3d data: A survey. ACM Computing Surveys (CSUR), 50(2):20, 2017.",./refs/download/2/Triplet-center loss for multi-view 3D object retrieval.pdf,Triplet-center loss for multi-view 3D object retrieval
0,"E. Johns, S. Leutenegger, A. J. Davison",Pairwise decomposition of image sequences for active multi-view recognition, In CVPR,,,2016,,"E. Johns, S. Leutenegger, and A. J. Davison. Pairwise decomposition of image sequences for active multi-view recognition. In CVPR, pages 3813–3822, 2016.",./refs/download/2/Triplet-center loss for multi-view 3D object retrieval.pdf,Triplet-center loss for multi-view 3D object retrieval
0,"R. Klokov and , V. Lempitsky",Escape from cells: Deep kd-networks for the recognition of 3d point cloud models, arXiv:1704,.01222,,2017,,"R. Klokov and V. Lempitsky. Escape from cells: Deep kd-networks for the recognition of 3d point cloud models. arXiv:1704.01222, 2017.",./refs/download/2/Triplet-center loss for multi-view 3D object retrieval.pdf,Triplet-center loss for multi-view 3D object retrieval
0,"A. Krizhevsky, I. Sutskever, G. E. Hinton",Imagenet classification with deep convolutional neural networks, In NIPS,,,1105,,"A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classification with deep convolutional neural networks. In NIPS, pages 1097–1105.",./refs/download/2/Triplet-center loss for multi-view 3D object retrieval.pdf,Triplet-center loss for multi-view 3D object retrieval
0,"B. Li, Y. Lu, A. Godil, T. Schreck, M. Aono, H. Johan, J. M. Saavedra, S. Tashiro",Shrec’13 track: Large scale sketchbased 3d shape retrieval, In Eurographics Workshop,,,2013,,"B. Li, Y. Lu, A. Godil, T. Schreck, M. Aono, H. Johan, J. M. Saavedra, and S. Tashiro. Shrec’13 track: Large scale sketchbased 3d shape retrieval. In Eurographics Workshop, pages 89–96, 2013.",./refs/download/2/Triplet-center loss for multi-view 3D object retrieval.pdf,Triplet-center loss for multi-view 3D object retrieval
0,"Y. Li, S. Pirk, H. Su, C. R. Qi, L. J. Guibas",Fpnn: Field probing neural networks for 3d data, In NIPS,,,2016,,"Y. Li, S. Pirk, H. Su, C. R. Qi, and L. J. Guibas. Fpnn: Field probing neural networks for 3d data. In NIPS, pages 307– 315, 2016.",./refs/download/2/Triplet-center loss for multi-view 3D object retrieval.pdf,Triplet-center loss for multi-view 3D object retrieval
0,"H. Liu, Y. Tian, Y. Yang, L. Pang, T. Huang",Deep relative distance learning: Tell the difference between similar vehicles, In CVPR,,,2016,,"H. Liu, Y. Tian, Y. Yang, L. Pang, and T. Huang. Deep relative distance learning: Tell the difference between similar vehicles. In CVPR, pages 2167–2175, 2016.",./refs/download/2/Triplet-center loss for multi-view 3D object retrieval.pdf,Triplet-center loss for multi-view 3D object retrieval
0,"D. Maturana and , S. Scherer",Voxnet: A 3d convolutional neural network for real-time object recognition, In IROS,,,2015,,"D. Maturana and S. Scherer. Voxnet: A 3d convolutional neural network for real-time object recognition. In IROS, pages 922–928, 2015.",./refs/download/2/Triplet-center loss for multi-view 3D object retrieval.pdf,Triplet-center loss for multi-view 3D object retrieval
0,"A. Notchenko, E. Kapushev, E. Burnaev",Sparse 3d convolutional neural networks for large-scale shape retrieval, arXiv:,,,1611,,"A. Notchenko, E. Kapushev, and E. Burnaev. Sparse 3d convolutional neural networks for large-scale shape retrieval. arXiv:1611.",./refs/download/2/Triplet-center loss for multi-view 3D object retrieval.pdf,Triplet-center loss for multi-view 3D object retrieval
0,"H. Oh Song, Y. Xiang, S. Jegelka, S. Savarese",Deep metric learning via lifted structured feature embedding, In CVPR,,,2016,,"H. Oh Song, Y. Xiang, S. Jegelka, and S. Savarese. Deep metric learning via lifted structured feature embedding. In CVPR, pages 4004–4012, 2016.",./refs/download/2/Triplet-center loss for multi-view 3D object retrieval.pdf,Triplet-center loss for multi-view 3D object retrieval
0,"C. R. Qi, H. Su, K. Mo, L. J. Guibas",Pointnet: Deep learning on point sets for 3d classification and segmentation, In CVPR,,,2017,,"C. R. Qi, H. Su, K. Mo, and L. J. Guibas. Pointnet: Deep learning on point sets for 3d classification and segmentation. In CVPR, 2017.",./refs/download/2/Triplet-center loss for multi-view 3D object retrieval.pdf,Triplet-center loss for multi-view 3D object retrieval
0,"C. R. Qi, H. Su, M. Nießner, A. Dai, M. Yan, L. J. Guibas",Volumetric and multi-view cnns for object classification on 3d data, In CVPR,,,2016,,"C. R. Qi, H. Su, M. Nießner, A. Dai, M. Yan, and L. J. Guibas. Volumetric and multi-view cnns for object classification on 3d data. In CVPR, pages 5648–5656, 2016.",./refs/download/2/Triplet-center loss for multi-view 3D object retrieval.pdf,Triplet-center loss for multi-view 3D object retrieval
0,"C. R. Qi, L. Yi, H. Su, L. J. Guibas",Pointnet++: Deep hierarchical feature learning on point sets in a metric space, In NIPS,,,2017,,"C. R. Qi, L. Yi, H. Su, and L. J. Guibas. Pointnet++: Deep hierarchical feature learning on point sets in a metric space. In NIPS, 2017.",./refs/download/2/Triplet-center loss for multi-view 3D object retrieval.pdf,Triplet-center loss for multi-view 3D object retrieval
0,M. Savva,F, Yu,,,2016,,"M. Savva, F. Yu, H. Su, M. Aono, B. Chen, D. Cohen-Or, W. Deng, H. Su, S. Bai, X. Bai, et al. Shrec16 track: largescale 3d shape retrieval from shapenet core55. In 3DOR, 2016.",./refs/download/2/Triplet-center loss for multi-view 3D object retrieval.pdf,Triplet-center loss for multi-view 3D object retrieval
0,M. Savva,F, Yu,,,2017,,"M. Savva, F. Yu, H. Su, A. Kanezaki, T. Furuya, R. Ohbuchi, Z. Zhou, R. Yu, S. Bai, X. Bai, et al. Shrec17 track largescale 3d shape retrieval from shapenet core55. In 3DOR, 2017.",./refs/download/2/Triplet-center loss for multi-view 3D object retrieval.pdf,Triplet-center loss for multi-view 3D object retrieval
0,"F. Schroff, D. Kalenichenko, J. Philbin",Facenet: A unified embedding for face recognition and clustering, In CVPR,,,2015,,"F. Schroff, D. Kalenichenko, and J. Philbin. Facenet: A unified embedding for face recognition and clustering. In CVPR, pages 815–823, 2015.",./refs/download/2/Triplet-center loss for multi-view 3D object retrieval.pdf,Triplet-center loss for multi-view 3D object retrieval
0,"N. Sedaghat, M. Zolfaghari, T. Brox",Orientationboosted voxel nets for 3d object recognition, In BMVC,,,2017,,"N. Sedaghat, M. Zolfaghari, and T. Brox. Orientationboosted voxel nets for 3d object recognition. In BMVC, 2017.",./refs/download/2/Triplet-center loss for multi-view 3D object retrieval.pdf,Triplet-center loss for multi-view 3D object retrieval
0,"B. Shi, S. Bai, Z. Zhou, X. Bai",Deeppano: Deep panoramic representation for 3-d shape recognition, IEEE Signal Processing Letters,,,2015,22,"B. Shi, S. Bai, Z. Zhou, and X. Bai. Deeppano: Deep panoramic representation for 3-d shape recognition. IEEE Signal Processing Letters, 22(12):2339–2343, 2015.",./refs/download/2/Triplet-center loss for multi-view 3D object retrieval.pdf,Triplet-center loss for multi-view 3D object retrieval
0,"K. Simonyan and , A. Zisserman",Very deep convolutional networks for large-scale image recognition, arXiv:1409,.1556,,2014,,"K. Simonyan and A. Zisserman. Very deep convolutional networks for large-scale image recognition. arXiv:1409.1556, 2014.",./refs/download/2/Triplet-center loss for multi-view 3D object retrieval.pdf,Triplet-center loss for multi-view 3D object retrieval
0,"H. Su, S. Maji, E. Kalogerakis, E. Learned-Miller",Multiview convolutional neural networks for 3d shape recognition, In ICCV,,,2015,,"H. Su, S. Maji, E. Kalogerakis, and E. Learned-Miller. Multiview convolutional neural networks for 3d shape recognition. In ICCV, pages 945–953, 2015.",./refs/download/2/Triplet-center loss for multi-view 3D object retrieval.pdf,Triplet-center loss for multi-view 3D object retrieval
0,"J. W. Tangelder and , R. C. Veltkamp",A survey of content based 3d shape retrieval methods, Multimedia tools and applications,,,2008,39,"J. W. Tangelder and R. C. Veltkamp. A survey of content based 3d shape retrieval methods. Multimedia tools and applications, 39(3):441, 2008.",./refs/download/2/Triplet-center loss for multi-view 3D object retrieval.pdf,Triplet-center loss for multi-view 3D object retrieval
0,"F. Wang, L. Kang, Y. Li",Sketch-based 3d shape retrieval using convolutional neural networks, In CVPR,,,2015,,"F. Wang, L. Kang, and Y. Li. Sketch-based 3d shape retrieval using convolutional neural networks. In CVPR, pages 1875– 1883, 2015.",./refs/download/2/Triplet-center loss for multi-view 3D object retrieval.pdf,Triplet-center loss for multi-view 3D object retrieval
0,"F. Wang, X. Xiang, J. Cheng, A. L. Yuille",Normface: L 2 hypersphere embedding for face verification, In ACM on Multimedia Conference,,,1049,,"F. Wang, X. Xiang, J. Cheng, and A. L. Yuille. Normface: L 2 hypersphere embedding for face verification. In ACM on Multimedia Conference, pages 1041–1049.",./refs/download/2/Triplet-center loss for multi-view 3D object retrieval.pdf,Triplet-center loss for multi-view 3D object retrieval
0,"J. Wang, F. Zhou, S. Wen, X. Liu, Y. Lin",Deep metric learning with angular loss, In ICCV,,,2017,,"J. Wang, F. Zhou, S. Wen, X. Liu, and Y. Lin. Deep metric learning with angular loss. In ICCV, pages 4321–4329, 2017.",./refs/download/2/Triplet-center loss for multi-view 3D object retrieval.pdf,Triplet-center loss for multi-view 3D object retrieval
0,"Y. Wen, K. Zhang, Z. Li, Y. Qiao",A discriminative feature learning approach for deep face recognition, In ECCV,,,2016,,"Y. Wen, K. Zhang, Z. Li, and Y. Qiao. A discriminative feature learning approach for deep face recognition. In ECCV, pages 499–515, 2016.",./refs/download/2/Triplet-center loss for multi-view 3D object retrieval.pdf,Triplet-center loss for multi-view 3D object retrieval
0,"Z. Wu, S. Song, A. Khosla, F. Yu, L. Zhang, X. Tang, J. Xiao",3d shapenets: A deep representation for volumetric shapes, In CVPR,,,2015,,"Z. Wu, S. Song, A. Khosla, F. Yu, L. Zhang, X. Tang, and J. Xiao. 3d shapenets: A deep representation for volumetric shapes. In CVPR, pages 1912–1920, 2015.",./refs/download/2/Triplet-center loss for multi-view 3D object retrieval.pdf,Triplet-center loss for multi-view 3D object retrieval
0,"J. Xie, G. Dai, F. Zhu, Y. Fang",Learning barycentric representations of 3d shapes for sketch-based 3d shape retrieval, In CVPR,,,2017,,"J. Xie, G. Dai, F. Zhu, and Y. Fang. Learning barycentric representations of 3d shapes for sketch-based 3d shape retrieval. In CVPR, pages 5068–5076, 2017.",./refs/download/2/Triplet-center loss for multi-view 3D object retrieval.pdf,Triplet-center loss for multi-view 3D object retrieval
0,"J. Xie, G. Dai, F. Zhu, E. K. Wong, Y. Fang",Deepshape: Deep-learned shape descriptor for 3d shape retrieval, TPAMI,,,2017,39,"J. Xie, G. Dai, F. Zhu, E. K. Wong, and Y. Fang. Deepshape: Deep-learned shape descriptor for 3d shape retrieval. TPAMI, 39(7):1335–1345, 2017.",./refs/download/2/Triplet-center loss for multi-view 3D object retrieval.pdf,Triplet-center loss for multi-view 3D object retrieval
0,"F. Zhu, J. Xie, Y. Fang",Learning cross-domain neural networks for sketch-based 3d shape retrieval, In AAAI,,,2016,,"F. Zhu, J. Xie, and Y. Fang. Learning cross-domain neural networks for sketch-based 3d shape retrieval. In AAAI, pages 3683–3689, 2016.",./refs/download/2/Triplet-center loss for multi-view 3D object retrieval.pdf,Triplet-center loss for multi-view 3D object retrieval
0,,,,,,,, J. Tao and ,./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,, P. Ekman and ,./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,, P. Ekman and ,./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,, W. V. Friesen and ,./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,," S. Du, Y. Tao, and ",./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,," M. Lyons, S. Akamatsu, M. Kamachi, and ",./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,," T. Kanade, and ",./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,," P. Lucey, J. F. Cohn, T. Kanade, J. Saragih, Z. Ambadar, and ",./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,," M. Pantic, M. Valstar, R. Rademaker, and ",./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,," R. Gross, I. Matthews, J. Cohn, T. Kanade, and ",./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,, J. F. Cohn and ,./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,," M. F. Valstar, M. Pantic, Z. Ambadar, and ",./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,," S. M. Mavadati, M. H. Mahoor, K. Bartlett, P. Trinh, and ",./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,," D. McDuff, R. Kaliouby, T. Senechal, M. Amr, J. Cohn, and ",./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,," I. Sneddon, M. McRorie, G. McKeown, and ",./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,," J. F. Grafsgaard, J. B. Wiggins, K. E. Boyer, E. N. Wiebe, and ",./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,," A. Dhall, R. Goecke, J. Joshi, M. Wagner, and ",./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,," A. Mollahosseini, B. Hasani, M. J. Salvador, H. Abdollahi, D. Chan, and ",./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,," S. Zafeiriou, A. Papaioannou, I. Kotsia, M. A. Nicolaou, and ",./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,," C. F. Benitez-Quiroz, R. Srinivasan, and ",./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,," M. A. Nicolaou, H. Gunes, and ",./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,," F. Ringeval, A. Sonderegger, J. Sauer, and ",./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,," A. Yazdani, T. Ebrahimi, T. Pun, A. Nijholt, and ",./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,," A. Dhall, R. Goecke, S. Lucey, and ",./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,, A. Mollahosseini and ,./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,," S. Ren, X. Cao, Y. Wei, and ",./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,, P. Viola and ,./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,," D. You, O. C. Hamsici, and ",./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,," P. Lucey, J. F. Cohn, K. M. Prkachin, P. E. Solomon, and ",./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,, M. M. Bradley and ,./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,," B. Schuller, M. Valstar, F. Eyben, G. McKeown, R. Cowie, and ",./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,," B. Schuller, M. Valster, F. Eyben, R. Cowie, and ",./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,," M. Valstar, B. Schuller, K. Smith, F. Eyben, B. Jiang, S. Bilakhia, S. Schnieder, R. Cowie, and ",./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,," M. Valstar, B. Schuller, K. Smith, T. Almaev, F. Eyben, J. Krajewski, R. Cowie, and ",./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,," F. Ringeval, B. Schuller, M. Valstar, R. Cowie, and ",./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,," M. Valstar, J. Gratch, B. Schuller, F. Ringeval, D. Lalanne, M. T. Torres, S. Scherer, G. Stratou, R. Cowie, and ",./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,," G. McKeown, M. Valstar, R. Cowie, M. Pantic, and ",./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,," A. Mollahosseini, D. Chan, and ",./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,," C. Shan, S. Gong, and ",./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,," X. Zhang, M. H. Mahoor, and ",./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,," L. He, D. Jiang, L. Yang, E. Pei, P. Wu, and ",./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,," Y. Fan, X. Lu, D. Li, and ",./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,," M. Sokolova, N. Japkowicz, and ",./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,, P. E. Shrout and ,./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,," L. A. Jeni, J. F. Cohn, and ",./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,, S. Bermejo and ,./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,," M. Mohammadi, E. Fatemizadeh, and ",./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,, C. Liu and ,./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,," A. Krizhevsky, I. Sutskever, and ",./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,, A. Toshev and ,./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,," Y. Taigman, M. Yang, M. Ranzato, and ",./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,," C. Sagonas, E. Antonakos, G. Tzimiropoulos, S. Zafeiriou, and ",./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,, G. Paltoglou and ,./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,, C. Cortes and ,./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,, A. Smola and ,./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,," G. Caridakis, K. Karpouzis, and ",./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,, H. He and ,./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,," Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Girshick, S. Guadarrama, and ",./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,,,,,,,, N. Dalal and ,./refs/download/2/AffectNet: A database for facial expression.pdf,AffectNet: A database for facial expression
0,"A. Adams, J. Baek, M. A. Davis",Fast high-dimensional filtering using the permutohedral lattice, Computer Graphics Forum,,,2010,29,"A. Adams, J. Baek, and M. A. Davis. Fast high-dimensional filtering using the permutohedral lattice. Computer Graphics Forum, 29(2):753–762, 2010.",./refs/download/2/SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing.pdf,SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing
0,"V. Aurich and , J. Weule",Non-linear Gaussian filters performing edge preserving diffusion, In DAGM,,,1995,,"V. Aurich and J. Weule. Non-linear Gaussian filters performing edge preserving diffusion. In DAGM, pages 538–545. Springer, 1995.",./refs/download/2/SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing.pdf,SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing
0,"S. Bai, X. Bai, Z. Zhou, Z. Zhang, L. J. Latecki",GIFT: a real-time and scalable 3D shape search engine, In Proc,. CVPR,,2016,,"S. Bai, X. Bai, Z. Zhou, Z. Zhang, and L. J. Latecki. GIFT: a real-time and scalable 3D shape search engine. In Proc. CVPR, 2016.",./refs/download/2/SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing.pdf,SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing
0,"D. Boscaini, J. Masci, S. Melzi, M. M. Bronstein, U. Castellani, P. Vandergheynst",Learning class-specific descriptors for deformable shapes using localized spectral convolutional networks, In Proc,. SGP,,2015,,"D. Boscaini, J. Masci, S. Melzi, M. M. Bronstein, U. Castellani, and P. Vandergheynst. Learning class-specific descriptors for deformable shapes using localized spectral convolutional networks. In Proc. SGP, 2015.",./refs/download/2/SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing.pdf,SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing
0,"D. Boscaini, J. Masci, E. Rodolà, M. M. Bronstein",Learning shape correspondence with anisotropic convolutional neural networks, In Proc,. NIPS,,2016,,"D. Boscaini, J. Masci, E. Rodolà, and M. M. Bronstein. Learning shape correspondence with anisotropic convolutional neural networks. In Proc. NIPS, 2016.",./refs/download/2/SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing.pdf,SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing
0,"A. Brock, T. Lim, J. M. Ritchie, N. Weston",Generative and discriminative voxel modeling with convolutional neural networks, arXiv:,,,1608,,"A. Brock, T. Lim, J. M. Ritchie, and N. Weston. Generative and discriminative voxel modeling with convolutional neural networks. arXiv:1608.",./refs/download/2/SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing.pdf,SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing
0,"M. M. Bronstein, J. Bruna, Y. LeCun, A. Szlam, P. Vandergheynst",Geometric deep learning: Going beyond euclidean data, IEEE Signal Processing Magazine,,,2017,34,"M. M. Bronstein, J. Bruna, Y. LeCun, A. Szlam, and P. Vandergheynst. Geometric deep learning: Going beyond euclidean data. IEEE Signal Processing Magazine, 34(4):18– 42, 2017.",./refs/download/2/SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing.pdf,SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing
0,"J. Bruna, W. Zaremba, A. Szlam, Y. LeCun",Spectral networks and locally connected networks on graphs, In Proc,. ICLR,,2014,,"J. Bruna, W. Zaremba, A. Szlam, and Y. LeCun. Spectral networks and locally connected networks on graphs. In Proc. ICLR, 2014.",./refs/download/2/SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing.pdf,SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing
0,"Z. Cao, Q. Huang, K. Ramani",3D object classification via spherical projections, In Proc,. 3DV,,2017,,"Z. Cao, Q. Huang, and K. Ramani. 3D object classification via spherical projections. In Proc. 3DV, 2017.",./refs/download/2/SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing.pdf,SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing
0,"M. Defferrard, X. Bresson, P. Vandergheynst",Convolutional neural networks on graphs with fast localized spectral filtering, arXiv:,,,1606,,"M. Defferrard, X. Bresson, and P. Vandergheynst. Convolutional neural networks on graphs with fast localized spectral filtering. arXiv:1606.",./refs/download/2/SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing.pdf,SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing
0,"M. Everingham, S. M. A. Eslami, L. Van Gool, C. K. I. Williams, J. Winn, A. Zisserman",The Pascal Visual Object Classes Challenge: A retrospective, IJCV,,,2015,111,"M. Everingham, S. M. A. Eslami, L. Van Gool, C. K. I. Williams, J. Winn, and A. Zisserman. The Pascal Visual Object Classes Challenge: A retrospective. IJCV, 111(1):98– 136, Jan. 2015.",./refs/download/2/SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing.pdf,SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing
0,"D. Ezuz, J. Solomon, V. G. Kim, M. Ben-Chen",GWCNN: A metric alignment layer for deep shape analysis, Computer Graphics Forum,,,2017,36,"D. Ezuz, J. Solomon, V. G. Kim, and M. Ben-Chen. GWCNN: A metric alignment layer for deep shape analysis. Computer Graphics Forum, 36(5), 2017.",./refs/download/2/SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing.pdf,SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing
0,"R. Gadde, V. Jampani, R. Marlet, P. Gehler",Efficient 2D and 3D facade segmentation using auto-context, PAMI,,,2017,,"R. Gadde, V. Jampani, R. Marlet, and P. Gehler. Efficient 2D and 3D facade segmentation using auto-context. PAMI, 2017.",./refs/download/2/SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing.pdf,SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing
0,"A. Garcia-Garcia, F. Gomez-Donoso, J. G. Rodrı́guez, S. Orts, M. Cazorla, J. A. López",PointNet: A 3D convolutional neural network for real-time object class recognition, In Proc,. IJCNN,,2016,,"A. Garcia-Garcia, F. Gomez-Donoso, J. G. Rodrı́guez, S. Orts, M. Cazorla, and J. A. López. PointNet: A 3D convolutional neural network for real-time object class recognition. In Proc. IJCNN, 2016.",./refs/download/2/SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing.pdf,SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing
0,"B. Graham and , L. van der Maaten",Submanifold sparse convolutional networks, arXiv:1706,.01307,,2017,,"B. Graham and L. van der Maaten. Submanifold sparse convolutional networks. arXiv:1706.01307, 2017.",./refs/download/2/SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing.pdf,SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing
0,"B. Hariharan, P. Arbeláez, R. Girshick, J. Malik",Hypercolumns for object segmentation and fine-grained localization, In Proc,. CVPR,,2015,,"B. Hariharan, P. Arbeláez, R. Girshick, and J. Malik. Hypercolumns for object segmentation and fine-grained localization. In Proc. CVPR, pages 447–456, 2015.",./refs/download/2/SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing.pdf,SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing
0,"V. Hegde and , R. Zadeh",FusionNet: 3D object classification using multiple data representations, arXiv:1607,.05695,,2016,,"V. Hegde and R. Zadeh. FusionNet: 3D object classification using multiple data representations. arXiv:1607.05695, 2016.",./refs/download/2/SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing.pdf,SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing
0,"M. Henaff, J. Bruna, Y. LeCun",Deep convolutional networks on graph-structured data, arXiv:,,,1506,,"M. Henaff, J. Bruna, and Y. LeCun. Deep convolutional networks on graph-structured data. arXiv:1506.",./refs/download/2/SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing.pdf,SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing
0,"H. Huang, E. Kalegorakis, S. Chaudhuri, D. Ceylan, V. Kim, E. Yumer",Learning local shape descriptors with viewbased convolutional neural networks, ACM Trans,. Graph.,,2018,,"H. Huang, E. Kalegorakis, S. Chaudhuri, D. Ceylan, V. Kim, and E. Yumer. Learning local shape descriptors with viewbased convolutional neural networks. ACM Trans. Graph., 2018.",./refs/download/2/SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing.pdf,SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing
0,"V. Jampani, R. Gadde, P. V. Gehler",Video propagation networks, In Proc,. CVPR,,2017,,"V. Jampani, R. Gadde, and P. V. Gehler. Video propagation networks. In Proc. CVPR, 2017.",./refs/download/2/SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing.pdf,SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing
0,"V. Jampani, M. Kiefel, P. V. Gehler",Learning sparse high dimensional filters: Image filtering, dense CRFs and bilateral neural networks,. In Proc. CVPR,,2016,,"V. Jampani, M. Kiefel, and P. V. Gehler. Learning sparse high dimensional filters: Image filtering, dense CRFs and bilateral neural networks. In Proc. CVPR, 2016.",./refs/download/2/SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing.pdf,SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing
0,"Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Girshick, S. Guadarrama, T. Darrell",Caffe: Convolutional architecture for fast feature embedding, In Proc,. ACM Multimedia,,2014,,"Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Girshick, S. Guadarrama, and T. Darrell. Caffe: Convolutional architecture for fast feature embedding. In Proc. ACM Multimedia, 2014.",./refs/download/2/SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing.pdf,SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing
0,"E. Kalogerakis, M. Averkiou, S. Maji, S. Chaudhuri",3D shape segmentation with projective convolutional networks, In Proc,. CVPR,,2017,,"E. Kalogerakis, M. Averkiou, S. Maji, and S. Chaudhuri. 3D shape segmentation with projective convolutional networks. In Proc. CVPR, 2017.",./refs/download/2/SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing.pdf,SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing
0,"M. Kiefel, V. Jampani, P. V. Gehler",Permutohedral lattice CNNs, In ICLR workshops,,,2015,,"M. Kiefel, V. Jampani, and P. V. Gehler. Permutohedral lattice CNNs. In ICLR workshops, May 2015.",./refs/download/2/SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing.pdf,SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing
0,"D. Kingma and , J. Ba",Adam: A method for stochastic optimization, arXiv:1412,.6980,,2014,,"D. Kingma and J. Ba. Adam: A method for stochastic optimization. arXiv:1412.6980, 2014.",./refs/download/2/SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing.pdf,SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing
0,"R. Klokov and , V. Lempitsky",Escape from cells: Deep KdNetworks for the recognition of 3D point cloud models, In Proc,. ICCV,,2017,,"R. Klokov and V. Lempitsky. Escape from cells: Deep KdNetworks for the recognition of 3D point cloud models. In Proc. ICCV, 2017.",./refs/download/2/SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing.pdf,SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing
0,"H. Maron, M. Galun, N. Aigerman, M. Trope, N. Dym, E. Yumer, V. G. Kim, Y. Lipman",Convolutional neural networks on surfaces via seamless toric covers, ACM Trans,. Graph.,,2017,36,"H. Maron, M. Galun, N. Aigerman, M. Trope, N. Dym, E. Yumer, V. G. Kim, and Y. Lipman. Convolutional neural networks on surfaces via seamless toric covers. ACM Trans. Graph., 36(4), 2017.",./refs/download/2/SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing.pdf,SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing
0,"J. Masci, D. Boscaini, M. Bronstein, P. Vandergheynst",Geodesic convolutional neural networks on Riemannian manifolds, In Proc,. ICCV workshops,,2015,,"J. Masci, D. Boscaini, M. Bronstein, and P. Vandergheynst. Geodesic convolutional neural networks on Riemannian manifolds. In Proc. ICCV workshops, 2015.",./refs/download/2/SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing.pdf,SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing
0,"D. Maturana and , S. Scherer",3D convolutional neural networks for landing zone detection from LiDAR, In Proc,. ICRA,,2015,,"D. Maturana and S. Scherer. 3D convolutional neural networks for landing zone detection from LiDAR. In Proc. ICRA, 2015.",./refs/download/2/SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing.pdf,SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing
0,"F. Monti, D. Boscaini, J. Masci, E. Rodola, J. Svoboda, M. M. Bronstein",Geometric deep learning on graphs and manifolds using mixture model CNNs, In Proc,. CVPR,,2017,,"F. Monti, D. Boscaini, J. Masci, E. Rodola, J. Svoboda, and M. M. Bronstein. Geometric deep learning on graphs and manifolds using mixture model CNNs. In Proc. CVPR, 2017.",./refs/download/2/SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing.pdf,SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing
0,B. T. Phong,Illumination for computer generated pictures, Commun,. ACM,,1975,18,"B. T. Phong. Illumination for computer generated pictures. Commun. ACM, 18(6), 1975.",./refs/download/2/SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing.pdf,SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing
0,"C. R. Qi, H. Su, K. Mo, L. J. Guibas",PointNet: Deep learning on point sets for 3D classification and segmentation, In Proc,. CVPR,,2017,,"C. R. Qi, H. Su, K. Mo, and L. J. Guibas. PointNet: Deep learning on point sets for 3D classification and segmentation. In Proc. CVPR, 2017.",./refs/download/2/SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing.pdf,SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing
0,"C. R. Qi, H. Su, M. Niener, A. Dai, M. Yan, L. J. Guibas",Volumetric and multi-view CNNs for object classification on 3D data, In Proc,. CVPR,,2016,,"C. R. Qi, H. Su, M. Niener, A. Dai, M. Yan, and L. J. Guibas. Volumetric and multi-view CNNs for object classification on 3D data. In Proc. CVPR, 2016.",./refs/download/2/SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing.pdf,SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing
0,"C. R. Qi, L. Yi, H. Su, L. Guibas",PointNet++: Deep hierarchical feature learning on point sets in a metric space, In Proc,. NIPS,,2017,,"C. R. Qi, L. Yi, H. Su, and L. Guibas. PointNet++: Deep hierarchical feature learning on point sets in a metric space. In Proc. NIPS, 2017.",./refs/download/2/SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing.pdf,SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing
0,"G. Riegler, A. O. Ulusoy, H. Bischof, A. Geiger",OctNetFusion: Learning depth fusion from data, In Proc,. 3DV,,2017,,"G. Riegler, A. O. Ulusoy, H. Bischof, and A. Geiger. OctNetFusion: Learning depth fusion from data. In Proc. 3DV, 2017.",./refs/download/2/SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing.pdf,SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing
0,"G. Riegler, A. O. Ulusoys, A. Geiger",Octnet: Learning deep 3D representations at high resolutions, In Proc,. CVPR,,2017,,"G. Riegler, A. O. Ulusoys, and A. Geiger. Octnet: Learning deep 3D representations at high resolutions. In Proc. CVPR, 2017.",./refs/download/2/SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing.pdf,SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing
0,"H. Riemenschneider, A. Bódis-Szomorú, J. Weissenberg, L. Van Gool",Learning where to classify in multi-view semantic segmentation, In Proc,. ECCV,,2014,,"H. Riemenschneider, A. Bódis-Szomorú, J. Weissenberg, and L. Van Gool. Learning where to classify in multi-view semantic segmentation. In Proc. ECCV, 2014.",./refs/download/2/SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing.pdf,SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing
0,"N. Sedaghat, M. Zolfaghari, E. Amiri, T. Brox",Orientation-boosted voxel nets for 3D object recognition, In Proc,. BMVC,,2017,,"N. Sedaghat, M. Zolfaghari, E. Amiri, and T. Brox. Orientation-boosted voxel nets for 3D object recognition. In Proc. BMVC, 2017.",./refs/download/2/SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing.pdf,SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing
0,"A. Sinha, J. Bai, K. Ramani",Deep learning 3D shape surfaces using geometry images, In Proc,. ECCV,,2016,,"A. Sinha, J. Bai, and K. Ramani. Deep learning 3D shape surfaces using geometry images. In Proc. ECCV, 2016.",./refs/download/2/SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing.pdf,SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing
0,"H. Su, S. Maji, E. Kalogerakis, E. G. Learned-Miller",Multi-view convolutional neural networks for 3D shape recognition, In Proc,. ICCV,,2015,,"H. Su, S. Maji, E. Kalogerakis, and E. G. Learned-Miller. Multi-view convolutional neural networks for 3D shape recognition. In Proc. ICCV, 2015.",./refs/download/2/SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing.pdf,SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing
0,"M. Tatarchenko, A. Dosovitskiy, T. Brox",Octree generating networks: Efficient convolutional architectures for high-resolution 3D outputs, In Proc,. ICCV,,2017,,"M. Tatarchenko, A. Dosovitskiy, and T. Brox. Octree generating networks: Efficient convolutional architectures for high-resolution 3D outputs. In Proc. ICCV, 2017.",./refs/download/2/SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing.pdf,SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing
0,"C. Tomasi and , R. Manduchi",Bilateral filtering for gray and color images, In Proc,. ICCV,,1998,,"C. Tomasi and R. Manduchi. Bilateral filtering for gray and color images. In Proc. ICCV, 1998.",./refs/download/2/SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing.pdf,SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing
0,"Z. Wu, S. Song, A. Khosla, F. Yu, L. Zhang, X. Tang, J. Xiao",3D shapenets: A deep representation for volumetric shapes, In Proc,. CVPR,,2015,,"Z. Wu, S. Song, A. Khosla, F. Yu, L. Zhang, X. Tang, and J. Xiao. 3D shapenets: A deep representation for volumetric shapes. In Proc. CVPR, 2015.",./refs/download/2/SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing.pdf,SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing
0,L. Yi,V, G,. Kim,,2016,,"L. Yi, V. G. Kim, D. Ceylan, I. Shen, M. Yan, H. Su, A. Lu, Q. Huang, A. Sheffer, L. Guibas, et al. A scalable active framework for region annotation in 3D shape collections. ACM Trans. Graph., 35(6):210, 2016.",./refs/download/2/SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing.pdf,SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing
0,"L. Yi, H. Su, X. Guo, L. Guibas",SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation, In Proc,. CVPR,,2017,,"L. Yi, H. Su, X. Guo, and L. Guibas. SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation. In Proc. CVPR, 2017.",./refs/download/2/SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing.pdf,SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing
0,"M. Zaheer, S. Kottur, S. Ravanbakhsh, B. Poczos, R. R. Salakhutdinov, A. J. Smola",Deep sets, In Proc,. NIPS,,2017,,"M. Zaheer, S. Kottur, S. Ravanbakhsh, B. Poczos, R. R. Salakhutdinov, and A. J. Smola. Deep sets. In Proc. NIPS, pages 3394–3404, 2017.",./refs/download/2/SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing.pdf,SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing
0,,,,,,,," P. Agrawal, R. B. Girshick, and ",./refs/download/2/Domain adaptive transfer learning with specialist models.pdf,Domain adaptive transfer learning with specialist models
0,,,,,,,," H. Azizpour, A. S. Razavian, J. Sullivan, A. Maki, and ",./refs/download/2/Domain adaptive transfer learning with specialist models.pdf,Domain adaptive transfer learning with specialist models
0,,,,,,,," T. Berg, J. Liu, S. W. Lee, M. L. Alexander, D. W. Jacobs, and ",./refs/download/2/Domain adaptive transfer learning with specialist models.pdf,Domain adaptive transfer learning with specialist models
0,,,,,,,," L. Bossard, M. Guillaumin, and ",./refs/download/2/Domain adaptive transfer learning with specialist models.pdf,Domain adaptive transfer learning with specialist models
0,,,,,,,," D. J. Fleet, T. Pajdla, B. Schiele, and ",./refs/download/2/Domain adaptive transfer learning with specialist models.pdf,Domain adaptive transfer learning with specialist models
0,,,,,,,," L. Chen, G. Papandreou, I. Kokkinos, K. Murphy, and ",./refs/download/2/Domain adaptive transfer learning with specialist models.pdf,Domain adaptive transfer learning with specialist models
0,,,,,,,," Y. Cui, Y. Song, C. Sun, A. Howard, and ",./refs/download/2/Domain adaptive transfer learning with specialist models.pdf,Domain adaptive transfer learning with specialist models
0,,,,,,,," J. Donahue, Y. Jia, O. Vinyals, J. Hoffman, N. Zhang, E. Tzeng, and ",./refs/download/2/Domain adaptive transfer learning with specialist models.pdf,Domain adaptive transfer learning with specialist models
0,,,,,,,, W. Ge and ,./refs/download/2/Domain adaptive transfer learning with specialist models.pdf,Domain adaptive transfer learning with specialist models
0,,,,,,,," K. He, G. Gkioxari, P. Dollr, and ",./refs/download/2/Domain adaptive transfer learning with specialist models.pdf,Domain adaptive transfer learning with specialist models
0,,,,,,,," J. Huang, V. Rathod, C. Sun, M. Zhu, A. K. Balan, A. Fathi, I. Fischer, Z. Wojna, Y. Song, S. Guadarrama, and ",./refs/download/2/Domain adaptive transfer learning with specialist models.pdf,Domain adaptive transfer learning with specialist models
0,,,,,,,," Y. Huang, Y. Cheng, D. Chen, H. Lee, J. Ngiam, Q. V. Le, and ",./refs/download/2/Domain adaptive transfer learning with specialist models.pdf,Domain adaptive transfer learning with specialist models
0,,,,,,,," S. Kornblith, J. Shlens, and ",./refs/download/2/Domain adaptive transfer learning with specialist models.pdf,Domain adaptive transfer learning with specialist models
0,,,,,,,," J. Krause, J. Deng, M. Stark, and ",./refs/download/2/Domain adaptive transfer learning with specialist models.pdf,Domain adaptive transfer learning with specialist models
0,,,,,,,," J. Krause, B. Sapp, A. Howard, H. Zhou, A. Toshev, T. Duerig, J. Philbin, and ",./refs/download/2/Domain adaptive transfer learning with specialist models.pdf,Domain adaptive transfer learning with specialist models
0,,,,,,,, A. Krizhevsky and ,./refs/download/2/Domain adaptive transfer learning with specialist models.pdf,Domain adaptive transfer learning with specialist models
0,,,,,,,," A. Krizhevsky, I. Sutskever, and ",./refs/download/2/Domain adaptive transfer learning with specialist models.pdf,Domain adaptive transfer learning with specialist models
0,,,,,,,," D. K. Mahajan, R. B. Girshick, V. Ramanathan, K. He, M. Paluri, Y. Li, A. Bharambe, and ",./refs/download/2/Domain adaptive transfer learning with specialist models.pdf,Domain adaptive transfer learning with specialist models
0,,,,,,,," S. Maji, E. Rahtu, J. Kannala, M. B. Blaschko, and ",./refs/download/2/Domain adaptive transfer learning with specialist models.pdf,Domain adaptive transfer learning with specialist models
0,,,,,,,," O. M. Parkhi, A. Vedaldi, A. Zisserman, and ",./refs/download/2/Domain adaptive transfer learning with specialist models.pdf,Domain adaptive transfer learning with specialist models
0,,,,,,,," A. S. Razavian, H. Azizpour, J. Sullivan, and ",./refs/download/2/Domain adaptive transfer learning with specialist models.pdf,Domain adaptive transfer learning with specialist models
0,,,,,,,," E. Real, A. Aggarwal, Y. Huang, and ",./refs/download/2/Domain adaptive transfer learning with specialist models.pdf,Domain adaptive transfer learning with specialist models
0,,,,,,,," S. Ren, K. He, R. B. Girshick, and ",./refs/download/2/Domain adaptive transfer learning with specialist models.pdf,Domain adaptive transfer learning with specialist models
0,,,,,,,," O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, A. C. Berg, and ",./refs/download/2/Domain adaptive transfer learning with specialist models.pdf,Domain adaptive transfer learning with specialist models
0,,,,,,,," M. Saerens, P. Latinne, and ",./refs/download/2/Domain adaptive transfer learning with specialist models.pdf,Domain adaptive transfer learning with specialist models
0,,,,,,,," E. Shelhamer, J. Long, and ",./refs/download/2/Domain adaptive transfer learning with specialist models.pdf,Domain adaptive transfer learning with specialist models
0,,,,,,,," C. Sun, A. Shrivastava, S. Singh, and ",./refs/download/2/Domain adaptive transfer learning with specialist models.pdf,Domain adaptive transfer learning with specialist models
0,,,,,,,," C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, and ",./refs/download/2/Domain adaptive transfer learning with specialist models.pdf,Domain adaptive transfer learning with specialist models
0,,,,,,,," B. Thomee, D. A. Shamma, G. Friedland, B. Elizalde, K. Ni, D. Poland, D. Borth, and ",./refs/download/2/Domain adaptive transfer learning with specialist models.pdf,Domain adaptive transfer learning with specialist models
0,,,,,,,," J. Yosinski, J. Clune, Y. Bengio, and ",./refs/download/2/Domain adaptive transfer learning with specialist models.pdf,Domain adaptive transfer learning with specialist models
0,,,,,,,," F. Yu, D. Wang, and ",./refs/download/2/Domain adaptive transfer learning with specialist models.pdf,Domain adaptive transfer learning with specialist models
0,,,,,,,," A. R. Zamir, A. Sax, W. B. Shen, L. J. Guibas, J. Malik, and ",./refs/download/2/Domain adaptive transfer learning with specialist models.pdf,Domain adaptive transfer learning with specialist models
0,,,,,,,," K. Zhang, B. Schlkopf, K. Muandet, and ",./refs/download/2/Domain adaptive transfer learning with specialist models.pdf,Domain adaptive transfer learning with specialist models
0,,,,,,,," B. Zoph, V. Vasudevan, J. Shlens, and ",./refs/download/2/Domain adaptive transfer learning with specialist models.pdf,Domain adaptive transfer learning with specialist models
0,,,,,,,," D. Boscaini, J. Masci, S. Melzi, M. M. Bronstein, U. Castellani, and ",./refs/download/2/SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation.pdf,SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation
0,,,,,,,," D. Boscaini, J. Masci, E. Rodolà, and ",./refs/download/2/SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation.pdf,SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation
0,,,,,,,," J. Bruna, W. Zaremba, A. Szlam, and ",./refs/download/2/SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation.pdf,SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation
0,,,,,,,," A. X. Chang, T. Funkhouser, L. Guibas, P. Hanrahan, Q. Huang, Z. Li, S. Savarese, M. Savva, S. Song, H. Su, J. Xiao, L. Yi, and ",./refs/download/2/SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation.pdf,SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation
0,,,,,,,," M. Defferrard, X. Bresson, and ",./refs/download/2/SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation.pdf,SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation
0,,,,,,,," D. K. Duvenaud, D. Maclaurin, J. Iparraguirre, R. Bombarell, T. Hirzel, A. Aspuru-Guzik, and ",./refs/download/2/SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation.pdf,SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation
0,,,,,,,," K. Guo, D. Zou, and ",./refs/download/2/SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation.pdf,SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation
0,,,,,,,," M. Henaff, J. Bruna, and ",./refs/download/2/SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation.pdf,SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation
0,,,,,,,," H. Su, and ",./refs/download/2/SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation.pdf,SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation
0,,,,,,,," E. Kalogerakis, A. Hertzmann, and ",./refs/download/2/SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation.pdf,SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation
0,,,,,,,," V. G. Kim, S. Chaudhuri, L. Guibas, and ",./refs/download/2/SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation.pdf,SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation
0,,,,,,,," V. G. Kim, W. Li, N. J. Mitra, S. Chaudhuri, S. DiVerdi, and ",./refs/download/2/SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation.pdf,SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation
0,,,,,,,, R. Liu and ,./refs/download/2/SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation.pdf,SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation
0,,,,,,,, R. Liu and ,./refs/download/2/SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation.pdf,SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation
0,,,,,,,," J. Long, E. Shelhamer, and ",./refs/download/2/SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation.pdf,SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation
0,,,,,,,, A. Makadia and ,./refs/download/2/SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation.pdf,SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation
0,,,,,,,," J. Masci, D. Boscaini, M. Bronstein, and ",./refs/download/2/SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation.pdf,SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation
0,,,,,,,, D. Maturana and ,./refs/download/2/SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation.pdf,SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation
0,,,,,,,," M. Ovsjanikov, M. Ben-Chen, J. Solomon, A. Butscher, and ",./refs/download/2/SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation.pdf,SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation
0,,,,,,,," D. I. Shuman, B. Ricaud, and ",./refs/download/2/SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation.pdf,SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation
0,,,,,,,," C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, and ",./refs/download/2/SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation.pdf,SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation
0,,,,,,,," F. Wang, Q. Huang, and ",./refs/download/2/SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation.pdf,SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation
0,,,,,,,," F. Wang, Q. Huang, M. Ovsjanikov, and ",./refs/download/2/SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation.pdf,SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation
0,,,,,,,," Z. Wu, R. Shou, Y. Wang, and ",./refs/download/2/SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation.pdf,SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation
0,,,,,,,," Z. Xie, K. Xu, L. Liu, and ",./refs/download/2/SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation.pdf,SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation
0,,,,,,,," M. Yan, H. Su, C. Lu, Q. Huang, A. Sheffer, and ",./refs/download/2/SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation.pdf,SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation
0,,,,,,,, F. Yu and ,./refs/download/2/SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation.pdf,SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation
0,,,,,,,,"Andrew R Barron. Approximation and estimation bounds for artificial neural networks. Machine Learning, 14(1):115â€“133, 1994.",./refs/download/2/The expressive power of neural networks: A view from the width.pdf,The expressive power of neural networks: A view from the width
0,"Nadav Cohen, Or Sharir, Amnon Shashua",On the expressive power of deep learning: A tensor analysis,Conference on Learning Theory,"698â€“728, ",,2016,,"Nadav Cohen, Or Sharir, and Amnon Shashua. On the expressive power of deep learning: A tensor analysis. In Conference on Learning Theory, pages 698â€“728, 2016.",./refs/download/2/The expressive power of neural networks: A view from the width.pdf,The expressive power of neural networks: A view from the width
0,,,,,,,,"George Cybenko. Approximation by superpositions of a sigmoidal function. Mathematics of Control, Signals, and Systems (MCSS), 2(4):303â€“314, 1989.",./refs/download/2/The expressive power of neural networks: A view from the width.pdf,The expressive power of neural networks: A view from the width
0,"Olivier Delalleau , Yoshua Bengio",Shallow vs,deep sum-product networks. In Advances in Neural Information Processing Systems,"666â€“674, ",,2011,,"Olivier Delalleau and Yoshua Bengio. Shallow vs. deep sum-product networks. In Advances in Neural Information Processing Systems, pages 666â€“674, 2011.",./refs/download/2/The expressive power of neural networks: A view from the width.pdf,The expressive power of neural networks: A view from the width
0,"Ronen Eldan , Ohad Shamir",The power of depth for feedforward neural networks,Conference on Learning Theory,"907â€“940, ",,2016,,"Ronen Eldan and Ohad Shamir. The power of depth for feedforward neural networks. In Conference on Learning Theory, pages 907â€“940, 2016.",./refs/download/2/The expressive power of neural networks: A view from the width.pdf,The expressive power of neural networks: A view from the width
0,,,,,,,,"Ken-Ichi Funahashi. On the approximate realization of continuous mappings by neural networks. Neural networks, 2(3):183â€“192, 1989.",./refs/download/2/The expressive power of neural networks: A view from the width.pdf,The expressive power of neural networks: A view from the width
0,,,,,,,,"Nick Harvey, Chris Liaw, and Abbas Mehrabian. Nearly-tight vc-dimension bounds for piecewise linear neural networks. COLT 2017",./refs/download/2/The expressive power of neural networks: A view from the width.pdf,The expressive power of neural networks: A view from the width
0,"Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun",Deep residual learning for image recognition,Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,"770â€“778, ",,2016,,"Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 770â€“778, 2016.",./refs/download/2/The expressive power of neural networks: A view from the width.pdf,The expressive power of neural networks: A view from the width
0,"Kurt Hornik, Maxwell Stinchcombe, Halbert White",Multilayer feedforward networks are universal approximators,Neural networks,"359â€“366, ",2(5):,1989,,"Kurt Hornik, Maxwell Stinchcombe, and Halbert White. Multilayer feedforward networks are universal approximators. Neural networks, 2(5):359â€“366, 1989.",./refs/download/2/The expressive power of neural networks: A view from the width.pdf,The expressive power of neural networks: A view from the width
0,,,,,,,,"Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convolutional neural networks. In Advances in neural information processing systems, pages 1097",./refs/download/2/The expressive power of neural networks: A view from the width.pdf,The expressive power of neural networks: A view from the width
0,,,,,,,,"Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. CoRR, abs/1409.1556, 2014.",./refs/download/2/The expressive power of neural networks: A view from the width.pdf,The expressive power of neural networks: A view from the width
0,,,,,,,,"Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott E. Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. Going deeper with convolutions. CoRR, abs/1409.4842, 2014.",./refs/download/2/The expressive power of neural networks: A view from the width.pdf,The expressive power of neural networks: A view from the width
0,,,,,,,,Matus Telgarsky. Benefits of depth in neural networks. COLT 2016,./refs/download/2/The expressive power of neural networks: A view from the width.pdf,The expressive power of neural networks: A view from the width
0,,,,,,,,"Dmitry Yarotsky. Error bounds for approximations with deep relu networks. arXiv:1610.01145, 2016.",./refs/download/2/The expressive power of neural networks: A view from the width.pdf,The expressive power of neural networks: A view from the width
0,,,,,,,,"Quynh Nguyen and Matthias Hein. The loss surface of deep and wide neural networks. In Doina Precup and Yee Whye Teh, editors, Proceedings of the 34th International Conference on Machine Learning, volume 70 of Proceedings of Machine Learning Research, pages 2603",./refs/download/2/The expressive power of neural networks: A view from the width.pdf,The expressive power of neural networks: A view from the width
0,"Peter Anderson, Qi Wu, Damien Teney, Jake Bruce, Mark Johnson, Niko Sünderhauf, Ian D. Reid, Stephen Gould, Anton van den Hengel",Vision-andlanguage navigation: Interpreting visually-grounded navigation instructions in real environments,arXiv preprint arXiv:1711.07280,,,2017,,"Peter Anderson, Qi Wu, Damien Teney, Jake Bruce, Mark Johnson, Niko Sünderhauf, Ian D. Reid, Stephen Gould, and Anton van den Hengel. Vision-andlanguage navigation: Interpreting visually-grounded navigation instructions in real environments. arXiv preprint arXiv:1711.07280, 2017.",./refs/download/2/Chalet: Cornell house agent learning environment.pdf,Chalet: Cornell house agent learning environment
0,,,,,,,,"Charles Beattie, Joel Z Leibo, Denis Teplyashin, Tom Ward, Marcus Wainwright, Heinrich Küttler, Andrew Lefrancq, Simon Green, Vı́ctor Valdés, Amir Sadik, et al. Deepmind lab. arXiv preprint arXiv:1612.03801, 2016.",./refs/download/2/Chalet: Cornell house agent learning environment.pdf,Chalet: Cornell house agent learning environment
0,,,,,,,,"Yonatan Bisk, Deniz Yuret, and Daniel Marcu. Natural language communication with robots. In Proceedings of the 15th Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 751–761, San Diego, CA, June 2016.",./refs/download/2/Chalet: Cornell house agent learning environment.pdf,Chalet: Cornell house agent learning environment
0,,,,,,,,"Greg Brockman, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John Schulman, Jie Tang, and Wojciech Zaremba. Openai gym, 2016.",./refs/download/2/Chalet: Cornell house agent learning environment.pdf,Chalet: Cornell house agent learning environment
0,"Simon Brodeur, Ethan Perez, Ankesh Anand, Florian Golemo, Luca Celotti, Florian Strub, Jean Rouat, Hugo Larochelle, Aaron C. Courville",HoME: a Household Multimodal Environment,arXiv preprint arXiv:1711.11017,,,2017,,"Simon Brodeur, Ethan Perez, Ankesh Anand, Florian Golemo, Luca Celotti, Florian Strub, Jean Rouat, Hugo Larochelle, and Aaron C. Courville. HoME: a Household Multimodal Environment. arXiv preprint arXiv:1711.11017, 2017.",./refs/download/2/Chalet: Cornell house agent learning environment.pdf,Chalet: Cornell house agent learning environment
0,"Abhishek Das, Samyak Datta, Georgia Gkioxari, Stefan Lee, Devi Parikh, Dhruv Batra",Embodied Question Answering,arXiv preprint arXiv:1711.11543,,,2017,,"Abhishek Das, Samyak Datta, Georgia Gkioxari, Stefan Lee, Devi Parikh, and Dhruv Batra. Embodied Question Answering. arXiv preprint arXiv:1711.11543, 2017.",./refs/download/2/Chalet: Cornell house agent learning environment.pdf,Chalet: Cornell house agent learning environment
0,"Daniel Gordon, Aniruddha Kembhavi, Mohammad Rastegari, Joseph Redmon, Dieter Fox, Ali Farhadi",IQA: Visual Question Answering in Interactive Environments,arXiv preprint arXiv:1712.03316,,,2017,,"Daniel Gordon, Aniruddha Kembhavi, Mohammad Rastegari, Joseph Redmon, Dieter Fox, and Ali Farhadi. IQA: Visual Question Answering in Interactive Environments. arXiv preprint arXiv:1712.03316, 2017.",./refs/download/2/Chalet: Cornell house agent learning environment.pdf,Chalet: Cornell house agent learning environment
0,"Karl Moritz Hermann, Felix Hill, Simon Green, Fumin Wang, Ryan Faulkner, Hubert Soyer, David Szepesvari, Wojciech Marian Czarnecki, Max Jaderberg, Denis Teplyashin, Marcus Wainwright, Chris Apps, Demis Hassabis, Phil Blunsom",Grounded Language Learning in a Simulated 3D World,arXiv preprint arXiv:1706.06551,,,2017,,"Karl Moritz Hermann, Felix Hill, Simon Green, Fumin Wang, Ryan Faulkner, Hubert Soyer, David Szepesvari, Wojciech Marian Czarnecki, Max Jaderberg, Denis Teplyashin, Marcus Wainwright, Chris Apps, Demis Hassabis, and Phil Blunsom. Grounded Language Learning in a Simulated 3D World. arXiv preprint arXiv:1706.06551, 2017.",./refs/download/2/Chalet: Cornell house agent learning environment.pdf,Chalet: Cornell house agent learning environment
0,,,,,,,,"Michaela Jänner, Karthik Narasimhan, and Regina Barzilay. Representation learning for grounded spatial reasoning. CoRR, abs/1707.03938, 2017.",./refs/download/2/Chalet: Cornell house agent learning environment.pdf,Chalet: Cornell house agent learning environment
0,,,,,,,,"Justin Johnson, Bharath Hariharan, Laurens van der Maaten, Li Fei-Fei, C. Lawrence Zitnick, and Ross B. Girshick. CLEVR: A diagnostic dataset for compositional language and elementary visual reasoning. CoRR, abs/1612.06890, 2016.",./refs/download/2/Chalet: Cornell house agent learning environment.pdf,Chalet: Cornell house agent learning environment
0,,,,,,,,"Matthew Johnson, Katja Hofmann, Tim Hutton, and David Bignell. The malmo platform for artificial intelligence experimentation. In International Joint Conferences on Artificial Intelligence, pages 4246",./refs/download/2/Chalet: Cornell house agent learning environment.pdf,Chalet: Cornell house agent learning environment
0,"Michal Kempka, Marek Wydmuch, Grzegorz Runc, Jakub Toczek, Wojciech Jaskowski",Vizdoom: A doom-based AI research platform for visual reinforcement learning,arXiv preprint arXiv:1605.02097,,,2016,,"Michal Kempka, Marek Wydmuch, Grzegorz Runc, Jakub Toczek, and Wojciech Jaskowski. Vizdoom: A doom-based AI research platform for visual reinforcement learning. arXiv preprint arXiv:1605.02097, 2016.",./refs/download/2/Chalet: Cornell house agent learning environment.pdf,Chalet: Cornell house agent learning environment
0,,,,,,,,"Dipendra Misra, John Langford, and Yoav Artzi. Mapping instructions and visual observations to actions with reinforcement learning. In Proceedings of the 2017",./refs/download/2/Chalet: Cornell house agent learning environment.pdf,Chalet: Cornell house agent learning environment
0,,,,,,,,CHALET Type Simulated Simulated Simulated Real Images Simulated Simulated Simulated Number of Environments 45K houses + variations Thousand houses 120 rooms 90 houses 4500,./refs/download/2/Chalet: Cornell house agent learning environment.pdf,Chalet: Cornell house agent learning environment
0,,,,,,,,"Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), 2015.",./refs/download/2/Chalet: Cornell house agent learning environment.pdf,Chalet: Cornell house agent learning environment
0,,,,,,,,"Girshick, R., Donahue, J., Darrell, T., Malik, J.: Rich feature hierarchies for accurate object detection and semantic segmentation. In: CVPR. (2014) 2. Donahue, J., Jia, Y., Vinyals, O., Hoffman, J., Zhang, N., Tzeng, E., Darrell, T.: DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition. arXiv:1310.1531 (2013) 3. Zeiler, M.D., Fergus, R.: Visualizing and understanding convolutional neural networks. In: ECCV. (2014) 16 Mahajan et al. 4. He, K., Gkioxari, G., Dollar, P., Girshick, R.: Mask R-CNN. In: ICCV. (2017) 5. Long, J., Shelhamer, E., Darrell, T.: Fully convolutional networks for semantic segmentation. In: CVPR. (2015) 6. Zhao, H., Shi, J., Qi, X., Wang, X., Jia, J.: Pyramid scene parsing network. In: CVPR. (2017) 7. Cao, Z., Simon, T., Wei, S.E., Sheikh, Y.: Realtime multi-person 2d pose estimation using part affinity fields. In: CVPR. (2017) 8. Papandreou, G., Zhu, T., Kanazawa, N., Toshev, A., Tompson, J., Bregler, C., Murphy, K.: Towards accurate multi-person pose estimation in the wild. In: CVPR. (2017) 9. Carreira, J., Zisserman, A.: Quo vadis, action recognition? a new model and the kinetics dataset. In: CVPR. (2017) 10. Eigen, D., Fergus, R.: Predicting depth, surface normals and semantic labels with a common multi-scale convolutional architecture. In: ICCV. (2015) 11. Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Karpathy, A., Khosla, A., Bernstein, M., Berg, A.C., Fei-Fei, L.: ImageNet Large Scale Visual Recognition Challenge. IJCV (2015) 12. Agrawal, P., Girshick, R., Malik, J.: Analyzing the performance of multilayer neural networks for object recognition. In: ECCV. (2014) 13. Huh, M., Agrawal, P., Efros, A.: What makes ImageNet good for transfer learning? arXiv:1608.08614 (2016) 14. Zhou, B., Lapedriza, A., Khosla, A., Oliva, A., Torralba, A.: Places: A 10 million image database for scene recognition. PAMI (2017) 15. Xie, S., Girshick, R., Dollar, P., Tu, Z., He, K.: Aggregated residual transformations for deep neural networks. In: CVPR. (2017) 16. Joulin, A., van der Maaten, L., Jabri, A., Vasilache, N.: Learning visual features from large weakly supervised data. In: Proceedings of the European Conference on Computer Vision (ECCV), Springer (2016) 67–84 17. Sun, C., Shrivastava, A., Singh, S., Gupta, A.: Revisiting unreasonable effectiveness of data in deep learning era. In: Proc. ICCV. (2017) 18. Lin, T.Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Dollár, P., Zitnick, C.L.: Microsoft COCO: Common objects in context. In: European conference on computer vision, Springer (2014) 740–755 19. Goyal, P., Dollar, P., Girshick, R., Noordhuis, P., Wesolowski, L., Kyrola, A., Tulloch, A., Jia, Y., He, K.: Accurate, large minibatch SGD: Training ImageNet in 1 hour. In: arXiv:1706.02677. (2017) 20. WordNet: About WordNet. http://wordnet.princeton.edu (2010) 21. Welinder, P., Branson, S., Mita, T., Wah, C., Schroff, F., Belongie, S., Perona, P.: Caltech-UCSD Birds 200. Technical report, Caltech (2010) 22. Gordo, A., Almazan, J., Revaud, J., Larlus, D.: Deep image retrieval: Learning global representations for image search. In: arXiv:1604.01325. (2016) 23. Tolias, G., Sicre, R., , Jegou, H.: Particular object retrieval with integral maxpooling of cnn activations. In: ICLR. (2016) 24. He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. In: CVPR. (2016) 25. Huang, G., Liu, Z., Weinberger, K., van der Maaten, L.: Densely connected convolutional networks. In: CVPR. (2017) 26. Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A.: Inception-v4, inception-resnet and the impact of residual connections on learning. In: arXiv:1602.07261. (2016) 27. Ioffe, S., Szegedy, C.: Batch normalization: Accelerating deep network training by reducing internal covariate shift. In: ICML. (2015) Exploring the Limits of Weakly Supervised Pretraining 17 28. He, K., Zhang, X., Ren, S., Sun, J.: Delving deep into rectifiers: Surpassing humanlevel performance on imagenet classification. In: ICCV. (2015) 29. Pathak, D., Girshick, R., Dollár, P., Darrell, T., Hariharan, B.: Learning features by watching objects move. In: CVPR. (2017) 30. Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., Fei-Fei, L.: Imagenet: A large-scale hierarchical image database. In: CVPR. (2009) 31. Zoph, B., Vasudevan, V., Shlens, J., Le, Q.: Learning transferable architectures for scalable image recognition. In: arXiv:1707.07012. (2017) 32. Storck, P., Cisse, M.: Convnets and imagenet beyond accuracy: Explanations, bias detection, adversarial examples and model criticism. In: arXiv:1711.11443. (2017) 33. Misra, I., Zitnick, C.L., Mitchell, M., Girshick, R.: Seeing through the human reporting bias: Visual classifiers from noisy human-centric labels. In: CVPR. (2016) 34. Mikolov, T., Sutskever, I., Chen, K., Corrado, G., Dean, J.: Distributed representations of words and phrases and their compositionality. In: NIPS. (2013) 35. Brysbaert, M., Warriner, A.B., Kuperman, V.: Concreteness ratings for 40 thousand generally known english word lemmas. Behavior Research Methods (2014) 36. Girshick, R., Radosavovic, I., Gkioxari, G., Dollár, P., He, K.: Detectron. https://github.com/facebookresearch/detectron (2018) 37. Lin, T.Y., Dollár, P., Girshick, R., He, K., Hariharan, B., Belongie, S.: Feature pyramid networks for object detection. In: CVPR. (2017) 38. Li, A., Jabri, A., Joulin, A., van der Maaten, L.: Learning visual n-grams from web data. In: Proc. ICCV. (2017) 39. Thomee, B., Shamma, D.A., Friedland, G., Elizalde, B., Ni, K., Poland, D., Borth, D., Li, L.J.: Yfcc100m: The new data in multimedia research. Communications of the ACM 59(2) (2016) 64–73 40. Veit, A., Nickel, M., Belongie, S., van der Maaten, L.: Separating self-expression and visual content in hashtag supervision. In: arXiv 1711.",./refs/download/2/Exploring the limits of weakly supervised pretraining.pdf,Exploring the limits of weakly supervised pretraining
0,,,,,,,," I. Armeni, O. Sener, A. R. Zamir, H. Jiang, I. Brilakis, M. Fischer, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance segmentation
0,,,,,,,," V. Badrinarayanan, A. Kendall, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance segmentation
0,,,,,,,," L. Bertinetto, J. Valmadre, J. F. Henriques, A. Vedaldi, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance segmentation
0,,,,,,,," X. Chen, H. Ma, J. Wan, B. Li, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance segmentation
0,,,,,,,," S. Chopra, R. Hadsell, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance segmentation
0,,,,,,,," A. Dai, A. X. Chang, M. Savva, M. Halber, T. Funkhouser, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance segmentation
0,,,,,,,," A. Dai, C. R. Qi, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance segmentation
0,,,,,,,," J. Dai, K. He, Y. Li, S. Ren, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance segmentation
0,,,,,,,," J. Dai, K. He, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance segmentation
0,,,,,,,, Z. Deng and ,./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance segmentation
0,,,,,,,," A. Frome, Y. Singer, F. Sha, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance segmentation
0,,,,,,,," W. Liu, A. Ranga, A. Tyagi, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance segmentation
0,,,,,,,," R. Girshick, J. Donahue, T. Darrell, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance segmentation
0,,,,,,,," X. Han, T. Leung, Y. Jia, R. Sukthankar, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance segmentation
0,,,,,,,," X. Han, Z. Li, H. Huang, E. Kalogerakis, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance segmentation
0,,,,,,,," K. He, G. Gkioxari, P. Dollar, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance segmentation
0,,,,,,,, D. Kingma and ,./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance segmentation
0,,,,,,,," G. Koch, R. Zemel, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance segmentation
0,,,,,,,," A. Krizhevsky, I. Sutskever, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance segmentation
0,,,,,,,," L. Leal-Taix, C. Canton-Ferrer, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance segmentation
0,,,,,,,," Y. Li, H. Qi, J. Dai, X. Ji, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance segmentation
0,,,,,,,," P. Dollar, R. Girshick, K. He, B. Hariharan, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance segmentation
0,,,,,,,," P. Goyal, R. Girshick, K. He, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance segmentation
0,,,,,,,, D. Maturana and ,./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance segmentation
0,,,,,,,, A. Newell and ,./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance segmentation
0,,,,,,,, G. Pang and ,./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance segmentation
0,,,,,,,," G. Pang, R. Qiu, J. Huang, S. You, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance segmentation
0,,,,,,,," P. O. Pinheiro, R. Collobert, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance segmentation
0,,,,,,,," R. Collobert, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance segmentation
0,,,,,,,," C. R. Qi, H. Su, K. Mo, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance segmentation
0,,,,,,,," C. R. Qi, H. Su, M. Nießner, A. Dai, M. Yan, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance segmentation
0,,,,,,,," C. R. Qi, L. Yi, H. Su, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance segmentation
0,,,,,,,," X. Qi, R. Liao, J. Jia, S. Fidler, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance segmentation
0,,,,,,,," J. Redmon, S. Divvala, R. Girshick, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance segmentation
0,,,,,,,, J. Redmon and ,./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance segmentation
0,,,,,,,," S. Ren, K. He, R. Girshick, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance segmentation
0,,,,,,,, Z. Ren and ,./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance segmentation
0,,,,,,,," G. Riegler, A. O. Ulusoy, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance segmentation
0,,,,,,,," N. Silberman, D. Hoiem, P. Kohli, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance segmentation
0,,,,,,,," E. Simo-Serra, E. Trulls, L. Ferraz, I. Kokkinos, P. Fua, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance segmentation
0,,,,,,,, S. Song and ,./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance segmentation
0,,,,,,,, S. Song and ,./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance segmentation
0,,,,,,,," S. Song, F. Yu, A. Zeng, A. X. Chang, M. Savva, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance segmentation
0,,,,,,,," M. Tatarchenko, A. Dosovitskiy, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance segmentation
0,,,,,,,," W. Wang, Q. Huang, S. You, C. Yang, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance segmentation
0,,,,,,,, K. Q. Weinberger and ,./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance segmentation
0,,,,,,,," Z. Wu, S. Song, A. Khosla, F. Yu, L. Zhang, X. Tang, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance segmentation
0,,,,,,,," D. Yi, Z. Lei, S. Liao, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance segmentation
0,,,,,,,," D. Ciregan, U. Meier, and ",./refs/download/2/Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms.pdf,Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms
0,,,,,,,," G. Cohen, S. Afshar, J. Tapson, and ",./refs/download/2/Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms.pdf,Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms
0,,,,,,,," K. Li, and ",./refs/download/2/Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms.pdf,Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms
0,,,,,,,, A. Krizhevsky and ,./refs/download/2/Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms.pdf,Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms
0,,,,,,,," Y. LeCun, L. Bottou, Y. Bengio, and ",./refs/download/2/Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms.pdf,Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms
0,,,,,,,," L. Wan, M. Zeiler, S. Zhang, Y. L. Cun, and ",./refs/download/2/Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms.pdf,Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms
0,,,,,,,," Y. Xu, T. Fan, M. Xu, L. Zeng and ",./refs/download/2/SpiderCNN: Deep learning on point sets with parameterized convolutional filters.pdf,SpiderCNN: Deep learning on point sets with parameterized convolutional filters
0,,,,,,,," Y. Xu, T. Fan, M. Xu, L. Zeng and ",./refs/download/2/SpiderCNN: Deep learning on point sets with parameterized convolutional filters.pdf,SpiderCNN: Deep learning on point sets with parameterized convolutional filters
0,,,,,,,," Y. Xu, T. Fan, M. Xu, L. Zeng and ",./refs/download/2/SpiderCNN: Deep learning on point sets with parameterized convolutional filters.pdf,SpiderCNN: Deep learning on point sets with parameterized convolutional filters
0,,,,,,,," Y. Xu, T. Fan, M. Xu, L. Zeng and ",./refs/download/2/SpiderCNN: Deep learning on point sets with parameterized convolutional filters.pdf,SpiderCNN: Deep learning on point sets with parameterized convolutional filters
0,,,,,,,," Y. Xu, T. Fan, M. Xu, L. Zeng and ",./refs/download/2/SpiderCNN: Deep learning on point sets with parameterized convolutional filters.pdf,SpiderCNN: Deep learning on point sets with parameterized convolutional filters
0,,,,,,,," Y. Xu, T. Fan, M. Xu, L. Zeng and ",./refs/download/2/SpiderCNN: Deep learning on point sets with parameterized convolutional filters.pdf,SpiderCNN: Deep learning on point sets with parameterized convolutional filters
0,,,,,,,," Y. Xu, T. Fan, M. Xu, L. Zeng and ",./refs/download/2/SpiderCNN: Deep learning on point sets with parameterized convolutional filters.pdf,SpiderCNN: Deep learning on point sets with parameterized convolutional filters
0,,,,,,,," Y. Xu, T. Fan, M. Xu, L. Zeng and ",./refs/download/2/SpiderCNN: Deep learning on point sets with parameterized convolutional filters.pdf,SpiderCNN: Deep learning on point sets with parameterized convolutional filters
0,"J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, L. Fei-Fei",ImageNet: A Large-Scale Hierarchical Image Database,CVPR09,,,2009,,"J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei, “ImageNet: A Large-Scale Hierarchical Image Database,” in CVPR09, 2009.",./refs/download/2/Imagenet: A large-scale hierarchical image database.pdf,Imagenet: A large-scale hierarchical image database
0,C. Fellbaum,WordNet: An Electronic Lexical Database, Bradford Books,,,1998,,"C. Fellbaum, WordNet: An Electronic Lexical Database. Bradford Books, 1998.",./refs/download/2/Imagenet: A large-scale hierarchical image database.pdf,Imagenet: A large-scale hierarchical image database
0,"P. Salembier and , T. Sikora",Introduction to MPEG-7: Multimedia Content Description Interface, B,. Manjunath,,2002,,"P. Salembier and T. Sikora, Introduction to MPEG-7: Multimedia Content Description Interface, B. Manjunath, Ed. New York, NY, USA: John Wiley & Sons, Inc., 2002.",./refs/download/2/Imagenet: A large-scale hierarchical image database.pdf,Imagenet: A large-scale hierarchical image database
0,"B. S. Manjunath, J. R. Ohm, V. V. Vasudevan, A. Yamada",Color and texture descriptors, IEEE Transactions on Circuits and Systems for Video Technology,,,2001,,"B. S. Manjunath, J. R. Ohm, V. V. Vasudevan, and A. Yamada, “Color and texture descriptors,” IEEE Transactions on Circuits and Systems for Video Technology, vol. 11, no. 6, pp. 703–715, Jun 2001.",./refs/download/2/Imagenet: A large-scale hierarchical image database.pdf,Imagenet: A large-scale hierarchical image database
0,"S. Jeannin and , A. Divakaran",Mpeg-7 visual motion descriptors, IEEE Transactions on Circuits and Systems for Video Technology,,,2001,,"S. Jeannin and A. Divakaran, “Mpeg-7 visual motion descriptors,” IEEE Transactions on Circuits and Systems for Video Technology, vol. 11, no. 6, pp. 720–724, Jun 2001.",./refs/download/2/Imagenet: A large-scale hierarchical image database.pdf,Imagenet: A large-scale hierarchical image database
0,"C. S. Won, D. K. Park, Y. S. Jeon",Efficient use of mpeg-7 edge histogram descriptor, ETRI Journal,,,2002,,"C. S. Won, D. K. Park, and Y. S. Jeon, “Efficient use of mpeg-7 edge histogram descriptor,” ETRI Journal, vol. 24, no. 1, pp. 23–30, 2002.",./refs/download/2/Imagenet: A large-scale hierarchical image database.pdf,Imagenet: A large-scale hierarchical image database
0,"Y. Guo, Y. Liu, A. Oerlemans, S. Lao, S. Wu, M.S. Lew",Deep learning for visual understanding: A review,"Neurocomputing, ",,187 ,2016,27-48,"Y. Guo, Y. Liu, A. Oerlemans, S. Lao, S. Wu, M.S. Lew, Deep learning for visual understanding: A review, Neurocomputing, 187 (2016) 27-48","./refs/download/2/PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database.pdf","PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"W. Rawat, Z. Wang",Deep convolutional neural networks for image classification: A comprehensive review,"Neural computation, ",,29 ,2017,2352-2449,"W. Rawat, Z. Wang, Deep convolutional neural networks for image classification: A comprehensive review, Neural computation, 29 (2017) 2352-2449","./refs/download/2/PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database.pdf","PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, L. Fei-Fei",Imagenet: A large-scale hierarchical image database,,,,2009,,"J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, L. Fei-Fei, Imagenet: A large-scale hierarchical image database, 2009","./refs/download/2/PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database.pdf","PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"Z. Liu, P. Luo, S. Qiu, X. Wang, X. Tang",Deepfashion: Powering robust clothes recognition and retrieval with rich annotations,"Proceedings of the IEEE conference on computer vision and pattern recognition, ",,,2016,,"Z. Liu, P. Luo, S. Qiu, X. Wang, X. Tang, Deepfashion: Powering robust clothes recognition and retrieval with rich annotations, Proceedings of the IEEE conference on computer vision and pattern recognition, 2016","./refs/download/2/PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database.pdf","PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,,,,,,,,"Y. Ge, R. Zhang, X. Wang, X. Tang, P. Luo, Deepfashion2: A versatile benchmark for detection, pose estimation, segmentation and re-identification of clothing images, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2019","./refs/download/2/PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database.pdf","PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"Z. Wu, S. Song, A. Khosla, F. Yu, L. Zhang, X. Tang, J. Xiao",3d shapenets: A deep representation for volumetric shapes,"Proceedings of the IEEE conference on computer vision and pattern recognition, ",,,2015,,"Z. Wu, S. Song, A. Khosla, F. Yu, L. Zhang, X. Tang, J. Xiao, 3d shapenets: A deep representation for volumetric shapes, Proceedings of the IEEE conference on computer vision and pattern recognition, 2015","./refs/download/2/PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database.pdf","PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"M. Aubry, D. Maturana, A.A. Efros, B.C. Russell, J. Sivic",Seeing 3d chairs: exemplar part-based 2d-3d alignment using a large dataset of cad models,"Proceedings of the IEEE conference on computer vision and pattern recognition, ",,,2014,,"M. Aubry, D. Maturana, A.A. Efros, B.C. Russell, J. Sivic, Seeing 3d chairs: exemplar part-based 2d-3d alignment using a large dataset of cad models, Proceedings of the IEEE conference on computer vision and pattern recognition, 2014","./refs/download/2/PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database.pdf","PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"B. de Bruijn, T.A. Nguyen, D. Bucur, K. Tei",Benchmark Datasets for Fault Detection and Classification in Sensor Data,"SENSORNETS, ",,,2016,,"B. de Bruijn, T.A. Nguyen, D. Bucur, K. Tei, Benchmark Datasets for Fault Detection and Classification in Sensor Data, SENSORNETS, 2016","./refs/download/2/PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database.pdf","PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"T. Karras, S. Laine, T. Aila",A style-based generator architecture for generative adversarial networks,"Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, ",,,2019,,"T. Karras, S. Laine, T. Aila, A style-based generator architecture for generative adversarial networks, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2019","./refs/download/2/PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database.pdf","PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"R. Vemulapalli, A. Agarwala",A compact embedding for facial expression similarity,"Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, ",,,2019,,"R. Vemulapalli, A. Agarwala, A compact embedding for facial expression similarity, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2019","./refs/download/2/PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database.pdf","PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"K. Mo, S. Zhu, A.X. Chang, L. Yi, S. Tripathi, L.J. Guibas, H. Su",Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding,"Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, ",,,2019,,"K. Mo, S. Zhu, A.X. Chang, L. Yi, S. Tripathi, L.J. Guibas, H. Su, Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2019","./refs/download/2/PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database.pdf","PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"J. Krause, M. Stark, J. Deng, L. Fei-Fei",3d object representations for fine-grained categorization,"Proceedings of the IEEE international conference on computer vision workshops, ",,,2013,,"J. Krause, M. Stark, J. Deng, L. Fei-Fei, 3d object representations for fine-grained categorization, Proceedings of the IEEE international conference on computer vision workshops, 2013","./refs/download/2/PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database.pdf","PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"R. He, C. Lin, J. McAuley",Fashionista: A fashion-aware graphical system for exploring visually similar items,"Proceedings of the 25th International Conference Companion on World Wide Web, ",,,2016,,"R. He, C. Lin, J. McAuley, Fashionista: A fashion-aware graphical system for exploring visually similar items, Proceedings of the 25th International Conference Companion on World Wide Web, 2016","./refs/download/2/PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database.pdf","PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"X. Zou, X. Kong, W. Wong, C. Wang, Y. Liu, Y. Cao",Fashionai: A hierarchical dataset for fashion understanding,"Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops, ",,,2019,,"X. Zou, X. Kong, W. Wong, C. Wang, Y. Liu, Y. Cao, Fashionai: A hierarchical dataset for fashion understanding, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops, 2019","./refs/download/2/PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database.pdf","PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"H. Xiao, K. Rasul, R. Vollgraf",Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms,"arXiv preprint arXiv:1708.07747, ",,,2017,,"H. Xiao, K. Rasul, R. Vollgraf, Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms, arXiv preprint arXiv:1708.07747, (2017)","./refs/download/2/PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database.pdf","PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,,,,,,,,"B. Loni, L.Y. Cheung, M. Riegler, A. Bozzon, L. Gottlieb, M. Larson, Fashion 1000","./refs/download/2/PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database.pdf","PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"N. Rostamzadeh, S. Hosseini, T. Boquet, W. Stokowiec, Y. Zhang, C. Jauvin, C. Pal",Fashion-gen: The generative fashion dataset and challenge,"arXiv preprint arXiv:1806.08317, ",,,2018,,"N. Rostamzadeh, S. Hosseini, T. Boquet, W. Stokowiec, Y. Zhang, C. Jauvin, C. Pal, Fashion-gen: The generative fashion dataset and challenge, arXiv preprint arXiv:1806.08317, (2018)","./refs/download/2/PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database.pdf","PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"K. Simonyan, A. Zisserman",Very deep convolutional networks for large-scale image recognition,"arXiv preprint arXiv:1409.1556, ",,,2014,,"K. Simonyan, A. Zisserman, Very deep convolutional networks for large-scale image recognition, arXiv preprint arXiv:1409.1556, (2014)","./refs/download/2/PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database.pdf","PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, A. Rabinovich",Going deeper with convolutions,"Proceedings of the IEEE conference on computer vision and pattern recognition, ",,,2015,,"C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, A. Rabinovich, Going deeper with convolutions, Proceedings of the IEEE conference on computer vision and pattern recognition, 2015","./refs/download/2/PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database.pdf","PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"K. He, X. Zhang, S. Ren, J. Sun",Deep residual learning for image recognition,"Proceedings of the IEEE conference on computer vision and pattern recognition, ",,,2016,,"K. He, X. Zhang, S. Ren, J. Sun, Deep residual learning for image recognition, Proceedings of the IEEE conference on computer vision and pattern recognition, 2016","./refs/download/2/PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database.pdf","PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"G. Huang, Z. Liu, L. Van Der Maaten, K.Q. Weinberger",Densely connected convolutional networks,"Proceedings of the IEEE conference on computer vision and pattern recognition, ",,,2017,,"G. Huang, Z. Liu, L. Van Der Maaten, K.Q. Weinberger, Densely connected convolutional networks, Proceedings of the IEEE conference on computer vision and pattern recognition, 2017","./refs/download/2/PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database.pdf","PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"M. Tan, Q. Le",Efficientnet: Rethinking model scaling for convolutional neural networks,"International Conference on Machine Learning, ","PMLR, ",,2019,,"M. Tan, Q. Le, Efficientnet: Rethinking model scaling for convolutional neural networks, International Conference on Machine Learning, PMLR, 2019","./refs/download/2/PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database.pdf","PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"L. Yuan, T. Wang, X. Zhang, F.E. Tay, Z. Jie, W. Liu, J. Feng",Central similarity quantization for efficient image and video retrieval,"Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, ",,,2020,,"L. Yuan, T. Wang, X. Zhang, F.E. Tay, Z. Jie, W. Liu, J. Feng, Central similarity quantization for efficient image and video retrieval, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2020","./refs/download/2/PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database.pdf","PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"Z. Cao, M. Long, J. Wang, P.S. Yu",Hashnet: Deep learning to hash by continuation,"Proceedings of the IEEE international conference on computer vision, ",,,2017,,"Z. Cao, M. Long, J. Wang, P.S. Yu, Hashnet: Deep learning to hash by continuation, Proceedings of the IEEE international conference on computer vision, 2017","./refs/download/2/PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database.pdf","PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,,,,,,,,"A. Ng, M. Jordan, Y. Weiss, On Spectral Clustering: Analysis and an algorithm, in: T. Dietterich, S. Becker, Z. Ghahramani (Eds.) Advances in Neural Information Processing Systems, MIT Press, 2002","./refs/download/2/PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database.pdf","PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"H. Zhao, H. Liu, Y. Fu",Incomplete multi-modal visual data grouping,"Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence, ",,,2016,,"H. Zhao, H. Liu, Y. Fu, Incomplete multi-modal visual data grouping, Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence, 2016","./refs/download/2/PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database.pdf","PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"M. Hu, S. Chen",Doubly Aligned Incomplete Multi-view Clustering,"International Joint Conference on Artificial Intelligence, ",,,2018,,"M. Hu, S. Chen, Doubly Aligned Incomplete Multi-view Clustering, International Joint Conference on Artificial Intelligence, 2018","./refs/download/2/PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database.pdf","PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"J. Wen, Y. Xu, H. Liu",Incomplete Multiview Spectral Clustering With Adaptive Graph Learning,"IEEE Transactions on Cybernetics, ",,50 ,2020,1418-1429,"J. Wen, Y. Xu, H. Liu, Incomplete Multiview Spectral Clustering With Adaptive Graph Learning, IEEE Transactions on Cybernetics, 50 (2020) 1418-1429","./refs/download/2/PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database.pdf","PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"J. Guo, J. Ye",Anchors bring ease: An embarrassingly simple approach to partial multi-view clustering,"Proceedings of the AAAI Conference on Artificial Intelligence, ",,,2019,,"J. Guo, J. Ye, Anchors bring ease: An embarrassingly simple approach to partial multi-view clustering, Proceedings of the AAAI Conference on Artificial Intelligence, 2019","./refs/download/2/PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database.pdf","PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"E. Amigó, J. Gonzalo, J. Artiles, F. Verdejo",A comparison of extrinsic clustering evaluation metrics based on formal constraints,"Information retrieval, ",,12 ,2009,461-486,"E. Amigó, J. Gonzalo, J. Artiles, F. Verdejo, A comparison of extrinsic clustering evaluation metrics based on formal constraints, Information retrieval, 12 (2009) 461-486","./refs/download/2/PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database.pdf","PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"K. Zhan, X. Chang, J. Guan, L. Chen, Z. Ma, Y. Yang",Adaptive structure discovery for multimedia analysis using multiple features,"IEEE transactions on cybernetics, ",,49 ,2018,1826-1834,"K. Zhan, X. Chang, J. Guan, L. Chen, Z. Ma, Y. Yang, Adaptive structure discovery for multimedia analysis using multiple features, IEEE transactions on cybernetics, 49 (2018) 1826-1834","./refs/download/2/PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database.pdf","PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database"
0,"R. Hu, W. Li, O. Van Kaick, A. Shamir, H. Zhang, H. Huang",Learning to predict part mobility from a single static snapshot, ACM Transactions on Graphics (TOG),,,2017,36,"R. Hu, W. Li, O. Van Kaick, A. Shamir, H. Zhang, and H. Huang. Learning to predict part mobility from a single static snapshot. ACM Transactions on Graphics (TOG), 36(6):227, 2017.",./refs/download/2/Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding
0,"R. Hu, O. van Kaick, B. Wu, H. Huang, A. Shamir, H. Zhang",Learning how objects function via co-analysis of interactions, ACM Transactions on Graphics (TOG),,,2016,35,"R. Hu, O. van Kaick, B. Wu, H. Huang, A. Shamir, and H. Zhang. Learning how objects function via co-analysis of interactions. ACM Transactions on Graphics (TOG), 35(4):47, 2016.",./refs/download/2/Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding
0,"R. Hu, Z. Yan, J. Zhang, O. van Kaick, A. Shamir, H. Zhang, H. Huang",Predictive and generative neural networks for object functionality, In Computer Graphics Forum (Eurographics State-of-the-art report),,,2018,,"R. Hu, Z. Yan, J. Zhang, O. van Kaick, A. Shamir, H. Zhang, and H. Huang. Predictive and generative neural networks for object functionality. In Computer Graphics Forum (Eurographics State-of-the-art report), volume 37, pages 603– 624, 2018.",./refs/download/2/Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding
0,"J. Huang, H. Su, L. Guibas",Robust watertight manifold surface generation method for shapenet models, arXiv preprint arXiv:,,,1802,,"J. Huang, H. Su, and L. Guibas. Robust watertight manifold surface generation method for shapenet models. arXiv preprint arXiv:1802.",./refs/download/2/Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding
0,"A. Jain, T. Thormählen, T. Ritschel, H.-P. Seidel",Exploring shape variations by 3d-model decomposition and partbased recombination, In Computer Graphics Forum,,,2012,,"A. Jain, T. Thormählen, T. Ritschel, and H.-P. Seidel. Exploring shape variations by 3d-model decomposition and partbased recombination. In Computer Graphics Forum, volume 31, pages 631–640. Wiley Online Library, 2012.",./refs/download/2/Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding
0,"E. Kalogerakis, A. Hertzmann, K. Singh",Learning 3D mesh segmentation and labeling, ACM Transactions on Graphics (TOG),,,2010,29,"E. Kalogerakis, A. Hertzmann, and K. Singh. Learning 3D mesh segmentation and labeling. ACM Transactions on Graphics (TOG), 29(4):102, 2010.",./refs/download/2/Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding
0,"V. G. Kim, S. Chaudhuri, L. Guibas, T. Funkhouser",Shape2pose: Human-centric shape analysis, ACM Transactions on Graphics (TOG),,,2014,33,"V. G. Kim, S. Chaudhuri, L. Guibas, and T. Funkhouser. Shape2pose: Human-centric shape analysis. ACM Transactions on Graphics (TOG), 33(4):120, 2014.",./refs/download/2/Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding
0,"R. Klokov and , V. Lempitsky",Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models, In Computer Vision (ICCV),,,2017,2017,"R. Klokov and V. Lempitsky. Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models. In Computer Vision (ICCV), 2017 IEEE International Conference on, pages 863–872. IEEE, 2017.",./refs/download/2/Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding
0,"E. Kolve, R. Mottaghi, D. Gordon, Y. Zhu, A. Gupta, A. Farhadi",Ai2-thor: An interactive 3d environment for visual ai, arXiv preprint arXiv:,,,1712,,"E. Kolve, R. Mottaghi, D. Gordon, Y. Zhu, A. Gupta, and A. Farhadi. Ai2-thor: An interactive 3d environment for visual ai. arXiv preprint arXiv:1712.",./refs/download/2/Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding
0,"P. Krähenbühl and , V. Koltun",Parameter learning and convergent inference for dense random fields, In International Conference on Machine Learning,,,2013,,"P. Krähenbühl and V. Koltun. Parameter learning and convergent inference for dense random fields. In International Conference on Machine Learning, pages 513–521, 2013.",./refs/download/2/Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding
0,H. W. Kuhn,The hungarian method for the assignment problem, Naval research logistics quarterly,,,1955,,"H. W. Kuhn. The hungarian method for the assignment problem. Naval research logistics quarterly, 2(1-2):83–97, 1955.",./refs/download/2/Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding
0,"T. Le and , Y. Duan",PointGrid: A deep network for 3D shape understanding, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,,,2018,,"T. Le and Y. Duan. PointGrid: A deep network for 3D shape understanding. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 9204– 9214, 2018.",./refs/download/2/Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding
0,"J. Li, B. M. Chen, G. H. Lee",SO-Net: Self-organizing network for point cloud analysis, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,,,2018,,"J. Li, B. M. Chen, and G. H. Lee. SO-Net: Self-organizing network for point cloud analysis. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 9397–9406, 2018.",./refs/download/2/Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding
0,"J. Li, K. Xu, S. Chaudhuri, E. Yumer, H. Zhang, L. Guibas",Grass: Generative recursive autoencoders for shape structures, ACM Transactions on Graphics (TOG),,,2017,36,"J. Li, K. Xu, S. Chaudhuri, E. Yumer, H. Zhang, and L. Guibas. Grass: Generative recursive autoencoders for shape structures. ACM Transactions on Graphics (TOG), 36(4):52, 2017.",./refs/download/2/Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding
0,"Y. Li, R. Bu, M. Sun, B. Chen",PointCNN: Convolution on X -transformed points, Advances in neural information processing systems (NIPS),,,2018,,"Y. Li, R. Bu, M. Sun, and B. Chen. PointCNN: Convolution on X -transformed points. Advances in neural information processing systems (NIPS), 2018.",./refs/download/2/Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding
0,"Z. Liu, W. T. Freeman, J. B. Tenenbaum, J. Wu",Physical primitive decomposition, arXiv preprint arXiv:,,,1809,,"Z. Liu, W. T. Freeman, J. B. Tenenbaum, and J. Wu. Physical primitive decomposition. arXiv preprint arXiv:1809.",./refs/download/2/Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding
0,"M. Attene, S. Katz, M. Mortara, G. Patané, M. Spagnuolo, A. Tal",Mesh segmentation-a comparative study, In Shape Modeling and Applications,,,2006,,"M. Attene, S. Katz, M. Mortara, G. Patané, M. Spagnuolo, and A. Tal. Mesh segmentation-a comparative study. In Shape Modeling and Applications, 2006.",./refs/download/2/Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding
0,"H. Benhabiles, J.-P. Vandeborre, G. Lavoué, M. Daoudi",A framework for the objective evaluation of segmentation algorithms using a ground-truth of human segmented 3Dmodels, In IEEE International Conference on Shape Modeling and Applications (SMI),,,2009,,"H. Benhabiles, J.-P. Vandeborre, G. Lavoué, and M. Daoudi. A framework for the objective evaluation of segmentation algorithms using a ground-truth of human segmented 3Dmodels. In IEEE International Conference on Shape Modeling and Applications (SMI), pages Session–5, 2009.",./refs/download/2/Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding
0,A. X. Chang,T, Funkhouser,,,1512,,"A. X. Chang, T. Funkhouser, L. Guibas, P. Hanrahan, Q. Huang, Z. Li, S. Savarese, M. Savva, S. Song, H. Su, et al. ShapeNet: An information-rich 3D model repository. arXiv preprint arXiv:1512.",./refs/download/2/Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding
0,"A. X. Chang, R. Mago, P. Krishna, M. Savva, C. Fellbaum",Linking WordNet to 3D shapes, In Global WordNet Conference,,,2018,,"A. X. Chang, R. Mago, P. Krishna, M. Savva, and C. Fellbaum. Linking WordNet to 3D shapes. In Global WordNet Conference, 2018.",./refs/download/2/Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding
0,"X. Chen, A. Golovinskiy, T. Funkhouser",A benchmark for 3D mesh segmentation, ACM Transactions on Graphics (Proc,. SIGGRAPH),,2009,,"X. Chen, A. Golovinskiy, and T. Funkhouser. A benchmark for 3D mesh segmentation. ACM Transactions on Graphics (Proc. SIGGRAPH), 2009.",./refs/download/2/Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding
0,"B. Graham, M. Engelcke, L. van der Maaten",3D semantic segmentation with submanifold sparse convolutional networks, Proceedings of the IEEE Computer Vision and Pattern Recognition (CVPR),,,2018,,"B. Graham, M. Engelcke, and L. van der Maaten. 3D semantic segmentation with submanifold sparse convolutional networks. Proceedings of the IEEE Computer Vision and Pattern Recognition (CVPR), pages 18–22, 2018.",./refs/download/2/Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding
0,P. Hermosilla,T, Ritschel,,,1806,,"P. Hermosilla, T. Ritschel, P.-P. Vázquez, À. Vinacua, and T. Ropinski. Monte carlo convolution for learning on non-uniformly sampled point clouds. arXiv preprint arXiv:1806.",./refs/download/2/Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding
0,"D. D. Hoffman and , W. A. Richards",Parts of recognition, Cognition,,,1984,18,"D. D. Hoffman and W. A. Richards. Parts of recognition. Cognition, 18(1-3):65–96, 1984.",./refs/download/2/Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding
0,"R. Hu, L. Fan, L. Liu",Co-segmentation of 3D shapes via subspace clustering, In Computer graphics forum,,,1713,,"R. Hu, L. Fan, and L. Liu. Co-segmentation of 3D shapes via subspace clustering. In Computer graphics forum, volume 31, pages 1703–1713.",./refs/download/2/Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding
0,"C. Yan, D. Misra, A. Bennnett, A. Walsman, Y. Bisk, Y. Artzi",Chalet: Cornell house agent learning environment, arXiv preprint arXiv:,,,1801,,"C. Yan, D. Misra, A. Bennnett, A. Walsman, Y. Bisk, and Y. Artzi. Chalet: Cornell house agent learning environment. arXiv preprint arXiv:1801.",./refs/download/2/Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding
0,"L. Yi, L. Guibas, A. Hertzmann, V. G. Kim, H. Su, E. Yumer",Learning hierarchical shape segmentation and labeling from online repositories, ACM Transactions on Graphics (Proc,. SIGGRAPH Asia),,2017,,"L. Yi, L. Guibas, A. Hertzmann, V. G. Kim, H. Su, and E. Yumer. Learning hierarchical shape segmentation and labeling from online repositories. ACM Transactions on Graphics (Proc. SIGGRAPH Asia), 2017.",./refs/download/2/Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding
0,L. Yi,V, G,. Kim,,2016,,"L. Yi, V. G. Kim, D. Ceylan, I. Shen, M. Yan, H. Su, C. Lu, Q. Huang, A. Sheffer, L. Guibas, et al. A scalable active framework for region annotation in 3D shape collections. ACM Transactions on Graphics (TOG), 35(6):210, 2016.",./refs/download/2/Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding
0,"L. Yi, H. Su, X. Guo, L. J. Guibas",SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR),,,2017,,"L. Yi, H. Su, X. Guo, and L. J. Guibas. SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 6584–6592, 2017.",./refs/download/2/Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding
0,"Y. Zhu, D. Gordon, E. Kolve, D. Fox, L. Fei-Fei, A. Gupta, R. Mottaghi, A. Farhadi",Visual semantic planning using deep successor representations, arXiv preprint ArXiv:,,,1705,,"Y. Zhu, D. Gordon, E. Kolve, D. Fox, L. Fei-Fei, A. Gupta, R. Mottaghi, and A. Farhadi. Visual semantic planning using deep successor representations. arXiv preprint ArXiv:1705.",./refs/download/2/Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding
0,"M. Ovsjanikov, W. Li, L. Guibas, N. J. Mitra",Exploration of continuous variability in collections of 3d shapes, In ACM Transactions on Graphics (TOG),,,2011,,"M. Ovsjanikov, W. Li, L. Guibas, and N. J. Mitra. Exploration of continuous variability in collections of 3d shapes. In ACM Transactions on Graphics (TOG), volume 30, page 33. ACM, 2011.",./refs/download/2/Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding
0,"X. Puig, K. Ra, M. Boben, J. Li, T. Wang, S. Fidler, A. Torralba",Virtualhome: Simulating household activities via programs, In CVPR,,,2018,,"X. Puig, K. Ra, M. Boben, J. Li, T. Wang, S. Fidler, and A. Torralba. Virtualhome: Simulating household activities via programs. In CVPR, 2018.",./refs/download/2/Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding
0,"C. R. Qi, H. Su, K. Mo, L. J. Guibas",PointNet: Deep learning on point sets for 3D classification and segmentation, In Proc,. Computer Vision and Pattern Recognition (CVPR),,2017,,"C. R. Qi, H. Su, K. Mo, and L. J. Guibas. PointNet: Deep learning on point sets for 3D classification and segmentation. In Proc. Computer Vision and Pattern Recognition (CVPR), IEEE, volume 1, page 4, 2017.",./refs/download/2/Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding
0,"C. R. Qi, L. Yi, H. Su, L. J. Guibas",PointNet++: Deep hierarchical feature learning on point sets in a metric space, In Advances in Neural Information Processing Systems,,,2017,,"C. R. Qi, L. Yi, H. Su, and L. J. Guibas. PointNet++: Deep hierarchical feature learning on point sets in a metric space. In Advances in Neural Information Processing Systems, pages 5099–5108, 2017.",./refs/download/2/Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding
0,"H. Su, V. Jampani, D. Sun, S. Maji, E. Kalogerakis, M.-H. Yang, J. Kautz",SplatNet: Sparse lattice networks for point cloud processing, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,,,2018,,"H. Su, V. Jampani, D. Sun, S. Maji, E. Kalogerakis, M.-H. Yang, and J. Kautz. SplatNet: Sparse lattice networks for point cloud processing. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2530–2539, 2018.",./refs/download/2/Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding
0,"M. Sung, H. Su, R. Yu, L. Guibas",Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions, Advances in neural information processing systems (NIPS),,,2018,,"M. Sung, H. Su, R. Yu, and L. Guibas. Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions. Advances in neural information processing systems (NIPS), 2018.",./refs/download/2/Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding
0,"W. Wang, R. Yu, Q. Huang, U. Neumann",SGPN: Similarity group proposal network for 3D point cloud instance segmentation, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR),,,2018,,"W. Wang, R. Yu, Q. Huang, and U. Neumann. SGPN: Similarity group proposal network for 3D point cloud instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 2569–2578, 2018.",./refs/download/2/Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding
0,"X. Wang, B. Zhou, H. Fang, X. Chen, Q. Zhao, K. Xu",Learning to group and label fine-grained shape components, ACM Transactions on Graphics (SIGGRAPH Asia 2018),,,2018,37,"X. Wang, B. Zhou, H. Fang, X. Chen, Q. Zhao, and K. Xu. Learning to group and label fine-grained shape components. ACM Transactions on Graphics (SIGGRAPH Asia 2018), 37(6), 2018.",./refs/download/2/Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding
0,"Y. Wang, S. Asafi, O. Van Kaick, H. Zhang, D. Cohen-Or, B. Chen",Active co-analysis of a set of shapes, ACM Transactions on Graphics (TOG),,,2012,31,"Y. Wang, S. Asafi, O. Van Kaick, H. Zhang, D. Cohen-Or, and B. Chen. Active co-analysis of a set of shapes. ACM Transactions on Graphics (TOG), 31(6):165, 2012.",./refs/download/2/Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding
0,"Y. Wang, Y. Sun, Z. Liu, S. E. Sarma, M. M. Bronstein, J. M. Solomon",Dynamic graph cnn for learning on point clouds, arXiv preprint arXiv:,,,1801,,"Y. Wang, Y. Sun, Z. Liu, S. E. Sarma, M. M. Bronstein, and J. M. Solomon. Dynamic graph cnn for learning on point clouds. arXiv preprint arXiv:1801.",./refs/download/2/Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding
0,"Z. Wang and , F. Lu",VoxSegNet: Volumetric CNNs for semantic part segmentation of 3D shapes, arXiv preprint arXiv:1809,.00226,,2018,,"Z. Wang and F. Lu. VoxSegNet: Volumetric CNNs for semantic part segmentation of 3D shapes. arXiv preprint arXiv:1809.00226, 2018.",./refs/download/2/Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding
0,"Z. Wu, X. Wang, D. Lin, D. Lischinski, D. Cohen-Or, H. Huang",Structure-aware generative network for 3d-shape modeling, arXiv preprint arXiv:,,,1808,,"Z. Wu, X. Wang, D. Lin, D. Lischinski, D. Cohen-Or, and H. Huang. Structure-aware generative network for 3d-shape modeling. arXiv preprint arXiv:1808.",./refs/download/2/Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding
0,"Y. Xu, T. Fan, M. Xu, L. Zeng, Y. Qiao",SpiderCNN: Deep learning on point sets with parameterized convolutional filters, European Conference on Computer Vision (ECCV),,,2018,,"Y. Xu, T. Fan, M. Xu, L. Zeng, and Y. Qiao. SpiderCNN: Deep learning on point sets with parameterized convolutional filters. European Conference on Computer Vision (ECCV), 2018.",./refs/download/2/Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine-grained and hierarchical part-level 3d object understanding
0,,,,,,,," R. Hu, Z. Yan, J. Zhang, O. van Kaick, A. Shamir, H. Zhang, and ",./refs/download/2/Predictive and generative neural networks for object functionality.pdf,Predictive and generative neural networks for object functionality
0,,,,,,,," R. Hu, Z. Yan, J. Zhang, O. van Kaick, A. Shamir, H. Zhang, and ",./refs/download/2/Predictive and generative neural networks for object functionality.pdf,Predictive and generative neural networks for object functionality
0,,,,,,,," R. Hu, Z. Yan, J. Zhang, O. van Kaick, A. Shamir, H. Zhang, and ",./refs/download/2/Predictive and generative neural networks for object functionality.pdf,Predictive and generative neural networks for object functionality
0,,,,,,,," R. Hu, Z. Yan, J. Zhang, O. van Kaick, A. Shamir, H. Zhang, and ",./refs/download/2/Predictive and generative neural networks for object functionality.pdf,Predictive and generative neural networks for object functionality
0,,,,,,,," R. Hu, Z. Yan, J. Zhang, O. van Kaick, A. Shamir, H. Zhang, and ",./refs/download/2/Predictive and generative neural networks for object functionality.pdf,Predictive and generative neural networks for object functionality
0,,,,,,,," R. Hu, Z. Yan, J. Zhang, O. van Kaick, A. Shamir, H. Zhang, and ",./refs/download/2/Predictive and generative neural networks for object functionality.pdf,Predictive and generative neural networks for object functionality
0,,,,,,,," F. Fouhey, Mikel Rodriguez, and ",./refs/download/2/Predictive and generative neural networks for object functionality.pdf,Predictive and generative neural networks for object functionality
0,,,,,,,," R. Greene, Christopher Baldassano, Diane M. Beck, and ",./refs/download/2/Predictive and generative neural networks for object functionality.pdf,Predictive and generative neural networks for object functionality
0,,,,,,,," J. Mitra, and ",./refs/download/2/Predictive and generative neural networks for object functionality.pdf,Predictive and generative neural networks for object functionality
0,,,,,,,," X. Han, Z. Li, H. Huang, E. Kalogerakis, and ",./refs/download/2/Predictive and generative neural networks for object functionality.pdf,Predictive and generative neural networks for object functionality
0,,,,,,,," G. Kim, Siddhartha Chaudhuri, Leonidas Guibas, and ",./refs/download/2/Predictive and generative neural networks for object functionality.pdf,Predictive and generative neural networks for object functionality
0,,,,,,,," M. Bronstein, and ",./refs/download/2/Predictive and generative neural networks for object functionality.pdf,Predictive and generative neural networks for object functionality
0,,,,,,,," R. Qi, Li Yi, Hao Su, and ",./refs/download/2/Predictive and generative neural networks for object functionality.pdf,Predictive and generative neural networks for object functionality
0,,,,,,,," X. Chang, Pat Hanrahan, Matthew Fisher, and ",./refs/download/2/Predictive and generative neural networks for object functionality.pdf,Predictive and generative neural networks for object functionality
0,,,,,,,," X. Chang, Pat Hanrahan, Matthew Fisher, and ",./refs/download/2/Predictive and generative neural networks for object functionality.pdf,Predictive and generative neural networks for object functionality
0,,,,,,,," G. Kim, Siddhartha Chaudhuri, and ",./refs/download/2/Predictive and generative neural networks for object functionality.pdf,Predictive and generative neural networks for object functionality
0,,,,,,,," T. Freeman, and ",./refs/download/2/Predictive and generative neural networks for object functionality.pdf,Predictive and generative neural networks for object functionality
0,,,,,,,," Z. Wu, S. Song, A. Khosla, F. Yu, L. Zhang, X. Tang, and ",./refs/download/2/Predictive and generative neural networks for object functionality.pdf,Predictive and generative neural networks for object functionality
0,,,,,,,," G. Altarelli, R. Barbieri, M. Carena, N. Polonsky and ",./refs/download/2/beyond.pdf,beyond
0,,,,,,,, H. Georgi and ,./refs/download/2/beyond.pdf,beyond
0,,,,,,,," H. Georgi, H. Quinn and ",./refs/download/2/beyond.pdf,beyond
0,,,,,,,, E. Fahri and ,./refs/download/2/beyond.pdf,beyond
0,,,,,,,, S. Dimopoulos and ,./refs/download/2/beyond.pdf,beyond
0,,,,,,,, S. Dimopoulos and ,./refs/download/2/beyond.pdf,beyond
0,,,,,,,," S. Dimopoulos, S. Raby and ",./refs/download/2/beyond.pdf,beyond
0,,,,,,,, T. Elliot and ,./refs/download/2/beyond.pdf,beyond
0,,,,,,,," G. Zoupanos, J. Kubo and ",./refs/download/2/beyond.pdf,beyond
0,,,,,,,," M. Matsuda, T. Hayashi, Y. Koide and ",./refs/download/2/beyond.pdf,beyond
0,,,,,,,, P. Nath and ,./refs/download/2/beyond.pdf,beyond
0,,,,,,,, S. Miyake and ,./refs/download/2/beyond.pdf,beyond
0,,,,,,,, G. Altarelli and ,./refs/download/2/beyond.pdf,beyond
0,,,,,,,," G. Altarelli, R. Barbieri and ",./refs/download/2/beyond.pdf,beyond
0,,,,,,,," G. Altarelli, R. Barbieri and ",./refs/download/2/beyond.pdf,beyond
0,,,,,,,," R. Barbieri, G. Dvali and ",./refs/download/2/beyond.pdf,beyond
0,,,,,,,, B. Pendleton and ,./refs/download/2/beyond.pdf,beyond
0,,,,,,,," L. Alvarez-Gaume, J. Polchinski and ",./refs/download/2/beyond.pdf,beyond
0,,,,,,,," J. Bagger, S. Dimopoulos and ",./refs/download/2/beyond.pdf,beyond
0,,,,,,,, J. Ellis and ,./refs/download/2/beyond.pdf,beyond
0,,,,,,,," M. Carena, S. Pokorski and ",./refs/download/2/beyond.pdf,beyond
0,,,,,,,," M. Carena, M. Olechowski, S. Wagner and ",./refs/download/2/beyond.pdf,beyond
0,,,,,,,," Y. Okada, M. Yamaguchi and ",./refs/download/2/beyond.pdf,beyond
0,,,,,,,," J. Ellis, G. Ridolfi and ",./refs/download/2/beyond.pdf,beyond
0,,,,,,,," R. Barbieri, R. Frigeni and ",./refs/download/2/beyond.pdf,beyond
0,,,,,,,, M. Carena and ,./refs/download/2/beyond.pdf,beyond
0,,,,,,,," C. Kounnas, F. Zwirner and ",./refs/download/2/beyond.pdf,beyond
0,,,,,,,," P. Binetruy, E. Dudas and ",./refs/download/2/beyond.pdf,beyond
0,,,,,,,," N. Cabibbo, L. Maiani, G. Parisi and ",./refs/download/2/beyond.pdf,beyond
0,,,,,,,, G. Altarelli and ,./refs/download/2/beyond.pdf,beyond
0,,,,,,,, H. Georgi and ,./refs/download/2/beyond.pdf,beyond
0,,,,,,,," J. Harvey, P. Ramond and ",./refs/download/2/beyond.pdf,beyond
0,,,,,,,, T. Han and ,./refs/download/2/beyond.pdf,beyond
0,,,,,,,, S. Raby and ,./refs/download/2/beyond.pdf,beyond
0,,,,,,,," J. Bagger, S. Dimopoulos, H. Georgi and ",./refs/download/2/beyond.pdf,beyond
0,,,,,,,, C. Jarlskog and ,./refs/download/2/beyond.pdf,beyond
0,,,,,,,," S. Dimopoulos, S. Raby and ",./refs/download/2/beyond.pdf,beyond
0,,,,,,,," K. Li, and ",./refs/download/2/Facial expression recognition from world wild web.pdf,Facial expression recognition from world wild web
0,,,,,,,," A. Dhall, R. Goecke, J. Joshi, M. Wagner, and ",./refs/download/2/Facial expression recognition from world wild web.pdf,Facial expression recognition from world wild web
0,,,,,,,," A. Dhall, R. Goecke, S. Lucey, and ",./refs/download/2/Facial expression recognition from world wild web.pdf,Facial expression recognition from world wild web
0,,,,,,,, T. Gehrig and ,./refs/download/2/Facial expression recognition from world wild web.pdf,Facial expression recognition from world wild web
0,,,,,,,," J. F. Grafsgaard, J. B. Wiggins, K. E. Boyer, E. N. Wiebe, and ",./refs/download/2/Facial expression recognition from world wild web.pdf,Facial expression recognition from world wild web
0,,,,,,,," T. Gritti, C. Shan, V. Jeanne, and ",./refs/download/2/Facial expression recognition from world wild web.pdf,Facial expression recognition from world wild web
0,,,,,,,," R. Gross, I. Matthews, J. Cohn, T. Kanade, and ",./refs/download/2/Facial expression recognition from world wild web.pdf,Facial expression recognition from world wild web
0,,,,,,,, H. Kobayashi and ,./refs/download/2/Facial expression recognition from world wild web.pdf,Facial expression recognition from world wild web
0,,,,,,,," A. Krizhevsky, I. Sutskever, and ",./refs/download/2/Facial expression recognition from world wild web.pdf,Facial expression recognition from world wild web
0,,,,,,,, C. Liu and ,./refs/download/2/Facial expression recognition from world wild web.pdf,Facial expression recognition from world wild web
0,,,,,,,," M. Liu, S. Li, S. Shan, and ",./refs/download/2/Facial expression recognition from world wild web.pdf,Facial expression recognition from world wild web
0,,,,,,,," M. Lyons, S. Akamatsu, M. Kamachi, and ",./refs/download/2/Facial expression recognition from world wild web.pdf,Facial expression recognition from world wild web
0,,,,,,,," S. M. Mavadati, M. H. Mahoor, K. Bartlett, P. Trinh, and ",./refs/download/2/Facial expression recognition from world wild web.pdf,Facial expression recognition from world wild web
0,,,,,,,," D. McDuff, R. Kaliouby, T. Senechal, M. Amr, J. Cohn, and ",./refs/download/2/Facial expression recognition from world wild web.pdf,Facial expression recognition from world wild web
0,,,,,,,," M. Mohammadi, E. Fatemizadeh, and ",./refs/download/2/Facial expression recognition from world wild web.pdf,Facial expression recognition from world wild web
0,,,,,,,," M. R. Mohammadi, E. Fatemizadeh, and ",./refs/download/2/Facial expression recognition from world wild web.pdf,Facial expression recognition from world wild web
0,,,,,,,," A. Mollahosseini, D. Chan, and ",./refs/download/2/Facial expression recognition from world wild web.pdf,Facial expression recognition from world wild web
0,,,,,,,," A. Mollahosseini, G. Graitzer, E. Borts, S. Conyers, R. M. Voyles, R. Cole, and ",./refs/download/2/Facial expression recognition from world wild web.pdf,Facial expression recognition from world wild web
0,,,,,,,, A. Mollahosseini and ,./refs/download/2/Facial expression recognition from world wild web.pdf,Facial expression recognition from world wild web
0,,,,,,,," M. Oquab, L. Bottou, I. Laptev, and ",./refs/download/2/Facial expression recognition from world wild web.pdf,Facial expression recognition from world wild web
0,,,,,,,," M. Pantic, M. Valstar, R. Rademaker, and ",./refs/download/2/Facial expression recognition from world wild web.pdf,Facial expression recognition from world wild web
0,,,,,,,," S. Ren, X. Cao, Y. Wei, and ",./refs/download/2/Facial expression recognition from world wild web.pdf,Facial expression recognition from world wild web
0,,,,,,,," E. Rentzeperis, A. Stergiou, A. Pnevmatikakis, and ",./refs/download/2/Facial expression recognition from world wild web.pdf,Facial expression recognition from world wild web
0,,,,,,,," C. Sagonas, E. Antonakos, G. Tzimiropoulos, S. Zafeiriou, and ",./refs/download/2/Facial expression recognition from world wild web.pdf,Facial expression recognition from world wild web
0,,,,,,,," C. Sagonas, G. Tzimiropoulos, S. Zafeiriou, and ",./refs/download/2/Facial expression recognition from world wild web.pdf,Facial expression recognition from world wild web
0,,,,,,,," C. Sagonas, G. Tzimiropoulos, S. Zafeiriou, and ",./refs/download/2/Facial expression recognition from world wild web.pdf,Facial expression recognition from world wild web
0,,,,,,,," C. Shan, S. Gong, and ",./refs/download/2/Facial expression recognition from world wild web.pdf,Facial expression recognition from world wild web
0,,,,,,,, S. Sukhbaatar and ,./refs/download/2/Facial expression recognition from world wild web.pdf,Facial expression recognition from world wild web
0,,,,,,,," C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, and ",./refs/download/2/Facial expression recognition from world wild web.pdf,Facial expression recognition from world wild web
0,,,,,,,," Y. Taigman, M. Yang, M. Ranzato, and ",./refs/download/2/Facial expression recognition from world wild web.pdf,Facial expression recognition from world wild web
0,,,,,,,, A. Toshev and ,./refs/download/2/Facial expression recognition from world wild web.pdf,Facial expression recognition from world wild web
0,,,,,,,," J. Weston, F. Ratle, H. Mobahi, and ",./refs/download/2/Facial expression recognition from world wild web.pdf,Facial expression recognition from world wild web
0,,,,,,,," T. Xiao, T. Xia, Y. Yang, C. Huang, and ",./refs/download/2/Facial expression recognition from world wild web.pdf,Facial expression recognition from world wild web
0,,,,,,,, Z. Yu and ,./refs/download/2/Facial expression recognition from world wild web.pdf,Facial expression recognition from world wild web
0,,,,,,,," X. Zhang, M. H. Mahoor, and ",./refs/download/2/Facial expression recognition from world wild web.pdf,Facial expression recognition from world wild web
0,,,,,,,," X. Zhang, A. Mollahosseini, B. Kargar, H. Amir, E. Boucher, R. M. Voyles, R. Nielsen, and ",./refs/download/2/Facial expression recognition from world wild web.pdf,Facial expression recognition from world wild web
0,,,,,,,, W. Zhen and ,./refs/download/2/Facial expression recognition from world wild web.pdf,Facial expression recognition from world wild web
0,,,,,,,," Y. Zong, W. Zheng, X. Huang, K. Yan, J. Yan, and ",./refs/download/2/Facial expression recognition from world wild web.pdf,Facial expression recognition from world wild web
0,,,,,,,," I. Armeni, O. Sener, A. R. Zamir, H. Jiang, I. Brilakis, M. Fischer, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation
0,,,,,,,," V. Badrinarayanan, A. Kendall, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation
0,,,,,,,," L. Bertinetto, J. Valmadre, J. F. Henriques, A. Vedaldi, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation
0,,,,,,,," X. Chen, H. Ma, J. Wan, B. Li, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation
0,,,,,,,," S. Chopra, R. Hadsell, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation
0,,,,,,,," A. Dai, A. X. Chang, M. Savva, M. Halber, T. Funkhouser, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation
0,,,,,,,," A. Dai, C. R. Qi, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation
0,,,,,,,," J. Dai, K. He, Y. Li, S. Ren, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation
0,,,,,,,," J. Dai, K. He, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation
0,,,,,,,, Z. Deng and ,./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation
0,,,,,,,," A. Frome, Y. Singer, F. Sha, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation
0,,,,,,,," W. Liu, A. Ranga, A. Tyagi, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation
0,,,,,,,," R. Girshick, J. Donahue, T. Darrell, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation
0,,,,,,,," X. Han, T. Leung, Y. Jia, R. Sukthankar, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation
0,,,,,,,," X. Han, Z. Li, H. Huang, E. Kalogerakis, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation
0,,,,,,,," K. He, G. Gkioxari, P. Dollar, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation
0,,,,,,,, D. Kingma and ,./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation
0,,,,,,,," G. Koch, R. Zemel, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation
0,,,,,,,," A. Krizhevsky, I. Sutskever, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation
0,,,,,,,," L. Leal-Taix, C. Canton-Ferrer, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation
0,,,,,,,," Y. Li, H. Qi, J. Dai, X. Ji, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation
0,,,,,,,," P. Dollar, R. Girshick, K. He, B. Hariharan, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation
0,,,,,,,," P. Goyal, R. Girshick, K. He, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation
0,,,,,,,, D. Maturana and ,./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation
0,,,,,,,, A. Newell and ,./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation
0,,,,,,,, G. Pang and ,./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation
0,,,,,,,," G. Pang, R. Qiu, J. Huang, S. You, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation
0,,,,,,,," P. O. Pinheiro, R. Collobert, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation
0,,,,,,,," R. Collobert, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation
0,,,,,,,," C. R. Qi, H. Su, K. Mo, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation
0,,,,,,,," C. R. Qi, H. Su, M. Nießner, A. Dai, M. Yan, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation
0,,,,,,,," C. R. Qi, L. Yi, H. Su, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation
0,,,,,,,," X. Qi, R. Liao, J. Jia, S. Fidler, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation
0,,,,,,,," J. Redmon, S. Divvala, R. Girshick, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation
0,,,,,,,, J. Redmon and ,./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation
0,,,,,,,," S. Ren, K. He, R. Girshick, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation
0,,,,,,,, Z. Ren and ,./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation
0,,,,,,,," G. Riegler, A. O. Ulusoy, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation
0,,,,,,,," N. Silberman, D. Hoiem, P. Kohli, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation
0,,,,,,,," E. Simo-Serra, E. Trulls, L. Ferraz, I. Kokkinos, P. Fua, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation
0,,,,,,,, S. Song and ,./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation
0,,,,,,,, S. Song and ,./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation
0,,,,,,,," S. Song, F. Yu, A. Zeng, A. X. Chang, M. Savva, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation
0,,,,,,,," M. Tatarchenko, A. Dosovitskiy, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation
0,,,,,,,," W. Wang, Q. Huang, S. You, C. Yang, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation
0,,,,,,,, K. Q. Weinberger and ,./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation
0,,,,,,,," Z. Wu, S. Song, A. Khosla, F. Yu, L. Zhang, X. Tang, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation
0,,,,,,,," D. Yi, Z. Lei, S. Liao, and ",./refs/download/2/SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation.pdf,SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation
0,"P. Achlioptas, O. Diamanti, I. Mitliagkas, L. Guibas",Learning representations and generative models for 3d point clouds, arXiv preprint arXiv:,,,1707,,"P. Achlioptas, O. Diamanti, I. Mitliagkas, and L. Guibas. Learning representations and generative models for 3d point clouds. arXiv preprint arXiv:1707.",./refs/download/2/SO-Net: Self-organizing network for point cloud analysis.pdf,SO-Net: Self-organizing network for point cloud analysis
0,"I. Armeni, A. Sax, A. R. Zamir, S. Savarese",Joint 2D3D-Semantic Data for Indoor Scene Understanding, ArXiv e-prints,,,2017,,"I. Armeni, A. Sax, A. R. Zamir, and S. Savarese. Joint 2D3D-Semantic Data for Indoor Scene Understanding. ArXiv e-prints, Feb. 2017.",./refs/download/2/SO-Net: Self-organizing network for point cloud analysis.pdf,SO-Net: Self-organizing network for point cloud analysis
0,"S. Bai, X. Bai, Z. Zhou, Z. Zhang, L. Jan Latecki",Gift: A real-time and scalable 3d shape search engine, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,,,2016,,"S. Bai, X. Bai, Z. Zhou, Z. Zhang, and L. Jan Latecki. Gift: A real-time and scalable 3d shape search engine. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 5023–5032, 2016.",./refs/download/2/SO-Net: Self-organizing network for point cloud analysis.pdf,SO-Net: Self-organizing network for point cloud analysis
0,J. L. Bentley,Multidimensional binary search trees used for associative searching, Communications of the ACM,,,1975,18,"J. L. Bentley. Multidimensional binary search trees used for associative searching. Communications of the ACM, 18(9):509–517, 1975.",./refs/download/2/SO-Net: Self-organizing network for point cloud analysis.pdf,SO-Net: Self-organizing network for point cloud analysis
0,"D. Boscaini, J. Masci, S. Melzi, M. M. Bronstein, U. Castellani, P. Vandergheynst",Learning class-specific descriptors for deformable shapes using localized spectral convolutional networks, In Computer Graphics Forum,,,2015,,"D. Boscaini, J. Masci, S. Melzi, M. M. Bronstein, U. Castellani, and P. Vandergheynst. Learning class-specific descriptors for deformable shapes using localized spectral convolutional networks. In Computer Graphics Forum, volume 34, pages 13–23. Wiley Online Library, 2015.",./refs/download/2/SO-Net: Self-organizing network for point cloud analysis.pdf,SO-Net: Self-organizing network for point cloud analysis
0,"A. Brock, T. Lim, J. M. Ritchie, N. Weston",Generative and discriminative voxel modeling with convolutional neural networks, arXiv preprint arXiv:,,,1608,,"A. Brock, T. Lim, J. M. Ritchie, and N. Weston. Generative and discriminative voxel modeling with convolutional neural networks. arXiv preprint arXiv:1608.",./refs/download/2/SO-Net: Self-organizing network for point cloud analysis.pdf,SO-Net: Self-organizing network for point cloud analysis
0,"J. Bruna, W. Zaremba, A. Szlam, Y. LeCun",Spectral networks and locally connected networks on graphs, arXiv preprint arXiv:,,,1312,,"J. Bruna, W. Zaremba, A. Szlam, and Y. LeCun. Spectral networks and locally connected networks on graphs. arXiv preprint arXiv:1312.",./refs/download/2/SO-Net: Self-organizing network for point cloud analysis.pdf,SO-Net: Self-organizing network for point cloud analysis
0,A. X. Chang,T, Funkhouser,,,1512,,"A. X. Chang, T. Funkhouser, L. Guibas, P. Hanrahan, Q. Huang, Z. Li, S. Savarese, M. Savva, S. Song, H. Su, et al. Shapenet: An information-rich 3d model repository. arXiv preprint arXiv:1512.",./refs/download/2/SO-Net: Self-organizing network for point cloud analysis.pdf,SO-Net: Self-organizing network for point cloud analysis
0,"Y. Cheng, R. Cai, Z. Li, X. Zhao, K. Huang",Localitysensitive deconvolution networks with gated fusion for rgb-d indoor semantic segmentation, In CVPR,,,2017,,"Y. Cheng, R. Cai, Z. Li, X. Zhao, and K. Huang. Localitysensitive deconvolution networks with gated fusion for rgb-d indoor semantic segmentation. In CVPR, 2017.",./refs/download/2/SO-Net: Self-organizing network for point cloud analysis.pdf,SO-Net: Self-organizing network for point cloud analysis
0,"D. Ciregan, U. Meier, J. Schmidhuber",Multi-column deep neural networks for image classification, In Computer Vision and Pattern Recognition (CVPR),,,3649,2012,"D. Ciregan, U. Meier, and J. Schmidhuber. Multi-column deep neural networks for image classification. In Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on, pages 3642–3649.",./refs/download/2/SO-Net: Self-organizing network for point cloud analysis.pdf,SO-Net: Self-organizing network for point cloud analysis
0,"M. Engelcke, D. Rao, D. Z. Wang, C. H. Tong, I. Posner",Vote3deep: Fast object detection in 3d point clouds using efficient convolutional neural networks, In IEEE International Conference on Robotics and Automation (ICRA),,,2017,,"M. Engelcke, D. Rao, D. Z. Wang, C. H. Tong, and I. Posner. Vote3deep: Fast object detection in 3d point clouds using efficient convolutional neural networks. In IEEE International Conference on Robotics and Automation (ICRA), 2017.",./refs/download/2/SO-Net: Self-organizing network for point cloud analysis.pdf,SO-Net: Self-organizing network for point cloud analysis
0,"D. Erhan, Y. Bengio, A. Courville, P.-A. Manzagol, P. Vincent, S. Bengio",Why does unsupervised pre-training help deep learning? Journal of Machine Learning Research, 11(Feb):625–660,,,2010,,"D. Erhan, Y. Bengio, A. Courville, P.-A. Manzagol, P. Vincent, and S. Bengio. Why does unsupervised pre-training help deep learning? Journal of Machine Learning Research, 11(Feb):625–660, 2010.",./refs/download/2/SO-Net: Self-organizing network for point cloud analysis.pdf,SO-Net: Self-organizing network for point cloud analysis
0,"H. Fan, H. Su, L. Guibas",A point set generation network for 3d object reconstruction from a single image, ,,,2017,,"H. Fan, H. Su, and L. Guibas. A point set generation network for 3d object reconstruction from a single image. 2017.",./refs/download/2/SO-Net: Self-organizing network for point cloud analysis.pdf,SO-Net: Self-organizing network for point cloud analysis
0,"R. Garg, G. Carneiro, I. Reid",Unsupervised cnn for single view depth estimation: Geometry to the rescue, In ECCV,,,2016,,"R. Garg, G. Carneiro, and I. Reid. Unsupervised cnn for single view depth estimation: Geometry to the rescue. In ECCV, 2016.",./refs/download/2/SO-Net: Self-organizing network for point cloud analysis.pdf,SO-Net: Self-organizing network for point cloud analysis
0,"C. Godard, O. Mac Aodha, G. J. Brostow",Unsupervised monocular depth estimation with left-right consistency, arXiv preprint arXiv:,,,1609,,"C. Godard, O. Mac Aodha, and G. J. Brostow. Unsupervised monocular depth estimation with left-right consistency. arXiv preprint arXiv:1609.",./refs/download/2/SO-Net: Self-organizing network for point cloud analysis.pdf,SO-Net: Self-organizing network for point cloud analysis
0,"J. Johnson, M. Douze, H. Jégou",Billion-scale similarity search with gpus, arXiv preprint arXiv:,,,1702,,"J. Johnson, M. Douze, and H. Jégou. Billion-scale similarity search with gpus. arXiv preprint arXiv:1702.",./refs/download/2/SO-Net: Self-organizing network for point cloud analysis.pdf,SO-Net: Self-organizing network for point cloud analysis
0,"D. Kingma and , J. Ba",Adam: A method for stochastic optimization, arXiv preprint arXiv:1412,.6980,,2014,,"D. Kingma and J. Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014.",./refs/download/2/SO-Net: Self-organizing network for point cloud analysis.pdf,SO-Net: Self-organizing network for point cloud analysis
0,"R. Klokov and , V. Lempitsky",Escape from cells: Deep kdnetworks for the recognition of 3d point cloud models, arXiv preprint arXiv:1704,.01222,,2017,,"R. Klokov and V. Lempitsky. Escape from cells: Deep kdnetworks for the recognition of 3d point cloud models. arXiv preprint arXiv:1704.01222, 2017.",./refs/download/2/SO-Net: Self-organizing network for point cloud analysis.pdf,SO-Net: Self-organizing network for point cloud analysis
0,T. Kohonen,The self-organizing map, Neurocomputing,,,1998,21,"T. Kohonen. The self-organizing map. Neurocomputing, 21(1):1–6, 1998.",./refs/download/2/SO-Net: Self-organizing network for point cloud analysis.pdf,SO-Net: Self-organizing network for point cloud analysis
0,"Y. LeCun, L. Bottou, Y. Bengio, P. Haffner",Gradientbased learning applied to document recognition, Proceedings of the IEEE,,,1998,86,"Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradientbased learning applied to document recognition. Proceedings of the IEEE, 86(11):2278–2324, 1998.",./refs/download/2/SO-Net: Self-organizing network for point cloud analysis.pdf,SO-Net: Self-organizing network for point cloud analysis
0,"Y. Li, S. Pirk, H. Su, C. R. Qi, L. J. Guibas",Fpnn: Field probing neural networks for 3d data, In Advances in Neural Information Processing Systems,,,2016,,"Y. Li, S. Pirk, H. Su, C. R. Qi, and L. J. Guibas. Fpnn: Field probing neural networks for 3d data. In Advances in Neural Information Processing Systems, pages 307–315, 2016.",./refs/download/2/SO-Net: Self-organizing network for point cloud analysis.pdf,SO-Net: Self-organizing network for point cloud analysis
0,"M. Lin, Q. Chen, S. Yan",Network in network, arXiv preprint arXiv:,,,1312,,"M. Lin, Q. Chen, and S. Yan. Network in network. arXiv preprint arXiv:1312.",./refs/download/2/SO-Net: Self-organizing network for point cloud analysis.pdf,SO-Net: Self-organizing network for point cloud analysis
0,"J. Masci, D. Boscaini, M. Bronstein, P. Vandergheynst",Geodesic convolutional neural networks on riemannian manifolds, In ICCV Workshops,,,2015,,"J. Masci, D. Boscaini, M. Bronstein, and P. Vandergheynst. Geodesic convolutional neural networks on riemannian manifolds. In ICCV Workshops, 2015.",./refs/download/2/SO-Net: Self-organizing network for point cloud analysis.pdf,SO-Net: Self-organizing network for point cloud analysis
0,"D. Maturana and , S. Scherer",Voxnet: A 3d convolutional neural network for real-time object recognition, In IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),,,2015,,"D. Maturana and S. Scherer. Voxnet: A 3d convolutional neural network for real-time object recognition. In IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), 2015.",./refs/download/2/SO-Net: Self-organizing network for point cloud analysis.pdf,SO-Net: Self-organizing network for point cloud analysis
0,D. J. Meagher,Octree encoding: A new technique for the representation, manipulation and display of arbitrary 3-d objects by computer,. Electrical and Systems Engineering Department Rensseiaer Polytechnic Institute Image Processing Laboratory,,1980,,"D. J. Meagher. Octree encoding: A new technique for the representation, manipulation and display of arbitrary 3-d objects by computer. Electrical and Systems Engineering Department Rensseiaer Polytechnic Institute Image Processing Laboratory, 1980.",./refs/download/2/SO-Net: Self-organizing network for point cloud analysis.pdf,SO-Net: Self-organizing network for point cloud analysis
0,"C. R. Qi, H. Su, K. Mo, L. J. Guibas",Pointnet: Deep learning on point sets for 3d classification and segmentation, arXiv preprint arXiv:,,,1612,,"C. R. Qi, H. Su, K. Mo, and L. J. Guibas. Pointnet: Deep learning on point sets for 3d classification and segmentation. arXiv preprint arXiv:1612.",./refs/download/2/SO-Net: Self-organizing network for point cloud analysis.pdf,SO-Net: Self-organizing network for point cloud analysis
0,"C. R. Qi, H. Su, M. Nießner, A. Dai, M. Yan, L. J. Guibas",Volumetric and multi-view cnns for object classification on 3d data, In CVPR,,,2016,,"C. R. Qi, H. Su, M. Nießner, A. Dai, M. Yan, and L. J. Guibas. Volumetric and multi-view cnns for object classification on 3d data. In CVPR, 2016.",./refs/download/2/SO-Net: Self-organizing network for point cloud analysis.pdf,SO-Net: Self-organizing network for point cloud analysis
0,"C. R. Qi, L. Yi, H. Su, L. J. Guibas",Pointnet++: Deep hierarchical feature learning on point sets in a metric space, arXiv preprint arXiv:,,,1706,,"C. R. Qi, L. Yi, H. Su, and L. J. Guibas. Pointnet++: Deep hierarchical feature learning on point sets in a metric space. arXiv preprint arXiv:1706.",./refs/download/2/SO-Net: Self-organizing network for point cloud analysis.pdf,SO-Net: Self-organizing network for point cloud analysis
0,"S. Ravanbakhsh, J. Schneider, B. Poczos",Deep learning with sets and point clouds, arXiv preprint arXiv:,,,1611,,"S. Ravanbakhsh, J. Schneider, and B. Poczos. Deep learning with sets and point clouds. arXiv preprint arXiv:1611.",./refs/download/2/SO-Net: Self-organizing network for point cloud analysis.pdf,SO-Net: Self-organizing network for point cloud analysis
0,"G. Riegler, A. O. Ulusoy, A. Geiger",Octnet: Learning deep 3d representations at high resolutions, In CVPR,,,2017,,"G. Riegler, A. O. Ulusoy, and A. Geiger. Octnet: Learning deep 3d representations at high resolutions. In CVPR, 2017.",./refs/download/2/SO-Net: Self-organizing network for point cloud analysis.pdf,SO-Net: Self-organizing network for point cloud analysis
0,P. Y. Simard,D, Steinkraus,,,2003,,"P. Y. Simard, D. Steinkraus, J. C. Platt, et al. Best practices for convolutional neural networks applied to visual document analysis. In ICDAR, volume 3, pages 958–962, 2003.",./refs/download/2/SO-Net: Self-organizing network for point cloud analysis.pdf,SO-Net: Self-organizing network for point cloud analysis
0,"M. Simonovsky and , N. Komodakis",Dynamic edgeconditioned filters in convolutional neural networks on graphs, arXiv preprint arXiv:1704,.02901,,2017,,"M. Simonovsky and N. Komodakis. Dynamic edgeconditioned filters in convolutional neural networks on graphs. arXiv preprint arXiv:1704.02901, 2017.",./refs/download/2/SO-Net: Self-organizing network for point cloud analysis.pdf,SO-Net: Self-organizing network for point cloud analysis
0,"H. Su, S. Maji, E. Kalogerakis, E. Learned-Miller",Multiview convolutional neural networks for 3d shape recognition, In ICCV,,,2015,,"H. Su, S. Maji, E. Kalogerakis, and E. Learned-Miller. Multiview convolutional neural networks for 3d shape recognition. In ICCV, 2015.",./refs/download/2/SO-Net: Self-organizing network for point cloud analysis.pdf,SO-Net: Self-organizing network for point cloud analysis
0,"C. Wang, M. Pelillo, K. Siddiqi",Dominant set clustering and pooling for multi-view 3d object recognition, In BMVC,,,2017,,"C. Wang, M. Pelillo, and K. Siddiqi. Dominant set clustering and pooling for multi-view 3d object recognition. In BMVC, 2017.",./refs/download/2/SO-Net: Self-organizing network for point cloud analysis.pdf,SO-Net: Self-organizing network for point cloud analysis
0,"D. Z. Wang and , I. Posner",Voting for voting in online point cloud object detection, In Robotics: Science and Systems,,,2015,,"D. Z. Wang and I. Posner. Voting for voting in online point cloud object detection. In Robotics: Science and Systems, 2015.",./refs/download/2/SO-Net: Self-organizing network for point cloud analysis.pdf,SO-Net: Self-organizing network for point cloud analysis
0,"Z. Wu, S. Song, A. Khosla, F. Yu, L. Zhang, X. Tang, J. Xiao",3d shapenets: A deep representation for volumetric shapes, In CVPR,,,2015,,"Z. Wu, S. Song, A. Khosla, F. Yu, L. Zhang, X. Tang, and J. Xiao. 3d shapenets: A deep representation for volumetric shapes. In CVPR, 2015.",./refs/download/2/SO-Net: Self-organizing network for point cloud analysis.pdf,SO-Net: Self-organizing network for point cloud analysis
0,L. Yi,V, G,. Kim,,2016,,"L. Yi, V. G. Kim, D. Ceylan, I. Shen, M. Yan, H. Su, A. Lu, Q. Huang, A. Sheffer, L. Guibas, et al. A scalable active framework for region annotation in 3d shape collections. ACM Transactions on Graphics (TOG), 35(6):210, 2016.",./refs/download/2/SO-Net: Self-organizing network for point cloud analysis.pdf,SO-Net: Self-organizing network for point cloud analysis
0,"M. Zaheer, S. Kottur, S. Ravanbakhsh, B. Poczos, R. Salakhutdinov, A. Smola",Deep sets, arXiv preprint arXiv:,,,1703,,"M. Zaheer, S. Kottur, S. Ravanbakhsh, B. Poczos, R. Salakhutdinov, and A. Smola. Deep sets. arXiv preprint arXiv:1703.",./refs/download/2/SO-Net: Self-organizing network for point cloud analysis.pdf,SO-Net: Self-organizing network for point cloud analysis
0,,,,,,,,"Le Cun, Y., Denker, J.S., Solla, S.A.: Optimal brain damage. In: Advances in Neural Information Processing Systems (1990)",./refs/download/2/Netadapt: Platform-aware neural network adaptation for mobile applications.pdf,Netadapt: Platform-aware neural network adaptation for mobile applications
0,,,,,,,,"Liangzhen Lai, Naveen Suda, V.C.: Not all ops are created equal! In: SysML (2018)",./refs/download/2/Netadapt: Platform-aware neural network adaptation for mobile applications.pdf,Netadapt: Platform-aware neural network adaptation for mobile applications
0,"Z. Al-Halah, R. Stiefelhagen, K. Grauman",Fashion forward: Forecasting visual style in fashion, In ICCV,,,2017,,"Z. Al-Halah, R. Stiefelhagen, and K. Grauman. Fashion forward: Forecasting visual style in fashion. In ICCV, 2017.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"S. Belongie, J. Malik, J. Puzicha",Shape matching and object recognition using shape contexts, IEEE TPAMI,,,2002,,"S. Belongie, J. Malik, and J. Puzicha. Shape matching and object recognition using shape contexts. IEEE TPAMI, 2002.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"F. Bogo, A. Kanazawa, C. Lassner, P. Gehler, J. Romero, M. J. Black",Keep it smpl: Automatic estimation of 3d human pose and shape from a single image, In ECCV,,,2016,,"F. Bogo, A. Kanazawa, C. Lassner, P. Gehler, J. Romero, and M. J. Black. Keep it smpl: Automatic estimation of 3d human pose and shape from a single image. In ECCV, 2016.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"Z. Cao, T. Simon, S.-E. Wei, Y. Sheikh",Realtime multiperson 2d pose estimation using part affinity fields, In CVPR,,,2017,,"Z. Cao, T. Simon, S.-E. Wei, and Y. Sheikh. Realtime multiperson 2d pose estimation using part affinity fields. In CVPR, 2017.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"Q. Chen and , V. Koltun",Photographic image synthesis with cascaded refinement networks, In ICCV,,,2017,,"Q. Chen and V. Koltun. Photographic image synthesis with cascaded refinement networks. In ICCV, 2017.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"A. Dosovitskiy and , T. Brox",Generating images with perceptual similarity metrics based on deep networks, In NIPS,,,2016,,"A. Dosovitskiy and T. Brox. Generating images with perceptual similarity metrics based on deep networks. In NIPS, 2016.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"A. Dosovitskiy, J. Tobias Springenberg, T. Brox",Learning to generate chairs with convolutional neural networks, In CVPR,,,2015,,"A. Dosovitskiy, J. Tobias Springenberg, and T. Brox. Learning to generate chairs with convolutional neural networks. In CVPR, 2015.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"C. Gan, Z. Gan, X. He, J. Gao, L. Deng",Stylenet: Generating attractive visual captions with styles, In CVPR,,,2017,,"C. Gan, Z. Gan, X. He, J. Gao, and L. Deng. Stylenet: Generating attractive visual captions with styles. In CVPR, 2017.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"L. A. Gatys, A. S. Ecker, M. Bethge",Image style transfer using convolutional neural networks, In CVPR,,,2016,,"L. A. Gatys, A. S. Ecker, and M. Bethge. Image style transfer using convolutional neural networks. In CVPR, 2016.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"K. Gong, X. Liang, X. Shen, L. Lin",Look into person: Self-supervised structure-sensitive learning and a new benchmark for human parsing, In CVPR,,,2017,,"K. Gong, X. Liang, X. Shen, and L. Lin. Look into person: Self-supervised structure-sensitive learning and a new benchmark for human parsing. In CVPR, 2017.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, Y. Bengio",Generative adversarial nets, In NIPS,,,2014,,"I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio. Generative adversarial nets. In NIPS, 2014.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"P. Guan, L. Reiss, D. A. Hirshberg, A. Weiss, M. J. Black",Drape: Dressing any person, ACM TOG,,,2012,,"P. Guan, L. Reiss, D. A. Hirshberg, A. Weiss, and M. J. Black. Drape: Dressing any person. ACM TOG, 2012.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"M. Hadi Kiapour, X. Han, S. Lazebnik, A. C. Berg, T. L. Berg",Where to buy it: Matching street clothing photos in online shops, In ICCV,,,2015,,"M. Hadi Kiapour, X. Han, S. Lazebnik, A. C. Berg, and T. L. Berg. Where to buy it: Matching street clothing photos in online shops. In ICCV, 2015.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"X. Han, Z. Wu, P. X. Huang, X. Zhang, M. Zhu, Y. Li, Y. Zhao, L. S. Davis",Automatic spatially-aware fashion concept discovery, In ICCV,,,2017,,"X. Han, Z. Wu, P. X. Huang, X. Zhang, M. Zhu, Y. Li, Y. Zhao, and L. S. Davis. Automatic spatially-aware fashion concept discovery. In ICCV, 2017.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"X. Han, Z. Wu, Y.-G. Jiang, L. S. Davis",Learning fashion compatibility with bidirectional lstms, In ACM Multimedia,,,2017,,"X. Han, Z. Wu, Y.-G. Jiang, and L. S. Davis. Learning fashion compatibility with bidirectional lstms. In ACM Multimedia, 2017.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"T. Hassner, S. Harel, E. Paz, R. Enbar",Effective face frontalization in unconstrained images, In CVPR,,,2015,,"T. Hassner, S. Harel, E. Paz, and R. Enbar. Effective face frontalization in unconstrained images. In CVPR, 2015.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"A. Hilsmann and , P. Eisert",Tracking and retexturing cloth for real-time virtual clothing applications, In MIRAGE,,,2009,,"A. Hilsmann and P. Eisert. Tracking and retexturing cloth for real-time virtual clothing applications. In MIRAGE, 2009.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"Y. Hu, X. Yi, L. S. Davis",Collaborative fashion recommendation: a functional tensor factorization approach, In ACM Multimedia,,,2015,,"Y. Hu, X. Yi, and L. S. Davis. Collaborative fashion recommendation: a functional tensor factorization approach. In ACM Multimedia, 2015.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"P. Isola, J.-Y. Zhu, T. Zhou, A. A. Efros",Image-to-image translation with conditional adversarial networks, In CVPR,,,2017,,"P. Isola, J.-Y. Zhu, T. Zhou, and A. A. Efros. Image-to-image translation with conditional adversarial networks. In CVPR, 2017.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"N. Jetchev and , U. Bergmann",The conditional analogy gan: Swapping fashion articles on people images, In ICCVW,,,2017,,"N. Jetchev and U. Bergmann. The conditional analogy gan: Swapping fashion articles on people images. In ICCVW, 2017.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"J. Johnson, A. Alahi, L. Fei-Fei",Perceptual losses for real-time style transfer and super-resolution, In ECCV,,,2016,,"J. Johnson, A. Alahi, and L. Fei-Fei. Perceptual losses for real-time style transfer and super-resolution. In ECCV, 2016.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"A. Kanazawa, D. W. Jacobs, M. Chandraker",Warpnet: Weakly supervised matching for single-view reconstruction, In CVPR,,,2016,,"A. Kanazawa, D. W. Jacobs, and M. Chandraker. Warpnet: Weakly supervised matching for single-view reconstruction. In CVPR, 2016.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"D. Kingma and , J. Ba",Adam: A method for stochastic optimization, arXiv preprint arXiv:1412,.6980,,2014,,"D. Kingma and J. Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"A. Kovashka, D. Parikh, K. Grauman",Whittlesearch: Image search with relative attribute feedback, In CVPR,,,2012,,"A. Kovashka, D. Parikh, and K. Grauman. Whittlesearch: Image search with relative attribute feedback. In CVPR, 2012.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"C. Lassner, G. Pons-Moll, P. V. Gehler",A generative model of people in clothing, In ICCV,,,2017,,"C. Lassner, G. Pons-Moll, and P. V. Gehler. A generative model of people in clothing. In ICCV, 2017.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"C. Ledig, L. Theis, F. Huszár, J. Caballero, A. Cunningham, A. Acosta, A. Aitken, A. Tejani, J. Totz, Z. Wang, W. Shi",Photo-realistic single image super-resolution using a generative adversarial network, In CVPR,,,2017,,"C. Ledig, L. Theis, F. Huszár, J. Caballero, A. Cunningham, A. Acosta, A. Aitken, A. Tejani, J. Totz, Z. Wang, and W. Shi. Photo-realistic single image super-resolution using a generative adversarial network. In CVPR, 2017.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"X. Liang, L. Lin, W. Yang, P. Luo, J. Huang, S. Yan",Clothes co-parsing via joint image segmentation and labeling with application to clothing retrieval, IEEE TMM,,,2016,,"X. Liang, L. Lin, W. Yang, P. Luo, J. Huang, and S. Yan. Clothes co-parsing via joint image segmentation and labeling with application to clothing retrieval. IEEE TMM, 2016.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"S. Liu, Z. Song, G. Liu, C. Xu, H. Lu, S. Yan",Street-toshop: Cross-scenario clothing retrieval via parts alignment and auxiliary set, In CVPR,,,2012,,"S. Liu, Z. Song, G. Liu, C. Xu, H. Lu, and S. Yan. Street-toshop: Cross-scenario clothing retrieval via parts alignment and auxiliary set. In CVPR, 2012.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"Z. Liu, P. Luo, S. Qiu, X. Wang, X. Tang",Deepfashion: Powering robust clothes recognition and retrieval with rich annotations, In CVPR,,,2016,,"Z. Liu, P. Luo, S. Qiu, X. Wang, and X. Tang. Deepfashion: Powering robust clothes recognition and retrieval with rich annotations. In CVPR, 2016.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"L. Ma, X. Jia, Q. Sun, B. Schiele, T. Tuytelaars, L. Van Gool",Pose guided person image generation, In NIPS,,,2017,,"L. Ma, X. Jia, Q. Sun, B. Schiele, T. Tuytelaars, and L. Van Gool. Pose guided person image generation. In NIPS, 2017.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"A. Odena, C. Olah, J. Shlens",Conditional image synthesis with auxiliary classifier gans, In ICML,,,2017,,"A. Odena, C. Olah, and J. Shlens. Conditional image synthesis with auxiliary classifier gans. In ICML, 2017.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"G. Perarnau, J. van de Weijer, B. Raducanu, J. M. Álvarez",Invertible conditional gans for image editing, In NIPS Workshop,,,2016,,"G. Perarnau, J. van de Weijer, B. Raducanu, and J. M. Álvarez. Invertible conditional gans for image editing. In NIPS Workshop, 2016.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"G. Pons-Moll, S. Pujades, S. Hu, M. Black",Clothcap: Seamless 4d clothing capture and retargeting, ACM TOG,,,2017,,"G. Pons-Moll, S. Pujades, S. Hu, and M. Black. Clothcap: Seamless 4d clothing capture and retargeting. ACM TOG, 2017.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"A. Radford, L. Metz, S. Chintala",Unsupervised representation learning with deep convolutional generative adversarial networks, arXiv preprint arXiv:,,,1511,,"A. Radford, L. Metz, and S. Chintala. Unsupervised representation learning with deep convolutional generative adversarial networks. arXiv preprint arXiv:1511.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"S. Reed, Z. Akata, X. Yan, L. Logeswaran, B. Schiele, H. Lee",Generative adversarial text to image synthesis, In ICML,,,2016,,"S. Reed, Z. Akata, X. Yan, L. Logeswaran, B. Schiele, and H. Lee. Generative adversarial text to image synthesis. In ICML, 2016.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"O. Ronneberger, P. Fischer, T. Brox",U-net: Convolutional networks for biomedical image segmentation, In MICCAI,,,2015,,"O. Ronneberger, P. Fischer, and T. Brox. U-net: Convolutional networks for biomedical image segmentation. In MICCAI, 2015.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"T. Salimans, I. Goodfellow, W. Zaremba, V. Cheung, A. Radford, X. Chen",Improved techniques for training gans, In NIPS,,,2016,,"T. Salimans, I. Goodfellow, W. Zaremba, V. Cheung, A. Radford, and X. Chen. Improved techniques for training gans. In NIPS, 2016.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"M. Sekine, K. Sugita, F. Perbet, B. Stenger, M. Nishiyama",Virtual fitting by single-shot body shape estimation, In 3D Body Scanning Technologies,,,2014,,"M. Sekine, K. Sugita, F. Perbet, B. Stenger, and M. Nishiyama. Virtual fitting by single-shot body shape estimation. In 3D Body Scanning Technologies, 2014.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"W. Shen and , R. Liu",Learning residual images for face attribute manipulation, CVPR,,,2017,,"W. Shen and R. Liu. Learning residual images for face attribute manipulation. CVPR, 2017.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"K. Simonyan and , A. Zisserman",Very deep convolutional networks for large-scale image recognition, In ICLR,,,2015,,"K. Simonyan and A. Zisserman. Very deep convolutional networks for large-scale image recognition. In ICLR, 2015.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"A. Veit, B. Kovacs, S. Bell, J. McAuley, K. Bala, S. Belongie",Learning visual clothing style with heterogeneous dyadic co-occurrences, In CVPR,,,2015,,"A. Veit, B. Kovacs, S. Bell, J. McAuley, K. Bala, and S. Belongie. Learning visual clothing style with heterogeneous dyadic co-occurrences. In CVPR, 2015.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"K. Yamaguchi, M. Hadi Kiapour, T. L. Berg",Paper doll parsing: Retrieving similar styles to parse clothing items, In ICCV,,,2013,,"K. Yamaguchi, M. Hadi Kiapour, and T. L. Berg. Paper doll parsing: Retrieving similar styles to parse clothing items. In ICCV, 2013.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"S. Yang, T. Ambert, Z. Pan, K. Wang, L. Yu, T. Berg, M. C. Lin",Detailed garment recovery from a single-view image, In ICCV,,,2017,,"S. Yang, T. Ambert, Z. Pan, K. Wang, L. Yu, T. Berg, and M. C. Lin. Detailed garment recovery from a single-view image. In ICCV, 2017.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"D. Yoo, N. Kim, S. Park, A. S. Paek, I. S. Kweon",Pixellevel domain transfer, In ECCV,,,2016,,"D. Yoo, N. Kim, S. Park, A. S. Paek, and I. S. Kweon. Pixellevel domain transfer. In ECCV, 2016.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"H. Zhang, T. Xu, H. Li, S. Zhang, X. Huang, X. Wang, D. Metaxas",Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks, In ICCV,,,2017,,"H. Zhang, T. Xu, H. Li, S. Zhang, X. Huang, X. Wang, and D. Metaxas. Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks. In ICCV, 2017.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"B. Zhao, J. Feng, X. Wu, S. Yan",Memory-augmented attribute manipulation networks for interactive fashion search, In CVPR,,,2017,,"B. Zhao, J. Feng, X. Wu, and S. Yan. Memory-augmented attribute manipulation networks for interactive fashion search. In CVPR, 2017.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"S. Zhu, S. Fidler, R. Urtasun, D. Lin, C. L. Chen",Be your own prada: Fashion synthesis with structural coherence, In ICCV,,,2017,,"S. Zhu, S. Fidler, R. Urtasun, D. Lin, and C. L. Chen. Be your own prada: Fashion synthesis with structural coherence. In ICCV, 2017.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"X. Zhu, Z. Lei, J. Yan, D. Yi, S. Z. Li",High-fidelity pose and expression normalization for face recognition in the wild, In CVPR,,,2015,,"X. Zhu, Z. Lei, J. Yan, D. Yi, and S. Z. Li. High-fidelity pose and expression normalization for face recognition in the wild. In CVPR, 2015.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"K. Gong, X. Liang, X. Shen, L. Lin",Look into person: Self-supervised structure-sensitive learning and a new benchmark for human parsing, In CVPR,,,2017,,"K. Gong, X. Liang, X. Shen, and L. Lin. Look into person: Self-supervised structure-sensitive learning and a new benchmark for human parsing. In CVPR, 2017.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"J. Long, E. Shelhamer, T. Darrell",Fully convolutional networks for semantic segmentation, In CVPR,,,2015,,"J. Long, E. Shelhamer, and T. Darrell. Fully convolutional networks for semantic segmentation. In CVPR, 2015.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"F. Xia, P. Wang, L.-C. Chen, A. L. Yuille",Zoom better to see clearer: Human and object parsing with hierarchical auto-zoom net, In ECCV,,,2016,,"F. Xia, P. Wang, L.-C. Chen, and A. L. Yuille. Zoom better to see clearer: Human and object parsing with hierarchical auto-zoom net. In ECCV, 2016.",./refs/download/2/Viton: An image-based virtual try-on network.pdf,Viton: An image-based virtual try-on network
0,"Hadsell, R., Chopra, S., LeCun, Y., Hinton, G.",: Visualizing data using t-sne,Journal of machine learning research 9(Nov),,,2579,,"Ge, W. Huang, D. Dong, M. R. Scott Ablation Study We perform ablation studies on In-Shop Clothes and CUB-200-2011, as reported in Table 4. First, directly applying hard negative sampling (HNS) to the whole training set is difficult to obtain a performance gain. Actually, our baseline model applies a semi-HNS, which outperforms HNS. We design a strong class-level constrain - Anchor-Neighbor Sampling of HTL, which encourages the model to learn discriminative features from visual similar classes. This is the key to performance boost. Second, we integrated the proposed anchor-neighbor sampling and dynamic violate margin into HDC where a contrastive loss is used. As shown in Table 4 (bottom), HDC+ got an improvement of 7.3% R@1 on the In-Shop Clothes Retrieval, suggesting that our methods work practically well with a contrastive loss and HDC. Third, HTL with a depth of 16 achieves best performance at R@1 of 80.9%. This is used as default setting in all our experiments. We also include results of “flat” tree with depth=1. Results suggest that the “flat” tree with the proposed dynamic violate margin improves the R@1 from 75.3% to 78.9%, and hierarchy tree improves it further to 80.9%. Table 4. Ablation Studies on In-Shop Clothes Retrieval and CUB-200-2011. In-Shop Clothes 1 10 20 30 40 50 On Triplets with Sampling Random Sampling 59.3 83.5 87.9 90.5 91.3 93.0 Hard Negative Mining 60.1 84.3 88.2 90.2 91.5 92.6 Semi-Hard Negative Mining 62.3 85.1 89.0 91.1 92.4 93.4 Anchor-Neighbor Sampling (HTL) 75.3 91.8 94.3 96.2 96.7 97.5 R@ CUB-200-2011 4 8 16 1 2 51.4 51.6 55.9 56.4 63.9 63.9 68.4 68.5 32 74.8 74.2 78.2 78.5 83.4 84.4 86.0 86.2 90.0 89.9 92.2 92.4 94.3 94.6 95.5 95.5 HTL with A-N Sampling + Dynamic Violate Margin(αz ) Class Proxy(flat/depth=1) 78.9 93.4 94.8 96.0 96.5 97.5 56.0 68.1 78.2 HTL(depth=8) 78.7 93.3 94.6 96.2 96.9 97.4 56.2 68.5 78.3 HTL(depth=16) 80.9 94.3 95.8 97.2 97.4 97.8 57.1 68.8 78.7 HTL(depth=32) 79.3 93.8 95.0 96.9 97.1 97.5 56.4 68.5 78.5 86.2 86.1 86.5 86.2 92.3 92.3 92.5 92.3 95.5 95.5 95.5 95.5 HDC HDC+ 6 HDC+: Contrastive Loss with A-N Sampling + Dynamic Violate Margin(αz ) 62.1 84.9 89.0 91.2 92.3 93.1 53.6 65.7 77.0 85.6 91.5 95.5 69.4 88.6 93.4 94.1 95.3 96.5 54.1 66.3 77.2 85.6 91.7 95.5 Conclusion We have presented a new hierarchical triplet loss (HTL) which is able to select informative training samples (triplets) via an adaptively-updated hierarchical tree that encodes global context. HTL effectively handles the main limitation of random sampling, which is a critical issue for deep metric learning. First, we construct a hierarchical tree at the class level which encodes global context information over the whole dataset. Visual similar classes are merged recursively to form the hierarchy. Second, the problem of triplet collection is formulated by proposing a new violate margin, which is computed dynamically based on the designed hierarchical tree. This allows it to learn from more meaningful hard samples with the guide of global context. The proposed HTL is evaluated on the Deep Metric Learning with Hierarchical Triplet Loss 15 tasks of image retrieval and face recognition, where it achieves new state-of-theart performance on a number of standard benchmarks. 16 W. Ge, W. Huang, D. Dong, M. R. Scott References 1. Amos, B., Ludwiczuk, B., Satyanarayanan, M.: Openface: A general-purpose face recognition library with mobile applications. CMU School of Computer Science (2016) 2. Bai, S., Bai, X., Tian, Q., Latecki, L.J.: Regularized diffusion process for visual retrieval. In: AAAI. pp. 3967–3973 (2017) 3. Bai, S., Zhou, Z., Wang, J., Bai, X., Latecki, L.J., Tian, Q.: Ensemble diffusion for retrieval. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 774–783 (2017) 4. Bucher, M., Herbin, S., Jurie, F.: Hard negative mining for metric learning based zero-shot classification. In: European Conference on Computer Vision. pp. 524–531. Springer (2016) 5. Chen, W., Chen, X., Zhang, J., Huang, K.: Beyond triplet loss: A deep quadruplet network for person re-identification. In: The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (July 2017) 6. Hadsell, R., Chopra, S., LeCun, Y.: Dimensionality reduction by learning an invariant mapping. In: Computer vision and pattern recognition, 2006 IEEE computer society conference on. vol. 2, pp. 1735–1742. IEEE (2006) 7. Harwood, B., Kumar B G, V., Carneiro, G., Reid, I., Drummond, T.: Smart mining for deep metric learning. In: The IEEE International Conference on Computer Vision (ICCV) (Oct 2017) 8. Huang, G.B., Ramesh, M., Berg, T., Learned-Miller, E.: Labeled faces in the wild: A database for studying face recognition in unconstrained environments. Tech. Rep. 07-49, University of Massachusetts, Amherst (October 2007) 9. Ioffe, S., Szegedy, C.: Batch normalization: Accelerating deep network training by reducing internal covariate shift. In: International conference on machine learning. pp. 448–456 (2015) 10. Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J., Girshick, R., Guadarrama, S., Darrell, T.: Caffe: Convolutional architecture for fast feature embedding. In: Proceedings of the 22nd ACM international conference on Multimedia. pp. 675–678. ACM (2014) 11. Krause, J., Stark, M., Deng, J., Fei-Fei, L.: 3d object representations for finegrained categorization. In: 4th IEEE Workshop on 3D Representation and Recognition, ICCV (2013) 12. Kumar, B., Carneiro, G., Reid, I., et al.: Learning local image descriptors with deep siamese and triplet convolutional networks by minimising global loss functions. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 5385–5394 (2016) 13. van Lint, J.H., Wilson, R.M.: A course in combinatorics. Cambridge university press (2001) 14. Liu, W., Wen, Y., Yu, Z., Li, M., Raj, B., Song, L.: Sphereface: Deep hypersphere embedding for face recognition. In: The IEEE Conference on Computer Vision and Pattern Recognition (CVPR). vol. 1 (2017) 15. Liu, Z., Luo, P., Qiu, S., Wang, X., Tang, X.: Deepfashion: Powering robust clothes recognition and retrieval with rich annotations. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 1096–1104 (2016) 16. Maaten, L.v.d., Hinton, G.: Visualizing data using t-sne. Journal of machine learning research 9(Nov), 2579–2605 (2008) Deep Metric Learning with Hierarchical Triplet Loss 17 17. Opitz, M., Waltner, G., Possegger, H., Bischof, H.: Bier - boosting independent embeddings robustly. In: The IEEE International Conference on Computer Vision (ICCV) (Oct 2017) 18. Opitz, M., Waltner, G., Possegger, H., Bischof, H.: Bier-boosting independent embeddings robustly. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. pp. 5189–5198 (2017) 19. Orr, G.B., Müller, K.R.: Neural networks: tricks of the trade. Springer (2003) 20. Parkhi, O.M., Vedaldi, A., Zisserman, A., et al.: Deep face recognition. In: BMVC. vol. 1, p. 6 (2015) 21. Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Karpathy, A., Khosla, A., Bernstein, M., Berg, A.C., Fei-Fei, L.: ImageNet Large Scale Visual Recognition Challenge. International Journal of Computer Vision (IJCV) 115(3), 211–252 (2015).",./refs/download/2/Deep metric learning with hierarchical triplet loss.pdf,Deep metric learning with hierarchical triplet loss
0,,,,,,,, S. Bell and ,./refs/download/2/Learning visual clothing style with heterogeneous dyadic co-occurrences.pdf,Learning visual clothing style with heterogeneous dyadic co-occurrences
0,,,,,,,," S. Bell, P. Upchurch, N. Snavely, and ",./refs/download/2/Learning visual clothing style with heterogeneous dyadic co-occurrences.pdf,Learning visual clothing style with heterogeneous dyadic co-occurrences
0,,,,,,,," L. Bossard, M. Dantone, C. Leistner, C. Wengert, T. Quack, and ",./refs/download/2/Learning visual clothing style with heterogeneous dyadic co-occurrences.pdf,Learning visual clothing style with heterogeneous dyadic co-occurrences
0,,,,,,,," S. Chopra, R. Hadsell, and ",./refs/download/2/Learning visual clothing style with heterogeneous dyadic co-occurrences.pdf,Learning visual clothing style with heterogeneous dyadic co-occurrences
0,,,,,,,," R. Hadsell, S. Chopra, and ",./refs/download/2/Learning visual clothing style with heterogeneous dyadic co-occurrences.pdf,Learning visual clothing style with heterogeneous dyadic co-occurrences
0,,,,,,,," J. Hu, J. Lu, and ",./refs/download/2/Learning visual clothing style with heterogeneous dyadic co-occurrences.pdf,Learning visual clothing style with heterogeneous dyadic co-occurrences
0,,,,,,,," Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Girshick, S. Guadarrama, and ",./refs/download/2/Learning visual clothing style with heterogeneous dyadic co-occurrences.pdf,Learning visual clothing style with heterogeneous dyadic co-occurrences
0,,,,,,,," A. Kovashka, D. Parikh, and ",./refs/download/2/Learning visual clothing style with heterogeneous dyadic co-occurrences.pdf,Learning visual clothing style with heterogeneous dyadic co-occurrences
0,,,,,,,," A. Krizhevsky, I. Sutskever, and ",./refs/download/2/Learning visual clothing style with heterogeneous dyadic co-occurrences.pdf,Learning visual clothing style with heterogeneous dyadic co-occurrences
0,,,,,,,," Y. LeCun, L. Bottou, Y. Bengio, and ",./refs/download/2/Learning visual clothing style with heterogeneous dyadic co-occurrences.pdf,Learning visual clothing style with heterogeneous dyadic co-occurrences
0,,,,,,,," Y. Cui, S. Belongie, and ",./refs/download/2/Learning visual clothing style with heterogeneous dyadic co-occurrences.pdf,Learning visual clothing style with heterogeneous dyadic co-occurrences
0,,,,,,,," G. Linden, B. Smith, and ",./refs/download/2/Learning visual clothing style with heterogeneous dyadic co-occurrences.pdf,Learning visual clothing style with heterogeneous dyadic co-occurrences
0,,,,,,,," J. McAuley, C. Targett, Q. Shi, and ",./refs/download/2/Learning visual clothing style with heterogeneous dyadic co-occurrences.pdf,Learning visual clothing style with heterogeneous dyadic co-occurrences
0,,,,,,,," A. C. Murillo, I. S. Kwak, L. Bourdev, D. Kriegman, and ",./refs/download/2/Learning visual clothing style with heterogeneous dyadic co-occurrences.pdf,Learning visual clothing style with heterogeneous dyadic co-occurrences
0,,,,,,,," A. S. Razavian, H. Azizpour, J. Sullivan, and ",./refs/download/2/Learning visual clothing style with heterogeneous dyadic co-occurrences.pdf,Learning visual clothing style with heterogeneous dyadic co-occurrences
0,,,,,,,," O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, A. C. Berg, and ",./refs/download/2/Learning visual clothing style with heterogeneous dyadic co-occurrences.pdf,Learning visual clothing style with heterogeneous dyadic co-occurrences
0,,,,,,,," C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, and ",./refs/download/2/Learning visual clothing style with heterogeneous dyadic co-occurrences.pdf,Learning visual clothing style with heterogeneous dyadic co-occurrences
0,,,,,,,, L. van der Maaten and ,./refs/download/2/Learning visual clothing style with heterogeneous dyadic co-occurrences.pdf,Learning visual clothing style with heterogeneous dyadic co-occurrences
0,,,,,,,," S. Vittayakorn, K. Yamaguchi, A. C. Berg, and ",./refs/download/2/Learning visual clothing style with heterogeneous dyadic co-occurrences.pdf,Learning visual clothing style with heterogeneous dyadic co-occurrences
0,J. L. Bentley,Multidimensional binary search trees used for associative searching, Communications of the ACM,,,1975,18,"J. L. Bentley. Multidimensional binary search trees used for associative searching. Communications of the ACM, 18(9):509–517, 1975.",./refs/download/2/Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models.pdf,Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models
0,"D. Boscaini, J. Masci, S. Melzi, M. M. Bronstein, U. Castellani, P. Vandergheynst",Learning class-specific descriptors for deformable shapes using localized spectral convolutional networks, Comput,. Graph. Forum,,2015,34,"D. Boscaini, J. Masci, S. Melzi, M. M. Bronstein, U. Castellani, and P. Vandergheynst. Learning class-specific descriptors for deformable shapes using localized spectral convolutional networks. Comput. Graph. Forum, 34(5):13–23, 2015.",./refs/download/2/Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models.pdf,Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models
0,"D. Boscaini, J. Masci, E. Rodolà, M. M. Bronstein",Learning shape correspondence with anisotropic convolutional neural networks, In Proc,. NIPS,,2016,,"D. Boscaini, J. Masci, E. Rodolà, and M. M. Bronstein. Learning shape correspondence with anisotropic convolutional neural networks. In Proc. NIPS, pages 3189–3197, 2016.",./refs/download/2/Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models.pdf,Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models
0,"A. Brock, T. Lim, J. Ritchie, N. Weston",Generative and discriminative voxel modeling with convolutional neural networks, arXiv preprint arXiv:,,,1608,,"A. Brock, T. Lim, J. Ritchie, and N. Weston. Generative and discriminative voxel modeling with convolutional neural networks. arXiv preprint arXiv:1608.",./refs/download/2/Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models.pdf,Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models
0,"J. Bromley, J. W. Bentz, L. Bottou, I. Guyon, Y. LeCun, C. Moore, E. Säckinger, R. Shah",Signature verification using a siamese time delay neural network, International Journal of Pattern Recognition and Artificial Intelligence,,,1993,,"J. Bromley, J. W. Bentz, L. Bottou, I. Guyon, Y. LeCun, C. Moore, E. Säckinger, and R. Shah. Signature verification using a siamese time delay neural network. International Journal of Pattern Recognition and Artificial Intelligence, 7(04):669–688, 1993.",./refs/download/2/Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models.pdf,Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models
0,"J. Bruna, W. Zaremba, A. Szlam, Y. LeCun",Spectral networks and locally connected networks on graphs, arXiv preprint arXiv:,,,1312,,"J. Bruna, W. Zaremba, A. Szlam, and Y. LeCun. Spectral networks and locally connected networks on graphs. arXiv preprint arXiv:1312.",./refs/download/2/Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models.pdf,Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models
0,A. X. Chang,T, Funkhouser,,,1512,,"A. X. Chang, T. Funkhouser, L. Guibas, P. Hanrahan, Q. Huang, Z. Li, S. Savarese, M. Savva, S. Song, H. Su, et al. Shapenet: An information-rich 3d model repository. arXiv preprint arXiv:1512.",./refs/download/2/Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models.pdf,Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models
0,"S. Chopra, R. Hadsell, Y. LeCun",Learning a similarity metric discriminatively, with application to face verification,. In Proc. CVPR,,2005,,"S. Chopra, R. Hadsell, and Y. LeCun. Learning a similarity metric discriminatively, with application to face verification. In Proc. CVPR, pages 539–546, 2005.",./refs/download/2/Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models.pdf,Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models
0,S. Dieleman,J, Schlter,,,2015,,"S. Dieleman, J. Schlter, C. Raffel, E. Olson, et al. Lasagne: First release., Aug. 2015.",./refs/download/2/Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models.pdf,Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models
0,"J. D. Foley, A. Van Dam, S. K. Feiner, J. F. Hughes, R. L. Phillips",Introduction to computer graphics, volume 55,. Addison-Wesley Reading,,1994,,"J. D. Foley, A. Van Dam, S. K. Feiner, J. F. Hughes, and R. L. Phillips. Introduction to computer graphics, volume 55. Addison-Wesley Reading, 1994.",./refs/download/2/Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models.pdf,Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models
0,"A. Guttman, M. Stonebraker, C. U. B. E. R. LAB",Rtrees: A Dynamic Index Structure for Spatial Searching, Memorandum (University of California,,,1983,,"A. Guttman, M. Stonebraker, and C. U. B. E. R. LAB. Rtrees: A Dynamic Index Structure for Spatial Searching. Memorandum (University of California, Berkeley, Electronics Research Laboratory). Defense Technical Information Center, 1983.",./refs/download/2/Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models.pdf,Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models
0,"V. Hegde and , R. Zadeh",Fusionnet: 3d object classification using multiple data representations, arXiv preprint arXiv:1607,.05695,,2016,,"V. Hegde and R. Zadeh. Fusionnet: 3d object classification using multiple data representations. arXiv preprint arXiv:1607.05695, 2016.",./refs/download/2/Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models.pdf,Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models
0,"M. Jaderberg, K. Simonyan, A. Zisserman, K. Kavukcuoglu",Spatial transformer networks, In Proc,. NIPS,,2015,,"M. Jaderberg, K. Simonyan, A. Zisserman, and K. Kavukcuoglu. Spatial transformer networks. In Proc. NIPS, pages 2017–2025, 2015.",./refs/download/2/Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models.pdf,Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models
0,"D. Laptev, N. Savinov, J. M. Buhmann, M. Pollefeys",TI-POOLING: transformation-invariant pooling for feature learning in convolutional neural networks, In Proc,. CVPR,,2016,,"D. Laptev, N. Savinov, J. M. Buhmann, and M. Pollefeys. TI-POOLING: transformation-invariant pooling for feature learning in convolutional neural networks. In Proc. CVPR, pages 289–297, 2016.",./refs/download/2/Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models.pdf,Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models
0,"Y. LeCun, L. Bottou, Y. Bengio, P. Haffner",Gradientbased learning applied to document recognition, Proceedings of the IEEE,,,1998,86,"Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradientbased learning applied to document recognition. Proceedings of the IEEE, 86(11):2278–2324, 1998.",./refs/download/2/Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models.pdf,Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models
0,"Y. Li, S. Pirk, H. Su, C. R. Qi, L. J. Guibas",Fpnn: Field probing neural networks for 3d data, In Proc,. NIPS,,2016,,"Y. Li, S. Pirk, H. Su, C. R. Qi, and L. J. Guibas. Fpnn: Field probing neural networks for 3d data. In Proc. NIPS, 2016.",./refs/download/2/Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models.pdf,Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models
0,"J. Long, E. Shelhamer, T. Darrell",Fully convolutional networks for semantic segmentation, In Proc,. CVPR,,2015,,"J. Long, E. Shelhamer, and T. Darrell. Fully convolutional networks for semantic segmentation. In Proc. CVPR, pages 3431–3440, 2015.",./refs/download/2/Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models.pdf,Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models
0,"D. Maturana and , S. Scherer",Voxnet: A 3d convolutional neural network for real-time object recognition, In Proc,. IROS,,2015,,"D. Maturana and S. Scherer. Voxnet: A 3d convolutional neural network for real-time object recognition. In Proc. IROS, pages 922–928. IEEE, 2015.",./refs/download/2/Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models.pdf,Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models
0,D. J. Meagher,Octree encoding: A new technique for the representation, manipulation and display of arbitrary 3-d objects by computer,. Electrical and Systems Engineering Department Rensseiaer Polytechnic Institute Image Processing Laboratory,,1980,,"D. J. Meagher. Octree encoding: A new technique for the representation, manipulation and display of arbitrary 3-d objects by computer. Electrical and Systems Engineering Department Rensseiaer Polytechnic Institute Image Processing Laboratory, 1980.",./refs/download/2/Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models.pdf,Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models
0,"C. R. Qi, H. Su, K. Mo, L. J. Guibas",Pointnet: Deep learning on point sets for 3d classification and segmentation, arXiv preprint arXiv:,,,1612,,"C. R. Qi, H. Su, K. Mo, and L. J. Guibas. Pointnet: Deep learning on point sets for 3d classification and segmentation. arXiv preprint arXiv:1612.",./refs/download/2/Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models.pdf,Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models
0,"C. R. Qi, H. Su, M. Niessner, A. Dai, M. Yan, L. J. Guibas",Volumetric and multi-view cnns for object classification on 3d data, In Proc,. CVPR,,2016,,"C. R. Qi, H. Su, M. Niessner, A. Dai, M. Yan, and L. J. Guibas. Volumetric and multi-view cnns for object classification on 3d data. In Proc. CVPR, 2016.",./refs/download/2/Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models.pdf,Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models
0,A. Requicha,H, Voelcker,,,1977,,"A. Requicha, H. Voelcker, and U. of Rochester. Production Automation Project. Constructive Solid Geometry. TM (Rochester, PAP). Production Automation Project, University of Rochester, 1977.",./refs/download/2/Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models.pdf,Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models
0,"G. Riegler, A. O. Ulusoy, A. Geiger",Octnet: Learning deep 3d representations at high resolutions, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,,,2017,,"G. Riegler, A. O. Ulusoy, and A. Geiger. Octnet: Learning deep 3d representations at high resolutions. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2017.",./refs/download/2/Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models.pdf,Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models
0,"O. Ronneberger, P. Fischer, T. Brox",U-net: Convolutional networks for biomedical image segmentation, In Proc,. MICCAI,,2015,,"O. Ronneberger, P. Fischer, and T. Brox. U-net: Convolutional networks for biomedical image segmentation. In Proc. MICCAI, pages 234–241. Springer, 2015.",./refs/download/2/Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models.pdf,Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models
0,H. Samet,The design and analysis of spatial data structures, volume 199,. Addison-Wesley Reading,,1990,,"H. Samet. The design and analysis of spatial data structures, volume 199. Addison-Wesley Reading, MA, 1990.",./refs/download/2/Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models.pdf,Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models
0,M. Savva,F, Yu,,,2016,,"M. Savva, F. Yu, H. Su, M. Aono, B. Chen, D. Cohen-Or, W. Deng, H. Su, S. Bai, X. Bai, et al. SHREC16 track largescale 3d shape retrieval from ShapeNet Core-55. In Proceedings of the Eurographics Workshop on 3D Object Retrieval, 2016.",./refs/download/2/Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models.pdf,Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models
0,"M. Schultz and , T. Joachims",Learning a distance metric from relative comparisons, Advances in neural information processing systems (NIPS),,,2004,,"M. Schultz and T. Joachims. Learning a distance metric from relative comparisons. Advances in neural information processing systems (NIPS), page 41, 2004.",./refs/download/2/Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models.pdf,Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models
0,"R. A. Schumacker, B. Brand, M. G. Gilliland, W. H. Sharp",Study for applying computer-generated images to visual simulation, Technical report,,,1969,,"R. A. Schumacker, B. Brand, M. G. Gilliland, and W. H. Sharp. Study for applying computer-generated images to visual simulation. Technical report, DTIC Document, 1969.",./refs/download/2/Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models.pdf,Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models
0,"M. Simonovsky and , N. Komodakis",Dynamic edgeconditioned filters in convolutional neural networks on graphs, In Proc,. CVPR,,2017,,"M. Simonovsky and N. Komodakis. Dynamic edgeconditioned filters in convolutional neural networks on graphs. In Proc. CVPR, 2017.",./refs/download/2/Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models.pdf,Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models
0,"R. Socher, C. C. Lin, C. Manning, A. Y. Ng",Parsing natural scenes and natural language with recursive neural networks, In Proc,. ICML,,2011,,"R. Socher, C. C. Lin, C. Manning, and A. Y. Ng. Parsing natural scenes and natural language with recursive neural networks. In Proc. ICML, pages 129–136, 2011.",./refs/download/2/Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models.pdf,Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models
0,"H. Su, S. Maji, E. Kalogerakis, E. Learned-Miller",Multiview convolutional neural networks for 3d shape recognition, In Proc,. ICCV,,2015,,"H. Su, S. Maji, E. Kalogerakis, and E. Learned-Miller. Multiview convolutional neural networks for 3d shape recognition. In Proc. ICCV, pages 945–953, 2015.",./refs/download/2/Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models.pdf,Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models
0,"E. Ustinova and , V. S. Lempitsky",Learning deep embeddings with histogram loss, In Proc,. NIPS,,2016,,"E. Ustinova and V. S. Lempitsky. Learning deep embeddings with histogram loss. In Proc. NIPS, pages 4170–4178, 2016.",./refs/download/2/Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models.pdf,Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models
0,"D. Z. Wang and , I. Posner",Voting for voting in online point cloud object detection, In Proc,. RSS,,2015,,"D. Z. Wang and I. Posner. Voting for voting in online point cloud object detection. In Proc. RSS, 2015.",./refs/download/2/Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models.pdf,Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models
0,"J. Wu, C. Zhang, T. Xue, B. Freeman, J. Tenenbaum",Learning a probabilistic latent space of object shapes via 3d generative-adversarial modeling, In Proc,. NIPS,,2016,,"J. Wu, C. Zhang, T. Xue, B. Freeman, and J. Tenenbaum. Learning a probabilistic latent space of object shapes via 3d generative-adversarial modeling. In Proc. NIPS, pages 82– 90, 2016.",./refs/download/2/Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models.pdf,Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models
0,"Z. Wu, S. Song, A. Khosla, F. Yu, L. Zhang, X. Tang, J. Xiao",3d shapenets: A deep representation for volumetric shapes, In Proc,. CVPR,,2015,,"Z. Wu, S. Song, A. Khosla, F. Yu, L. Zhang, X. Tang, and J. Xiao. 3d shapenets: A deep representation for volumetric shapes. In Proc. CVPR, pages 1912–1920, 2015.",./refs/download/2/Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models.pdf,Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models
0,L. Yi,V, G,. Kim,,2016,,"L. Yi, V. G. Kim, D. Ceylan, I. Shen, M. Yan, H. Su, A. Lu, Q. Huang, A. Sheffer, L. Guibas, et al. A scalable active framework for region annotation in 3d shape collections. ACM Transactions on Graphics (TOG), 35(6):210, 2016.",./refs/download/2/Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models.pdf,Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models
0,"Ando, R., Zhang, T.",A framework for learning predictive structures from multiple tasks and unlabeled data,JMLR,,,2005,6,"References Ando, R. and Zhang, T. A framework for learning predictive structures from multiple tasks and unlabeled data. JMLR, 6, 2005.",./refs/download/2/Decaf: A deep convolutional activation feature for generic visual recognition.pdf,Decaf: A deep convolutional activation feature for generic visual recognition
0,"Bay, H., Tuytelaars, T., Gool, L.",Van,SURF: Speeded up robust features. In ECCV,,,2006,,"Bay, H., Tuytelaars, T., and Gool, L. Van. SURF: Speeded up robust features. In ECCV, 2006.",./refs/download/2/Decaf: A deep convolutional activation feature for generic visual recognition.pdf,Decaf: A deep convolutional activation feature for generic visual recognition
0,,,,,,,,"Berg, A., Deng, J., and Fei-Fei, L. ImageNet large scale vi- DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition sual recognition challenge 2012.",./refs/download/2/Decaf: A deep convolutional activation feature for generic visual recognition.pdf,Decaf: A deep convolutional activation feature for generic visual recognition
0,"Berg, T., Belhumeur, P.","POOF: Part-based one-vs-one features for fine-grained categorization, face verification, and attribute estimation",In CVPR,,,2013,,"Berg, T. and Belhumeur, P. POOF: Part-based one-vs-one features for fine-grained categorization, face verification, and attribute estimation. In CVPR, 2013.",./refs/download/2/Decaf: A deep convolutional activation feature for generic visual recognition.pdf,Decaf: A deep convolutional activation feature for generic visual recognition
0,"Bo, L., Ren, X., Fox, D.",Kernel descriptors for visual recognition,In NIPS,,,2010,,"Bo, L., Ren, X., and Fox, D. Kernel descriptors for visual recognition. In NIPS, 2010.",./refs/download/2/Decaf: A deep convolutional activation feature for generic visual recognition.pdf,Decaf: A deep convolutional activation feature for generic visual recognition
0,"Caruana, R.",Multitask learning,Machine Learning,,,1997,28,"Caruana, R. Multitask learning. Machine Learning, 28, 1997.",./refs/download/2/Decaf: A deep convolutional activation feature for generic visual recognition.pdf,Decaf: A deep convolutional activation feature for generic visual recognition
0,"Chopra, S., Balakrishnan, S., Gopalan, R.",Dlid: Deep learning for domain adaptation by interpolating between domains,In ICML Workshop on Challenges in Representation Learning,,,2013,,"Chopra, S., Balakrishnan, S., and Gopalan, R. Dlid: Deep learning for domain adaptation by interpolating between domains. In ICML Workshop on Challenges in Representation Learning, 2013.",./refs/download/2/Decaf: A deep convolutional activation feature for generic visual recognition.pdf,Decaf: A deep convolutional activation feature for generic visual recognition
0,"Dalal, N., Triggs, B.",Histograms of oriented gradients for human detection,In CVPR,,,2005,,"Dalal, N. and Triggs, B. Histograms of oriented gradients for human detection. In CVPR, 2005.",./refs/download/2/Decaf: A deep convolutional activation feature for generic visual recognition.pdf,Decaf: A deep convolutional activation feature for generic visual recognition
0,"Daume III, H.",Frustratingly easy domain adaptation,In ACL,,,2007,,"Daume III, H. Frustratingly easy domain adaptation. In ACL, 2007.",./refs/download/2/Decaf: A deep convolutional activation feature for generic visual recognition.pdf,Decaf: A deep convolutional activation feature for generic visual recognition
0,"Deng, J., Dong, W., Socher, R., Li, L., Li, K., Fei-Fei, L.",ImageNet: A Large-Scale Hierarchical Image Database,In CVPR,,,2009,,"Deng, J., Dong, W., Socher, R., Li, L., Li, K., and Fei-Fei, L. ImageNet: A Large-Scale Hierarchical Image Database. In CVPR, 2009.",./refs/download/2/Decaf: A deep convolutional activation feature for generic visual recognition.pdf,Decaf: A deep convolutional activation feature for generic visual recognition
0,"Fei-Fei, L., Fergus, R., Perona, P.",Learning generative visual models from few training examples: an incremental Bayesian approach tested on 101 object categories,In CVPR,,,2004,,"Fei-Fei, L., Fergus, R., and Perona, P. Learning generative visual models from few training examples: an incremental Bayesian approach tested on 101 object categories. In CVPR, 2004.",./refs/download/2/Decaf: A deep convolutional activation feature for generic visual recognition.pdf,Decaf: A deep convolutional activation feature for generic visual recognition
0,"Felzenszwalb, P., Girshick, R., McAllester, D., Ramanan, D.",Object detection with discriminatively trained part-based models,PAMI,,,2010,32,"Felzenszwalb, P., Girshick, R., McAllester, D., and Ramanan, D. Object detection with discriminatively trained part-based models. PAMI, 32, 2010.",./refs/download/2/Decaf: A deep convolutional activation feature for generic visual recognition.pdf,Decaf: A deep convolutional activation feature for generic visual recognition
0,"Fidler, S., Leonardis, A.",Towards scalable representations of object categories: Learning a hierarchy of parts,In CVPR,,,2007,,"Fidler, S. and Leonardis, A. Towards scalable representations of object categories: Learning a hierarchy of parts. In CVPR, 2007.",./refs/download/2/Decaf: A deep convolutional activation feature for generic visual recognition.pdf,Decaf: A deep convolutional activation feature for generic visual recognition
0,"Gong, B., Shi, Y., Sha, F., Grauman, K.",Geodesic flow kernel for unsupervised domain adaptation,In CVPR,,,2012,,"Gong, B., Shi, Y., Sha, F., and Grauman, K. Geodesic flow kernel for unsupervised domain adaptation. In CVPR, 2012.",./refs/download/2/Decaf: A deep convolutional activation feature for generic visual recognition.pdf,Decaf: A deep convolutional activation feature for generic visual recognition
0,"Hinton, G., Salakhutdinov, R.",Reducing the dimensionality of data with neural networks,Science,,,2006,,"Hinton, G. and Salakhutdinov, R. Reducing the dimensionality of data with neural networks. Science, 2006.",./refs/download/2/Decaf: A deep convolutional activation feature for generic visual recognition.pdf,Decaf: A deep convolutional activation feature for generic visual recognition
0,"Hinton, G., Srivastava, N., Krizhevsky, A., Sutskever, I., Salakhutdinov, R.",Improving neural networks by preventing co-adaptation of feature detectors,arXiv preprint arXiv:1207.0580,,,2012,,"Hinton, G., Srivastava, N., Krizhevsky, A., Sutskever, I., and Salakhutdinov, R. Improving neural networks by preventing co-adaptation of feature detectors. arXiv preprint arXiv:1207.0580, 2012.",./refs/download/2/Decaf: A deep convolutional activation feature for generic visual recognition.pdf,Decaf: A deep convolutional activation feature for generic visual recognition
0,"Hoffman, J., Rodner, E., Donahue, J., Saenko, K., Darrell, T.",Efficient learning of domain-invariant image representations,In ICLR,,,2013,,"Hoffman, J., Rodner, E., Donahue, J., Saenko, K., and Darrell, T. Efficient learning of domain-invariant image representations. In ICLR, 2013.",./refs/download/2/Decaf: A deep convolutional activation feature for generic visual recognition.pdf,Decaf: A deep convolutional activation feature for generic visual recognition
0,"Hsu, D., Kakade, S., Langford, J., Zhang, T.",Multilabel prediction via compressed sensing,arXiv preprint arXiv:0902.1284,,,2009,,"Hsu, D., Kakade, S., Langford, J., and Zhang, T. Multilabel prediction via compressed sensing. arXiv preprint arXiv:0902.1284, 2009.",./refs/download/2/Decaf: A deep convolutional activation feature for generic visual recognition.pdf,Decaf: A deep convolutional activation feature for generic visual recognition
0,"Jarrett, K., Kavukcuoglu, K., Ranzato, M.",", and LeCun, Y",What is the best multi-stage architecture for object recognition? In ICCV,,,2009,,"Jarrett, K., Kavukcuoglu, K., Ranzato, M., and LeCun, Y. What is the best multi-stage architecture for object recognition? In ICCV, 2009.",./refs/download/2/Decaf: A deep convolutional activation feature for generic visual recognition.pdf,Decaf: A deep convolutional activation feature for generic visual recognition
0,,,,,,,,"Kennedy, L. and Hauptmann, A. LSCOM lexicon definitions and annotations (version 1.0). 2006.",./refs/download/2/Decaf: A deep convolutional activation feature for generic visual recognition.pdf,Decaf: A deep convolutional activation feature for generic visual recognition
0,"Krizhevsky, A., Sutskever, I., Hinton, G. E.",ImageNet classification with deep convolutional neural networks,In NIPS,,,2012,,"Krizhevsky, A., Sutskever, I., and Hinton, G. E. ImageNet classification with deep convolutional neural networks. In NIPS, 2012.",./refs/download/2/Decaf: A deep convolutional activation feature for generic visual recognition.pdf,Decaf: A deep convolutional activation feature for generic visual recognition
0,"Kulis, B., Saenko, K., Darrell, T.",What you saw is not what you get: Domain adaptation using asymmetric kernel transforms,In CVPR,,,2011,,"Kulis, B., Saenko, K., and Darrell, T. What you saw is not what you get: Domain adaptation using asymmetric kernel transforms. In CVPR, 2011.",./refs/download/2/Decaf: A deep convolutional activation feature for generic visual recognition.pdf,Decaf: A deep convolutional activation feature for generic visual recognition
0,"Le, Q., Zou, W., Yeung, S., Ng, A.",Learning hierarchical invariant spatio-temporal features for action recognition with independent subspace analysis,In CVPR,,,2011,,"Le, Q., Zou, W., Yeung, S., and Ng, A. Learning hierarchical invariant spatio-temporal features for action recognition with independent subspace analysis. In CVPR, 2011.",./refs/download/2/Decaf: A deep convolutional activation feature for generic visual recognition.pdf,Decaf: A deep convolutional activation feature for generic visual recognition
0,"Le, Q., Ranzato, M., Monga, R., Devin, M., Chen, K., Corrado, G., Dean, J., Ng, A.",Building high-level features using large scale unsupervised learning,In ICML,,,2012,,"Le, Q., Ranzato, M., Monga, R., Devin, M., Chen, K., Corrado, G., Dean, J., and Ng, A. Building high-level features using large scale unsupervised learning. In ICML, 2012.",./refs/download/2/Decaf: A deep convolutional activation feature for generic visual recognition.pdf,Decaf: A deep convolutional activation feature for generic visual recognition
0,"LeCun, Y., Boser, B., Denker, J., Henderson, D., Howard, R., Hubbard, W., Jackel, L.",Backpropagation applied to handwritten zip code recognition,Neural Computation,,,1989,,"LeCun, Y., Boser, B., Denker, J., Henderson, D., Howard, R., Hubbard, W., and Jackel, L. Backpropagation applied to handwritten zip code recognition. Neural Computation, 1989.",./refs/download/2/Decaf: A deep convolutional activation feature for generic visual recognition.pdf,Decaf: A deep convolutional activation feature for generic visual recognition
0,"LeCun, Y., Bottou, L., Bengio, Y., Haffner, P.",Gradient-based learning applied to document recognition,In IEEE,,,1998,,"LeCun, Y., Bottou, L., Bengio, Y., and Haffner, P. Gradient-based learning applied to document recognition. In IEEE, 1998.",./refs/download/2/Decaf: A deep convolutional activation feature for generic visual recognition.pdf,Decaf: A deep convolutional activation feature for generic visual recognition
0,"Li, L., Su, H., Fei-Fei, L., Xing, E.",Object bank: A highlevel image representation for scene classification & semantic feature sparsification,In NIPS,,,2010,,"Li, L., Su, H., Fei-Fei, L., and Xing, E. Object bank: A highlevel image representation for scene classification & semantic feature sparsification. In NIPS, 2010.",./refs/download/2/Decaf: A deep convolutional activation feature for generic visual recognition.pdf,Decaf: A deep convolutional activation feature for generic visual recognition
0,"Mesnil, G., Dauphin, Y., Glorot, X., Rifai, S., Bengio, Y., Goodfellow, I., Lavoie, E., Muller, X., Desjardins, G., Warde-Farley, D., Vincent, P., Courville, A., Berkgstra, J.",Unsupervised and transfer learning challenge: a deep learning approach,JMLR,,,2012,27,"Mesnil, G., Dauphin, Y., Glorot, X., Rifai, S., Bengio, Y., Goodfellow, I., Lavoie, E., Muller, X., Desjardins, G., Warde-Farley, D., Vincent, P., Courville, A., and Berkgstra, J. Unsupervised and transfer learning challenge: a deep learning approach. JMLR, 27, 2012.",./refs/download/2/Decaf: A deep convolutional activation feature for generic visual recognition.pdf,Decaf: A deep convolutional activation feature for generic visual recognition
0,"Oliva, A., Torralba, A.",Modeling the shape of the scene: A holistic representation of the spatial envelope,IJCV,,,2001,,"Oliva, A. and Torralba, A. Modeling the shape of the scene: A holistic representation of the spatial envelope. IJCV, 2001.",./refs/download/2/Decaf: A deep convolutional activation feature for generic visual recognition.pdf,Decaf: A deep convolutional activation feature for generic visual recognition
0,"Quattoni, A., Collins, M., Darrell, T.",Transfer learning for image classication with sparse prototype representations,In CVPR,,,2008,,"Quattoni, A., Collins, M., and Darrell, T. Transfer learning for image classication with sparse prototype representations. In CVPR, 2008.",./refs/download/2/Decaf: A deep convolutional activation feature for generic visual recognition.pdf,Decaf: A deep convolutional activation feature for generic visual recognition
0,"Battle, A., Lee, H., Packer, B., Ng, A.",Selftaught learning: Transfer learning from unlabeled data,In ICML,,,2007,,"Raina, R. at, Battle, A., Lee, H., Packer, B., and Ng, A. Selftaught learning: Transfer learning from unlabeled data. In ICML, 2007.",./refs/download/2/Decaf: A deep convolutional activation feature for generic visual recognition.pdf,Decaf: A deep convolutional activation feature for generic visual recognition
0,"Ren, X., Ramanan, D.",Histograms of sparse codes for object detection,In CVPR,,,2013,,"Ren, X. and Ramanan, D. Histograms of sparse codes for object detection. In CVPR, 2013.",./refs/download/2/Decaf: A deep convolutional activation feature for generic visual recognition.pdf,Decaf: A deep convolutional activation feature for generic visual recognition
0,"Saenko, K., Kulis, B., Fritz, M., Darrell, T.",Adapting visual category models to new domains,In ECCV,,,2010,,"Saenko, K., Kulis, B., Fritz, M., and Darrell, T. Adapting visual category models to new domains. In ECCV, 2010.",./refs/download/2/Decaf: A deep convolutional activation feature for generic visual recognition.pdf,Decaf: A deep convolutional activation feature for generic visual recognition
0,"Singh, S., Gupta, A., Efros, A.",Unsupervised discovery of mid-level discriminative patches,In ECCV,,,2012,,"Singh, S., Gupta, A., and Efros, A. Unsupervised discovery of mid-level discriminative patches. In ECCV, 2012.",./refs/download/2/Decaf: A deep convolutional activation feature for generic visual recognition.pdf,Decaf: A deep convolutional activation feature for generic visual recognition
0,,,,,,,,"Thrun, S. Is learning the n-th thing any easier than learning the first? In NIPS, 1996.",./refs/download/2/Decaf: A deep convolutional activation feature for generic visual recognition.pdf,Decaf: A deep convolutional activation feature for generic visual recognition
0,"Torralba, A., Efros, A.",Unbiased look at dataset bias,In CVPR,,,2011,,"Torralba, A. and Efros, A. Unbiased look at dataset bias. In CVPR, 2011.",./refs/download/2/Decaf: A deep convolutional activation feature for generic visual recognition.pdf,Decaf: A deep convolutional activation feature for generic visual recognition
0,,,,,,,,"Torresani, L., Szummer, M., and Fitzgibbon, A. Efficient object category recognition using classemes. In ECCV. 2010.",./refs/download/2/Decaf: A deep convolutional activation feature for generic visual recognition.pdf,Decaf: A deep convolutional activation feature for generic visual recognition
0,"Maaten, L., Hinton, G.",Visualizing data using t-sne,JMLR,,,2008,9,"van der Maaten, L. and Hinton, G. Visualizing data using t-sne. JMLR, 9, 2008.",./refs/download/2/Decaf: A deep convolutional activation feature for generic visual recognition.pdf,Decaf: A deep convolutional activation feature for generic visual recognition
0,"Wang, J., Yang, J., Yu, K., Lv, F., Huang, T., Gong, Y.",Locality-constrained linear coding for image classification,In CVPR,,,2010,,"Wang, J., Yang, J., Yu, K., Lv, F., Huang, T., and Gong, Y. Locality-constrained linear coding for image classification. In CVPR, 2010.",./refs/download/2/Decaf: A deep convolutional activation feature for generic visual recognition.pdf,Decaf: A deep convolutional activation feature for generic visual recognition
0,,,,,,,,"Generic Visual Recognition Welinder, P., Branson, S., Mita, T., Wah, C., Schroff, F., Belongie, S., and Perona, P. Caltech-UCSD Birds 200. Technical Report CNS-TR-2010-001, California Institute of Technology, 2010.",./refs/download/2/Decaf: A deep convolutional activation feature for generic visual recognition.pdf,Decaf: A deep convolutional activation feature for generic visual recognition
0,"Xiao, J., Hays, J., Ehinger, K., Oliva, A., Torralba, A.",Sun database: Large-scale scene recognition from abbey to zoo,In CVPR,,,2010,,"Xiao, J., Hays, J., Ehinger, K., Oliva, A., and Torralba, A. Sun database: Large-scale scene recognition from abbey to zoo. In CVPR, 2010.",./refs/download/2/Decaf: A deep convolutional activation feature for generic visual recognition.pdf,Decaf: A deep convolutional activation feature for generic visual recognition
0,"Tian, Y., Duan, L., Gao, W.",Group-sensitive multiple kernel learning for object categorization,In ICCV,,,2009,,"Yang, J., L., Y., Tian, Y., Duan, L., and Gao, W. Group-sensitive multiple kernel learning for object categorization. In ICCV, 2009.",./refs/download/2/Decaf: A deep convolutional activation feature for generic visual recognition.pdf,Decaf: A deep convolutional activation feature for generic visual recognition
0,"Zhang, N., Farrell, R., Iandola, F., Darrell, T.",Deformable part descriptors for fine-grained recognition and attribute prediction,In ICCV,,,2013,,"Zhang, N., Farrell, R., Iandola, F., and Darrell, T. Deformable part descriptors for fine-grained recognition and attribute prediction. In ICCV, 2013.",./refs/download/2/Decaf: A deep convolutional activation feature for generic visual recognition.pdf,Decaf: A deep convolutional activation feature for generic visual recognition
0,"Zhu, L., Chen, Y., Yuille, A.",Unsupervised learning of a probabilistic grammar for object detection and parsing,In NIPS,,,2007,,"Zhu, L., Chen, Y., and Yuille, A. Unsupervised learning of a probabilistic grammar for object detection and parsing. In NIPS, 2007.",./refs/download/2/Decaf: A deep convolutional activation feature for generic visual recognition.pdf,Decaf: A deep convolutional activation feature for generic visual recognition
0,,,,,,,," X. Chang, Thomas Funkhouser, Leonidas J. Guibas, Pat Hanrahan, Qixing Huang, Zimo Li, Silvio Savarese, Manolis Savva, Shuran Song, Hao Su, Jianxiong Xiao, Li Yi, and ",./refs/download/2/Learning to group and label fine-grained shape components.pdf,Learning to group and label fine-grained shape components
0,,,,,,,," G. Kim, Qi-Xing Huang, Niloy J. Mitra, and ",./refs/download/2/Learning to group and label fine-grained shape components.pdf,Learning to group and label fine-grained shape components
0,,,,,,,," G. Kim, Siddhartha Chaudhuri, and ",./refs/download/2/Learning to group and label fine-grained shape components.pdf,Learning to group and label fine-grained shape components
0,,,,,,,," E. A. van de Sande, Jasper R. R. Uijlings, Theo Gevers, and ",./refs/download/2/Learning to group and label fine-grained shape components.pdf,Learning to group and label fine-grained shape components
0,,,,,,,," G. Kim, Hao Su, and ",./refs/download/2/Learning to group and label fine-grained shape components.pdf,Learning to group and label fine-grained shape components
0,"C. Beattie, J. Z. Leibo, D. Teplyashin, T. Ward, M. Wainwright, H. Küttler, A. Lefrancq, S. Green, V. Valdés, A. Sadik, J. Schrittwieser, K. Anderson, S. York, M. Cant, A. Cain, A. Bolton, S. Gaffney, H. King, D. Hassabis, S. Legg, S. Petersen",Deepmind lab, arXiv,,,2016,,"C. Beattie, J. Z. Leibo, D. Teplyashin, T. Ward, M. Wainwright, H. Küttler, A. Lefrancq, S. Green, V. Valdés, A. Sadik, J. Schrittwieser, K. Anderson, S. York, M. Cant, A. Cain, A. Bolton, S. Gaffney, H. King, D. Hassabis, S. Legg, and S. Petersen. Deepmind lab. arXiv, 2016.",./refs/download/2/Ai2-thor: An interactive 3d environment for visual ai.pdf,Ai2-thor: An interactive 3d environment for visual ai
0,"M. G. Bellemare, Y. Naddaf, J. Veness, M. Bowling",The arcade learning environment: An evaluation platform for general agents, J,. of Artificial Intelligence Research,,2013,47,"M. G. Bellemare, Y. Naddaf, J. Veness, and M. Bowling. The arcade learning environment: An evaluation platform for general agents. J. of Artificial Intelligence Research, 47:253– 279, 2013.",./refs/download/2/Ai2-thor: An interactive 3d environment for visual ai.pdf,Ai2-thor: An interactive 3d environment for visual ai
0,"S. Brodeur, E. Perez, A. Anand, F. Golemo, L. Celotti, F. Strub, J. Rouat, H. Larochelle, A. Courville",Home: a household multimodal environment, arXiv,,,2017,,"S. Brodeur, E. Perez, A. Anand, F. Golemo, L. Celotti, F. Strub, J. Rouat, H. Larochelle, and A. Courville. Home: a household multimodal environment. arXiv, 2017.",./refs/download/2/Ai2-thor: An interactive 3d environment for visual ai.pdf,Ai2-thor: An interactive 3d environment for visual ai
0,"A. Chang, A. Dai, T. Funkhouser, M. Halber, M. Niessner, M. Savva, S. Song, A. Zeng, Y. Zhang",Matterport3d: Learning from rgb-d data in indoor environments, In 3DV,,,2017,,"A. Chang, A. Dai, T. Funkhouser, M. Halber, M. Niessner, M. Savva, S. Song, A. Zeng, and Y. Zhang. Matterport3d: Learning from rgb-d data in indoor environments. In 3DV, 2017.",./refs/download/2/Ai2-thor: An interactive 3d environment for visual ai.pdf,Ai2-thor: An interactive 3d environment for visual ai
0,"A. Dosovitskiy, G. Ros, F. Codevilla, A. Lopez, V. Koltun",CARLA: An open urban driving simulator, In CORL,,,2017,,"A. Dosovitskiy, G. Ros, F. Codevilla, A. Lopez, and V. Koltun. CARLA: An open urban driving simulator. In CORL, 2017.",./refs/download/2/Ai2-thor: An interactive 3d environment for visual ai.pdf,Ai2-thor: An interactive 3d environment for visual ai
0,"K. Ehsani, R. Mottaghi, A. Farhadi",SeGAN: Segmenting and generating the invisible, In CVPR,,,2018,,"K. Ehsani, R. Mottaghi, and A. Farhadi. SeGAN: Segmenting and generating the invisible. In CVPR, 2018.",./refs/download/2/Ai2-thor: An interactive 3d environment for visual ai.pdf,Ai2-thor: An interactive 3d environment for visual ai
0,"A. Gaidon, Q. Wang, Y. Cabon, E. Vig",Virtual worlds as proxy for multi-object tracking analysis, In CVPR,,,2016,,"A. Gaidon, Q. Wang, Y. Cabon, and E. Vig. Virtual worlds as proxy for multi-object tracking analysis. In CVPR, 2016.",./refs/download/2/Ai2-thor: An interactive 3d environment for visual ai.pdf,Ai2-thor: An interactive 3d environment for visual ai
0,"D. Gordon, A. Kembhavi, M. Rastegari, J. Redmon, D. Fox, A. Farhadi",IQA: Visual question answering in interactive environments, In CVPR,,,2018,,"D. Gordon, A. Kembhavi, M. Rastegari, J. Redmon, D. Fox, and A. Farhadi. IQA: Visual question answering in interactive environments. In CVPR, 2018.",./refs/download/2/Ai2-thor: An interactive 3d environment for visual ai.pdf,Ai2-thor: An interactive 3d environment for visual ai
0,"A. Handa, V. Patraucean, S. Stent, R. Cipolla",Scenenet: An annotated model generator for indoor scene understanding, In ICRA,,,2016,,"A. Handa, V. Patraucean, S. Stent, and R. Cipolla. Scenenet: An annotated model generator for indoor scene understanding. In ICRA, 2016.",./refs/download/2/Ai2-thor: An interactive 3d environment for visual ai.pdf,Ai2-thor: An interactive 3d environment for visual ai
0,"M. Johnson, K. Hofmann, T. Hutton, D. Bignell",The malmo platform for artificial intelligence experimentation, In Intl,. Joint Conference on Artificial Intelligence,,2016,,"M. Johnson, K. Hofmann, T. Hutton, and D. Bignell. The malmo platform for artificial intelligence experimentation. In Intl. Joint Conference on Artificial Intelligence, 2016.",./refs/download/2/Ai2-thor: An interactive 3d environment for visual ai.pdf,Ai2-thor: An interactive 3d environment for visual ai
0,"M. Kempka, M. Wydmuch, G. Runc, J. Toczek, W. Jakowski",Vizdoom: A doom-based ai research platform for visual reinforcement learning, In IEEE Conference on Computational Intelligence and Games,,,2016,,"M. Kempka, M. Wydmuch, G. Runc, J. Toczek, and W. Jakowski. Vizdoom: A doom-based ai research platform for visual reinforcement learning. In IEEE Conference on Computational Intelligence and Games, 2016.",./refs/download/2/Ai2-thor: An interactive 3d environment for visual ai.pdf,Ai2-thor: An interactive 3d environment for visual ai
0,"A. Lerer, S. Gross, R. Fergus",Learning physical intuition of block towers by example, In ICML,,,2016,,"A. Lerer, S. Gross, and R. Fergus. Learning physical intuition of block towers by example. In ICML, 2016.",./refs/download/2/Ai2-thor: An interactive 3d environment for visual ai.pdf,Ai2-thor: An interactive 3d environment for visual ai
0,"J. McCormac, A. Handa, S. Leutenegger, A. J. Davison",Scenenet RGB-D: 5m photorealistic images of synthetic indoor trajectories with ground truth, In ICCV,,,2017,,"J. McCormac, A. Handa, S. Leutenegger, and A. J. Davison. Scenenet RGB-D: 5m photorealistic images of synthetic indoor trajectories with ground truth. In ICCV, 2017.",./refs/download/2/Ai2-thor: An interactive 3d environment for visual ai.pdf,Ai2-thor: An interactive 3d environment for visual ai
0,"G. Ros, L. Sellart, J. Materzynska, D. Vazquez, A. Lopez",The SYNTHIA Dataset: A large collection of synthetic images for semantic segmentation of urban scenes, In CVPR,,,2016,,"G. Ros, L. Sellart, J. Materzynska, D. Vazquez, and A. Lopez. The SYNTHIA Dataset: A large collection of synthetic images for semantic segmentation of urban scenes. In CVPR, 2016.",./refs/download/2/Ai2-thor: An interactive 3d environment for visual ai.pdf,Ai2-thor: An interactive 3d environment for visual ai
0,"M. Savva, A. X. Chang, A. Dosovitskiy, T. Funkhouser, V. Koltun",MINOS: Multimodal indoor simulator for navigation in complex environments, arXiv,,,2017,,"M. Savva, A. X. Chang, A. Dosovitskiy, T. Funkhouser, and V. Koltun. MINOS: Multimodal indoor simulator for navigation in complex environments. arXiv, 2017.",./refs/download/2/Ai2-thor: An interactive 3d environment for visual ai.pdf,Ai2-thor: An interactive 3d environment for visual ai
0,"M. Savva, A. Kadian, O. Maksymets, Y. Zhao, E. Wijmans, B. Jain, J. Straub, J. Liu, V. Koltun, J. Malik, D. Parikh, D. Batra",Habitat: A platform for embodied ai research, arXiv,,,2019,,"M. Savva, A. Kadian, O. Maksymets, Y. Zhao, E. Wijmans, B. Jain, J. Straub, J. Liu, V. Koltun, J. Malik, D. Parikh, and D. Batra. Habitat: A platform for embodied ai research. arXiv, 2019.",./refs/download/2/Ai2-thor: An interactive 3d environment for visual ai.pdf,Ai2-thor: An interactive 3d environment for visual ai
0,"S. Song, F. Yu, A. Zeng, A. X. Chang, M. Savva, T. Funkhouser",Semantic scene completion from a single depth image, In CVPR,,,2017,,"S. Song, F. Yu, A. Zeng, A. X. Chang, M. Savva, and T. Funkhouser. Semantic scene completion from a single depth image. In CVPR, 2017.",./refs/download/2/Ai2-thor: An interactive 3d environment for visual ai.pdf,Ai2-thor: An interactive 3d environment for visual ai
0,"G. Synnaeve, N. Nardelli, A. Auvolat, S. Chintala, T. Lacroix, Z. Lin, F. Richoux, N. Usunier",Torchcraft: a library for machine learning research on real-time strategy games, arXiv,,,2016,,"G. Synnaeve, N. Nardelli, A. Auvolat, S. Chintala, T. Lacroix, Z. Lin, F. Richoux, and N. Usunier. Torchcraft: a library for machine learning research on real-time strategy games. arXiv, 2016.",./refs/download/2/Ai2-thor: An interactive 3d environment for visual ai.pdf,Ai2-thor: An interactive 3d environment for visual ai
0,"Y. Tian, Q. Gong, W. Shang, Y. Wu, L. Zitnick",ELF: an extensive, lightweight and flexible research platform for real-time strategy games,. arXiv,,2017,,"Y. Tian, Q. Gong, W. Shang, Y. Wu, and L. Zitnick. ELF: an extensive, lightweight and flexible research platform for real-time strategy games. arXiv, 2017.",./refs/download/2/Ai2-thor: An interactive 3d environment for visual ai.pdf,Ai2-thor: An interactive 3d environment for visual ai
0,"M. Wortsman, K. Ehsani, M. Rastegari, A. Farhadi, R. Mottaghi",Learning to learn how to learn: Self-adaptive visual navigation using meta-learning, In CVPR,,,2019,,"M. Wortsman, K. Ehsani, M. Rastegari, A. Farhadi, and R. Mottaghi. Learning to learn how to learn: Self-adaptive visual navigation using meta-learning. In CVPR, 2019.",./refs/download/2/Ai2-thor: An interactive 3d environment for visual ai.pdf,Ai2-thor: An interactive 3d environment for visual ai
0,"B. Wymann, E. Espié, C. Guionneau, C. Dimitrakakis, R. Coulom, A. Sumner",TORCS, the open racing car simulator,,,2013,,"B. Wymann, E. Espié, C. Guionneau, C. Dimitrakakis, R. Coulom, and A. Sumner. TORCS, the open racing car simulator, v1.3.5. http://www.torcs.org, 2013.",./refs/download/2/Ai2-thor: An interactive 3d environment for visual ai.pdf,Ai2-thor: An interactive 3d environment for visual ai
0,"W. Yang, X. Wang, A. Farhadi, A. Gupta, R. Mottaghi",Visual semantic navigation using scene priors, In ICLR,,,2019,,"W. Yang, X. Wang, A. Farhadi, A. Gupta, and R. Mottaghi. Visual semantic navigation using scene priors. In ICLR, 2019.",./refs/download/2/Ai2-thor: An interactive 3d environment for visual ai.pdf,Ai2-thor: An interactive 3d environment for visual ai
0,"Y. Zhu, D. Gordon, E. Kolve, D. Fox, L. Fei-Fei, A. Gupta, R. Mottaghi, A. Farhadi",Visual semantic planning using deep successor representations, In ICCV,,,2017,,"Y. Zhu, D. Gordon, E. Kolve, D. Fox, L. Fei-Fei, A. Gupta, R. Mottaghi, and A. Farhadi. Visual semantic planning using deep successor representations. In ICCV, 2017.",./refs/download/2/Ai2-thor: An interactive 3d environment for visual ai.pdf,Ai2-thor: An interactive 3d environment for visual ai
0,"Y. Zhu, R. Mottaghi, E. Kolve, J. J. Lim, A. Gupta, L. FeiFei, A. Farhadi",Target-driven visual navigation in indoor scenes using deep reinforcement learning, In ICRA,,,2017,,"Y. Zhu, R. Mottaghi, E. Kolve, J. J. Lim, A. Gupta, L. FeiFei, and A. Farhadi. Target-driven visual navigation in indoor scenes using deep reinforcement learning. In ICRA, 2017.",./refs/download/2/Ai2-thor: An interactive 3d environment for visual ai.pdf,Ai2-thor: An interactive 3d environment for visual ai
0,,,,,,,," P. Bojanowski, N. Agrawal, I. Laptev, J. Sivic, and ",./refs/download/2/Virtualhome: Simulating household activities via programs.pdf,Virtualhome: Simulating household activities via programs
0,,,,,,,," M. Allamanis, D. Tarlow, A. D. Gordon, and ",./refs/download/2/Virtualhome: Simulating household activities via programs.pdf,Virtualhome: Simulating household activities via programs
0,,,,,,,," G. Brockman, V. Cheung, L. Pettersson, J. Schneider, J. Schulman, J. Tang, and ",./refs/download/2/Virtualhome: Simulating household activities via programs.pdf,Virtualhome: Simulating household activities via programs
0,,,,,,,," S. Brodeur, E. Perez, A. Anand, F. Golemo, L. Celotti, F. Strub, J. Rouat, H. Larochelle, and ",./refs/download/2/Virtualhome: Simulating household activities via programs.pdf,Virtualhome: Simulating household activities via programs
0,,,,,,,," A. Dosovitskiy, G. Ros, F. Codevilla, A. Lopez, and ",./refs/download/2/Virtualhome: Simulating household activities via programs.pdf,Virtualhome: Simulating household activities via programs
0,,,,,,,," A. Gaidon, Q. Wang, Y. Cabon, and ",./refs/download/2/Virtualhome: Simulating household activities via programs.pdf,Virtualhome: Simulating household activities via programs
0,,,,,,,," J. Johnson, B. Hariharan, L. van der Maaten, J. Hoffman, L. Fei-Fei, C. L. Zitnick, and ",./refs/download/2/Virtualhome: Simulating household activities via programs.pdf,Virtualhome: Simulating household activities via programs
0,,,,,,,," R. Kiros, Y. Zhu, R. Salakhutdinov, R. Zemel, A. Torralba, R. Urtasun, and ",./refs/download/2/Virtualhome: Simulating household activities via programs.pdf,Virtualhome: Simulating household activities via programs
0,,,,,,,," E. Kolve, R. Mottaghi, D. Gordon, Y. Zhu, A. Gupta, and ",./refs/download/2/Virtualhome: Simulating household activities via programs.pdf,Virtualhome: Simulating household activities via programs
0,,,,,,,," S. Lauria, G. Bugmann, T. Kyriacou, J. Bos, and ",./refs/download/2/Virtualhome: Simulating household activities via programs.pdf,Virtualhome: Simulating household activities via programs
0,,,,,,,," C. Li, D. Tarlow, A. L. Gaunt, M. Brockschmidt, and ",./refs/download/2/Virtualhome: Simulating household activities via programs.pdf,Virtualhome: Simulating household activities via programs
0,,,,,,,," W. Ling, E. Grefenstette, K. M. Hermann, T. Kočisky, A. Senior, F. Wang, and ",./refs/download/2/Virtualhome: Simulating household activities via programs.pdf,Virtualhome: Simulating household activities via programs
0,,,,,,,," M. MacMahon, B. Stankiewicz, and ",./refs/download/2/Virtualhome: Simulating household activities via programs.pdf,Virtualhome: Simulating household activities via programs
0,,,,,,,," H. Mei, M. Bansal, and ",./refs/download/2/Virtualhome: Simulating household activities via programs.pdf,Virtualhome: Simulating household activities via programs
0,,,,,,,," T. Mikolov, K. Chen, G. Corrado, and ",./refs/download/2/Virtualhome: Simulating household activities via programs.pdf,Virtualhome: Simulating household activities via programs
0,,,,,,,, D. Nyga and ,./refs/download/2/Virtualhome: Simulating household activities via programs.pdf,Virtualhome: Simulating household activities via programs
0,,,,,,,," C. Quirk, R. Mooney, and ",./refs/download/2/Virtualhome: Simulating household activities via programs.pdf,Virtualhome: Simulating household activities via programs
0,,,,,,,," S. J. Rennie, E. Marcheret, Y. Mroueh, J. Ross, and ",./refs/download/2/Virtualhome: Simulating household activities via programs.pdf,Virtualhome: Simulating household activities via programs
0,,,,,,,," S. R. Richter, V. Vineet, S. Roth, and ",./refs/download/2/Virtualhome: Simulating household activities via programs.pdf,Virtualhome: Simulating household activities via programs
0,,,,,,,," M. Savva, A. X. Chang, A. Dosovitskiy, T. Funkhouser, and ",./refs/download/2/Virtualhome: Simulating household activities via programs.pdf,Virtualhome: Simulating household activities via programs
0,,,,,,,," O. Sener, A. Zamir, S. Savarese, and ",./refs/download/2/Virtualhome: Simulating household activities via programs.pdf,Virtualhome: Simulating household activities via programs
0,,,,,,,," S. Shah, D. Dey, C. Lovett, and ",./refs/download/2/Virtualhome: Simulating household activities via programs.pdf,Virtualhome: Simulating household activities via programs
0,,,,,,,," G. A. Sigurdsson, G. Varol, X. Wang, A. Farhadi, I. Laptev, and ",./refs/download/2/Virtualhome: Simulating household activities via programs.pdf,Virtualhome: Simulating household activities via programs
0,,,,,,,," I. Sutskever, O. Vinyals, and ",./refs/download/2/Virtualhome: Simulating household activities via programs.pdf,Virtualhome: Simulating household activities via programs
0,,,,,,,," S. Tellex, T. Kollar, S. Dickerson, M. R. Walter, A. G. Banerjee, S. J. Teller, and ",./refs/download/2/Virtualhome: Simulating household activities via programs.pdf,Virtualhome: Simulating household activities via programs
0,,,,,,,," Y. Wu, Y. Wu, G. Gkioxari, and ",./refs/download/2/Virtualhome: Simulating household activities via programs.pdf,Virtualhome: Simulating household activities via programs
0,,,,,,,," Y. Yang, A. Guha, C. Fermuller, and ",./refs/download/2/Virtualhome: Simulating household activities via programs.pdf,Virtualhome: Simulating household activities via programs
0,,,,,,,," Y. Yang, Y. Li, C. Fermuller, and ",./refs/download/2/Virtualhome: Simulating household activities via programs.pdf,Virtualhome: Simulating household activities via programs
0,,,,,,,," B. Zhou, A. Andonian, and ",./refs/download/2/Virtualhome: Simulating household activities via programs.pdf,Virtualhome: Simulating household activities via programs
0,,,,,,,," Y. Zhu, R. Kiros, R. Zemel, R. Salakhutdinov, R. Urtasun, A. Torralba, and ",./refs/download/2/Virtualhome: Simulating household activities via programs.pdf,Virtualhome: Simulating household activities via programs
0,"Bartlett, M.S., Littlewort, G., Frank, M., Lainscsek, C., Fasel, I., Movellan, J.",: Fully automatic facial action recognition in spontaneous behavior,In: Automatic Face and Gesture Recognition,,,2006,,"Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J., Devin, M., Ghemawat, S., Irving, G., Isard, M., et al.: Tensorflow: a system for large-scale machine learning. In: OSDI, vol. 16, pp. 265–283 (2016) 2. Alabort-i-Medina, J., Antonakos, E., Booth, J., Snape, P., Zafeiriou, S.: Menpo: A comprehensive platform for parametric image alignment and visual deformable models. In: Proceedings of the ACM International Conference on Multimedia, MM ’14, pp. 679–682. ACM, New York, NY, USA (2014) 3. Albanie, S., Vedaldi, A.: Learning grimaces by watching tv. In: Proceedings of the British Machine Vision Conference (BMVC) (2016) 4. Aung, M.S., Kaltwang, S., Romera-paredes, B., Martinez, B., Singh, A., Cella, M., Valstar, M.F., Meng, H., Kemp, A., Elkins, A.C., Tyler, N., Watson, P.J., Williams, A.C., Pantic, M., Berthouze, N.: The automatic detection of chronic pain-related expression: requirements, challenges and a multimodal dataset. IEEE Transactions on Affective Computing (2016) 5. Bartlett, M.S., Littlewort, G., Frank, M., Lainscsek, C., Fasel, I., Movellan, J.: Fully automatic facial action recognition in spontaneous behavior. In: Automatic Face and Gesture Recognition, 2006.",./refs/download/2/Deep affect prediction in-the-wild: Aff-wild database and challenge.pdf,Deep affect prediction in-the-wild: Aff-wild database and challenge
0,"Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., Fei-Fei, L.",: Imagenet: A large-scale hierarchical image database,In: Computer Vision and Pattern Recognition,,,2009,,"Chang, W.Y., Hsu, S.H., Chien, J.H.: Fatauva-net : An integrated deep learning framework for facial attribute recognition, action unit (au) detection, and valence-arousal estimation. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshop (2017) 7. Chatfield, K., Simonyan, K., Vedaldi, A., Zisserman, A.: Return of the devil in the details: Delving deep into convolutional nets. arXiv preprint arXiv:1405.3531 (2014) 8. Chrysos, G.G., Antonakos, E., Snape, P., Asthana, A., Zafeiriou, S.: A comprehensive performance evaluation of deformable face tracking in-the-wild. International Journal of Computer Vision 126(2-4), 198–232 (2018) 9. Chung, J., Gulcehre, C., Cho, K., Bengio, Y.: Empirical evaluation of gated recurrent neural networks on sequence modeling. arXiv preprint arXiv:1412.3555 (2014) 10. Corneanu, C., Oliu, M., Cohn, J., Escalera, S.: Survey on rgb, 3d, thermal, and multimodal approaches for facial expression recognition: History, trends, and affect-related applications. IEEE transactions on pattern analysis and machine intelligence (2016) 11. Cowie, R., Cornelius, R.R.: Describing the emotional states that are expressed in speech. Speech communication 40(1), 5–32 (2003) 12. Cowie, R., Douglas-Cowie, E., Savvidou*, S., McMahon, E., Sawey, M., Schröder, M.: ’feeltrace’: An instrument for recording perceived emotion in real time. In: ISCA tutorial and research workshop (ITRW) on speech and emotion (2000) 13. Cowie, R., McKeown, G., Douglas-Cowie, E.: Tracing emotion: an overview. International Journal of Synthetic Emotions (IJSE) 3(1), 1–17 (2012) 14. Dalgleish, T., Power, M.: Handbook of cognition and emotion. John Wiley & Sons (2000) 15. Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., Fei-Fei, L.: Imagenet: A large-scale hierarchical image database. In: Computer Vision and Pattern Recognition, 2009.",./refs/download/2/Deep affect prediction in-the-wild: Aff-wild database and challenge.pdf,Deep affect prediction in-the-wild: Aff-wild database and challenge
0,,,,,,,,"Dhall, A., Goecke, R., Ghosh, S., Joshi, J., Hoey, J., Gedeon, T.: From individual to group-level emotion recognition: Emotiw 5.0. In: Proceedings of the 19th ACM International Conference on Multimodal Interaction, pp. 524–528. ACM (2017) 17. Dhall, A., Goecke, R., Joshi, J., Hoey, J., Gedeon, T.: Emotiw 2016: Video and group-level emotion recognition challenges. In: Proceedings of the 18th ACM International Conference on Multimodal Interaction, pp. 427–432. ACM (2016) 18. Dhall, A., Goecke, R., Joshi, J., Sikka, K., Gedeon, T.: Emotion recognition in the wild challenge 2014: Baseline, data and protocol. In: Proceedings of the 16th International Conference on Multimodal Interaction, pp. 461–466. ACM (2014) 19. Dhall, A., Goecke, R., Joshi, J., Wagner, M., Gedeon, T.: Emotion recognition in the wild challenge 2013.",./refs/download/2/Deep affect prediction in-the-wild: Aff-wild database and challenge.pdf,Deep affect prediction in-the-wild: Aff-wild database and challenge
0,,,,,,,,"Dhall, A., Ramana Murthy, O., Goecke, R., Joshi, J., Gedeon, T.: Video and image based emotion recognition challenges in the wild: Emotiw 2015.",./refs/download/2/Deep affect prediction in-the-wild: Aff-wild database and challenge.pdf,Deep affect prediction in-the-wild: Aff-wild database and challenge
0,"Hochreiter, S., Schmidhuber, J., Lucey, P., Cohn, J.F., Kanade, T., Saragih, J., Ambadar, Z., Matthews, I., Lucey, P., Cohn, J.F., Prkachin, K.M., Solomon, P.E., Matthews, I., Pantic, M., Valstar, M., Rademaker, R., Maat, L.",: Web-based database for facial expression analysis,In: Multimedia and Expo,,,2005,,"Douglas-Cowie, E., Cowie, R., Cox, C., Amier, N., Heylen, D.K.: The sensitive artificial listner: an induction technique for generating emotionally coloured conversation. In: LREC Workshop on Corpora for Research on Emotion and Affect. ELRA (2008) 22. Gross, R., Matthews, I., Cohn, J., Kanade, T., Baker, S.: Multi-pie. Image and Vision Computing 28(5), 807–813 (2010) 23. Hardoon, D.R., Szedmak, S., Shawe-Taylor, J.: Canonical correlation analysis; an overview with application to learning methods. Technical report, Royal Holloway, University of London (2003) 24. He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770–778 (2016) 19 25. Hochreiter, S., Schmidhuber, J.: Long short-term memory. Neural computation 9(8), 1735–1780 (1997) 26. Hu, P., Cai, D., Wang, S., Yao, A., Chen, Y.: Learning supervised scoring ensemble for emotion recognition in the wild. In: Proceedings of the 19th ACM International Conference on Multimodal Interaction, pp. 553–560. ACM (2017) 27. Jung, H., Lee, S., Yim, J., Park, S., Kim, J.: Joint fine-tuning in deep neural networks for facial expression recognition. In: Proceedings of the IEEE International Conference on Computer Vision, pp. 2983–2991 (2015) 28. Knyazev, B., Shvetsov, R., Efremova, N., Kuharenko, A.: Convolutional neural networks pretrained on large face recognition datasets for emotion classification from video. arXiv preprint arXiv:1711.04598 (2017) 29. Koelstra, S., Muhl, C., Soleymani, M., Lee, J.S., Yazdani, A., Ebrahimi, T., Pun, T., Nijholt, A., Patras, I.: Deap: A database for emotion analysis; using physiological signals. IEEE Transactions on Affective Computing 3(1), 18–31 (2012) 30. Kollias, D., Nicolaou, M., Kotsia, I., Zhao, G., Zafeiriou, S.: Recognition of affect in the wild using deep neural networks. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshop (2017) 31. Kossaifi, J., Tzimiropoulos, G., Todorovic, S., Pantic, M.: Afewva database for valence and arousal estimation in-the-wild. Image and Vision Computing (2017) 32. Lawrence, I., Lin, K.: A concordance correlation coefficient to evaluate reproducibility. Biometrics pp. 255–268 (1989) 33. Lee, A.: Welcome to virtualdub. org!-virtualdub. org (2002) 34. Li, J., Chen, Y., Xiao, S., Zhao, J., Roy, S., Feng, J., Yan, S., Sim, T.: Estimation of affective level in the wild with multiple memory networks. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshop (2017) 35. Lucey, P., Cohn, J.F., Kanade, T., Saragih, J., Ambadar, Z., Matthews, I.: The extended cohn-kanade dataset (ck+): A complete dataset for action unit and emotion-specified expression. In: Computer Vision and Pattern Recognition Workshops (CVPRW), 2010 IEEE Computer Society Conference on, pp. 94–101. IEEE (2010) 36. Lucey, P., Cohn, J.F., Prkachin, K.M., Solomon, P.E., Matthews, I.: Painful data: The unbc-mcmaster shoulder pain expression archive database. In: Automatic Face & Gesture Recognition and Workshops (FG 2011), 2011 IEEE International Conference on, pp. 57– 64. IEEE (2011) 37. Mahoor, M., Hasani, B.: Facial affect estimation in the wild using deep residual and convolutional networks. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshop (2017) 38. Mathias, M., Benenson, R., Pedersoli, M., Van Gool, L.: Face detection without bells and whistles. In: European Conference on Computer Vision, pp. 720–735. Springer (2014) 39. McKeown, G., Valstar, M., Cowie, R., Pantic, M., Schröder, M.: The semaine database: Annotated multimodal records of emotionally colored conversations between a person and a limited agent. Affective Computing, IEEE Transactions on 3(1), 5–17 (2012) 40. More, A.: Survey of resampling techniques for improving classification performance in unbalanced datasets. arXiv preprint arXiv:1608.06048 (2016) 41. Pantic, M., Valstar, M., Rademaker, R., Maat, L.: Web-based database for facial expression analysis. In: Multimedia and Expo, 2005.",./refs/download/2/Deep affect prediction in-the-wild: Aff-wild database and challenge.pdf,Deep affect prediction in-the-wild: Aff-wild database and challenge
0,"Parkhi, O.M., Vedaldi, A., Zisserman, A.",: Deep face recognition,In: BMVC,. Gesture Recognition,,2008,"vol. 1, p. 6 (2015) 43. Plutchik, R.: Emotion: A psychoevolutionary synthesis. Harpercollins College Division (1980) 44. Ringeval, F., Schuller, B., Valstar, M., Cowie, R., Pantic, M.: Avec 2015: The 5th international audio/visual emotion challenge and Dimitrios Kollias ? et al. 20 45. 46. 47. 48. 49. 50. 51. 52. 53. 54. 55. 56. 57. 58. 59. 60. 61. 62. workshop. In: Proceedings of the 23rd ACM international conference on Multimedia, pp. 1335–1336. ACM (2015) Ringeval, F., Schuller, B., Valstar, M., Gratch, J., Cowie, R., Scherer, S., Mozgai, S., Cummins, N., Schmi, M., Pantic, M.: Avec 2017–real-life depression, and affect recognition workshop and challenge (2017) Ringeval, F., Sonderegger, A., Sauer, J., Lalanne, D.: Introducing the recola multimodal corpus of remote collaborative and affective interactions. In: Automatic Face and Gesture Recognition (FG), 2013 10th IEEE International Conference and Workshops on, pp. 1–8. IEEE (2013) Russell, J.A.: Evidence of convergent validity on the dimensions of affect. Journal of personality and social psychology 36(10), 1152 (1978) Sariyanidi, E., Gunes, H., Cavallaro, A.: Automatic analysis of facial affect: A survey of registration, representation, and recognition. Pattern Analysis and Machine Intelligence, IEEE Transactions on 37(6), 1113–1133 (2015) Schuller, B., Valstar, M., Eyben, F., McKeown, G., Cowie, R., Pantic, M.: Avec 2011–the first international audio/visual emotion challenge. In: Affective Computing and Intelligent Interaction, pp. 415–424. Springer (2011) Schuller, B., Valster, M., Eyben, F., Cowie, R., Pantic, M.: Avec 2012: the continuous audio/visual emotion challenge. In: Proceedings of the 14th ACM international conference on Multimodal interaction, pp. 449–456. ACM (2012) Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale image recognition. arXiv:1409.1556 (2014) Sneddon, I., McRorie, M., McKeown, G., Hanratty, J.: The belfast induced natural emotion database. IEEE Transactions on Affective Computing 3(1), 32–41 (2012) Soleymani, M., Lichtenauer, J., Pun, T., Pantic, M.: A multimodal database for affect recognition and implicit tagging. IEEE Transactions on Affective Computing 3(1), 42–55 (2012) Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A.A.: Inception-v4, inception-resnet and the impact of residual connections on learning. In: AAAI, vol. 4, p. 12 (2017) Tian, Y.l., Kanade, T., Cohn, J.F.: Recognizing action units for facial expression analysis. Pattern Analysis and Machine Intelligence, IEEE Transactions on 23(2), 97–115 (2001) Valstar, M., Gratch, J., Schuller, B., Ringeval, F., Lalanne, D., Torres Torres, M., Scherer, S., Stratou, G., Cowie, R., Pantic, M.: Avec 2016: Depression, mood, and emotion recognition workshop and challenge. In: Proceedings of the 6th International Workshop on Audio/Visual Emotion Challenge, pp. 3–10. ACM (2016) Valstar, M., Pantic, M.: Induced disgust, happiness and surprise: an addition to the mmi facial expression database. In: Proc. 3rd Intern. Workshop on EMOTION (satellite of LREC): Corpora for Research on Emotion and Affect, p. 65 (2010) Valstar, M., Schuller, B., Smith, K., Almaev, T., Eyben, F., Krajewski, J., Cowie, R., Pantic, M.: Avec 2014: 3d dimensional affect and depression recognition challenge. In: Proceedings of the 4th International Workshop on Audio/Visual Emotion Challenge, pp. 3–10. ACM (2014) Valstar, M., Schuller, B., Smith, K., Eyben, F., Jiang, B., Bilakhia, S., Schnieder, S., Cowie, R., Pantic, M.: Avec 2013: the continuous audio/visual emotion and depression recognition challenge. In: Proceedings of the 3rd ACM international workshop on Audio/visual emotion challenge, pp. 3–10. ACM (2013) Vielzeuf, V., Pateux, S., Jurie, F.: Temporal multimodal fusion for video emotion classification in the wild. arXiv preprint arXiv:1709.07200 (2017) Whissel, C.: The dictionary of affect in language, emotion: Theory, research and experience: vol. 4, the measurement of emotions, r. Plutchik and H. Kellerman, Eds., New York: Academic (1989) Yin, L., Chen, X., Sun, Y., Worm, T., Reale, M.: A high-resolution 3d dynamic facial expression database. In: Automatic Face & 63. 64. 65. 66","Parkhi, O.M., Vedaldi, A., Zisserman, A.: Deep face recognition. In: BMVC, vol. 1, p. 6 (2015) 43. Plutchik, R.: Emotion: A psychoevolutionary synthesis. Harpercollins College Division (1980) 44. Ringeval, F., Schuller, B., Valstar, M., Cowie, R., Pantic, M.: Avec 2015: The 5th international audio/visual emotion challenge and Dimitrios Kollias ? et al. 20 45. 46. 47. 48. 49. 50. 51. 52. 53. 54. 55. 56. 57. 58. 59. 60. 61. 62. workshop. In: Proceedings of the 23rd ACM international conference on Multimedia, pp. 1335–1336. ACM (2015) Ringeval, F., Schuller, B., Valstar, M., Gratch, J., Cowie, R., Scherer, S., Mozgai, S., Cummins, N., Schmi, M., Pantic, M.: Avec 2017–real-life depression, and affect recognition workshop and challenge (2017) Ringeval, F., Sonderegger, A., Sauer, J., Lalanne, D.: Introducing the recola multimodal corpus of remote collaborative and affective interactions. In: Automatic Face and Gesture Recognition (FG), 2013 10th IEEE International Conference and Workshops on, pp. 1–8. IEEE (2013) Russell, J.A.: Evidence of convergent validity on the dimensions of affect. Journal of personality and social psychology 36(10), 1152 (1978) Sariyanidi, E., Gunes, H., Cavallaro, A.: Automatic analysis of facial affect: A survey of registration, representation, and recognition. Pattern Analysis and Machine Intelligence, IEEE Transactions on 37(6), 1113–1133 (2015) Schuller, B., Valstar, M., Eyben, F., McKeown, G., Cowie, R., Pantic, M.: Avec 2011–the first international audio/visual emotion challenge. In: Affective Computing and Intelligent Interaction, pp. 415–424. Springer (2011) Schuller, B., Valster, M., Eyben, F., Cowie, R., Pantic, M.: Avec 2012: the continuous audio/visual emotion challenge. In: Proceedings of the 14th ACM international conference on Multimodal interaction, pp. 449–456. ACM (2012) Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale image recognition. arXiv:1409.1556 (2014) Sneddon, I., McRorie, M., McKeown, G., Hanratty, J.: The belfast induced natural emotion database. IEEE Transactions on Affective Computing 3(1), 32–41 (2012) Soleymani, M., Lichtenauer, J., Pun, T., Pantic, M.: A multimodal database for affect recognition and implicit tagging. IEEE Transactions on Affective Computing 3(1), 42–55 (2012) Szegedy, C., Ioffe, S., Vanhoucke, V., Alemi, A.A.: Inception-v4, inception-resnet and the impact of residual connections on learning. In: AAAI, vol. 4, p. 12 (2017) Tian, Y.l., Kanade, T., Cohn, J.F.: Recognizing action units for facial expression analysis. Pattern Analysis and Machine Intelligence, IEEE Transactions on 23(2), 97–115 (2001) Valstar, M., Gratch, J., Schuller, B., Ringeval, F., Lalanne, D., Torres Torres, M., Scherer, S., Stratou, G., Cowie, R., Pantic, M.: Avec 2016: Depression, mood, and emotion recognition workshop and challenge. In: Proceedings of the 6th International Workshop on Audio/Visual Emotion Challenge, pp. 3–10. ACM (2016) Valstar, M., Pantic, M.: Induced disgust, happiness and surprise: an addition to the mmi facial expression database. In: Proc. 3rd Intern. Workshop on EMOTION (satellite of LREC): Corpora for Research on Emotion and Affect, p. 65 (2010) Valstar, M., Schuller, B., Smith, K., Almaev, T., Eyben, F., Krajewski, J., Cowie, R., Pantic, M.: Avec 2014: 3d dimensional affect and depression recognition challenge. In: Proceedings of the 4th International Workshop on Audio/Visual Emotion Challenge, pp. 3–10. ACM (2014) Valstar, M., Schuller, B., Smith, K., Eyben, F., Jiang, B., Bilakhia, S., Schnieder, S., Cowie, R., Pantic, M.: Avec 2013: the continuous audio/visual emotion and depression recognition challenge. In: Proceedings of the 3rd ACM international workshop on Audio/visual emotion challenge, pp. 3–10. ACM (2013) Vielzeuf, V., Pateux, S., Jurie, F.: Temporal multimodal fusion for video emotion classification in the wild. arXiv preprint arXiv:1709.07200 (2017) Whissel, C.: The dictionary of affect in language, emotion: Theory, research and experience: vol. 4, the measurement of emotions, r. Plutchik and H. Kellerman, Eds., New York: Academic (1989) Yin, L., Chen, X., Sun, Y., Worm, T., Reale, M.: A high-resolution 3d dynamic facial expression database. In: Automatic Face & 63. 64. 65. 66. Gesture Recognition, 2008.",./refs/download/2/Deep affect prediction in-the-wild: Aff-wild database and challenge.pdf,Deep affect prediction in-the-wild: Aff-wild database and challenge
0,"Yin, L., Wei, X., Sun, Y., Wang, J., Rosato, M.J.",: A 3d facial expression database for facial behavior research,In: Automatic face and gesture recognition,,,2006,,"Yin, L., Wei, X., Sun, Y., Wang, J., Rosato, M.J.: A 3d facial expression database for facial behavior research. In: Automatic face and gesture recognition, 2006.",./refs/download/2/Deep affect prediction in-the-wild: Aff-wild database and challenge.pdf,Deep affect prediction in-the-wild: Aff-wild database and challenge
0,"Y. Cao, J. Xu, T. Liu, H. Li, Y. Huang, H. Hon",Adapting ranking svm to document retrieval, In Proc,. Annual ACM SIGIR Conf.,,2006,,"Y. Cao, J. Xu, T. Liu, H. Li, Y. Huang, and H. Hon. Adapting ranking svm to document retrieval. In Proc. Annual ACM SIGIR Conf., 2006.",./refs/download/2/Deep semantic ranking based hashing for multi-label image retrieval.pdf,Deep semantic ranking based hashing for multi-label image retrieval
0,"J. Donahue, Y. Jia, O. Vinyals, J. Hoffman, N. Zhang, E. Tzeng, T. Darrell",Decaf: A deep convolutional activation feature for generic visual recognition, In Proc,. Int. Conf. Mach. Learn. (ICML),,2014,,"J. Donahue, Y. Jia, O. Vinyals, J. Hoffman, N. Zhang, E. Tzeng, and T. Darrell. Decaf: A deep convolutional activation feature for generic visual recognition. In Proc. Int. Conf. Mach. Learn. (ICML), 2014.",./refs/download/2/Deep semantic ranking based hashing for multi-label image retrieval.pdf,Deep semantic ranking based hashing for multi-label image retrieval
0,"A. Frome, G. S. Corrado, J. Shlens, S. Bengio, J. Dean, M. Ranzato, T. Mikolov",Devise: A deep visual-semantic embedding model, In Proc,. Adv. Neural Info. Process. Syst. (NIPS),,2013,,"A. Frome, G. S. Corrado, J. Shlens, S. Bengio, J. Dean, M. Ranzato, and T. Mikolov. Devise: A deep visual-semantic embedding model. In Proc. Adv. Neural Info. Process. Syst. (NIPS), 2013.",./refs/download/2/Deep semantic ranking based hashing for multi-label image retrieval.pdf,Deep semantic ranking based hashing for multi-label image retrieval
0,"A. Gionis, P. Indyk, R. Motwani",Similarity search in high dimensions via hashing, In Proc,. Int. Conf. Very Large Data Bases (VLDB),,1999,,"A. Gionis, P. Indyk, and R. Motwani. Similarity search in high dimensions via hashing. In Proc. Int. Conf. Very Large Data Bases (VLDB), 1999.",./refs/download/2/Deep semantic ranking based hashing for multi-label image retrieval.pdf,Deep semantic ranking based hashing for multi-label image retrieval
0,"R. Girshick, J. Donahue, T. Darrell, J. Malik",Rich feature hierarchies for accurate object detection and semantic segmentation, In Proc,. IEEE Conf. Comp. Vis. Pattern Recogn. (CVPR),,2014,,"R. Girshick, J. Donahue, T. Darrell, and J. Malik. Rich feature hierarchies for accurate object detection and semantic segmentation. In Proc. IEEE Conf. Comp. Vis. Pattern Recogn. (CVPR), 2014.",./refs/download/2/Deep semantic ranking based hashing for multi-label image retrieval.pdf,Deep semantic ranking based hashing for multi-label image retrieval
0,"Y. Gong, Y. Jia, T. Leung, A. Toshev, S. Ioffe",Deep convolutional ranking for multilabel image annotation, CoRR,,,1312,,"Y. Gong, Y. Jia, T. Leung, A. Toshev, and S. Ioffe. Deep convolutional ranking for multilabel image annotation. CoRR, abs/1312.",./refs/download/2/Deep semantic ranking based hashing for multi-label image retrieval.pdf,Deep semantic ranking based hashing for multi-label image retrieval
0,"Y. Gong, S. Lazebnik, A. Gordo, F. Perronnin",Iterative quantization: a procrustean approach to learning binary codes for large-scale image retrieval, IEEE T,. Pattern Analysis Mach. Intelli. (TPAMI),,2012,,"Y. Gong, S. Lazebnik, A. Gordo, and F. Perronnin. Iterative quantization: a procrustean approach to learning binary codes for large-scale image retrieval. IEEE T. Pattern Analysis Mach. Intelli. (TPAMI), 2012.",./refs/download/2/Deep semantic ranking based hashing for multi-label image retrieval.pdf,Deep semantic ranking based hashing for multi-label image retrieval
0,"M. J. Huiskes and , M. S. Lew",The mir flickr retrieval evaluation, In Proc,. ACM Int. Conf. Multimedia Info. Retrieval,,2008,,"M. J. Huiskes and M. S. Lew. The mir flickr retrieval evaluation. In Proc. ACM Int. Conf. Multimedia Info. Retrieval, 2008.",./refs/download/2/Deep semantic ranking based hashing for multi-label image retrieval.pdf,Deep semantic ranking based hashing for multi-label image retrieval
0,"K. Jarvelin and , J. Kekalainen",Ir evaluation methods for retrieving highly relevant documents, In Proc,. Annual ACM SIGIR Conf.,,2000,,"K. Jarvelin and J. Kekalainen. Ir evaluation methods for retrieving highly relevant documents. In Proc. Annual ACM SIGIR Conf., 2000.",./refs/download/2/Deep semantic ranking based hashing for multi-label image retrieval.pdf,Deep semantic ranking based hashing for multi-label image retrieval
0,T. Joachims,Optimizing search engines using clickthrough data, In Proc,. ACM Knowledge Discovery and Data Mining,,2002,,"T. Joachims. Optimizing search engines using clickthrough data. In Proc. ACM Knowledge Discovery and Data Mining, 2002.",./refs/download/2/Deep semantic ranking based hashing for multi-label image retrieval.pdf,Deep semantic ranking based hashing for multi-label image retrieval
0,A. Krizhevsky,One weird trick for parallelizing convolutional neural networks, CoRR,,,1404,,"A. Krizhevsky. One weird trick for parallelizing convolutional neural networks. CoRR, abs/1404.",./refs/download/2/Deep semantic ranking based hashing for multi-label image retrieval.pdf,Deep semantic ranking based hashing for multi-label image retrieval
0,"A. Krizhevsky, I. Sutskever, G. E. Hinton",Imagenet classification with deep convolutional neural networks, In Proc,. Adv. Neural Info. Process. Syst. (NIPS),,2012,,"A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classification with deep convolutional neural networks. In Proc. Adv. Neural Info. Process. Syst. (NIPS), 2012.",./refs/download/2/Deep semantic ranking based hashing for multi-label image retrieval.pdf,Deep semantic ranking based hashing for multi-label image retrieval
0,"B. Kulis and , T. Darrell",Learning to hash with binary reconstructive embeddings, In Proc,. Adv. Neural Info. Process. Syst. (NIPS),,2009,,"B. Kulis and T. Darrell. Learning to hash with binary reconstructive embeddings. In Proc. Adv. Neural Info. Process. Syst. (NIPS), 2009.",./refs/download/2/Deep semantic ranking based hashing for multi-label image retrieval.pdf,Deep semantic ranking based hashing for multi-label image retrieval
0,"X. Li, G. Lin, C. Shen, A. van den Hengel, A. R. Dick",Learning hash functions using column generation, In Proc,. Int. Conf. Mach. Learn. (ICML),,2013,,"X. Li, G. Lin, C. Shen, A. van den Hengel, and A. R. Dick. Learning hash functions using column generation. In Proc. Int. Conf. Mach. Learn. (ICML), 2013.",./refs/download/2/Deep semantic ranking based hashing for multi-label image retrieval.pdf,Deep semantic ranking based hashing for multi-label image retrieval
0,"G. Lin, C. Shen, J. Xin",Optimizing ranking measures for compact binary code learning, In Proc,. Eur. Conf. Comp. Vis. (ECCV),,2014,,"G. Lin, C. Shen, and J. Xin. Optimizing ranking measures for compact binary code learning. In Proc. Eur. Conf. Comp. Vis. (ECCV), 2014.",./refs/download/2/Deep semantic ranking based hashing for multi-label image retrieval.pdf,Deep semantic ranking based hashing for multi-label image retrieval
0,"W. Liu, J. Wang, R. Ji, Y. Jiang, S. Chang",Supervised hashing with kernels, In Proc,. IEEE Conf. Comp. Vis. Pattern Recogn. (CVPR),,2012,,"W. Liu, J. Wang, R. Ji, Y. Jiang, and S. Chang. Supervised hashing with kernels. In Proc. IEEE Conf. Comp. Vis. Pattern Recogn. (CVPR), 2012.",./refs/download/2/Deep semantic ranking based hashing for multi-label image retrieval.pdf,Deep semantic ranking based hashing for multi-label image retrieval
0,D. G. Lowe,Object recognition from local scale-invariant features, In Proc,. Int. Conf. Comp. Vis. (ICCV),,1999,,"D. G. Lowe. Object recognition from local scale-invariant features. In Proc. Int. Conf. Comp. Vis. (ICCV), 1999.",./refs/download/2/Deep semantic ranking based hashing for multi-label image retrieval.pdf,Deep semantic ranking based hashing for multi-label image retrieval
0,"M. Norouzi and , D. J. Fleet",Minimal loss hashing for compact binary codes, In Proc,. Int. Conf. Mach. Learn. (ICML),,2011,,"M. Norouzi and D. J. Fleet. Minimal loss hashing for compact binary codes. In Proc. Int. Conf. Mach. Learn. (ICML), 2011.",./refs/download/2/Deep semantic ranking based hashing for multi-label image retrieval.pdf,Deep semantic ranking based hashing for multi-label image retrieval
0,"M. Norouzi, D. J. Fleet, R. Salakhutdinov",Hamming distance metric learning, In Proc,. Adv. Neural Info. Process. Syst. (NIPS),,2012,,"M. Norouzi, D. J. Fleet, and R. Salakhutdinov. Hamming distance metric learning. In Proc. Adv. Neural Info. Process. Syst. (NIPS), 2012.",./refs/download/2/Deep semantic ranking based hashing for multi-label image retrieval.pdf,Deep semantic ranking based hashing for multi-label image retrieval
0,"A. Oliva and , A. Torralba",Modeling the shape of the scene: A holistic representation of the spatial envelope, International journal of computer vision (IJCV),,,2001,,"A. Oliva and A. Torralba. Modeling the shape of the scene: A holistic representation of the spatial envelope. International journal of computer vision (IJCV), 2001.",./refs/download/2/Deep semantic ranking based hashing for multi-label image retrieval.pdf,Deep semantic ranking based hashing for multi-label image retrieval
0,"O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, A. C. Berg, F. Li",Imagenet large scale visual recognition challenge, CoRR,,,1409,,"O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, A. C. Berg, and F. Li. Imagenet large scale visual recognition challenge. CoRR, abs/1409.",./refs/download/2/Deep semantic ranking based hashing for multi-label image retrieval.pdf,Deep semantic ranking based hashing for multi-label image retrieval
0,"R. Salakhutdinov and , G. Hinton",Semantic hashing, International Journal of Approximate Reasoning,,,2009,,"R. Salakhutdinov and G. Hinton. Semantic hashing. International Journal of Approximate Reasoning, 2009.",./refs/download/2/Deep semantic ranking based hashing for multi-label image retrieval.pdf,Deep semantic ranking based hashing for multi-label image retrieval
0,"G. Shakhnarovich, P. A. Viola, T. Darrell",Fast pose estimation with parameter-sensitive hashing, In Proc,. Int. Conf. Comp. Vis. (ICCV),,2003,,"G. Shakhnarovich, P. A. Viola, and T. Darrell. Fast pose estimation with parameter-sensitive hashing. In Proc. Int. Conf. Comp. Vis. (ICCV), 2003.",./refs/download/2/Deep semantic ranking based hashing for multi-label image retrieval.pdf,Deep semantic ranking based hashing for multi-label image retrieval
0,"N. Srivastava and , R. Salakhutdinov",Multimodal learning with deep boltzmann machines, In Proc,. Adv. Neural Info. Process. Syst. (NIPS),,2012,,"N. Srivastava and R. Salakhutdinov. Multimodal learning with deep boltzmann machines. In Proc. Adv. Neural Info. Process. Syst. (NIPS), 2012.",./refs/download/2/Deep semantic ranking based hashing for multi-label image retrieval.pdf,Deep semantic ranking based hashing for multi-label image retrieval
0,"Y. Sun, X. Wang, X. Tang",Deep learning face representation from predicting 10,000 classes,. In Proc. IEEE Conf. Comp. Vis. Pattern Recogn. (CVPR),,2014,,"Y. Sun, X. Wang, and X. Tang. Deep learning face representation from predicting 10,000 classes. In Proc. IEEE Conf. Comp. Vis. Pattern Recogn. (CVPR), 2014.",./refs/download/2/Deep semantic ranking based hashing for multi-label image retrieval.pdf,Deep semantic ranking based hashing for multi-label image retrieval
0,"A. Torralba, R. Fergus, Y. Weiss",Small codes and large image databases for recognition, In Proc,. IEEE Conf. Comp. Vis. Pattern Recogn. (CVPR),,2008,,"A. Torralba, R. Fergus, and Y. Weiss. Small codes and large image databases for recognition. In Proc. IEEE Conf. Comp. Vis. Pattern Recogn. (CVPR), 2008.",./refs/download/2/Deep semantic ranking based hashing for multi-label image retrieval.pdf,Deep semantic ranking based hashing for multi-label image retrieval
0,"J. Wang, S. Kumar, S.-F. Chang",Semi-supervised hashing for scalable image retrieval, In Proc,. IEEE Conf. Comp. Vis. Pattern Recogn. (CVPR),,2010,,"J. Wang, S. Kumar, and S.-F. Chang. Semi-supervised hashing for scalable image retrieval. In Proc. IEEE Conf. Comp. Vis. Pattern Recogn. (CVPR), 2010.",./refs/download/2/Deep semantic ranking based hashing for multi-label image retrieval.pdf,Deep semantic ranking based hashing for multi-label image retrieval
0,"J. Wang, W. Liu, A. X. Sun, Y. Jiang",Learning hash codes with listwise supervision, In Proc,. Int. Conf. Comp. Vis. (ICCV),,2013,,"J. Wang, W. Liu, A. X. Sun, and Y. Jiang. Learning hash codes with listwise supervision. In Proc. Int. Conf. Comp. Vis. (ICCV), 2013.",./refs/download/2/Deep semantic ranking based hashing for multi-label image retrieval.pdf,Deep semantic ranking based hashing for multi-label image retrieval
0,"J. Wang, Y. Song, T. Leung, C. Rosenberg, Y. Wu",Learning fine-grained image similarity with deep ranking, In Proc,. IEEE Conf. Comp. Vis. Pattern Recogn. (CVPR),,2014,,"J. Wang, Y. Song, T. Leung, C. Rosenberg, and Y. Wu. Learning fine-grained image similarity with deep ranking. In Proc. IEEE Conf. Comp. Vis. Pattern Recogn. (CVPR), 2014.",./refs/download/2/Deep semantic ranking based hashing for multi-label image retrieval.pdf,Deep semantic ranking based hashing for multi-label image retrieval
0,"J. Wang, J. Wang, N. Yu, S. Li",Order preserving hashing for approximate nearest neighbor search, In Proc,. of the 21st ACM Int. Conf. on Multimedia,,2013,,"J. Wang, J. Wang, N. Yu, and S. Li. Order preserving hashing for approximate nearest neighbor search. In Proc. of the 21st ACM Int. Conf. on Multimedia, 2013.",./refs/download/2/Deep semantic ranking based hashing for multi-label image retrieval.pdf,Deep semantic ranking based hashing for multi-label image retrieval
0,"Y. Weiss, A. Torralba, R. Fergus",Spectral hashing, In Proc,. Adv. Neural Info. Process. Syst. (NIPS),,2008,,"Y. Weiss, A. Torralba, and R. Fergus. Spectral hashing. In Proc. Adv. Neural Info. Process. Syst. (NIPS), 2008.",./refs/download/2/Deep semantic ranking based hashing for multi-label image retrieval.pdf,Deep semantic ranking based hashing for multi-label image retrieval
0,"R. Xia, Y. Pan, H. Lai, C. Liu, S. Yan",Supervised hashing for image retrieval via image representation learning, In Proc,. Twenty-Eighth AAAI Conf. on Arti. Intel. (AAAI),,2014,,"R. Xia, Y. Pan, H. Lai, C. Liu, and S. Yan. Supervised hashing for image retrieval via image representation learning. In Proc. Twenty-Eighth AAAI Conf. on Arti. Intel. (AAAI), 2014.",./refs/download/2/Deep semantic ranking based hashing for multi-label image retrieval.pdf,Deep semantic ranking based hashing for multi-label image retrieval
0,,,,,,,, E. L. Allgower and ,./refs/download/2/Hashnet: Deep learning to hash by continuation.pdf,Hashnet: Deep learning to hash by continuation
0,,,,,,,," Y. Bengio, A. Courville, and ",./refs/download/2/Hashnet: Deep learning to hash by continuation.pdf,Hashnet: Deep learning to hash by continuation
0,,,,,,,," Y. Bengio, P. Lamblin, D. Popovici, and ",./refs/download/2/Hashnet: Deep learning to hash by continuation.pdf,Hashnet: Deep learning to hash by continuation
0,,,,,,,," B. Schölkopf, J. C. Platt, and ",./refs/download/2/Hashnet: Deep learning to hash by continuation.pdf,Hashnet: Deep learning to hash by continuation
0,,,,,,,," J. Tang, R. Hong, H. Li, Z. Luo, and ",./refs/download/2/Hashnet: Deep learning to hash by continuation.pdf,Hashnet: Deep learning to hash by continuation
0,,,,,,,, M. Courbariaux and ,./refs/download/2/Hashnet: Deep learning to hash by continuation.pdf,Hashnet: Deep learning to hash by continuation
0,,,,,,,," H. Lai, Y. Pan, Y. Liu, and ",./refs/download/2/Hashnet: Deep learning to hash by continuation.pdf,Hashnet: Deep learning to hash by continuation
0,,,,,,,," J. P. Dmochowski, P. Sajda, and ",./refs/download/2/Hashnet: Deep learning to hash by continuation.pdf,Hashnet: Deep learning to hash by continuation
0,,,,,,,," M. S. Lew, N. Sebe, C. Djeraba, and ",./refs/download/2/Hashnet: Deep learning to hash by continuation.pdf,Hashnet: Deep learning to hash by continuation
0,,,,,,,," J. Donahue, Y. Jia, O. Vinyals, J. Hoffman, N. Zhang, E. Tzeng, and ",./refs/download/2/Hashnet: Deep learning to hash by continuation.pdf,Hashnet: Deep learning to hash by continuation
0,,,,,,,," S. Wang, and ",./refs/download/2/Hashnet: Deep learning to hash by continuation.pdf,Hashnet: Deep learning to hash by continuation
0,,,,,,,," V. Erin Liong, J. Lu, G. Wang, P. Moulin, and ",./refs/download/2/Hashnet: Deep learning to hash by continuation.pdf,Hashnet: Deep learning to hash by continuation
0,,,,,,,," M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan, P. Dollár, and ",./refs/download/2/Hashnet: Deep learning to hash by continuation.pdf,Hashnet: Deep learning to hash by continuation
0,,,,,,,," D. J. Fleet, A. Punjani, and ",./refs/download/2/Hashnet: Deep learning to hash by continuation.pdf,Hashnet: Deep learning to hash by continuation
0,,,,,,,," H. Liu, R. Wang, S. Shan, and ",./refs/download/2/Hashnet: Deep learning to hash by continuation.pdf,Hashnet: Deep learning to hash by continuation
0,,,,,,,, Y. Gong and ,./refs/download/2/Hashnet: Deep learning to hash by continuation.pdf,Hashnet: Deep learning to hash by continuation
0,,,,,,,," K. He, X. Zhang, S. Ren, and ",./refs/download/2/Hashnet: Deep learning to hash by continuation.pdf,Hashnet: Deep learning to hash by continuation
0,,,,,,,," G. E. Hinton, S. Osindero, and ",./refs/download/2/Hashnet: Deep learning to hash by continuation.pdf,Hashnet: Deep learning to hash by continuation
0,,,,,,,, S. Ioffe and ,./refs/download/2/Hashnet: Deep learning to hash by continuation.pdf,Hashnet: Deep learning to hash by continuation
0,,,,,,,," H. Jegou, M. Douze, and ",./refs/download/2/Hashnet: Deep learning to hash by continuation.pdf,Hashnet: Deep learning to hash by continuation
0,,,,,,,," Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Girshick, S. Guadarrama, and ",./refs/download/2/Hashnet: Deep learning to hash by continuation.pdf,Hashnet: Deep learning to hash by continuation
0,,,,,,,," W. Liu, J. Wang, S. Kumar, and ",./refs/download/2/Hashnet: Deep learning to hash by continuation.pdf,Hashnet: Deep learning to hash by continuation
0,,,,,,,," X. Liu, J. He, B. Lang, and ",./refs/download/2/Hashnet: Deep learning to hash by continuation.pdf,Hashnet: Deep learning to hash by continuation
0,,,,,,,," C. Ma, I. W. Tsang, F. Peng, and ",./refs/download/2/Hashnet: Deep learning to hash by continuation.pdf,Hashnet: Deep learning to hash by continuation
0,,,,,,,, V. Nair and ,./refs/download/2/Hashnet: Deep learning to hash by continuation.pdf,Hashnet: Deep learning to hash by continuation
0,,,,,,,, J. Fürnkranz and ,./refs/download/2/Hashnet: Deep learning to hash by continuation.pdf,Hashnet: Deep learning to hash by continuation
0,,,,,,,, M. Norouzi and ,./refs/download/2/Hashnet: Deep learning to hash by continuation.pdf,Hashnet: Deep learning to hash by continuation
0,,,,,,,," M. Norouzi, D. M. Blei, and ",./refs/download/2/Hashnet: Deep learning to hash by continuation.pdf,Hashnet: Deep learning to hash by continuation
0,,,,,,,," A. Krizhevsky, I. Sutskever, and ",./refs/download/2/Hashnet: Deep learning to hash by continuation.pdf,Hashnet: Deep learning to hash by continuation
0,,,,,,,," O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, A. C. Berg, and ",./refs/download/2/Hashnet: Deep learning to hash by continuation.pdf,Hashnet: Deep learning to hash by continuation
0,,,,,,,, B. Kulis and ,./refs/download/2/Hashnet: Deep learning to hash by continuation.pdf,Hashnet: Deep learning to hash by continuation
0,,,,,,,, R. Salakhutdinov and ,./refs/download/2/Hashnet: Deep learning to hash by continuation.pdf,Hashnet: Deep learning to hash by continuation
0,,,,,,,," F. Shen, C. Shen, W. Liu, and ",./refs/download/2/Hashnet: Deep learning to hash by continuation.pdf,Hashnet: Deep learning to hash by continuation
0,,,,,,,," A. W. Smeulders, M. Worring, S. Santini, A. Gupta, and ",./refs/download/2/Hashnet: Deep learning to hash by continuation.pdf,Hashnet: Deep learning to hash by continuation
0,,,,,,,," N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, and ",./refs/download/2/Hashnet: Deep learning to hash by continuation.pdf,Hashnet: Deep learning to hash by continuation
0,,,,,,,," J. Wang, S. Kumar, and ",./refs/download/2/Hashnet: Deep learning to hash by continuation.pdf,Hashnet: Deep learning to hash by continuation
0,,,,,,,," J. Wang, H. T. Shen, J. Song, and ",./refs/download/2/Hashnet: Deep learning to hash by continuation.pdf,Hashnet: Deep learning to hash by continuation
0,,,,,,,," Y. Weiss, A. Torralba, and ",./refs/download/2/Hashnet: Deep learning to hash by continuation.pdf,Hashnet: Deep learning to hash by continuation
0,,,,,,,," R. Xia, Y. Pan, H. Lai, C. Liu, and ",./refs/download/2/Hashnet: Deep learning to hash by continuation.pdf,Hashnet: Deep learning to hash by continuation
0,,,,,,,," F. X. Yu, S. Kumar, Y. Gong, and ",./refs/download/2/Hashnet: Deep learning to hash by continuation.pdf,Hashnet: Deep learning to hash by continuation
0,,,,,,,," F. Zhao, Y. Huang, L. Wang, and ",./refs/download/2/Hashnet: Deep learning to hash by continuation.pdf,Hashnet: Deep learning to hash by continuation
0,,,,,,,," H. Zhu, M. Long, J. Wang, and ",./refs/download/2/Hashnet: Deep learning to hash by continuation.pdf,Hashnet: Deep learning to hash by continuation
0,,,,,,,," F. Bastien, P. Lamblin, R. Pascanu, J. Bergstra, I. Goodfellow, A. Bergeron, N. Bouchard, D. Warde-Farley, and ",./refs/download/2/Fast training of triplet-based deep binary embedding networks.pdf,Fast training of triplet-based deep binary embedding networks
0,,,,,,,, M. A. Carreira-Perpinan and ,./refs/download/2/Fast training of triplet-based deep binary embedding networks.pdf,Fast training of triplet-based deep binary embedding networks
0,,,,,,,," D. Chen, X. Cao, L. Wang, F. Wen, and ",./refs/download/2/Fast training of triplet-based deep binary embedding networks.pdf,Fast training of triplet-based deep binary embedding networks
0,,,,,,,," J. Tang, R. Hong, H. Li, Z. Luo, and ",./refs/download/2/Fast training of triplet-based deep binary embedding networks.pdf,Fast training of triplet-based deep binary embedding networks
0,,,,,,,," V. Erin Liong, J. Lu, G. Wang, P. Moulin, and ",./refs/download/2/Fast training of triplet-based deep binary embedding networks.pdf,Fast training of triplet-based deep binary embedding networks
0,,,,,,,," Y. Gong, S. Lazebnik, A. Gordo, and ",./refs/download/2/Fast training of triplet-based deep binary embedding networks.pdf,Fast training of triplet-based deep binary embedding networks
0,,,,,,,," G. B. Huang, M. Ramesh, T. Berg, and ",./refs/download/2/Fast training of triplet-based deep binary embedding networks.pdf,Fast training of triplet-based deep binary embedding networks
0,,,,,,,," Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Girshick, S. Guadarrama, and ",./refs/download/2/Fast training of triplet-based deep binary embedding networks.pdf,Fast training of triplet-based deep binary embedding networks
0,,,,,,,," K. Jiang, Q. Que, and ",./refs/download/2/Fast training of triplet-based deep binary embedding networks.pdf,Fast training of triplet-based deep binary embedding networks
0,,,,,,,," B. F. Klare, B. Klein, E. Taborsky, A. Blanton, J. Cheney, K. Allen, P. Grother, A. Mah, M. Burge, and ",./refs/download/2/Fast training of triplet-based deep binary embedding networks.pdf,Fast training of triplet-based deep binary embedding networks
0,,,,,,,, B. Kulis and ,./refs/download/2/Fast training of triplet-based deep binary embedding networks.pdf,Fast training of triplet-based deep binary embedding networks
0,,,,,,,, B. Kulis and ,./refs/download/2/Fast training of triplet-based deep binary embedding networks.pdf,Fast training of triplet-based deep binary embedding networks
0,,,,,,,," H. Lai, Y. Pan, Y. Liu, and ",./refs/download/2/Fast training of triplet-based deep binary embedding networks.pdf,Fast training of triplet-based deep binary embedding networks
0,,,,,,,," X. Li, G. Lin, C. Shen, A. Van den Hengel, and ",./refs/download/2/Fast training of triplet-based deep binary embedding networks.pdf,Fast training of triplet-based deep binary embedding networks
0,,,,,,,," G. Lin, C. Shen, Q. Shi, A. van den Hengel, and ",./refs/download/2/Fast training of triplet-based deep binary embedding networks.pdf,Fast training of triplet-based deep binary embedding networks
0,,,,,,,," G. Lin, C. Shen, D. Suter, and ",./refs/download/2/Fast training of triplet-based deep binary embedding networks.pdf,Fast training of triplet-based deep binary embedding networks
0,,,,,,,," W. Liu, J. Wang, S. Kumar, and ",./refs/download/2/Fast training of triplet-based deep binary embedding networks.pdf,Fast training of triplet-based deep binary embedding networks
0,,,,,,,," M. Mathias, R. Benenson, M. Pedersoli, and ",./refs/download/2/Fast training of triplet-based deep binary embedding networks.pdf,Fast training of triplet-based deep binary embedding networks
0,,,,,,,," M. Norouzi, D. M. Blei, and ",./refs/download/2/Fast training of triplet-based deep binary embedding networks.pdf,Fast training of triplet-based deep binary embedding networks
0,,,,,,,, A. Quattoni and ,./refs/download/2/Fast training of triplet-based deep binary embedding networks.pdf,Fast training of triplet-based deep binary embedding networks
0,,,,,,,," O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, A. C. Berg, and ",./refs/download/2/Fast training of triplet-based deep binary embedding networks.pdf,Fast training of triplet-based deep binary embedding networks
0,,,,,,,," F. Schroff, D. Kalenichenko, and ",./refs/download/2/Fast training of triplet-based deep binary embedding networks.pdf,Fast training of triplet-based deep binary embedding networks
0,,,,,,,," F. Shen, C. Shen, W. Liu, and ",./refs/download/2/Fast training of triplet-based deep binary embedding networks.pdf,Fast training of triplet-based deep binary embedding networks
0,,,,,,,," F. Shen, C. Shen, Q. Shi, A. Van Den Hengel, and ",./refs/download/2/Fast training of triplet-based deep binary embedding networks.pdf,Fast training of triplet-based deep binary embedding networks
0,,,,,,,, K. Simonyan and ,./refs/download/2/Fast training of triplet-based deep binary embedding networks.pdf,Fast training of triplet-based deep binary embedding networks
0,,,,,,,," Y. Sun, D. Liang, X. Wang, and ",./refs/download/2/Fast training of triplet-based deep binary embedding networks.pdf,Fast training of triplet-based deep binary embedding networks
0,,,,,,,," Y. Taigman, M. Yang, M. Ranzato, and ",./refs/download/2/Fast training of triplet-based deep binary embedding networks.pdf,Fast training of triplet-based deep binary embedding networks
0,,,,,,,," D. Wang, C. Otto, and ",./refs/download/2/Fast training of triplet-based deep binary embedding networks.pdf,Fast training of triplet-based deep binary embedding networks
0,,,,,,,," J. Wang, Y. Song, T. Leung, C. Rosenberg, J. Wang, J. Philbin, B. Chen, and ",./refs/download/2/Fast training of triplet-based deep binary embedding networks.pdf,Fast training of triplet-based deep binary embedding networks
0,,,,,,,, K. Q. Weinberger and ,./refs/download/2/Fast training of triplet-based deep binary embedding networks.pdf,Fast training of triplet-based deep binary embedding networks
0,,,,,,,," Y. Weiss, R. Fergus, and ",./refs/download/2/Fast training of triplet-based deep binary embedding networks.pdf,Fast training of triplet-based deep binary embedding networks
0,,,,,,,," Y. Weiss, A. Torralba, and ",./refs/download/2/Fast training of triplet-based deep binary embedding networks.pdf,Fast training of triplet-based deep binary embedding networks
0,,,,,,,, X. Xiong and ,./refs/download/2/Fast training of triplet-based deep binary embedding networks.pdf,Fast training of triplet-based deep binary embedding networks
0,,,,,,,," D. Yi, Z. Lei, S. Liao, and ",./refs/download/2/Fast training of triplet-based deep binary embedding networks.pdf,Fast training of triplet-based deep binary embedding networks
0,,,,,,,," R. Zhang, L. Lin, R. Zhang, W. Zuo, and ",./refs/download/2/Fast training of triplet-based deep binary embedding networks.pdf,Fast training of triplet-based deep binary embedding networks
0,,,,,,,," F. Zhao, Y. Huang, L. Wang, and ",./refs/download/2/Fast training of triplet-based deep binary embedding networks.pdf,Fast training of triplet-based deep binary embedding networks
0,"Baker, O. , Gupta, N.","Naik, and R",Raskar. Designing neural network architectures using reinforcement learning. ICLR,,,2017,,"Baker, O. Gupta, N. Naik, and R. Raskar. Designing neural network architectures using reinforcement learning. ICLR, 2017.",./refs/download/2/MnasNet: Platform-aware neural architecture search for mobile.pdf,MnasNet: Platform-aware neural architecture search for mobile
0,"Dong, A.-C. , Cheng, D.-C. , Juan, W.","Wei, and M",Sun. DPP-Net: Device-aware progressive search for paretooptimal neural architectures. ECCV,,,2018,,"Dong, A.-C. Cheng, D.-C. Juan, W. Wei, and M. Sun. DPP-Net: Device-aware progressive search for paretooptimal neural architectures. ECCV, 2018.",./refs/download/2/MnasNet: Platform-aware neural architecture search for mobile.pdf,MnasNet: Platform-aware neural architecture search for mobile
0,"Elsken, J. H.","Metzen, and F",Hutter. Multi-objective architecture search for cnns. arXiv preprint arXiv:1804.09081,,,2018,,"Elsken, J. H. Metzen, and F. Hutter. Multi-objective architecture search for cnns. arXiv preprint arXiv:1804.09081, 2018.",./refs/download/2/MnasNet: Platform-aware neural architecture search for mobile.pdf,MnasNet: Platform-aware neural architecture search for mobile
0,"Gholami, K. , Kwon, B. , Wu, Z. , Tai, X. , Yue, P. , Jin, S.","Zhao, and K",Keutzer. Squeezenext: Hardware-aware neural network design. ECV Workshop at CVPR,,,2018,,"Gholami, K. Kwon, B. Wu, Z. Tai, X. Yue, P. Jin, S. Zhao, and K. Keutzer. Squeezenext: Hardware-aware neural network design. ECV Workshop at CVPR, 2018.",./refs/download/2/MnasNet: Platform-aware neural architecture search for mobile.pdf,MnasNet: Platform-aware neural architecture search for mobile
0,"Gordon, E. , Eban, O. , Nachum, B. , Chen, H. , Wu, T.-J.","Yang, and E",Choi. Morphnet: Fast & simple resourceconstrained structure learning of deep networks. CVPR,,,2018,,"Gordon, E. Eban, O. Nachum, B. Chen, H. Wu, T.-J. Yang, and E. Choi. Morphnet: Fast & simple resourceconstrained structure learning of deep networks. CVPR, 2018.",./refs/download/2/MnasNet: Platform-aware neural architecture search for mobile.pdf,MnasNet: Platform-aware neural architecture search for mobile
0,"Goyal, P. , Dollár, R. , Girshick, P. , Noordhuis, L. , Wesolowski, A. , Kyrola, A. , Tulloch, Y.","Jia, and K",He. Accurate,,,2017,large minibatch sgd: training imagenet in 1 hour. arXiv preprint arXiv:1706.02677,"Goyal, P. Dollár, R. Girshick, P. Noordhuis, L. Wesolowski, A. Kyrola, A. Tulloch, Y. Jia, and K. He. Accurate, large minibatch sgd: training imagenet in 1 hour. arXiv preprint arXiv:1706.02677, 2017.",./refs/download/2/MnasNet: Platform-aware neural architecture search for mobile.pdf,MnasNet: Platform-aware neural architecture search for mobile
0,,,,,,,,"Han, H. Mao, and W. J. Dally. Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding. ICLR, 2016.",./refs/download/2/MnasNet: Platform-aware neural architecture search for mobile.pdf,MnasNet: Platform-aware neural architecture search for mobile
0,"He, X. , Zhang, S.","Ren, and J",Sun. Deep residual learning for image recognition. CVPR,,,2016,pages 770–778,"He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. CVPR, pages 770–778, 2016.",./refs/download/2/MnasNet: Platform-aware neural architecture search for mobile.pdf,MnasNet: Platform-aware neural architecture search for mobile
0,"He, J. , Lin, Z. , Liu, H. , Wang, L.-J.","Li, and S",Han. Amc: Automl for model compression and acceleration on mobile devices. ECCV,,,2018,,"He, J. Lin, Z. Liu, H. Wang, L.-J. Li, and S. Han. Amc: Automl for model compression and acceleration on mobile devices. ECCV, 2018.",./refs/download/2/MnasNet: Platform-aware neural architecture search for mobile.pdf,MnasNet: Platform-aware neural architecture search for mobile
0,"Howard, M. , Zhu, B. , Chen, D. , Kalenichenko, W. , Wang, T. , Weyand, M.","Andreetto, and H",Adam. Mobilenets: Efficient convolutional neural networks for mobile vision applications. arXiv preprint arXiv:1704.04861,,,2017,,"Howard, M. Zhu, B. Chen, D. Kalenichenko, W. Wang, T. Weyand, M. Andreetto, and H. Adam. Mobilenets: Efficient convolutional neural networks for mobile vision applications. arXiv preprint arXiv:1704.04861, 2017.",./refs/download/2/MnasNet: Platform-aware neural architecture search for mobile.pdf,MnasNet: Platform-aware neural architecture search for mobile
0,"Hsu, S.-H. , Chang, D.-C. , Juan, J.-Y. , Pan, Y.-T.","Chen, W",Wei,,,2018,and S.-C. Chang. MONAS: Multi-objective neural architecture search using reinforcement learning. arXiv preprint arXiv:1806.10332,"Hsu, S.-H. Chang, D.-C. Juan, J.-Y. Pan, Y.-T. Chen, W. Wei, and S.-C. Chang. MONAS: Multi-objective neural architecture search using reinforcement learning. arXiv preprint arXiv:1806.10332, 2018.",./refs/download/2/MnasNet: Platform-aware neural architecture search for mobile.pdf,MnasNet: Platform-aware neural architecture search for mobile
0,"Hu, L.","Shen, and G",Sun. Squeeze-and-excitation networks. CVPR,,,2018,,"Hu, L. Shen, and G. Sun. Squeeze-and-excitation networks. CVPR, 2018.",./refs/download/2/MnasNet: Platform-aware neural architecture search for mobile.pdf,MnasNet: Platform-aware neural architecture search for mobile
0,"Huang, S. , Liu, L.","van der Maaten, and K",Q. Weinberger. Condensenet: An efficient densenet using learned group convolutions. CVPR,,,2018,,"Huang, S. Liu, L. van der Maaten, and K. Q. Weinberger. Condensenet: An efficient densenet using learned group convolutions. CVPR, 2018.",./refs/download/2/MnasNet: Platform-aware neural architecture search for mobile.pdf,MnasNet: Platform-aware neural architecture search for mobile
0,"Iandola, S. , Han, M. W. , Moskewicz, K. , Ashraf, W. J.","Dally, and K",Keutzer. Squeezenet: Alexnet-level accuracy with 50x fewer parameters and ¡0.5 mb model size. arXiv preprint arXiv:1602.07360,,,2016,,"Iandola, S. Han, M. W. Moskewicz, K. Ashraf, W. J. Dally, and K. Keutzer. Squeezenet: Alexnet-level accuracy with 50x fewer parameters and ¡0.5 mb model size. arXiv preprint arXiv:1602.07360, 2016.",./refs/download/2/MnasNet: Platform-aware neural architecture search for mobile.pdf,MnasNet: Platform-aware neural architecture search for mobile
0,"Jacob, S. , Kligys, B. , Chen, M. , Zhu, M. , Tang, A. , Howard, H.","Adam, and D",Kalenichenko. Quantization and training of neural networks for efficient integer-arithmetic-only inference. CVPR,,,2018,,"Jacob, S. Kligys, B. Chen, M. Zhu, M. Tang, A. Howard, H. Adam, and D. Kalenichenko. Quantization and training of neural networks for efficient integer-arithmetic-only inference. CVPR, 2018.",./refs/download/2/MnasNet: Platform-aware neural architecture search for mobile.pdf,MnasNet: Platform-aware neural architecture search for mobile
0,"Kandasamy, W. , Neiswanger, J. , Schneider, B.","Poczos, and E",Xing. Neural architecture search with bayesian optimisation and optimal transport. NeurIPS,,,2018,,"Kandasamy, W. Neiswanger, J. Schneider, B. Poczos, and E. Xing. Neural architecture search with bayesian optimisation and optimal transport. NeurIPS, 2018.",./refs/download/2/MnasNet: Platform-aware neural architecture search for mobile.pdf,MnasNet: Platform-aware neural architecture search for mobile
0,"Lin, M. , Maire, S. , Belongie, J. , Hays, P. , Perona, D. , Ramanan, P.","Dollár, and C",L. Zitnick. Microsoft COCO: Common objects in context. ECCV,,,2014,,"Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan, P. Dollár, and C. L. Zitnick. Microsoft COCO: Common objects in context. ECCV, 2014.",./refs/download/2/MnasNet: Platform-aware neural architecture search for mobile.pdf,MnasNet: Platform-aware neural architecture search for mobile
0,"Liu, B. , Zoph, J. , Shlens, W. , Hua, L.-J. , Li, L. , Fei-Fei, A. , Yuille, J.","Huang, and K",Murphy. Progressive neural architecture search. ECCV,,,2018,,"Liu, B. Zoph, J. Shlens, W. Hua, L.-J. Li, L. Fei-Fei, A. Yuille, J. Huang, and K. Murphy. Progressive neural architecture search. ECCV, 2018.",./refs/download/2/MnasNet: Platform-aware neural architecture search for mobile.pdf,MnasNet: Platform-aware neural architecture search for mobile
0,"Liu, K. , Simonyan, O. , Vinyals, C.","Fernando, and K",Kavukcuoglu. Hierarchical representations for efficient architecture search. ICLR,,,2018,,"Liu, K. Simonyan, O. Vinyals, C. Fernando, and K. Kavukcuoglu. Hierarchical representations for efficient architecture search. ICLR, 2018.",./refs/download/2/MnasNet: Platform-aware neural architecture search for mobile.pdf,MnasNet: Platform-aware neural architecture search for mobile
0,"Liu, K.","Simonyan, and Y",Yang. DARTS: Differentiable architecture search. ICLR,,,2019,,"Liu, K. Simonyan, and Y. Yang. DARTS: Differentiable architecture search. ICLR, 2019.",./refs/download/2/MnasNet: Platform-aware neural architecture search for mobile.pdf,MnasNet: Platform-aware neural architecture search for mobile
0,"Liu, D. , Anguelov, D. , Erhan, C. , Szegedy, S. , Reed, C.Y.","Fu, and A",C. Berg. SSD: Single shot multibox detector. ECCV,,,2016,,"Liu, D. Anguelov, D. Erhan, C. Szegedy, S. Reed, C.Y. Fu, and A. C. Berg. SSD: Single shot multibox detector. ECCV, 2016.",./refs/download/2/MnasNet: Platform-aware neural architecture search for mobile.pdf,MnasNet: Platform-aware neural architecture search for mobile
0,,,,,,,,"Luo, F. Tian, T. Qin, and T.-Y. Liu. Neural architecture optimization. NeurIPS, 2018.",./refs/download/2/MnasNet: Platform-aware neural architecture search for mobile.pdf,MnasNet: Platform-aware neural architecture search for mobile
0,"Ma, X. , Zhang, H.-T.","Zheng, and J",Sun. Shufflenet v2: Practical guidelines for efficient cnn architecture design. ECCV,,,2018,,"Ma, X. Zhang, H.-T. Zheng, and J. Sun. Shufflenet v2: Practical guidelines for efficient cnn architecture design. ECCV, 2018.",./refs/download/2/MnasNet: Platform-aware neural architecture search for mobile.pdf,MnasNet: Platform-aware neural architecture search for mobile
0,"Pham, M. Y. , Guan, B. , Zoph, Q. V.","Le, and J",Dean. Efficient neural architecture search via parameter sharing. ICML,,,2018,,"Pham, M. Y. Guan, B. Zoph, Q. V. Le, and J. Dean. Efficient neural architecture search via parameter sharing. ICML, 2018.",./refs/download/2/MnasNet: Platform-aware neural architecture search for mobile.pdf,MnasNet: Platform-aware neural architecture search for mobile
0,"Real, A. , Aggarwal, Y.","Huang, and Q",V. Le. Regularized evolution for image classifier architecture search. AAAI,,,2019,,"Real, A. Aggarwal, Y. Huang, and Q. V. Le. Regularized evolution for image classifier architecture search. AAAI, 2019.",./refs/download/2/MnasNet: Platform-aware neural architecture search for mobile.pdf,MnasNet: Platform-aware neural architecture search for mobile
0,"Russakovsky, J. , Deng, H. , Su, J. , Krause, S. , Satheesh, S. , Ma, Z. , Huang, A. , Karpathy, A. , Khosla, M.","Bernstein, et al",Imagenet large scale visual recognition challenge. International Journal of Computer Vision,,,2015,115(3):211–252,"Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, et al. Imagenet large scale visual recognition challenge. International Journal of Computer Vision, 115(3):211–252, 2015.",./refs/download/2/MnasNet: Platform-aware neural architecture search for mobile.pdf,MnasNet: Platform-aware neural architecture search for mobile
0,,,,,,,,"Sandler, A. Howard, M. Zhu, A. Zhmoginov, and L.-C. Chen. Mobilenetv2: Inverted residuals and linear bottlenecks. CVPR, 2018.",./refs/download/2/MnasNet: Platform-aware neural architecture search for mobile.pdf,MnasNet: Platform-aware neural architecture search for mobile
0,"Schulman, F. , Wolski, P. , Dhariwal, A.","Radford, and O",Klimov. Proximal policy optimization algorithms. arXiv preprint arXiv:1707.06347,,,2017,,"Schulman, F. Wolski, P. Dhariwal, A. Radford, and O. Klimov. Proximal policy optimization algorithms. arXiv preprint arXiv:1707.06347, 2017.",./refs/download/2/MnasNet: Platform-aware neural architecture search for mobile.pdf,MnasNet: Platform-aware neural architecture search for mobile
0,"Szegedy, S. , Ioffe, V.","Vanhoucke, and A",A. Alemi. Inception-v4,,,2017,"inception-resnet and the impact of residual connections on learning. AAAI, 4:12","Szegedy, S. Ioffe, V. Vanhoucke, and A. A. Alemi. Inception-v4, inception-resnet and the impact of residual connections on learning. AAAI, 4:12, 2017.",./refs/download/2/MnasNet: Platform-aware neural architecture search for mobile.pdf,MnasNet: Platform-aware neural architecture search for mobile
0,"Yang, A. , Howard, B. , Chen, X. , Zhang, A. , Go, V.","Sze, and H",Adam. Netadapt: Platform-aware neural network adaptation for mobile applications. ECCV,,,2018,,"Yang, A. Howard, B. Chen, X. Zhang, A. Go, V. Sze, and H. Adam. Netadapt: Platform-aware neural network adaptation for mobile applications. ECCV, 2018.",./refs/download/2/MnasNet: Platform-aware neural architecture search for mobile.pdf,MnasNet: Platform-aware neural architecture search for mobile
0,"Zhang, X. , Zhou, M.","Lin, and J",Sun. Shufflenet: An extremely efficient convolutional neural network for mobile devices. CVPR,,,2018,,"Zhang, X. Zhou, M. Lin, and J. Sun. Shufflenet: An extremely efficient convolutional neural network for mobile devices. CVPR, 2018.",./refs/download/2/MnasNet: Platform-aware neural architecture search for mobile.pdf,MnasNet: Platform-aware neural architecture search for mobile
0,"Zhou, S. , Ebrahimi, S.",Ö,Arık,,,2018,"H. Yu, H. Liu, and G. Diamos. Resource-efficient neural architect. arXiv preprint arXiv:1806.07912","Zhou, S. Ebrahimi, S. Ö. Arık, H. Yu, H. Liu, and G. Diamos. Resource-efficient neural architect. arXiv preprint arXiv:1806.07912, 2018.",./refs/download/2/MnasNet: Platform-aware neural architecture search for mobile.pdf,MnasNet: Platform-aware neural architecture search for mobile
0,"Zoph, V. , Vasudevan, J.","Shlens, and Q",V. Le. Learning transferable architectures for scalable image recognition. CVPR,,,2018,,"Zoph, V. Vasudevan, J. Shlens, and Q. V. Le. Learning transferable architectures for scalable image recognition. CVPR, 2018.",./refs/download/2/MnasNet: Platform-aware neural architecture search for mobile.pdf,MnasNet: Platform-aware neural architecture search for mobile
0,"Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., Fei-Fei, L.",: Imagenet: A large-scale hierarchical image database,In: Computer Vision and Pattern Recognition,,,2009,,"Deng, J., Dong, W., Socher, R., Li, L.J., Li, K., Fei-Fei, L.: Imagenet: A large-scale hierarchical image database. In: Computer Vision and Pattern Recognition, 2009.",./refs/download/2/Deep networks with stochastic depth.pdf,Deep networks with stochastic depth
0,,,,,,,,"Netzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B., Ng, A.Y.: Reading digits in natural images with unsupervised feature learning. In: NIPS workshop on deep learning and unsupervised feature learning. Volume 2011.",./refs/download/2/Deep networks with stochastic depth.pdf,Deep networks with stochastic depth
0,,,,,,,,"References Abbeel, P. and Ng, A. Y. (2004).",./refs/download/2/Representation learning: A review and new perspectives.pdf,Representation learning: A review and new perspectives
0,,,,,,,,"Arjovsky, M., Chintala, S., and Bottou, L. (2017). Wasserstein generative adversarial networks. In International Conference on Machine Learning, pages 214–223. Bell, A. J. and Sejnowski, T. J. (1997).",./refs/download/2/Representation learning: A review and new perspectives.pdf,Representation learning: A review and new perspectives
0,,,,,,,,"Bengio, Y., Delalleau, O., Roux, N. L., Paiement, J.-F., Vincent, P., and Ouimet, M. (2004). Learning eigenfunctions links spectral embedding and kernel PCA. Neural Computation, 16(10):2197–2219. Blei, D. M., Kucukelbir, A., and McAuliffe, J. D. (2017).",./refs/download/2/Representation learning: A review and new perspectives.pdf,Representation learning: A review and new perspectives
0,,,,,,,,"Breiman, L. (2017). Classification and regression trees. Routledge. Dai, J., Lu, Y., and Wu, Y. N. (2014).",./refs/download/2/Representation learning: A review and new perspectives.pdf,Representation learning: A review and new perspectives
0,,,,,,,,"Dai, Z., Almahairi, A., Bachman, P., Hovy, E., and Courville, A. (2017). Calibrating energy-based generative adversarial networks. In International Conference on Learning Representations. Dempster, A. P., Laird, N. M., and Rubin, D. B. (1977).",./refs/download/2/Representation learning: A review and new perspectives.pdf,Representation learning: A review and new perspectives
0,,,,,,,,"Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K. (2019). Bert: Pre-training of deep bidirectional transformers for language understanding. In The Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 4171–4186. Dinh, L., Krueger, D., and Bengio, Y. (2014).",./refs/download/2/Representation learning: A review and new perspectives.pdf,Representation learning: A review and new perspectives
0,,,,,,,,"Dinh, L., Sohl-Dickstein, J., and Bengio, S. (2017). Density estimation using real NVP. In International Conference on Learning Representations. Dornhoff, L. L. (1972).",./refs/download/2/Representation learning: A review and new perspectives.pdf,Representation learning: A review and new perspectives
0,,,,,,,,"Friedman, J. H. (1991). Multivariate adaptive regression splines. The Annals of Statistics, pages 1–67. Gao, R., Lu, Y., Zhou, J., Zhu, S.-C., and Wu, Y. N. (2018a). Learning generative ConvNets via multi-grid modeling and sampling. In IEEE Conference on Computer Vision and Pattern Recognition, pages 9155–9164. Gao, R., Xie, J., Zhu, S.-C., and Wu, Y. N. (2018b). Learning grid cells as vector representation of self-position coupled with matrix representation of self-motion. In International Conference on Learning Representations. Gao, R., Xie, J., Zhu, S.-C., and Wu, Y. N. (2018c). Learning vector representation of content and matrix representation of change: Towards a representational model of V1. arXiv preprint arXiv:1902.03871. Gómez-Bombarelli, R., Wei, J. N., Duvenaud, D., Hernández-Lobato, J. M., Sánchez-Lengeling, B., Sheberla, D., Aguilera-Iparraguirre, J., Hirzel, T. D., Adams, R. P., and Aspuru-Guzik, A. (2018).",./refs/download/2/Representation learning: A review and new perspectives.pdf,Representation learning: A review and new perspectives
0,,,,,,,,"Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., and Bengio, Y. (2014). Generative adversarial nets. In Advances in Neural Information Processing Systems, pages 2672–2680. Grathwohl, W., Chen, R. T., Betterncourt, J., Sutskever, I., and Duvenaud, D. (2019).",./refs/download/2/Representation learning: A review and new perspectives.pdf,Representation learning: A review and new perspectives
0,,,,,,,,"Hafting, T., Fyhn, M., Molden, S., Moser, M.-B., and Moser, E. I. (2005). Microstructure of a spatial map in the entorhinal cortex. Nature, 436(7052):801. Hamilton, W. L., Ying, R., and Leskovec, J. (2017).",./refs/download/2/Representation learning: A review and new perspectives.pdf,Representation learning: A review and new perspectives
0,,,,,,,,"Han, T., Lu, Y., Zhu, S.-C., and Wu, Y. N. (2017). Alternating back-propagation for generator network. In The AAAI Conference on Artificial Intelligence, volume 3, pages 1976–1984. Han, T., Nijkamp, E., Fang, X., Hill, M., Zhu, S.-C., and Wu, Y. N. (2019).",./refs/download/2/Representation learning: A review and new perspectives.pdf,Representation learning: A review and new perspectives
0,,,,,,,,"Hinton, G. E. (2002). Training products of experts by minimizing contrastive divergence. Neural Computation, 14(8):1771–1800. Hinton, G. E. (2012).",./refs/download/2/Representation learning: A review and new perspectives.pdf,Representation learning: A review and new perspectives
0,,,,,,,,"Hinton, G. E., Dayan, P., Frey, B. J., and Neal, R. M. (1995). The “wake-sleep” algorithm for unsupervised neural networks. Science, 268(5214):1158–1161. Hochreiter, S. and Schmidhuber, J. (1997).",./refs/download/2/Representation learning: A review and new perspectives.pdf,Representation learning: A review and new perspectives
0,,,,,,,,"Hubel, D. H. and Wiesel, T. N. (1959).",./refs/download/2/Representation learning: A review and new perspectives.pdf,Representation learning: A review and new perspectives
0,,,,,,,,"Hyvärinen, A., Karhunen, J., and Oja, E. (2004). Independent component analysis, volume 46. Isola, P., Zhu, J.-Y., Zhou, T., and Efros, A. A. (2017).",./refs/download/2/Representation learning: A review and new perspectives.pdf,Representation learning: A review and new perspectives
0,,,,,,,,"Jin, L., Lazarow, J., and Tu, Z. (2017). Introspective classification with convolutional nets. In Advances in Neural Information Processing Systems, pages 823–833. 27 Jordan, M. I., Ghahramani, Z., Jaakkola, T. S., and Saul, L. K. (1999).",./refs/download/2/Representation learning: A review and new perspectives.pdf,Representation learning: A review and new perspectives
0,,,,,,,,"Karras, T., Aila, T., Laine, S., and Lehtinen, J. (2017). Progressive growing of gans for improved quality, stability, and variation. International Conference on Learning Representations. Kim, T. and Bengio, Y. (2016).",./refs/download/2/Representation learning: A review and new perspectives.pdf,Representation learning: A review and new perspectives
0,,,,,,,,"Kingma, D. P. and Dhariwal, P. (2018).",./refs/download/2/Representation learning: A review and new perspectives.pdf,Representation learning: A review and new perspectives
0,,,,,,,,"Kingma, D. P. and Welling, M. (2014).",./refs/download/2/Representation learning: A review and new perspectives.pdf,Representation learning: A review and new perspectives
0,,,,,,,,"Kipf, T. N. and Welling, M. (2016).",./refs/download/2/Representation learning: A review and new perspectives.pdf,Representation learning: A review and new perspectives
0,,,,,,,,"Koren, Y., Bell, R., and Volinsky, C. (2009). Matrix factorization techniques for recommender systems. Computer, (8):30–37. Krizhevsky, A., Sutskever, I., and Hinton, G. E. (2012).",./refs/download/2/Representation learning: A review and new perspectives.pdf,Representation learning: A review and new perspectives
0,,,,,,,,"Kruskal, J. B. (1964). Multidimensional scaling by optimizing goodness of fit to a nonmetric hypothesis. Psychometrika, 29(1):1–27. Lafferty, J., McCallum, A., and Pereira, F. C. (2001).",./refs/download/2/Representation learning: A review and new perspectives.pdf,Representation learning: A review and new perspectives
0,,,,,,,,"Lazarow, J., Jin, L., and Tu, Z. (2017). Introspective neural networks for generative modeling. In IEEE International Conference on Computer Vision, pages 2774–2783. LeCun, Y., Bottou, L., Bengio, Y., and Haffner, P. (1998).",./refs/download/2/Representation learning: A review and new perspectives.pdf,Representation learning: A review and new perspectives
0,,,,,,,,"Lee, D. D. and Seung, H. S. (2001).",./refs/download/2/Representation learning: A review and new perspectives.pdf,Representation learning: A review and new perspectives
0,,,,,,,,"Lee, H., Grosse, R., Ranganath, R., and Ng, A. Y. (2009). Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations. In International Conference on Machine Learning, pages 609–616. Lee, K., Xu, W., Fan, F., and Tu, Z. (2018).",./refs/download/2/Representation learning: A review and new perspectives.pdf,Representation learning: A review and new perspectives
0,,,,,,,,"Li, K.-C. (1991). Sliced inverse regression for dimension reduction. Journal of the American Statistical Association, 86(414):316–327. Liu, Z., Luo, P., Wang, X., and Tang, X. (2015).",./refs/download/2/Representation learning: A review and new perspectives.pdf,Representation learning: A review and new perspectives
0,,,,,,,,"Lu, Y., Zhu, S.-C., and Wu, Y. N. (2016). Learning FRAME models using CNN filters. In The AAAI Conference on Artificial Intelligence. Maaten, L. v. d. and Hinton, G. (2008).",./refs/download/2/Representation learning: A review and new perspectives.pdf,Representation learning: A review and new perspectives
0,,,,,,,,"Mikolov, T., Chen, K., Corrado, G., and Dean, J. (2013). Efficient estimation of word representations in vector space. ICLR workshop. 28 Mirza, M. and Osindero, S. (2014).",./refs/download/2/Representation learning: A review and new perspectives.pdf,Representation learning: A review and new perspectives
0,,,,,,,,"Mnih, A. and Gregor, K. (2014).",./refs/download/2/Representation learning: A review and new perspectives.pdf,Representation learning: A review and new perspectives
0,,,,,,,,"Neal, R. M. (2011). MCMC using hamiltonian dynamics. Handbook of Markov Chain Monte Carlo, 2. Ngiam, J., Chen, Z., Koh, P. W., and Ng, A. Y. (2011).",./refs/download/2/Representation learning: A review and new perspectives.pdf,Representation learning: A review and new perspectives
0,,,,,,,,"Nijkamp, E., Zhu, S.-C., and Wu, Y. N. (2019). On learning non-convergent short-run MCMC toward energy-based model. arXiv preprint arXiv:1904.09770. O’Keefe, J. (1979).",./refs/download/2/Representation learning: A review and new perspectives.pdf,Representation learning: A review and new perspectives
0,,,,,,,,"Olshausen, B. A. and Field, D. J. (1997).",./refs/download/2/Representation learning: A review and new perspectives.pdf,Representation learning: A review and new perspectives
0,,,,,,,,"Paccanaro, A. and Hinton, G. E. (2001).",./refs/download/2/Representation learning: A review and new perspectives.pdf,Representation learning: A review and new perspectives
0,,,,,,,,"Pennington, J., Socher, R., and Manning, C. (2014). Glove: Global vectors for word representation. In Conference on Empirical Methods in Natural Language Processing, pages 1532–1543. Radford, A., Metz, L., and Chintala, S. (2015).",./refs/download/2/Representation learning: A review and new perspectives.pdf,Representation learning: A review and new perspectives
0,,,,,,,,"Radford, A., Narasimhan, K., Salimans, T., and Sutskever, I. (2018). derstanding by generative pre-training. URL https://s3-us-west-2. assets/researchcovers/languageunsupervised/language understanding paper. pdf. Improving language unamazonaws. com/openai- Reed, S., Akata, Z., Yan, X., Logeswaran, L., Schiele, B., and Lee, H. (2016).",./refs/download/2/Representation learning: A review and new perspectives.pdf,Representation learning: A review and new perspectives
0,,,,,,,,"Rezende, D. J. and Mohamed, S. (2015).",./refs/download/2/Representation learning: A review and new perspectives.pdf,Representation learning: A review and new perspectives
0,,,,,,,,"Rezende, D. J., Mohamed, S., and Wierstra, D. (2014). Stochastic backpropagation and approximate inference in deep generative models. International Conference on Machine Learning. Roweis, S. T. and Saul, L. K. (2000).",./refs/download/2/Representation learning: A review and new perspectives.pdf,Representation learning: A review and new perspectives
0,,,,,,,,"Rubin, D. B. and Thayer, D. T. (1982).",./refs/download/2/Representation learning: A review and new perspectives.pdf,Representation learning: A review and new perspectives
0,,,,,,,,"Salakhutdinov, R. and Hinton, G. E. (2009).",./refs/download/2/Representation learning: A review and new perspectives.pdf,Representation learning: A review and new perspectives
0,,,,,,,,"Sohn, K., Lee, H., and Yan, X. (2015). Learning structured output representation using deep conditional generative models. In Advances in Neural Information Processing Systems, pages 3483–3491. Sutton, R. S. and Barto, A. G. (1998).",./refs/download/2/Representation learning: A review and new perspectives.pdf,Representation learning: A review and new perspectives
0,,,,,,,,"Tibshirani, R. (1996). Regression shrinkage and selection via the lasso. Journal of the Royal Statistical Society. Series B (Methodological), 58(1):267–288. Tu, Z. (2007).",./refs/download/2/Representation learning: A review and new perspectives.pdf,Representation learning: A review and new perspectives
0,,,,,,,,"Tyleček, R. and Šára, R. (2013).",./refs/download/2/Representation learning: A review and new perspectives.pdf,Representation learning: A review and new perspectives
0,,,,,,,,"Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, L., and Polosukhin, I. (2017). Attention is all you need. In Advances in Neural Information Processing Systems, pages 5998–6008. Wang, T.-C., Liu, M.-Y., Zhu, J.-Y., Liu, G., Tao, A., Kautz, J., and Catanzaro, B. (2018).",./refs/download/2/Representation learning: A review and new perspectives.pdf,Representation learning: A review and new perspectives
0,,,,,,,,"Wu, Y. N., Gao, R., Han, T., and Zhu, S.-C. (2019). A tale of three probabilistic families: Discriminative, descriptive and generative models. Quarterly of Applied Mathematics, 77(2):423–465. Xie, J., Gao, R., Zheng, Z., Zhu, S.-C., and Wu, Y. N. (2019a). Learning dynamic generator model by alternating back-propagation through time. In The AAAI Conference on Artificial Intelligence. Xie, J., Lu, Y., Gao, R., and Wu, Y. N. (2018a). Cooperative learning of energy-based model and latent variable model via MCMC teaching. In The AAAI Conference on Artificial Intelligence. Xie, J., Lu, Y., Gao, R., Zhu, S.-C., and Wu, Y. N. (2018b). Cooperative training of descriptor and generator networks. IEEE Transactions on Pattern Analysis and Machine Intelligence. Xie, J., Lu, Y., Zhu, S.-C., and Wu, Y. N. (2016).",./refs/download/2/Representation learning: A review and new perspectives.pdf,Representation learning: A review and new perspectives
0,,,,,,,,"Xie, J., Zheng, Z., Fang, X., Zhu, S.-C., and Wu, Y. N. (2019b). Multimodal conditional learning with fast thinking policy-like model and slow thinking planner-like model. arXiv preprint arXiv:1902.02812. Xie, J., Zheng, Z., Gao, R., Wang, W., Zhu, S.-C., and Wu, Y. N. (2018c). Learning descriptor networks for 3D shape synthesis and analysis. In IEEE Conference on Computer Vision and Pattern Recognition, pages 8629–8638. Xie, J., Zhu, S.-C., and Nian Wu, Y. (2017).",./refs/download/2/Representation learning: A review and new perspectives.pdf,Representation learning: A review and new perspectives
0,,,,,,,,"Xing, X., Han, T., Gao, R., Zhu, S.-C., and Wu, Y. N. (2019). Unsupervised disentangling of appearance and geometry by deformable generator network. In IEEE Conference on Computer Vision and Pattern Recognition, pages 10354– 10363. Yu, F., Seff, A., Zhang, Y., Song, S., Funkhouser, T., and Xiao, J. (2015).",./refs/download/2/Representation learning: A review and new perspectives.pdf,Representation learning: A review and new perspectives
0,,,,,,,,"Zee, A. (2016). Group theory in a nutshell for physicists. Princeton University Press. Ziebart, B. D., Maas, A. L., Bagnell, J. A., and Dey, A. K. (2008).",./refs/download/2/Representation learning: A review and new perspectives.pdf,Representation learning: A review and new perspectives
0,,,,,,,,"References Bao, Y.; Fang, H.; and Zhang, J. 2014.",./refs/download/2/VBPR: visual bayesian personalized ranking from implicit feedback.pdf,VBPR: visual bayesian personalized ranking from implicit feedback
0,,,,,,,,"Bell, R. M.; Koren, Y.; and Volinsky, C. 2007.",./refs/download/2/VBPR: visual bayesian personalized ranking from implicit feedback.pdf,VBPR: visual bayesian personalized ranking from implicit feedback
0,,,,,,,,"Bennett, J., and Lanning, S. 2007.",./refs/download/2/VBPR: visual bayesian personalized ranking from implicit feedback.pdf,VBPR: visual bayesian personalized ranking from implicit feedback
0,,,,,,,,"Brown, P.; Bovey, J.; and Chen, X. 1997.",./refs/download/2/VBPR: visual bayesian personalized ranking from implicit feedback.pdf,VBPR: visual bayesian personalized ranking from implicit feedback
0,,,,,,,,"Das, A.; Datar, M.; Garg, A.; and Rajaram, S. 2007.",./refs/download/2/VBPR: visual bayesian personalized ranking from implicit feedback.pdf,VBPR: visual bayesian personalized ranking from implicit feedback
0,,,,,,,,"Donahue, J.; Jia, Y.; Vinyals, O.; Hoffman, J.; Zhang, N.; Tzeng, E.; and Darrell, T. 2014.",./refs/download/2/VBPR: visual bayesian personalized ranking from implicit feedback.pdf,VBPR: visual bayesian personalized ranking from implicit feedback
0,,,,,,,,"Gantner, Z.; Rendle, S.; Freudenthaler, C.; and SchmidtThieme, L. 2011.",./refs/download/2/VBPR: visual bayesian personalized ranking from implicit feedback.pdf,VBPR: visual bayesian personalized ranking from implicit feedback
0,,,,,,,,"Hu, Y.; Koren, Y.; and Volinsky, C. 2008.",./refs/download/2/VBPR: visual bayesian personalized ranking from implicit feedback.pdf,VBPR: visual bayesian personalized ranking from implicit feedback
0,,,,,,,,"Jagadeesh, V.; Piramuthu, R.; Bhardwaj, A.; Di, W.; and Sundaresan, N. 2014.",./refs/download/2/VBPR: visual bayesian personalized ranking from implicit feedback.pdf,VBPR: visual bayesian personalized ranking from implicit feedback
0,,,,,,,,"Jia, Y.; Shelhamer, E.; Donahue, J.; Karayev, S.; Long, J.; Girshick, R. B.; Guadarrama, S.; and Darrell, T. 2014.",./refs/download/2/VBPR: visual bayesian personalized ranking from implicit feedback.pdf,VBPR: visual bayesian personalized ranking from implicit feedback
0,,,,,,,,"Lu, X.; Lin, Z.; Jin, H.; Yang, J.; and Wang, J. Z. 2014.",./refs/download/2/VBPR: visual bayesian personalized ranking from implicit feedback.pdf,VBPR: visual bayesian personalized ranking from implicit feedback
0,,,,,,,,"Lu, Z.; Dou, Z.; Lian, J.; Xie, X.; and Yang, Q. 2015.",./refs/download/2/VBPR: visual bayesian personalized ranking from implicit feedback.pdf,VBPR: visual bayesian personalized ranking from implicit feedback
0,,,,,,,,"McAuley, J. J.; Targett, C.; Shi, Q.; and van den Hengel, A. 2015.",./refs/download/2/VBPR: visual bayesian personalized ranking from implicit feedback.pdf,VBPR: visual bayesian personalized ranking from implicit feedback
0,,,,,,,,"Pan, W., and Chen, L. 2013.",./refs/download/2/VBPR: visual bayesian personalized ranking from implicit feedback.pdf,VBPR: visual bayesian personalized ranking from implicit feedback
0,,,,,,,,"Pan, R.; Zhou, Y.; Cao, B.; Liu, N. N.; Lukose, R.; Scholz, M.; and Yang, Q. 2008.",./refs/download/2/VBPR: visual bayesian personalized ranking from implicit feedback.pdf,VBPR: visual bayesian personalized ranking from implicit feedback
0,,,,,,,,"Qiao, Z.; Zhang, P.; Cao, Y.; Zhou, C.; Guo, L.; and Fang, B. 2014.",./refs/download/2/VBPR: visual bayesian personalized ranking from implicit feedback.pdf,VBPR: visual bayesian personalized ranking from implicit feedback
0,,,,,,,,"Razavian, A. S.; Azizpour, H.; Sullivan, J.; and Carlsson, S. 2014.",./refs/download/2/VBPR: visual bayesian personalized ranking from implicit feedback.pdf,VBPR: visual bayesian personalized ranking from implicit feedback
0,,,,,,,,"Rendle, S.; Freudenthaler, C.; Gantner, Z.; and SchmidtThieme, L. 2009.",./refs/download/2/VBPR: visual bayesian personalized ranking from implicit feedback.pdf,VBPR: visual bayesian personalized ranking from implicit feedback
0,,,,,,,,"Russakovsky, O.; Deng, J.; Su, H.; Krause, J.; Satheesh, S.; Ma, S.; Huang, Z.; Karpathy, A.; Khosla, A.; Bernstein, M. S.; Berg, A. C.; and Fei-Fei, L. 2014.",./refs/download/2/VBPR: visual bayesian personalized ranking from implicit feedback.pdf,VBPR: visual bayesian personalized ranking from implicit feedback
0,,,,,,,,"Schein, A.; Popescul, A.; Ungar, L.; and Pennock, D. 2002.",./refs/download/2/VBPR: visual bayesian personalized ranking from implicit feedback.pdf,VBPR: visual bayesian personalized ranking from implicit feedback
0,,,,,,,,"Kalantidis, Y.; Kennedy, L.; and Li, L.-J. 2013.",./refs/download/2/VBPR: visual bayesian personalized ranking from implicit feedback.pdf,VBPR: visual bayesian personalized ranking from implicit feedback
0,,,,,,,,"Simo-Serra, E.; Fidler, S.; Moreno-Noguer, F.; and Urtasun, R. 2014.",./refs/download/2/VBPR: visual bayesian personalized ranking from implicit feedback.pdf,VBPR: visual bayesian personalized ranking from implicit feedback
0,,,,,,,,"Kanagal, B.; Ahmed, A.; Pandey, S.; Josifovski, V.; Yuan, J.; and Garcia-Pueyo, L. 2012.",./refs/download/2/VBPR: visual bayesian personalized ranking from implicit feedback.pdf,VBPR: visual bayesian personalized ranking from implicit feedback
0,,,,,,,,"Xu, G.; Gu, Y.; Dolog, P.; Zhang, Y.; and Kitsuregawa, M. 2011.",./refs/download/2/VBPR: visual bayesian personalized ranking from implicit feedback.pdf,VBPR: visual bayesian personalized ranking from implicit feedback
0,,,,,,,,"Karayev, S.; Trentacoste, M.; Han, H.; Agarwala, A.; Darrell, T.; Hertzmann, A.; and Winnemoeller, H. 2014.",./refs/download/2/VBPR: visual bayesian personalized ranking from implicit feedback.pdf,VBPR: visual bayesian personalized ranking from implicit feedback
0,,,,,,,,"Koenigstein, N.; Dror, G.; and Koren, Y. 2011.",./refs/download/2/VBPR: visual bayesian personalized ranking from implicit feedback.pdf,VBPR: visual bayesian personalized ranking from implicit feedback
0,,,,,,,,"Koren, Y., and Bell, R. 2011.",./refs/download/2/VBPR: visual bayesian personalized ranking from implicit feedback.pdf,VBPR: visual bayesian personalized ranking from implicit feedback
0,,,,,,,,"Krizhevsky, A.; Sutskever, I.; and Hinton, G. E. 2012.",./refs/download/2/VBPR: visual bayesian personalized ranking from implicit feedback.pdf,VBPR: visual bayesian personalized ranking from implicit feedback
0,,,,,,,,"Krohn-Grimberghe, A.; Drumond, L.; Freudenthaler, C.; and Schmidt-Thieme, L. 2012.",./refs/download/2/VBPR: visual bayesian personalized ranking from implicit feedback.pdf,VBPR: visual bayesian personalized ranking from implicit feedback
0,,,,,,,,"Yi, X.; Hong, L.; Zhong, E.; Liu, N. N.; and Rajan, S. 2014.",./refs/download/2/VBPR: visual bayesian personalized ranking from implicit feedback.pdf,VBPR: visual bayesian personalized ranking from implicit feedback
0,,,,,,,,"Zhao, T.; McAuley, J.; and King, I. 2014.",./refs/download/2/VBPR: visual bayesian personalized ranking from implicit feedback.pdf,VBPR: visual bayesian personalized ranking from implicit feedback
0,,,,,,,,"Zhou, T. C.; Ma, H.; Lyu, M. R.; and King, I. 2010.",./refs/download/2/VBPR: visual bayesian personalized ranking from implicit feedback.pdf,VBPR: visual bayesian personalized ranking from implicit feedback
0,,,,,,,,"Zhu, J.; Ma, H.; Chen, C.; and Bu, J. 2011.",./refs/download/2/VBPR: visual bayesian personalized ranking from implicit feedback.pdf,VBPR: visual bayesian personalized ranking from implicit feedback
0,M. Abadi,A, Agarwal,,,2015,,"M. Abadi, A. Agarwal, P. Barham, E. Brevdo, Z. Chen, C. Citro, G. S. Corrado, A. Davis, J. Dean, M. Devin, et al. Tensorflow: Large-scale machine learning on heterogeneous systems, 2015.",./refs/download/2/Mobilenets: Efficient convolutional neural networks for mobile vision applications.pdf,Mobilenets: Efficient convolutional neural networks for mobile vision applications
0,"W. Chen, J. T. Wilson, S. Tyree, K. Q. Weinberger, Y. Chen",Compressing neural networks with the hashing trick, CoRR,,,1504,,"W. Chen, J. T. Wilson, S. Tyree, K. Q. Weinberger, and Y. Chen. Compressing neural networks with the hashing trick. CoRR, abs/1504.",./refs/download/2/Mobilenets: Efficient convolutional neural networks for mobile vision applications.pdf,Mobilenets: Efficient convolutional neural networks for mobile vision applications
0,F. Chollet,Xception: Deep learning with depthwise separable convolutions, arXiv preprint arXiv:1610,.02357v2,,2016,,"F. Chollet. Xception: Deep learning with depthwise separable convolutions. arXiv preprint arXiv:1610.02357v2, 2016.",./refs/download/2/Mobilenets: Efficient convolutional neural networks for mobile vision applications.pdf,Mobilenets: Efficient convolutional neural networks for mobile vision applications
0,"M. Courbariaux, J.-P. David, Y. Bengio",Training deep neural networks with low precision multiplications, arXiv preprint arXiv:,,,1412,,"M. Courbariaux, J.-P. David, and Y. Bengio. Training deep neural networks with low precision multiplications. arXiv preprint arXiv:1412.",./refs/download/2/Mobilenets: Efficient convolutional neural networks for mobile vision applications.pdf,Mobilenets: Efficient convolutional neural networks for mobile vision applications
0,"S. Han, H. Mao, W. J. Dally",Deep compression: Compressing deep neural network with pruning, trained quantization and huffman coding,. CoRR,,1510,,"S. Han, H. Mao, and W. J. Dally. Deep compression: Compressing deep neural network with pruning, trained quantization and huffman coding. CoRR, abs/1510.",./refs/download/2/Mobilenets: Efficient convolutional neural networks for mobile vision applications.pdf,Mobilenets: Efficient convolutional neural networks for mobile vision applications
0,"J. Hays and , A. Efros",IM2GPS: estimating geographic information from a single image, In Proceedings of the IEEE International Conference on Computer Vision and Pattern Recognition,,,2008,,"J. Hays and A. Efros. IM2GPS: estimating geographic information from a single image. In Proceedings of the IEEE International Conference on Computer Vision and Pattern Recognition, 2008.",./refs/download/2/Mobilenets: Efficient convolutional neural networks for mobile vision applications.pdf,Mobilenets: Efficient convolutional neural networks for mobile vision applications
0,"J. Hays and , A. Efros",Large-Scale Image Geolocalization, In J,. Choi and G. Friedland,,2014,,"J. Hays and A. Efros. Large-Scale Image Geolocalization. In J. Choi and G. Friedland, editors, Multimodal Location Estimation of Videos and Images. Springer, 2014.",./refs/download/2/Mobilenets: Efficient convolutional neural networks for mobile vision applications.pdf,Mobilenets: Efficient convolutional neural networks for mobile vision applications
0,"K. He, X. Zhang, S. Ren, J. Sun",Deep residual learning for image recognition, arXiv preprint arXiv:,,,1512,,"K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. arXiv preprint arXiv:1512.",./refs/download/2/Mobilenets: Efficient convolutional neural networks for mobile vision applications.pdf,Mobilenets: Efficient convolutional neural networks for mobile vision applications
0,"G. Hinton, O. Vinyals, J. Dean",Distilling the knowledge in a neural network, arXiv preprint arXiv:,,,1503,,"G. Hinton, O. Vinyals, and J. Dean. Distilling the knowledge in a neural network. arXiv preprint arXiv:1503.",./refs/download/2/Mobilenets: Efficient convolutional neural networks for mobile vision applications.pdf,Mobilenets: Efficient convolutional neural networks for mobile vision applications
0,J. Huang,V, Rathod,,,1611,,"J. Huang, V. Rathod, C. Sun, M. Zhu, A. Korattikara, A. Fathi, I. Fischer, Z. Wojna, Y. Song, S. Guadarrama, et al. Speed/accuracy trade-offs for modern convolutional object detectors. arXiv preprint arXiv:1611.",./refs/download/2/Mobilenets: Efficient convolutional neural networks for mobile vision applications.pdf,Mobilenets: Efficient convolutional neural networks for mobile vision applications
0,"I. Hubara, M. Courbariaux, D. Soudry, R. El-Yaniv, Y. Bengio",Quantized neural networks: Training neural networks with low precision weights and activations, arXiv preprint arXiv:,,,1609,,"I. Hubara, M. Courbariaux, D. Soudry, R. El-Yaniv, and Y. Bengio. Quantized neural networks: Training neural networks with low precision weights and activations. arXiv preprint arXiv:1609.",./refs/download/2/Mobilenets: Efficient convolutional neural networks for mobile vision applications.pdf,Mobilenets: Efficient convolutional neural networks for mobile vision applications
0,"F. N. Iandola, M. W. Moskewicz, K. Ashraf, S. Han, W. J. Dally, K. Keutzer",Squeezenet: Alexnet-level accuracy with 50x fewer parameters and¡ 1mb model size, arXiv preprint arXiv:,,,1602,,"F. N. Iandola, M. W. Moskewicz, K. Ashraf, S. Han, W. J. Dally, and K. Keutzer. Squeezenet: Alexnet-level accuracy with 50x fewer parameters and¡ 1mb model size. arXiv preprint arXiv:1602.",./refs/download/2/Mobilenets: Efficient convolutional neural networks for mobile vision applications.pdf,Mobilenets: Efficient convolutional neural networks for mobile vision applications
0,"S. Ioffe and , C. Szegedy",Batch normalization: Accelerating deep network training by reducing internal covariate shift, arXiv preprint arXiv:1502,.03167,,2015,,"S. Ioffe and C. Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. arXiv preprint arXiv:1502.03167, 2015.",./refs/download/2/Mobilenets: Efficient convolutional neural networks for mobile vision applications.pdf,Mobilenets: Efficient convolutional neural networks for mobile vision applications
0,"M. Jaderberg, A. Vedaldi, A. Zisserman",Speeding up convolutional neural networks with low rank expansions, arXiv preprint arXiv:,,,1405,,"M. Jaderberg, A. Vedaldi, and A. Zisserman. Speeding up convolutional neural networks with low rank expansions. arXiv preprint arXiv:1405.",./refs/download/2/Mobilenets: Efficient convolutional neural networks for mobile vision applications.pdf,Mobilenets: Efficient convolutional neural networks for mobile vision applications
0,"Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Girshick, S. Guadarrama, T. Darrell",Caffe: Convolutional architecture for fast feature embedding, arXiv preprint arXiv:,,,1408,,"Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Girshick, S. Guadarrama, and T. Darrell. Caffe: Convolutional architecture for fast feature embedding. arXiv preprint arXiv:1408.",./refs/download/2/Mobilenets: Efficient convolutional neural networks for mobile vision applications.pdf,Mobilenets: Efficient convolutional neural networks for mobile vision applications
0,"J. Jin, A. Dundar, E. Culurciello",Flattened convolutional neural networks for feedforward acceleration, arXiv preprint arXiv:,,,1412,,"J. Jin, A. Dundar, and E. Culurciello. Flattened convolutional neural networks for feedforward acceleration. arXiv preprint arXiv:1412.",./refs/download/2/Mobilenets: Efficient convolutional neural networks for mobile vision applications.pdf,Mobilenets: Efficient convolutional neural networks for mobile vision applications
0,"A. Khosla, N. Jayadevaprakash, B. Yao, L. Fei-Fei",Novel dataset for fine-grained image categorization, In First Workshop on Fine-Grained Visual Categorization,,,2011,,"A. Khosla, N. Jayadevaprakash, B. Yao, and L. Fei-Fei. Novel dataset for fine-grained image categorization. In First Workshop on Fine-Grained Visual Categorization, IEEE Conference on Computer Vision and Pattern Recognition, Colorado Springs, CO, June 2011.",./refs/download/2/Mobilenets: Efficient convolutional neural networks for mobile vision applications.pdf,Mobilenets: Efficient convolutional neural networks for mobile vision applications
0,"J. Krause, B. Sapp, A. Howard, H. Zhou, A. Toshev, T. Duerig, J. Philbin, L. Fei-Fei",The unreasonable effectiveness of noisy data for fine-grained recognition, arXiv preprint arXiv:,,,1511,,"J. Krause, B. Sapp, A. Howard, H. Zhou, A. Toshev, T. Duerig, J. Philbin, and L. Fei-Fei. The unreasonable effectiveness of noisy data for fine-grained recognition. arXiv preprint arXiv:1511.",./refs/download/2/Mobilenets: Efficient convolutional neural networks for mobile vision applications.pdf,Mobilenets: Efficient convolutional neural networks for mobile vision applications
0,"A. Krizhevsky, I. Sutskever, G. E. Hinton",Imagenet classification with deep convolutional neural networks, In Advances in neural information processing systems,,,2012,,"A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classification with deep convolutional neural networks. In Advances in neural information processing systems, pages 1097–1105, 2012.",./refs/download/2/Mobilenets: Efficient convolutional neural networks for mobile vision applications.pdf,Mobilenets: Efficient convolutional neural networks for mobile vision applications
0,"V. Lebedev, Y. Ganin, M. Rakhuba, I. Oseledets, V. Lempitsky",Speeding-up convolutional neural networks using fine-tuned cp-decomposition, arXiv preprint arXiv:,,,1412,,"V. Lebedev, Y. Ganin, M. Rakhuba, I. Oseledets, and V. Lempitsky. Speeding-up convolutional neural networks using fine-tuned cp-decomposition. arXiv preprint arXiv:1412.",./refs/download/2/Mobilenets: Efficient convolutional neural networks for mobile vision applications.pdf,Mobilenets: Efficient convolutional neural networks for mobile vision applications
0,"W. Liu, D. Anguelov, D. Erhan, C. Szegedy, S. Reed",Ssd: Single shot multibox detector, arXiv preprint arXiv:,,,1512,,"W. Liu, D. Anguelov, D. Erhan, C. Szegedy, and S. Reed. Ssd: Single shot multibox detector. arXiv preprint arXiv:1512.",./refs/download/2/Mobilenets: Efficient convolutional neural networks for mobile vision applications.pdf,Mobilenets: Efficient convolutional neural networks for mobile vision applications
0,"M. Rastegari, V. Ordonez, J. Redmon, A. Farhadi",Xnornet: Imagenet classification using binary convolutional neural networks, arXiv preprint arXiv:,,,1603,,"M. Rastegari, V. Ordonez, J. Redmon, and A. Farhadi. Xnornet: Imagenet classification using binary convolutional neural networks. arXiv preprint arXiv:1603.",./refs/download/2/Mobilenets: Efficient convolutional neural networks for mobile vision applications.pdf,Mobilenets: Efficient convolutional neural networks for mobile vision applications
0,"S. Ren, K. He, R. Girshick, J. Sun",Faster r-cnn: Towards real-time object detection with region proposal networks, In Advances in neural information processing systems,,,2015,,"S. Ren, K. He, R. Girshick, and J. Sun. Faster r-cnn: Towards real-time object detection with region proposal networks. In Advances in neural information processing systems, pages 91–99, 2015.",./refs/download/2/Mobilenets: Efficient convolutional neural networks for mobile vision applications.pdf,Mobilenets: Efficient convolutional neural networks for mobile vision applications
0,O. Russakovsky,J, Deng,,,2015,,"O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, et al. Imagenet large scale visual recognition challenge. International Journal of Computer Vision, 115(3):211–252, 2015.",./refs/download/2/Mobilenets: Efficient convolutional neural networks for mobile vision applications.pdf,Mobilenets: Efficient convolutional neural networks for mobile vision applications
0,"F. Schroff, D. Kalenichenko, J. Philbin",Facenet: A unified embedding for face recognition and clustering, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,,,2015,,"F. Schroff, D. Kalenichenko, and J. Philbin. Facenet: A unified embedding for face recognition and clustering. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 815–823, 2015.",./refs/download/2/Mobilenets: Efficient convolutional neural networks for mobile vision applications.pdf,Mobilenets: Efficient convolutional neural networks for mobile vision applications
0,L. Sifre,Rigid-motion scattering for image classification, PhD thesis,,,2014,,"L. Sifre. Rigid-motion scattering for image classification. PhD thesis, Ph. D. thesis, 2014.",./refs/download/2/Mobilenets: Efficient convolutional neural networks for mobile vision applications.pdf,Mobilenets: Efficient convolutional neural networks for mobile vision applications
0,"K. Simonyan and , A. Zisserman",Very deep convolutional networks for large-scale image recognition, arXiv preprint arXiv:1409,.1556,,2014,,"K. Simonyan and A. Zisserman. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556, 2014.",./refs/download/2/Mobilenets: Efficient convolutional neural networks for mobile vision applications.pdf,Mobilenets: Efficient convolutional neural networks for mobile vision applications
0,"V. Sindhwani, T. Sainath, S. Kumar",Structured transforms for small-footprint deep learning, In Advances in Neural Information Processing Systems,,,2015,,"V. Sindhwani, T. Sainath, and S. Kumar. Structured transforms for small-footprint deep learning. In Advances in Neural Information Processing Systems, pages 3088–3096, 2015.",./refs/download/2/Mobilenets: Efficient convolutional neural networks for mobile vision applications.pdf,Mobilenets: Efficient convolutional neural networks for mobile vision applications
0,"C. Szegedy, S. Ioffe, V. Vanhoucke",Inception-v4, inception-resnet and the impact of residual connections on learning,,,1602,,"C. Szegedy, S. Ioffe, and V. Vanhoucke. Inception-v4, inception-resnet and the impact of residual connections on learning. arXiv preprint arXiv:1602.",./refs/download/2/Mobilenets: Efficient convolutional neural networks for mobile vision applications.pdf,Mobilenets: Efficient convolutional neural networks for mobile vision applications
0,"C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, A. Rabinovich",Going deeper with convolutions, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,,,2015,,"C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, and A. Rabinovich. Going deeper with convolutions. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1–9, 2015.",./refs/download/2/Mobilenets: Efficient convolutional neural networks for mobile vision applications.pdf,Mobilenets: Efficient convolutional neural networks for mobile vision applications
0,"C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, Z. Wojna",Rethinking the inception architecture for computer vision, arXiv preprint arXiv:,,,1512,,"C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, and Z. Wojna. Rethinking the inception architecture for computer vision. arXiv preprint arXiv:1512.",./refs/download/2/Mobilenets: Efficient convolutional neural networks for mobile vision applications.pdf,Mobilenets: Efficient convolutional neural networks for mobile vision applications
0,"B. Thomee, D. A. Shamma, G. Friedland, B. Elizalde, K. Ni, D. Poland, D. Borth, L.-J. Li",Yfcc100m: The new data in multimedia research, Communications of the ACM,,,2016,59,"B. Thomee, D. A. Shamma, G. Friedland, B. Elizalde, K. Ni, D. Poland, D. Borth, and L.-J. Li. Yfcc100m: The new data in multimedia research. Communications of the ACM, 59(2):64–73, 2016.",./refs/download/2/Mobilenets: Efficient convolutional neural networks for mobile vision applications.pdf,Mobilenets: Efficient convolutional neural networks for mobile vision applications
0,"T. Tieleman and , G. Hinton",Lecture 6,5-rmsprop: Divide the gradient by a running average of its recent magnitude,. COURSERA: Neural Networks for Machine Learning,,2012,,"T. Tieleman and G. Hinton. Lecture 6.5-rmsprop: Divide the gradient by a running average of its recent magnitude. COURSERA: Neural Networks for Machine Learning, 4(2), 2012.",./refs/download/2/Mobilenets: Efficient convolutional neural networks for mobile vision applications.pdf,Mobilenets: Efficient convolutional neural networks for mobile vision applications
0,"M. Wang, B. Liu, H. Foroosh",Factorized convolutional neural networks, arXiv preprint arXiv:,,,1608,,"M. Wang, B. Liu, and H. Foroosh. Factorized convolutional neural networks. arXiv preprint arXiv:1608.",./refs/download/2/Mobilenets: Efficient convolutional neural networks for mobile vision applications.pdf,Mobilenets: Efficient convolutional neural networks for mobile vision applications
0,"T. Weyand, I. Kostrikov, J. Philbin",PlaNet -Photo Geolocation with Convolutional Neural Networks, In European Conference on Computer Vision (ECCV),,,2016,,"T. Weyand, I. Kostrikov, and J. Philbin. PlaNet - Photo Geolocation with Convolutional Neural Networks. In European Conference on Computer Vision (ECCV), 2016.",./refs/download/2/Mobilenets: Efficient convolutional neural networks for mobile vision applications.pdf,Mobilenets: Efficient convolutional neural networks for mobile vision applications
0,"J. Wu, C. Leng, Y. Wang, Q. Hu, J. Cheng",Quantized convolutional neural networks for mobile devices, arXiv preprint arXiv:,,,1512,,"J. Wu, C. Leng, Y. Wang, Q. Hu, and J. Cheng. Quantized convolutional neural networks for mobile devices. arXiv preprint arXiv:1512.",./refs/download/2/Mobilenets: Efficient convolutional neural networks for mobile vision applications.pdf,Mobilenets: Efficient convolutional neural networks for mobile vision applications
0,"Z. Yang, M. Moczulski, M. Denil, N. de Freitas, A. Smola, L. Song, Z. Wang",Deep fried convnets, In Proceedings of the IEEE International Conference on Computer Vision,,,2015,,"Z. Yang, M. Moczulski, M. Denil, N. de Freitas, A. Smola, L. Song, and Z. Wang. Deep fried convnets. In Proceedings of the IEEE International Conference on Computer Vision, pages 1476–1483, 2015.",./refs/download/2/Mobilenets: Efficient convolutional neural networks for mobile vision applications.pdf,Mobilenets: Efficient convolutional neural networks for mobile vision applications
0,,,,,,,, J. Song and ,./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,, A. Andoni and ,./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,, A. Andoni and ,./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," A. Andoni, P. Indyk, H. L. Nguyen, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," V. Athitsos, M. Potamias, P. Papapetrou, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,, A. Babenko and ,./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,, S. Baluja and ,./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,, S. Baluja and ,./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,, S. Baluja and ,./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," M. Bawa, T. Condie, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," A. Z. Broder, S. C. Glassman, M. S. Manasse, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," A. Cherian, V. Morellas, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,, F. Chierichetti and ,./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," O. Chum, J. Philbin, M. Isard, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," O. Chum, J. Philbin, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," A. Dasgupta, R. Kumar, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," M. Datar, N. Immorlica, P. Indyk, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," W. Dong, Z. Wang, W. Josephson, M. Charikar, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,, C. Du and ,./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,, K. Eshghi and ,./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," J. Gan, J. Feng, Q. Fang, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," T. Ge, K. He, Q. Ke, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," A. Gionis, P. Indyk, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," Y. Gong, S. Kumar, H. A. Rowley, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," Y. Gong, S. Kumar, V. Verma, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,, Y. Gong and ,./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," Y. Gong, S. Lazebnik, A. Gordo, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," A. Gordo, F. Perronnin, Y. Gong, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," D. Gorisse, M. Cord, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,, R. M. Gray and ,./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," R. Radhakrishnan, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," J. He, S. Kumar, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," J. He, W. Liu, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," Z. Lin, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," Q. Yang, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," Y. Hwang, B. Han, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,, P. Indyk and ,./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," M. Jain, H. Jégou, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," P. Jain, B. Kulis, I. S. Dhillon, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," P. Jain, B. Kulis, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," P. Jain, S. Vijayanarasimhan, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," H. Jégou, L. Amsaleg, C. Schmid, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," H. Jégou, M. Douze, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," H. Jégou, T. Furon, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," J. Ji, J. Li, S. Yan, Q. Tian, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," J. Ji, J. Li, S. Yan, B. Zhang, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," J. Wang, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," J. Wang, X. Xue, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," Z. Jin, Y. Hu, Y. Lin, D. Zhang, S. Lin, D. Cai, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,, A. Joly and ,./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,, A. Joly and ,./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,, Y. Kalantidis and ,./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,, W. Kong and ,./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,, W. Kong and ,./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," N. Koudas, B. C. Ooi, H. T. Shen, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,, B. Kulis and ,./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,, B. Kulis and ,./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,, B. Kulis and ,./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," B. Kulis, P. Jain, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,, P. Li and ,./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," P. Li, K. W. Church, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," P. Li, T. Hastie, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,, P. Li and ,./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," P. Li, A. C. König, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," P. Li, M. Mitzenmacher, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," P. Li, A. B. Owen, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," P. Li, M. Wang, J. Cheng, C. Xu, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," X. Li, G. Lin, C. Shen, A. van den Hengel, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," G. Lin, C. Shen, Q. Shi, A. van den Hengel, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," G. Lin, C. Shen, D. Suter, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," D. A. Ross, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," Y. Lin, D. Cai, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," Y. Lin, R. Jin, D. Cai, S. Yan, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," W. Liu, J. Wang, S. Kumar, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," W. Liu, J. Wang, Y. Mu, S. Kumar, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," X. Liu, J. He, C. Deng, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," X. Liu, J. He, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," X. Liu, J. He, B. Lang, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," Y. Liu, J. Cui, Z. Huang, H. Li, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," Y. Liu, J. Shao, J. Xiao, F. Wu, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," Y. Liu, F. Wu, Y. Yang, Y. Zhuang, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," Q. Lv, W. Josephson, Z. Wang, M. Charikar, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," G. S. Manku, A. Jain, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,, Y. Matsushita and ,./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," R. Motwani, A. Naor, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," Y. Mu, J. Shen, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," Y. Mu, J. Wright, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,, Y. Mu and ,./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,, M. Muja and ,./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,, M. Muja and ,./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,, M. Norouzi and ,./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,, M. Norouzi and ,./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," M. Norouzi, D. J. Fleet, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," M. Norouzi, A. Punjani, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," R. O’Donnell, Y. Wu, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,, J. Pan and ,./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," L. Paulevé, H. Jégou, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,, M. Raginsky and ,./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,, A. Rahimi and ,./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,, R. Salakhutdinov and ,./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,, R. Salakhutdinov and ,./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,, V. Satuluri and ,./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," G. Shakhnarovich, P. A. Viola, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," J. Shao, F. Wu, C. Ouyang, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," F. Shen, C. Shen, Q. Shi, A. van den Hengel, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,, A. Shrivastava and ,./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," M. Slaney, Y. Lifshits, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," J. Song, Y. Yang, Z. Huang, H. T. Shen, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," J. Song, Y. Yang, Y. Yang, Z. Huang, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," C. Strecha, A. M. Bronstein, M. M. Bronstein, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,, K. Terasawa and ,./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," S. Vijayanarasimhan, P. Jain, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," J. Wang, O. Kumar, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," J. Wang, S. Kumar, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," J. Wang, S. Kumar, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," J. Wang, W. Liu, A. X. Sun, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," H. T. Shen, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," J. Wang, J. Wang, N. Yu, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," Q. Wang, D. Zhang, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," S. Wang, Q. Huang, S. Jiang, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," S. Wang, S. Jiang, Q. Huang, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," Y. Weiss, R. Fergus, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," Y. Weiss, A. Torralba, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," C. Wu, J. Zhu, D. Cai, C. Chen, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," H. Xia, P. Wu, S. C. H. Hoi, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," B. Xu, J. Bu, Y. Lin, C. Chen, X. He, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," H. Xu, J. Wang, Z. Li, G. Zeng, S. Li, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," J. Yagnik, D. Strelow, D. A. Ross, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," H. Yang, X. Bai, J. Zhou, P. Ren, Z. Zhang, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," F. Yu, S. Kumar, Y. Gong, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," D. Zhang, J. Wang, D. Cai, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," L. Zhang, Y. Zhang, J. Tang, X. Gu, J. Li, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," L. Zhang, Y. Zhang, D. Zhang, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," T. Zhang, C. Du, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," X. Zhang, L. Zhang, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," H. Jégou, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,, Y. Zhen and ,./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," X. Zhu, Z. Huang, H. Cheng, J. Cui, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," X. Zhu, Z. Huang, H. T. Shen, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,,,,,,,," Y. Zhuang, Y. Liu, F. Wu, Y. Zhang, and ",./refs/download/2/Hashing for similarity search: A survey.pdf,Hashing for similarity search: A survey
0,"R. Hu, W. Li, O. Van Kaick, A. Shamir, H. Zhang, H. Huang",Learning to predict part mobility from a single static snapshot, ACM Transactions on Graphics (TOG),,,2017,36,"R. Hu, W. Li, O. Van Kaick, A. Shamir, H. Zhang, and H. Huang. Learning to predict part mobility from a single static snapshot. ACM Transactions on Graphics (TOG), 36(6):227, 2017.",./refs/download/2/Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding
0,"R. Hu, O. van Kaick, B. Wu, H. Huang, A. Shamir, H. Zhang",Learning how objects function via co-analysis of interactions, ACM Transactions on Graphics (TOG),,,2016,35,"R. Hu, O. van Kaick, B. Wu, H. Huang, A. Shamir, and H. Zhang. Learning how objects function via co-analysis of interactions. ACM Transactions on Graphics (TOG), 35(4):47, 2016.",./refs/download/2/Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding
0,"R. Hu, Z. Yan, J. Zhang, O. van Kaick, A. Shamir, H. Zhang, H. Huang",Predictive and generative neural networks for object functionality, In Computer Graphics Forum (Eurographics State-of-the-art report),,,2018,,"R. Hu, Z. Yan, J. Zhang, O. van Kaick, A. Shamir, H. Zhang, and H. Huang. Predictive and generative neural networks for object functionality. In Computer Graphics Forum (Eurographics State-of-the-art report), volume 37, pages 603– 624, 2018.",./refs/download/2/Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding
0,"J. Huang, H. Su, L. Guibas",Robust watertight manifold surface generation method for shapenet models, arXiv preprint arXiv:,,,1802,,"J. Huang, H. Su, and L. Guibas. Robust watertight manifold surface generation method for shapenet models. arXiv preprint arXiv:1802.",./refs/download/2/Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding
0,"A. Jain, T. Thormählen, T. Ritschel, H.-P. Seidel",Exploring shape variations by 3d-model decomposition and partbased recombination, In Computer Graphics Forum,,,2012,,"A. Jain, T. Thormählen, T. Ritschel, and H.-P. Seidel. Exploring shape variations by 3d-model decomposition and partbased recombination. In Computer Graphics Forum, volume 31, pages 631–640. Wiley Online Library, 2012.",./refs/download/2/Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding
0,"E. Kalogerakis, A. Hertzmann, K. Singh",Learning 3D mesh segmentation and labeling, ACM Transactions on Graphics (TOG),,,2010,29,"E. Kalogerakis, A. Hertzmann, and K. Singh. Learning 3D mesh segmentation and labeling. ACM Transactions on Graphics (TOG), 29(4):102, 2010.",./refs/download/2/Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding
0,"V. G. Kim, S. Chaudhuri, L. Guibas, T. Funkhouser",Shape2pose: Human-centric shape analysis, ACM Transactions on Graphics (TOG),,,2014,33,"V. G. Kim, S. Chaudhuri, L. Guibas, and T. Funkhouser. Shape2pose: Human-centric shape analysis. ACM Transactions on Graphics (TOG), 33(4):120, 2014.",./refs/download/2/Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding
0,"R. Klokov and , V. Lempitsky",Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models, In Computer Vision (ICCV),,,2017,2017,"R. Klokov and V. Lempitsky. Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models. In Computer Vision (ICCV), 2017 IEEE International Conference on, pages 863–872. IEEE, 2017.",./refs/download/2/Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding
0,"E. Kolve, R. Mottaghi, D. Gordon, Y. Zhu, A. Gupta, A. Farhadi",Ai2-thor: An interactive 3d environment for visual ai, arXiv preprint arXiv:,,,1712,,"E. Kolve, R. Mottaghi, D. Gordon, Y. Zhu, A. Gupta, and A. Farhadi. Ai2-thor: An interactive 3d environment for visual ai. arXiv preprint arXiv:1712.",./refs/download/2/Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding
0,"P. Krähenbühl and , V. Koltun",Parameter learning and convergent inference for dense random fields, In International Conference on Machine Learning,,,2013,,"P. Krähenbühl and V. Koltun. Parameter learning and convergent inference for dense random fields. In International Conference on Machine Learning, pages 513–521, 2013.",./refs/download/2/Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding
0,H. W. Kuhn,The hungarian method for the assignment problem, Naval research logistics quarterly,,,1955,,"H. W. Kuhn. The hungarian method for the assignment problem. Naval research logistics quarterly, 2(1-2):83–97, 1955.",./refs/download/2/Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding
0,"T. Le and , Y. Duan",PointGrid: A deep network for 3D shape understanding, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,,,2018,,"T. Le and Y. Duan. PointGrid: A deep network for 3D shape understanding. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 9204– 9214, 2018.",./refs/download/2/Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding
0,"J. Li, B. M. Chen, G. H. Lee",SO-Net: Self-organizing network for point cloud analysis, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,,,2018,,"J. Li, B. M. Chen, and G. H. Lee. SO-Net: Self-organizing network for point cloud analysis. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 9397–9406, 2018.",./refs/download/2/Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding
0,"J. Li, K. Xu, S. Chaudhuri, E. Yumer, H. Zhang, L. Guibas",Grass: Generative recursive autoencoders for shape structures, ACM Transactions on Graphics (TOG),,,2017,36,"J. Li, K. Xu, S. Chaudhuri, E. Yumer, H. Zhang, and L. Guibas. Grass: Generative recursive autoencoders for shape structures. ACM Transactions on Graphics (TOG), 36(4):52, 2017.",./refs/download/2/Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding
0,"Y. Li, R. Bu, M. Sun, B. Chen",PointCNN: Convolution on X -transformed points, Advances in neural information processing systems (NIPS),,,2018,,"Y. Li, R. Bu, M. Sun, and B. Chen. PointCNN: Convolution on X -transformed points. Advances in neural information processing systems (NIPS), 2018.",./refs/download/2/Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding
0,"Z. Liu, W. T. Freeman, J. B. Tenenbaum, J. Wu",Physical primitive decomposition, arXiv preprint arXiv:,,,1809,,"Z. Liu, W. T. Freeman, J. B. Tenenbaum, and J. Wu. Physical primitive decomposition. arXiv preprint arXiv:1809.",./refs/download/2/Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding
0,"M. Attene, S. Katz, M. Mortara, G. Patané, M. Spagnuolo, A. Tal",Mesh segmentation-a comparative study, In Shape Modeling and Applications,,,2006,,"M. Attene, S. Katz, M. Mortara, G. Patané, M. Spagnuolo, and A. Tal. Mesh segmentation-a comparative study. In Shape Modeling and Applications, 2006.",./refs/download/2/Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding
0,"H. Benhabiles, J.-P. Vandeborre, G. Lavoué, M. Daoudi",A framework for the objective evaluation of segmentation algorithms using a ground-truth of human segmented 3Dmodels, In IEEE International Conference on Shape Modeling and Applications (SMI),,,2009,,"H. Benhabiles, J.-P. Vandeborre, G. Lavoué, and M. Daoudi. A framework for the objective evaluation of segmentation algorithms using a ground-truth of human segmented 3Dmodels. In IEEE International Conference on Shape Modeling and Applications (SMI), pages Session–5, 2009.",./refs/download/2/Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding
0,A. X. Chang,T, Funkhouser,,,1512,,"A. X. Chang, T. Funkhouser, L. Guibas, P. Hanrahan, Q. Huang, Z. Li, S. Savarese, M. Savva, S. Song, H. Su, et al. ShapeNet: An information-rich 3D model repository. arXiv preprint arXiv:1512.",./refs/download/2/Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding
0,"A. X. Chang, R. Mago, P. Krishna, M. Savva, C. Fellbaum",Linking WordNet to 3D shapes, In Global WordNet Conference,,,2018,,"A. X. Chang, R. Mago, P. Krishna, M. Savva, and C. Fellbaum. Linking WordNet to 3D shapes. In Global WordNet Conference, 2018.",./refs/download/2/Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding
0,"X. Chen, A. Golovinskiy, T. Funkhouser",A benchmark for 3D mesh segmentation, ACM Transactions on Graphics (Proc,. SIGGRAPH),,2009,,"X. Chen, A. Golovinskiy, and T. Funkhouser. A benchmark for 3D mesh segmentation. ACM Transactions on Graphics (Proc. SIGGRAPH), 2009.",./refs/download/2/Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding
0,"B. Graham, M. Engelcke, L. van der Maaten",3D semantic segmentation with submanifold sparse convolutional networks, Proceedings of the IEEE Computer Vision and Pattern Recognition (CVPR),,,2018,,"B. Graham, M. Engelcke, and L. van der Maaten. 3D semantic segmentation with submanifold sparse convolutional networks. Proceedings of the IEEE Computer Vision and Pattern Recognition (CVPR), pages 18–22, 2018.",./refs/download/2/Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding
0,P. Hermosilla,T, Ritschel,,,1806,,"P. Hermosilla, T. Ritschel, P.-P. Vázquez, À. Vinacua, and T. Ropinski. Monte carlo convolution for learning on non-uniformly sampled point clouds. arXiv preprint arXiv:1806.",./refs/download/2/Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding
0,"D. D. Hoffman and , W. A. Richards",Parts of recognition, Cognition,,,1984,18,"D. D. Hoffman and W. A. Richards. Parts of recognition. Cognition, 18(1-3):65–96, 1984.",./refs/download/2/Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding
0,"R. Hu, L. Fan, L. Liu",Co-segmentation of 3D shapes via subspace clustering, In Computer graphics forum,,,1713,,"R. Hu, L. Fan, and L. Liu. Co-segmentation of 3D shapes via subspace clustering. In Computer graphics forum, volume 31, pages 1703–1713.",./refs/download/2/Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding
0,"C. Yan, D. Misra, A. Bennnett, A. Walsman, Y. Bisk, Y. Artzi",Chalet: Cornell house agent learning environment, arXiv preprint arXiv:,,,1801,,"C. Yan, D. Misra, A. Bennnett, A. Walsman, Y. Bisk, and Y. Artzi. Chalet: Cornell house agent learning environment. arXiv preprint arXiv:1801.",./refs/download/2/Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding
0,"L. Yi, L. Guibas, A. Hertzmann, V. G. Kim, H. Su, E. Yumer",Learning hierarchical shape segmentation and labeling from online repositories, ACM Transactions on Graphics (Proc,. SIGGRAPH Asia),,2017,,"L. Yi, L. Guibas, A. Hertzmann, V. G. Kim, H. Su, and E. Yumer. Learning hierarchical shape segmentation and labeling from online repositories. ACM Transactions on Graphics (Proc. SIGGRAPH Asia), 2017.",./refs/download/2/Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding
0,L. Yi,V, G,. Kim,,2016,,"L. Yi, V. G. Kim, D. Ceylan, I. Shen, M. Yan, H. Su, C. Lu, Q. Huang, A. Sheffer, L. Guibas, et al. A scalable active framework for region annotation in 3D shape collections. ACM Transactions on Graphics (TOG), 35(6):210, 2016.",./refs/download/2/Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding
0,"L. Yi, H. Su, X. Guo, L. J. Guibas",SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR),,,2017,,"L. Yi, H. Su, X. Guo, and L. J. Guibas. SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation. Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 6584–6592, 2017.",./refs/download/2/Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding
0,"Y. Zhu, D. Gordon, E. Kolve, D. Fox, L. Fei-Fei, A. Gupta, R. Mottaghi, A. Farhadi",Visual semantic planning using deep successor representations, arXiv preprint ArXiv:,,,1705,,"Y. Zhu, D. Gordon, E. Kolve, D. Fox, L. Fei-Fei, A. Gupta, R. Mottaghi, and A. Farhadi. Visual semantic planning using deep successor representations. arXiv preprint ArXiv:1705.",./refs/download/2/Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding
0,"M. Ovsjanikov, W. Li, L. Guibas, N. J. Mitra",Exploration of continuous variability in collections of 3d shapes, In ACM Transactions on Graphics (TOG),,,2011,,"M. Ovsjanikov, W. Li, L. Guibas, and N. J. Mitra. Exploration of continuous variability in collections of 3d shapes. In ACM Transactions on Graphics (TOG), volume 30, page 33. ACM, 2011.",./refs/download/2/Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding
0,"X. Puig, K. Ra, M. Boben, J. Li, T. Wang, S. Fidler, A. Torralba",Virtualhome: Simulating household activities via programs, In CVPR,,,2018,,"X. Puig, K. Ra, M. Boben, J. Li, T. Wang, S. Fidler, and A. Torralba. Virtualhome: Simulating household activities via programs. In CVPR, 2018.",./refs/download/2/Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding
0,"C. R. Qi, H. Su, K. Mo, L. J. Guibas",PointNet: Deep learning on point sets for 3D classification and segmentation, In Proc,. Computer Vision and Pattern Recognition (CVPR),,2017,,"C. R. Qi, H. Su, K. Mo, and L. J. Guibas. PointNet: Deep learning on point sets for 3D classification and segmentation. In Proc. Computer Vision and Pattern Recognition (CVPR), IEEE, volume 1, page 4, 2017.",./refs/download/2/Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding
0,"C. R. Qi, L. Yi, H. Su, L. J. Guibas",PointNet++: Deep hierarchical feature learning on point sets in a metric space, In Advances in Neural Information Processing Systems,,,2017,,"C. R. Qi, L. Yi, H. Su, and L. J. Guibas. PointNet++: Deep hierarchical feature learning on point sets in a metric space. In Advances in Neural Information Processing Systems, pages 5099–5108, 2017.",./refs/download/2/Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding
0,"H. Su, V. Jampani, D. Sun, S. Maji, E. Kalogerakis, M.-H. Yang, J. Kautz",SplatNet: Sparse lattice networks for point cloud processing, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,,,2018,,"H. Su, V. Jampani, D. Sun, S. Maji, E. Kalogerakis, M.-H. Yang, and J. Kautz. SplatNet: Sparse lattice networks for point cloud processing. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2530–2539, 2018.",./refs/download/2/Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding
0,"M. Sung, H. Su, R. Yu, L. Guibas",Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions, Advances in neural information processing systems (NIPS),,,2018,,"M. Sung, H. Su, R. Yu, and L. Guibas. Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions. Advances in neural information processing systems (NIPS), 2018.",./refs/download/2/Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding
0,"W. Wang, R. Yu, Q. Huang, U. Neumann",SGPN: Similarity group proposal network for 3D point cloud instance segmentation, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR),,,2018,,"W. Wang, R. Yu, Q. Huang, and U. Neumann. SGPN: Similarity group proposal network for 3D point cloud instance segmentation. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 2569–2578, 2018.",./refs/download/2/Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding
0,"X. Wang, B. Zhou, H. Fang, X. Chen, Q. Zhao, K. Xu",Learning to group and label fine-grained shape components, ACM Transactions on Graphics (SIGGRAPH Asia 2018),,,2018,37,"X. Wang, B. Zhou, H. Fang, X. Chen, Q. Zhao, and K. Xu. Learning to group and label fine-grained shape components. ACM Transactions on Graphics (SIGGRAPH Asia 2018), 37(6), 2018.",./refs/download/2/Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding
0,"Y. Wang, S. Asafi, O. Van Kaick, H. Zhang, D. Cohen-Or, B. Chen",Active co-analysis of a set of shapes, ACM Transactions on Graphics (TOG),,,2012,31,"Y. Wang, S. Asafi, O. Van Kaick, H. Zhang, D. Cohen-Or, and B. Chen. Active co-analysis of a set of shapes. ACM Transactions on Graphics (TOG), 31(6):165, 2012.",./refs/download/2/Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding
0,"Y. Wang, Y. Sun, Z. Liu, S. E. Sarma, M. M. Bronstein, J. M. Solomon",Dynamic graph cnn for learning on point clouds, arXiv preprint arXiv:,,,1801,,"Y. Wang, Y. Sun, Z. Liu, S. E. Sarma, M. M. Bronstein, and J. M. Solomon. Dynamic graph cnn for learning on point clouds. arXiv preprint arXiv:1801.",./refs/download/2/Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding
0,"Z. Wang and , F. Lu",VoxSegNet: Volumetric CNNs for semantic part segmentation of 3D shapes, arXiv preprint arXiv:1809,.00226,,2018,,"Z. Wang and F. Lu. VoxSegNet: Volumetric CNNs for semantic part segmentation of 3D shapes. arXiv preprint arXiv:1809.00226, 2018.",./refs/download/2/Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding
0,"Z. Wu, X. Wang, D. Lin, D. Lischinski, D. Cohen-Or, H. Huang",Structure-aware generative network for 3d-shape modeling, arXiv preprint arXiv:,,,1808,,"Z. Wu, X. Wang, D. Lin, D. Lischinski, D. Cohen-Or, and H. Huang. Structure-aware generative network for 3d-shape modeling. arXiv preprint arXiv:1808.",./refs/download/2/Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding
0,"Y. Xu, T. Fan, M. Xu, L. Zeng, Y. Qiao",SpiderCNN: Deep learning on point sets with parameterized convolutional filters, European Conference on Computer Vision (ECCV),,,2018,,"Y. Xu, T. Fan, M. Xu, L. Zeng, and Y. Qiao. SpiderCNN: Deep learning on point sets with parameterized convolutional filters. European Conference on Computer Vision (ECCV), 2018.",./refs/download/2/Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding.pdf,Partnet: A large-scale benchmark for fine grained and hierarchical part-level 3d object understanding
0,"A. Adams, J. Baek, M. A. Davis",Fast high-dimensional filtering using the permutohedral lattice, Computer Graphics Forum,,,2010,29,"A. Adams, J. Baek, and M. A. Davis. Fast high-dimensional filtering using the permutohedral lattice. Computer Graphics Forum, 29(2):753–762, 2010.",./refs/download/2/SplatNet: Sparse lattice networks for point cloud processing.pdf,SplatNet: Sparse lattice networks for point cloud processing
0,"V. Aurich and , J. Weule",Non-linear Gaussian filters performing edge preserving diffusion, In DAGM,,,1995,,"V. Aurich and J. Weule. Non-linear Gaussian filters performing edge preserving diffusion. In DAGM, pages 538–545. Springer, 1995.",./refs/download/2/SplatNet: Sparse lattice networks for point cloud processing.pdf,SplatNet: Sparse lattice networks for point cloud processing
0,"S. Bai, X. Bai, Z. Zhou, Z. Zhang, L. J. Latecki",GIFT: a real-time and scalable 3D shape search engine, In Proc,. CVPR,,2016,,"S. Bai, X. Bai, Z. Zhou, Z. Zhang, and L. J. Latecki. GIFT: a real-time and scalable 3D shape search engine. In Proc. CVPR, 2016.",./refs/download/2/SplatNet: Sparse lattice networks for point cloud processing.pdf,SplatNet: Sparse lattice networks for point cloud processing
0,"D. Boscaini, J. Masci, S. Melzi, M. M. Bronstein, U. Castellani, P. Vandergheynst",Learning class-specific descriptors for deformable shapes using localized spectral convolutional networks, In Proc,. SGP,,2015,,"D. Boscaini, J. Masci, S. Melzi, M. M. Bronstein, U. Castellani, and P. Vandergheynst. Learning class-specific descriptors for deformable shapes using localized spectral convolutional networks. In Proc. SGP, 2015.",./refs/download/2/SplatNet: Sparse lattice networks for point cloud processing.pdf,SplatNet: Sparse lattice networks for point cloud processing
0,"D. Boscaini, J. Masci, E. Rodolà, M. M. Bronstein",Learning shape correspondence with anisotropic convolutional neural networks, In Proc,. NIPS,,2016,,"D. Boscaini, J. Masci, E. Rodolà, and M. M. Bronstein. Learning shape correspondence with anisotropic convolutional neural networks. In Proc. NIPS, 2016.",./refs/download/2/SplatNet: Sparse lattice networks for point cloud processing.pdf,SplatNet: Sparse lattice networks for point cloud processing
0,"A. Brock, T. Lim, J. M. Ritchie, N. Weston",Generative and discriminative voxel modeling with convolutional neural networks, arXiv:,,,1608,,"A. Brock, T. Lim, J. M. Ritchie, and N. Weston. Generative and discriminative voxel modeling with convolutional neural networks. arXiv:1608.",./refs/download/2/SplatNet: Sparse lattice networks for point cloud processing.pdf,SplatNet: Sparse lattice networks for point cloud processing
0,"M. M. Bronstein, J. Bruna, Y. LeCun, A. Szlam, P. Vandergheynst",Geometric deep learning: Going beyond euclidean data, IEEE Signal Processing Magazine,,,2017,34,"M. M. Bronstein, J. Bruna, Y. LeCun, A. Szlam, and P. Vandergheynst. Geometric deep learning: Going beyond euclidean data. IEEE Signal Processing Magazine, 34(4):18– 42, 2017.",./refs/download/2/SplatNet: Sparse lattice networks for point cloud processing.pdf,SplatNet: Sparse lattice networks for point cloud processing
0,"J. Bruna, W. Zaremba, A. Szlam, Y. LeCun",Spectral networks and locally connected networks on graphs, In Proc,. ICLR,,2014,,"J. Bruna, W. Zaremba, A. Szlam, and Y. LeCun. Spectral networks and locally connected networks on graphs. In Proc. ICLR, 2014.",./refs/download/2/SplatNet: Sparse lattice networks for point cloud processing.pdf,SplatNet: Sparse lattice networks for point cloud processing
0,"Z. Cao, Q. Huang, K. Ramani",3D object classification via spherical projections, In Proc,. 3DV,,2017,,"Z. Cao, Q. Huang, and K. Ramani. 3D object classification via spherical projections. In Proc. 3DV, 2017.",./refs/download/2/SplatNet: Sparse lattice networks for point cloud processing.pdf,SplatNet: Sparse lattice networks for point cloud processing
0,"M. Defferrard, X. Bresson, P. Vandergheynst",Convolutional neural networks on graphs with fast localized spectral filtering, arXiv:,,,1606,,"M. Defferrard, X. Bresson, and P. Vandergheynst. Convolutional neural networks on graphs with fast localized spectral filtering. arXiv:1606.",./refs/download/2/SplatNet: Sparse lattice networks for point cloud processing.pdf,SplatNet: Sparse lattice networks for point cloud processing
0,"M. Everingham, S. M. A. Eslami, L. Van Gool, C. K. I. Williams, J. Winn, A. Zisserman",The Pascal Visual Object Classes Challenge: A retrospective, IJCV,,,2015,111,"M. Everingham, S. M. A. Eslami, L. Van Gool, C. K. I. Williams, J. Winn, and A. Zisserman. The Pascal Visual Object Classes Challenge: A retrospective. IJCV, 111(1):98– 136, Jan. 2015.",./refs/download/2/SplatNet: Sparse lattice networks for point cloud processing.pdf,SplatNet: Sparse lattice networks for point cloud processing
0,"D. Ezuz, J. Solomon, V. G. Kim, M. Ben-Chen",GWCNN: A metric alignment layer for deep shape analysis, Computer Graphics Forum,,,2017,36,"D. Ezuz, J. Solomon, V. G. Kim, and M. Ben-Chen. GWCNN: A metric alignment layer for deep shape analysis. Computer Graphics Forum, 36(5), 2017.",./refs/download/2/SplatNet: Sparse lattice networks for point cloud processing.pdf,SplatNet: Sparse lattice networks for point cloud processing
0,"R. Gadde, V. Jampani, R. Marlet, P. Gehler",Efficient 2D and 3D facade segmentation using auto-context, PAMI,,,2017,,"R. Gadde, V. Jampani, R. Marlet, and P. Gehler. Efficient 2D and 3D facade segmentation using auto-context. PAMI, 2017.",./refs/download/2/SplatNet: Sparse lattice networks for point cloud processing.pdf,SplatNet: Sparse lattice networks for point cloud processing
0,"A. Garcia-Garcia, F. Gomez-Donoso, J. G. Rodrı́guez, S. Orts, M. Cazorla, J. A. López",PointNet: A 3D convolutional neural network for real-time object class recognition, In Proc,. IJCNN,,2016,,"A. Garcia-Garcia, F. Gomez-Donoso, J. G. Rodrı́guez, S. Orts, M. Cazorla, and J. A. López. PointNet: A 3D convolutional neural network for real-time object class recognition. In Proc. IJCNN, 2016.",./refs/download/2/SplatNet: Sparse lattice networks for point cloud processing.pdf,SplatNet: Sparse lattice networks for point cloud processing
0,"B. Graham and , L. van der Maaten",Submanifold sparse convolutional networks, arXiv:1706,.01307,,2017,,"B. Graham and L. van der Maaten. Submanifold sparse convolutional networks. arXiv:1706.01307, 2017.",./refs/download/2/SplatNet: Sparse lattice networks for point cloud processing.pdf,SplatNet: Sparse lattice networks for point cloud processing
0,"B. Hariharan, P. Arbeláez, R. Girshick, J. Malik",Hypercolumns for object segmentation and fine-grained localization, In Proc,. CVPR,,2015,,"B. Hariharan, P. Arbeláez, R. Girshick, and J. Malik. Hypercolumns for object segmentation and fine-grained localization. In Proc. CVPR, pages 447–456, 2015.",./refs/download/2/SplatNet: Sparse lattice networks for point cloud processing.pdf,SplatNet: Sparse lattice networks for point cloud processing
0,"V. Hegde and , R. Zadeh",FusionNet: 3D object classification using multiple data representations, arXiv:1607,.05695,,2016,,"V. Hegde and R. Zadeh. FusionNet: 3D object classification using multiple data representations. arXiv:1607.05695, 2016.",./refs/download/2/SplatNet: Sparse lattice networks for point cloud processing.pdf,SplatNet: Sparse lattice networks for point cloud processing
0,"M. Henaff, J. Bruna, Y. LeCun",Deep convolutional networks on graph-structured data, arXiv:,,,1506,,"M. Henaff, J. Bruna, and Y. LeCun. Deep convolutional networks on graph-structured data. arXiv:1506.",./refs/download/2/SplatNet: Sparse lattice networks for point cloud processing.pdf,SplatNet: Sparse lattice networks for point cloud processing
0,"H. Huang, E. Kalegorakis, S. Chaudhuri, D. Ceylan, V. Kim, E. Yumer",Learning local shape descriptors with viewbased convolutional neural networks, ACM Trans,. Graph.,,2018,,"H. Huang, E. Kalegorakis, S. Chaudhuri, D. Ceylan, V. Kim, and E. Yumer. Learning local shape descriptors with viewbased convolutional neural networks. ACM Trans. Graph., 2018.",./refs/download/2/SplatNet: Sparse lattice networks for point cloud processing.pdf,SplatNet: Sparse lattice networks for point cloud processing
0,"V. Jampani, R. Gadde, P. V. Gehler",Video propagation networks, In Proc,. CVPR,,2017,,"V. Jampani, R. Gadde, and P. V. Gehler. Video propagation networks. In Proc. CVPR, 2017.",./refs/download/2/SplatNet: Sparse lattice networks for point cloud processing.pdf,SplatNet: Sparse lattice networks for point cloud processing
0,"V. Jampani, M. Kiefel, P. V. Gehler",Learning sparse high dimensional filters: Image filtering, dense CRFs and bilateral neural networks,. In Proc. CVPR,,2016,,"V. Jampani, M. Kiefel, and P. V. Gehler. Learning sparse high dimensional filters: Image filtering, dense CRFs and bilateral neural networks. In Proc. CVPR, 2016.",./refs/download/2/SplatNet: Sparse lattice networks for point cloud processing.pdf,SplatNet: Sparse lattice networks for point cloud processing
0,"Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Girshick, S. Guadarrama, T. Darrell",Caffe: Convolutional architecture for fast feature embedding, In Proc,. ACM Multimedia,,2014,,"Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Girshick, S. Guadarrama, and T. Darrell. Caffe: Convolutional architecture for fast feature embedding. In Proc. ACM Multimedia, 2014.",./refs/download/2/SplatNet: Sparse lattice networks for point cloud processing.pdf,SplatNet: Sparse lattice networks for point cloud processing
0,"E. Kalogerakis, M. Averkiou, S. Maji, S. Chaudhuri",3D shape segmentation with projective convolutional networks, In Proc,. CVPR,,2017,,"E. Kalogerakis, M. Averkiou, S. Maji, and S. Chaudhuri. 3D shape segmentation with projective convolutional networks. In Proc. CVPR, 2017.",./refs/download/2/SplatNet: Sparse lattice networks for point cloud processing.pdf,SplatNet: Sparse lattice networks for point cloud processing
0,"M. Kiefel, V. Jampani, P. V. Gehler",Permutohedral lattice CNNs, In ICLR workshops,,,2015,,"M. Kiefel, V. Jampani, and P. V. Gehler. Permutohedral lattice CNNs. In ICLR workshops, May 2015.",./refs/download/2/SplatNet: Sparse lattice networks for point cloud processing.pdf,SplatNet: Sparse lattice networks for point cloud processing
0,"D. Kingma and , J. Ba",Adam: A method for stochastic optimization, arXiv:1412,.6980,,2014,,"D. Kingma and J. Ba. Adam: A method for stochastic optimization. arXiv:1412.6980, 2014.",./refs/download/2/SplatNet: Sparse lattice networks for point cloud processing.pdf,SplatNet: Sparse lattice networks for point cloud processing
0,"R. Klokov and , V. Lempitsky",Escape from cells: Deep KdNetworks for the recognition of 3D point cloud models, In Proc,. ICCV,,2017,,"R. Klokov and V. Lempitsky. Escape from cells: Deep KdNetworks for the recognition of 3D point cloud models. In Proc. ICCV, 2017.",./refs/download/2/SplatNet: Sparse lattice networks for point cloud processing.pdf,SplatNet: Sparse lattice networks for point cloud processing
0,"H. Maron, M. Galun, N. Aigerman, M. Trope, N. Dym, E. Yumer, V. G. Kim, Y. Lipman",Convolutional neural networks on surfaces via seamless toric covers, ACM Trans,. Graph.,,2017,36,"H. Maron, M. Galun, N. Aigerman, M. Trope, N. Dym, E. Yumer, V. G. Kim, and Y. Lipman. Convolutional neural networks on surfaces via seamless toric covers. ACM Trans. Graph., 36(4), 2017.",./refs/download/2/SplatNet: Sparse lattice networks for point cloud processing.pdf,SplatNet: Sparse lattice networks for point cloud processing
0,"J. Masci, D. Boscaini, M. Bronstein, P. Vandergheynst",Geodesic convolutional neural networks on Riemannian manifolds, In Proc,. ICCV workshops,,2015,,"J. Masci, D. Boscaini, M. Bronstein, and P. Vandergheynst. Geodesic convolutional neural networks on Riemannian manifolds. In Proc. ICCV workshops, 2015.",./refs/download/2/SplatNet: Sparse lattice networks for point cloud processing.pdf,SplatNet: Sparse lattice networks for point cloud processing
0,"D. Maturana and , S. Scherer",3D convolutional neural networks for landing zone detection from LiDAR, In Proc,. ICRA,,2015,,"D. Maturana and S. Scherer. 3D convolutional neural networks for landing zone detection from LiDAR. In Proc. ICRA, 2015.",./refs/download/2/SplatNet: Sparse lattice networks for point cloud processing.pdf,SplatNet: Sparse lattice networks for point cloud processing
0,"F. Monti, D. Boscaini, J. Masci, E. Rodola, J. Svoboda, M. M. Bronstein",Geometric deep learning on graphs and manifolds using mixture model CNNs, In Proc,. CVPR,,2017,,"F. Monti, D. Boscaini, J. Masci, E. Rodola, J. Svoboda, and M. M. Bronstein. Geometric deep learning on graphs and manifolds using mixture model CNNs. In Proc. CVPR, 2017.",./refs/download/2/SplatNet: Sparse lattice networks for point cloud processing.pdf,SplatNet: Sparse lattice networks for point cloud processing
0,B. T. Phong,Illumination for computer generated pictures, Commun,. ACM,,1975,18,"B. T. Phong. Illumination for computer generated pictures. Commun. ACM, 18(6), 1975.",./refs/download/2/SplatNet: Sparse lattice networks for point cloud processing.pdf,SplatNet: Sparse lattice networks for point cloud processing
0,"C. R. Qi, H. Su, K. Mo, L. J. Guibas",PointNet: Deep learning on point sets for 3D classification and segmentation, In Proc,. CVPR,,2017,,"C. R. Qi, H. Su, K. Mo, and L. J. Guibas. PointNet: Deep learning on point sets for 3D classification and segmentation. In Proc. CVPR, 2017.",./refs/download/2/SplatNet: Sparse lattice networks for point cloud processing.pdf,SplatNet: Sparse lattice networks for point cloud processing
0,"C. R. Qi, H. Su, M. Niener, A. Dai, M. Yan, L. J. Guibas",Volumetric and multi-view CNNs for object classification on 3D data, In Proc,. CVPR,,2016,,"C. R. Qi, H. Su, M. Niener, A. Dai, M. Yan, and L. J. Guibas. Volumetric and multi-view CNNs for object classification on 3D data. In Proc. CVPR, 2016.",./refs/download/2/SplatNet: Sparse lattice networks for point cloud processing.pdf,SplatNet: Sparse lattice networks for point cloud processing
0,"C. R. Qi, L. Yi, H. Su, L. Guibas",PointNet++: Deep hierarchical feature learning on point sets in a metric space, In Proc,. NIPS,,2017,,"C. R. Qi, L. Yi, H. Su, and L. Guibas. PointNet++: Deep hierarchical feature learning on point sets in a metric space. In Proc. NIPS, 2017.",./refs/download/2/SplatNet: Sparse lattice networks for point cloud processing.pdf,SplatNet: Sparse lattice networks for point cloud processing
0,"G. Riegler, A. O. Ulusoy, H. Bischof, A. Geiger",OctNetFusion: Learning depth fusion from data, In Proc,. 3DV,,2017,,"G. Riegler, A. O. Ulusoy, H. Bischof, and A. Geiger. OctNetFusion: Learning depth fusion from data. In Proc. 3DV, 2017.",./refs/download/2/SplatNet: Sparse lattice networks for point cloud processing.pdf,SplatNet: Sparse lattice networks for point cloud processing
0,"G. Riegler, A. O. Ulusoys, A. Geiger",Octnet: Learning deep 3D representations at high resolutions, In Proc,. CVPR,,2017,,"G. Riegler, A. O. Ulusoys, and A. Geiger. Octnet: Learning deep 3D representations at high resolutions. In Proc. CVPR, 2017.",./refs/download/2/SplatNet: Sparse lattice networks for point cloud processing.pdf,SplatNet: Sparse lattice networks for point cloud processing
0,"H. Riemenschneider, A. Bódis-Szomorú, J. Weissenberg, L. Van Gool",Learning where to classify in multi-view semantic segmentation, In Proc,. ECCV,,2014,,"H. Riemenschneider, A. Bódis-Szomorú, J. Weissenberg, and L. Van Gool. Learning where to classify in multi-view semantic segmentation. In Proc. ECCV, 2014.",./refs/download/2/SplatNet: Sparse lattice networks for point cloud processing.pdf,SplatNet: Sparse lattice networks for point cloud processing
0,"N. Sedaghat, M. Zolfaghari, E. Amiri, T. Brox",Orientation-boosted voxel nets for 3D object recognition, In Proc,. BMVC,,2017,,"N. Sedaghat, M. Zolfaghari, E. Amiri, and T. Brox. Orientation-boosted voxel nets for 3D object recognition. In Proc. BMVC, 2017.",./refs/download/2/SplatNet: Sparse lattice networks for point cloud processing.pdf,SplatNet: Sparse lattice networks for point cloud processing
0,"A. Sinha, J. Bai, K. Ramani",Deep learning 3D shape surfaces using geometry images, In Proc,. ECCV,,2016,,"A. Sinha, J. Bai, and K. Ramani. Deep learning 3D shape surfaces using geometry images. In Proc. ECCV, 2016.",./refs/download/2/SplatNet: Sparse lattice networks for point cloud processing.pdf,SplatNet: Sparse lattice networks for point cloud processing
0,"H. Su, S. Maji, E. Kalogerakis, E. G. Learned-Miller",Multi-view convolutional neural networks for 3D shape recognition, In Proc,. ICCV,,2015,,"H. Su, S. Maji, E. Kalogerakis, and E. G. Learned-Miller. Multi-view convolutional neural networks for 3D shape recognition. In Proc. ICCV, 2015.",./refs/download/2/SplatNet: Sparse lattice networks for point cloud processing.pdf,SplatNet: Sparse lattice networks for point cloud processing
0,"M. Tatarchenko, A. Dosovitskiy, T. Brox",Octree generating networks: Efficient convolutional architectures for high-resolution 3D outputs, In Proc,. ICCV,,2017,,"M. Tatarchenko, A. Dosovitskiy, and T. Brox. Octree generating networks: Efficient convolutional architectures for high-resolution 3D outputs. In Proc. ICCV, 2017.",./refs/download/2/SplatNet: Sparse lattice networks for point cloud processing.pdf,SplatNet: Sparse lattice networks for point cloud processing
0,"C. Tomasi and , R. Manduchi",Bilateral filtering for gray and color images, In Proc,. ICCV,,1998,,"C. Tomasi and R. Manduchi. Bilateral filtering for gray and color images. In Proc. ICCV, 1998.",./refs/download/2/SplatNet: Sparse lattice networks for point cloud processing.pdf,SplatNet: Sparse lattice networks for point cloud processing
0,"Z. Wu, S. Song, A. Khosla, F. Yu, L. Zhang, X. Tang, J. Xiao",3D shapenets: A deep representation for volumetric shapes, In Proc,. CVPR,,2015,,"Z. Wu, S. Song, A. Khosla, F. Yu, L. Zhang, X. Tang, and J. Xiao. 3D shapenets: A deep representation for volumetric shapes. In Proc. CVPR, 2015.",./refs/download/2/SplatNet: Sparse lattice networks for point cloud processing.pdf,SplatNet: Sparse lattice networks for point cloud processing
0,L. Yi,V, G,. Kim,,2016,,"L. Yi, V. G. Kim, D. Ceylan, I. Shen, M. Yan, H. Su, A. Lu, Q. Huang, A. Sheffer, L. Guibas, et al. A scalable active framework for region annotation in 3D shape collections. ACM Trans. Graph., 35(6):210, 2016.",./refs/download/2/SplatNet: Sparse lattice networks for point cloud processing.pdf,SplatNet: Sparse lattice networks for point cloud processing
0,"L. Yi, H. Su, X. Guo, L. Guibas",SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation, In Proc,. CVPR,,2017,,"L. Yi, H. Su, X. Guo, and L. Guibas. SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation. In Proc. CVPR, 2017.",./refs/download/2/SplatNet: Sparse lattice networks for point cloud processing.pdf,SplatNet: Sparse lattice networks for point cloud processing
0,"M. Zaheer, S. Kottur, S. Ravanbakhsh, B. Poczos, R. R. Salakhutdinov, A. J. Smola",Deep sets, In Proc,. NIPS,,2017,,"M. Zaheer, S. Kottur, S. Ravanbakhsh, B. Poczos, R. R. Salakhutdinov, and A. J. Smola. Deep sets. In Proc. NIPS, pages 3394–3404, 2017.",./refs/download/2/SplatNet: Sparse lattice networks for point cloud processing.pdf,SplatNet: Sparse lattice networks for point cloud processing
0,,,,,,,,"He, K., Zhang, X., Ren, S., and Sun, J. Delving Deep function. Journal of Statistical Planning and Inference, into Rectifiers: Surpassing Human-Level Performance 90(2):227–244, October 2000.",./refs/download/2/Batch normalization: Accelerating deep network training by reducing internal covariate shift.pdf,Batch normalization: Accelerating deep network training by reducing internal covariate shift
0,,,,,,,,"verfitHyvärinen, A. and Oja, E. Independent component analting. J. Mach. Learn. Res., 15(1):1929–1958, January ysis: Algorithms and applications. Neural Netw., 13 2014.",./refs/download/2/Batch normalization: Accelerating deep network training by reducing internal covariate shift.pdf,Batch normalization: Accelerating deep network training by reducing internal covariate shift
0,"LeCun, Y., Bottou, L., Bengio, Y.",", and Haffner, P",JMLR.org,,,2013,,"LeCun, Y., Bottou, L., Bengio, Y., and Haffner, P. JMLR.org, 2013.",./refs/download/2/Batch normalization: Accelerating deep network training by reducing internal covariate shift.pdf,Batch normalization: Accelerating deep network training by reducing internal covariate shift
0,"AnLeCun, Y., Bottou, L., Orr, G., Muller, K.",Efficient drew,Going deeper with convolutions. CoRR,,,2014,"backprop. In Orr, G. and K., Muller (eds.), Neural Netabs/1409.4842","AnLeCun, Y., Bottou, L., Orr, G., and Muller, K. Efficient drew. Going deeper with convolutions. CoRR, backprop. In Orr, G. and K., Muller (eds.), Neural Netabs/1409.4842, 2014.",./refs/download/2/Batch normalization: Accelerating deep network training by reducing internal covariate shift.pdf,Batch normalization: Accelerating deep network training by reducing internal covariate shift
0,,,,,,,,"In Shawe-Taylor, J., Zemel, tion using divisive normalization. In Proc. Computer R.S., Bartlett, P., Pereira, F.C.N., and Weinberger, K.Q. Vision and Pattern Recognition, pp. 1–8. IEEE Com(eds.), Advances in Neural Information Processing Sysputer Society, Jun 23-28 2008.",./refs/download/2/Batch normalization: Accelerating deep network training by reducing internal covariate shift.pdf,Batch normalization: Accelerating deep network training by reducing internal covariate shift
0,,,,,,,,"Bryan McCann, James Bradbury, Caiming Xiong, and Richard Socher. Learned in translation: Contextualized word vectors. CoRR, abs/1708.00107, 2017.",./refs/download/2/Gpipe: Efficient training of giant neural networks using pipeline parallelism.pdf,Gpipe: Efficient training of giant neural networks using pipeline parallelism
0,"Matthew Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, Luke Zettlemoyer",Deep contextualized word representations,ACL,,,2018,,"Matthew Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and Luke Zettlemoyer. Deep contextualized word representations. In ACL, 2018.",./refs/download/2/Gpipe: Efficient training of giant neural networks using pipeline parallelism.pdf,Gpipe: Efficient training of giant neural networks using pipeline parallelism
0,"Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova",Bert: Pre-training of deep bidirectional transformers for language understanding,arXiv preprint arXiv:1810.04805,,,2018,,"Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805, 2018.",./refs/download/2/Gpipe: Efficient training of giant neural networks using pipeline parallelism.pdf,Gpipe: Efficient training of giant neural networks using pipeline parallelism
0,,,,,,,,"Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language models are unsupervised multitask learners. 2019.",./refs/download/2/Gpipe: Efficient training of giant neural networks using pipeline parallelism.pdf,Gpipe: Efficient training of giant neural networks using pipeline parallelism
0,"Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, Li Fei-Fei",Imagenet: A large-scale hierarchical image database,CVPR. IEEE,,,2009,,"Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In CVPR. IEEE, 2009.",./refs/download/2/Gpipe: Efficient training of giant neural networks using pipeline parallelism.pdf,Gpipe: Efficient training of giant neural networks using pipeline parallelism
0,,,,,,,,"Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, and et al. Going deeper with convolutions. In CVPR, pages 1–9, 2015.",./refs/download/2/Gpipe: Efficient training of giant neural networks using pipeline parallelism.pdf,Gpipe: Efficient training of giant neural networks using pipeline parallelism
0,,,,,,,,"Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, and Zbigniew Wojna. Rethinking the inception architecture for computer vision. In CVPR, pages 2818",./refs/download/2/Gpipe: Efficient training of giant neural networks using pipeline parallelism.pdf,Gpipe: Efficient training of giant neural networks using pipeline parallelism
0,,,,,,,,"Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Identity mappings in deep residual networks. In European conference on computer vision, pages 630–645. Springer, 2016.",./refs/download/2/Gpipe: Efficient training of giant neural networks using pipeline parallelism.pdf,Gpipe: Efficient training of giant neural networks using pipeline parallelism
0,"Saining Xie, Ross Girshick, Piotr Dollár, Zhuowen Tu, Kaiming He",Aggregated residual transformations for deep neural networks,CVPR,,,2017,,"Saining Xie, Ross Girshick, Piotr Dollár, Zhuowen Tu, and Kaiming He. Aggregated residual transformations for deep neural networks. In CVPR, 2017.",./refs/download/2/Gpipe: Efficient training of giant neural networks using pipeline parallelism.pdf,Gpipe: Efficient training of giant neural networks using pipeline parallelism
0,"Jie Hu, Li Shen, Gang Sun",Squeeze-and-excitation networks,CVPR,,,2018,,"Jie Hu, Li Shen, and Gang Sun. Squeeze-and-excitation networks. CVPR, 2018.",./refs/download/2/Gpipe: Efficient training of giant neural networks using pipeline parallelism.pdf,Gpipe: Efficient training of giant neural networks using pipeline parallelism
0,"Barret Zoph, Vijay Vasudevan, Jonathon Shlens, Quoc V Le",Learning transferable architectures for scalable image recognition,CVPR,,,2018,,"Barret Zoph, Vijay Vasudevan, Jonathon Shlens, and Quoc V Le. Learning transferable architectures for scalable image recognition. CVPR, 2018.",./refs/download/2/Gpipe: Efficient training of giant neural networks using pipeline parallelism.pdf,Gpipe: Efficient training of giant neural networks using pipeline parallelism
0,"Esteban Real, Alok Aggarwal, Yanping Huang, Quoc V Le",Regularized evolution for image classifier architecture search,arXiv preprint arXiv:1802.01548,,,2018,,"Esteban Real, Alok Aggarwal, Yanping Huang, and Quoc V Le. Regularized evolution for image classifier architecture search. arXiv preprint arXiv:1802.01548, 2018.",./refs/download/2/Gpipe: Efficient training of giant neural networks using pipeline parallelism.pdf,Gpipe: Efficient training of giant neural networks using pipeline parallelism
0,"Andreas Griewank , Andrea Walther",Algorithm 799: revolve: an implementation of checkpointing for the reverse or adjoint mode of computational differentiation,ACM Transactions on Mathematical Software (TOMS),", ",26(1):,2000,19–45,"Andreas Griewank and Andrea Walther. Algorithm 799: revolve: an implementation of checkpointing for the reverse or adjoint mode of computational differentiation. ACM Transactions on Mathematical Software (TOMS), 26(1):19–45, 2000.",./refs/download/2/Gpipe: Efficient training of giant neural networks using pipeline parallelism.pdf,Gpipe: Efficient training of giant neural networks using pipeline parallelism
0,"Tianqi Chen, Bing Xu, Chiyuan Zhang, Carlos Guestrin",Training deep nets with sublinear memory cost,arXiv preprint arXiv:1604.06174,,,2016,,"Tianqi Chen, Bing Xu, Chiyuan Zhang, and Carlos Guestrin. Training deep nets with sublinear memory cost. arXiv preprint arXiv:1604.06174, 2016.",./refs/download/2/Gpipe: Efficient training of giant neural networks using pipeline parallelism.pdf,Gpipe: Efficient training of giant neural networks using pipeline parallelism
0,,,,,,,,"Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Neurips, pages 5998",./refs/download/2/Gpipe: Efficient training of giant neural networks using pipeline parallelism.pdf,Gpipe: Efficient training of giant neural networks using pipeline parallelism
0,,,,,,,,"Jonathan Shen, Patrick Nguyen, Yonghui Wu, Zhifeng Chen, Mia Xu Chen, Ye Jia, Anjuli Kannan, Tara Sainath, Yuan Cao, Chung-Cheng Chiu, et al. Lingvo: a modular and scalable framework for sequence-to-sequence modeling. arXiv preprint arXiv:1902.08295, 2019.",./refs/download/2/Gpipe: Efficient training of giant neural networks using pipeline parallelism.pdf,Gpipe: Efficient training of giant neural networks using pipeline parallelism
0,,,,,,,,"Yangqing Jia, Evan Shelhamer, Jeff Donahue, Sergey Karayev, Jonathan Long, Ross Girshick, Sergio Guadarrama, and Trevor Darrell. Caffe: Convolutional architecture for fast feature embedding. In Proceedings of the 22nd ACM international conference on Multimedia, pages 675–678. ACM, 2014.",./refs/download/2/Gpipe: Efficient training of giant neural networks using pipeline parallelism.pdf,Gpipe: Efficient training of giant neural networks using pipeline parallelism
0,"Tianqi Chen, Mu Li, Yutian Li, Min Lin, Naiyan Wang, Minjie Wang, Tianjun Xiao, Bing Xu, Chiyuan Zhang, Zheng Zhang",Mxnet: A flexible and efficient machine learning library for heterogeneous distributed systems,arXiv preprint arXiv:1512.01274,,,2015,,"Tianqi Chen, Mu Li, Yutian Li, Min Lin, Naiyan Wang, Minjie Wang, Tianjun Xiao, Bing Xu, Chiyuan Zhang, and Zheng Zhang. Mxnet: A flexible and efficient machine learning library for heterogeneous distributed systems. arXiv preprint arXiv:1512.01274, 2015.",./refs/download/2/Gpipe: Efficient training of giant neural networks using pipeline parallelism.pdf,Gpipe: Efficient training of giant neural networks using pipeline parallelism
0,,,,,,,,"Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. Automatic differentiation in pytorch. 2017.",./refs/download/2/Gpipe: Efficient training of giant neural networks using pipeline parallelism.pdf,Gpipe: Efficient training of giant neural networks using pipeline parallelism
0,"Sergey Ioffe , Christian Szegedy",Batch normalization: Accelerating deep network training by reducing internal covariate shift,ICML,,,2015,,"Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. ICML, 2015.",./refs/download/2/Gpipe: Efficient training of giant neural networks using pipeline parallelism.pdf,Gpipe: Efficient training of giant neural networks using pipeline parallelism
0,"Chao Peng, Tete Xiao, Zeming Li, Yuning Jiang, Xiangyu Zhang, Kai Jia, Gang Yu, Jian Sun",Megdet: A large mini-batch object detector,CVPR,"7, ",,2017,,"Chao Peng, Tete Xiao, Zeming Li, Yuning Jiang, Xiangyu Zhang, Kai Jia, Gang Yu, and Jian Sun. Megdet: A large mini-batch object detector. CVPR, 7, 2017.",./refs/download/2/Gpipe: Efficient training of giant neural networks using pipeline parallelism.pdf,Gpipe: Efficient training of giant neural networks using pipeline parallelism
0,"Ali Sharif Razavian, Hossein Azizpour, Josephine Sullivan, Stefan Carlsson",Cnn features off-the-shelf: An astounding baseline for recognition,CVPR Workshops,", ",,2014,512–519,"Ali Sharif Razavian, Hossein Azizpour, Josephine Sullivan, and Stefan Carlsson. Cnn features off-the-shelf: An astounding baseline for recognition. In CVPR Workshops, pages 512–519, 2014.",./refs/download/2/Gpipe: Efficient training of giant neural networks using pipeline parallelism.pdf,Gpipe: Efficient training of giant neural networks using pipeline parallelism
0,"Evan Shelhamer, Jonathan Long, Trevor Darrell",Fully convolutional networks for semantic segmentation,IEEE Trans. Pattern Anal. Mach. Intell.,", ",39(4):,2017,640–651,"Evan Shelhamer, Jonathan Long, and Trevor Darrell. Fully convolutional networks for semantic segmentation. IEEE Trans. Pattern Anal. Mach. Intell., 39(4):640–651, 2017.",./refs/download/2/Gpipe: Efficient training of giant neural networks using pipeline parallelism.pdf,Gpipe: Efficient training of giant neural networks using pipeline parallelism
0,"Terrance DeVries , Graham W Taylor",Improved regularization of convolutional neural networks with cutout,arXiv preprint arXiv:1708.04552,,,2017,,"Terrance DeVries and Graham W Taylor. Improved regularization of convolutional neural networks with cutout. arXiv preprint arXiv:1708.04552, 2017.",./refs/download/2/Gpipe: Efficient training of giant neural networks using pipeline parallelism.pdf,Gpipe: Efficient training of giant neural networks using pipeline parallelism
0,,,,,,,,"Simon Kornblith, Jonathon Shlens, and Quoc V. Le. Do better imagenet models transfer better? CoRR, abs/1805.08974, 2018.",./refs/download/2/Gpipe: Efficient training of giant neural networks using pipeline parallelism.pdf,Gpipe: Efficient training of giant neural networks using pipeline parallelism
0,"Ekin D Cubuk, Barret Zoph, Dandelion Mane, Vijay Vasudevan, Quoc V Le",Autoaugment: Learning augmentation policies from data,arXiv preprint arXiv:1805.09501,,,2018,,"Ekin D Cubuk, Barret Zoph, Dandelion Mane, Vijay Vasudevan, and Quoc V Le. Autoaugment: Learning augmentation policies from data. arXiv preprint arXiv:1805.09501, 2018.",./refs/download/2/Gpipe: Efficient training of giant neural networks using pipeline parallelism.pdf,Gpipe: Efficient training of giant neural networks using pipeline parallelism
0,"Dhruv Mahajan, Ross Girshick, Vignesh Ramanathan, Kaiming He, Manohar Paluri, Yixuan Li, Ashwin Bharambe, Laurens van der Maaten",Exploring the limits of weakly supervised pretraining,ECCV,,,2018,,"Dhruv Mahajan, Ross Girshick, Vignesh Ramanathan, Kaiming He, Manohar Paluri, Yixuan Li, Ashwin Bharambe, and Laurens van der Maaten. Exploring the limits of weakly supervised pretraining. ECCV, 2018.",./refs/download/2/Gpipe: Efficient training of giant neural networks using pipeline parallelism.pdf,Gpipe: Efficient training of giant neural networks using pipeline parallelism
0,,,,,,,,"Jiquan Ngiam, Daiyi Peng, Vijay Vasudevan, Simon Kornblith, Quoc Le, and Ruoming Pang. Domain adaptive transfer learning. 2018.",./refs/download/2/Gpipe: Efficient training of giant neural networks using pipeline parallelism.pdf,Gpipe: Efficient training of giant neural networks using pipeline parallelism
0,"Yuxin Peng, Xiangteng He, Junjie Zhao",Object-part attention model for fine-grained image classification,IEEE Transactions on Image Processing,", ",27(3):,2018,1487–1500,"Yuxin Peng, Xiangteng He, and Junjie Zhao. Object-part attention model for fine-grained image classification. IEEE Transactions on Image Processing, 27(3):1487–1500, 2018.",./refs/download/2/Gpipe: Efficient training of giant neural networks using pipeline parallelism.pdf,Gpipe: Efficient training of giant neural networks using pipeline parallelism
0,"Yin Cui, Yang Song, Chen Sun, Andrew Howard, Serge Belongie",Large scale fine-grained categorization and domain-specific transfer learning,CVPR,,,2018,,"Yin Cui, Yang Song, Chen Sun, Andrew Howard, and Serge Belongie. Large scale fine-grained categorization and domain-specific transfer learning. In CVPR, 2018.",./refs/download/2/Gpipe: Efficient training of giant neural networks using pipeline parallelism.pdf,Gpipe: Efficient training of giant neural networks using pipeline parallelism
0,"Fisher Yu, Dequan Wang, Trevor Darrell",Deep layer aggregation,CVPR,,,2018,,"Fisher Yu, Dequan Wang, and Trevor Darrell. Deep layer aggregation. In CVPR, 2018.",./refs/download/2/Gpipe: Efficient training of giant neural networks using pipeline parallelism.pdf,Gpipe: Efficient training of giant neural networks using pipeline parallelism
0,"Xiu-Shen Wei, Chen-Wei Xie, Jianxin Wu, Chunhua Shen",Mask-cnn: Localizing parts and selecting descriptors for fine-grained bird species categorization,Pattern Recognition,", ",76:,2018,704–714,"Xiu-Shen Wei, Chen-Wei Xie, Jianxin Wu, and Chunhua Shen. Mask-cnn: Localizing parts and selecting descriptors for fine-grained bird species categorization. Pattern Recognition, 76:704–714, 2018.",./refs/download/2/Gpipe: Efficient training of giant neural networks using pipeline parallelism.pdf,Gpipe: Efficient training of giant neural networks using pipeline parallelism
0,,,,,,,,"Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, and Yann N. Dauphin. Convolutional sequence to sequence learning. CoRR, abs/1705.03122, 2017.",./refs/download/2/Gpipe: Efficient training of giant neural networks using pipeline parallelism.pdf,Gpipe: Efficient training of giant neural networks using pipeline parallelism
0,,,,,,,,"Noam Shazeer, Youlong Cheng, Niki Parmar, Dustin Tran, Ashish Vaswani, Penporn Koanantakool, Peter Hawkins, HyoukJoong Lee, Mingsheng Hong, Cliff Young, et al. Mesh-tensorflow: Deep learning for supercomputers. In Neurips, pages 1041",./refs/download/2/Gpipe: Efficient training of giant neural networks using pipeline parallelism.pdf,Gpipe: Efficient training of giant neural networks using pipeline parallelism
0,,,,,,,,"Mia Xu Chen, Orhan Firat, Ankur Bapna, Melvin Johnson, Wolfgang Macherey, George Foster, Llion Jones, Niki Parmar, Mike Schuster, Zhifeng Chen, Yonghui Wu, and Macduff Hughes. The best of both worlds: Combining recent advances in neural machine translation. CoRR, abs/1804.09849, 2018.",./refs/download/2/Gpipe: Efficient training of giant neural networks using pipeline parallelism.pdf,Gpipe: Efficient training of giant neural networks using pipeline parallelism
0,,,,,,,,"Felix Wu, Angela Fan, Alexei Baevski, Yann N. Dauphin, and Michael Auli. Pay less attention with lightweight and dynamic convolutions. CoRR, abs/1901.10430, 2019.",./refs/download/2/Gpipe: Efficient training of giant neural networks using pipeline parallelism.pdf,Gpipe: Efficient training of giant neural networks using pipeline parallelism
0,,,,,,,,"Naveen Arivazhagan, Ankur Bapna, Orhan Firat, Dmitry Lepikhin, Melvin Johnson, Maxim Krikun, Mia Xu Chen, Yuan Cao, George Foster, Colin Cherry, et al. Massively multilingual neural machine translation in the wild: Findings and challenges. arXiv preprint arXiv:1907.05019, 2019.",./refs/download/2/Gpipe: Efficient training of giant neural networks using pipeline parallelism.pdf,Gpipe: Efficient training of giant neural networks using pipeline parallelism
0,"Hongyi Zhang, Yann N Dauphin, Tengyu Ma",Fixup initialization: Residual learning without normalization,arXiv preprint arXiv:1901.09321,,,2019,,"Hongyi Zhang, Yann N Dauphin, and Tengyu Ma. Fixup initialization: Residual learning without normalization. arXiv preprint arXiv:1901.09321, 2019.",./refs/download/2/Gpipe: Efficient training of giant neural networks using pipeline parallelism.pdf,Gpipe: Efficient training of giant neural networks using pipeline parallelism
0,,,,,,,,"Nitish Keskar, Dheevatsa Mudigere, Jorge Nocedal, Mikhail Smelyanskiy, and Ping T.P. Tang. On large-batch training for deep learning: Generalization gap and sharp minima. CoRR, abs/1609.04836, 2016.",./refs/download/2/Gpipe: Efficient training of giant neural networks using pipeline parallelism.pdf,Gpipe: Efficient training of giant neural networks using pipeline parallelism
0,,,,,,,,"Samuel L. Smith, Pieter-Jan Kindermans, and Quoc V. Le. Don’t decay the learning rate, increase the batch size. CoRR, abs/1711.00489, 2017.",./refs/download/2/Gpipe: Efficient training of giant neural networks using pipeline parallelism.pdf,Gpipe: Efficient training of giant neural networks using pipeline parallelism
0,,,,,,,,"Myle Ott, Sergey Edunov, David Grangier, and Michael Auli. Scaling neural machine translation. In Proceedings of the Third Conference on Machine Translation: Research Papers, pages 1–9, Belgium, Brussels, October 2018.",./refs/download/2/Gpipe: Efficient training of giant neural networks using pipeline parallelism.pdf,Gpipe: Efficient training of giant neural networks using pipeline parallelism
0,,,,,,,,"Alex Krizhevsky. One weird trick for parallelizing convolutional neural networks. arXiv preprint arXiv:1404.5997, 2014.",./refs/download/2/Gpipe: Efficient training of giant neural networks using pipeline parallelism.pdf,Gpipe: Efficient training of giant neural networks using pipeline parallelism
0,,,,,,,,"Seunghak Lee, Jin Kyu Kim, Xun Zheng, Qirong Ho, Garth A Gibson, and Eric P Xing. On model parallelization and scheduling strategies for distributed machine learning. In Neurips, pages 2834",./refs/download/2/Gpipe: Efficient training of giant neural networks using pipeline parallelism.pdf,Gpipe: Efficient training of giant neural networks using pipeline parallelism
0,"Azalia Mirhoseini, Hieu Pham, Quoc V Le, Benoit Steiner, Rasmus Larsen, Yuefeng Zhou, Naveen Kumar, Mohammad Norouzi, Samy Bengio, Jeff Dean",Device placement optimization with reinforcement learning,arXiv preprint arXiv:1706.04972,,,2017,,"Azalia Mirhoseini, Hieu Pham, Quoc V Le, Benoit Steiner, Rasmus Larsen, Yuefeng Zhou, Naveen Kumar, Mohammad Norouzi, Samy Bengio, and Jeff Dean. Device placement optimization with reinforcement learning. arXiv preprint arXiv:1706.04972, 2017.",./refs/download/2/Gpipe: Efficient training of giant neural networks using pipeline parallelism.pdf,Gpipe: Efficient training of giant neural networks using pipeline parallelism
0,,,,,,,,"Jeffrey Dean, Greg Corrado, Rajat Monga, Kai Chen, Matthieu Devin, Mark Mao, Marc aurelio Ranzato, Andrew Senior, Paul Tucker, Ke Yang, Quoc V. Le, and Andrew Y. Ng. Large scale distributed deep networks. In F. Pereira, C. J. C. Burges, L. Bottou, and K. Q. Weinberger, editors, Neurips 25, pages 1223",./refs/download/2/Gpipe: Efficient training of giant neural networks using pipeline parallelism.pdf,Gpipe: Efficient training of giant neural networks using pipeline parallelism
0,,,,,,,,"Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang Macherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et al. Google’s neural machine translation system: Bridging the gap between human and machine translation. Transactions of the Association for Computational Linguistics,, 2017.",./refs/download/2/Gpipe: Efficient training of giant neural networks using pipeline parallelism.pdf,Gpipe: Efficient training of giant neural networks using pipeline parallelism
0,"Aaron Harlap, Deepak Narayanan, Amar Phanishayee, Vivek Seshadri, Nikhil Devanur, Greg Ganger, Phil Gibbons",Pipedream: Fast and efficient pipeline parallel dnn training,arXiv preprint arXiv:1806.03377,,,2018,,"Aaron Harlap, Deepak Narayanan, Amar Phanishayee, Vivek Seshadri, Nikhil Devanur, Greg Ganger, and Phil Gibbons. Pipedream: Fast and efficient pipeline parallel dnn training. arXiv preprint arXiv:1806.03377, 2018.",./refs/download/2/Gpipe: Efficient training of giant neural networks using pipeline parallelism.pdf,Gpipe: Efficient training of giant neural networks using pipeline parallelism
0,,,,,,,,"Mu Li, David G Andersen, Jun Woo Park, Alexander J Smola, Amr Ahmed, Vanja Josifovski, James Long, Eugene J Shekita, and Bor-Yiing Su. Scaling distributed machine learning with the parameter server. In OSDI, volume 14, pages 583–598, 2014.",./refs/download/2/Gpipe: Efficient training of giant neural networks using pipeline parallelism.pdf,Gpipe: Efficient training of giant neural networks using pipeline parallelism
0,,,,,,,, M. Toeplitz and ,./refs/download/2/Circulant binary embedding.pdf,Circulant binary embedding
0,,,,,,,," H. Bagherinezhad, M. Rastegari, and ",./refs/download/2/Shufflenet: An extremely efficient convolutional neural network for mobile devices.pdf,Shufflenet: An extremely efficient convolutional neural network for mobile devices
0,,,,,,,," K. Li, and ",./refs/download/2/Shufflenet: An extremely efficient convolutional neural network for mobile devices.pdf,Shufflenet: An extremely efficient convolutional neural network for mobile devices
0,,,,,,,," R. Girshick, J. Donahue, T. Darrell, and ",./refs/download/2/Shufflenet: An extremely efficient convolutional neural network for mobile devices.pdf,Shufflenet: An extremely efficient convolutional neural network for mobile devices
0,,,,,,,," S. Han, H. Mao, and ",./refs/download/2/Shufflenet: An extremely efficient convolutional neural network for mobile devices.pdf,Shufflenet: An extremely efficient convolutional neural network for mobile devices
0,,,,,,,," S. Han, J. Pool, J. Tran, and ",./refs/download/2/Shufflenet: An extremely efficient convolutional neural network for mobile devices.pdf,Shufflenet: An extremely efficient convolutional neural network for mobile devices
0,,,,,,,, K. He and ,./refs/download/2/Shufflenet: An extremely efficient convolutional neural network for mobile devices.pdf,Shufflenet: An extremely efficient convolutional neural network for mobile devices
0,,,,,,,," K. He, X. Zhang, S. Ren, and ",./refs/download/2/Shufflenet: An extremely efficient convolutional neural network for mobile devices.pdf,Shufflenet: An extremely efficient convolutional neural network for mobile devices
0,,,,,,,," K. He, X. Zhang, S. Ren, and ",./refs/download/2/Shufflenet: An extremely efficient convolutional neural network for mobile devices.pdf,Shufflenet: An extremely efficient convolutional neural network for mobile devices
0,,,,,,,," G. Hinton, O. Vinyals, and ",./refs/download/2/Shufflenet: An extremely efficient convolutional neural network for mobile devices.pdf,Shufflenet: An extremely efficient convolutional neural network for mobile devices
0,,,,,,,," A. G. Howard, M. Zhu, B. Chen, D. Kalenichenko, W. Wang, T. Weyand, M. Andreetto, and ",./refs/download/2/Shufflenet: An extremely efficient convolutional neural network for mobile devices.pdf,Shufflenet: An extremely efficient convolutional neural network for mobile devices
0,,,,,,,," J. Hu, L. Shen, and ",./refs/download/2/Shufflenet: An extremely efficient convolutional neural network for mobile devices.pdf,Shufflenet: An extremely efficient convolutional neural network for mobile devices
0,,,,,,,," F. N. Iandola, S. Han, M. W. Moskewicz, K. Ashraf, W. J. Dally, and ",./refs/download/2/Shufflenet: An extremely efficient convolutional neural network for mobile devices.pdf,Shufflenet: An extremely efficient convolutional neural network for mobile devices
0,,,,,,,, S. Ioffe and ,./refs/download/2/Shufflenet: An extremely efficient convolutional neural network for mobile devices.pdf,Shufflenet: An extremely efficient convolutional neural network for mobile devices
0,,,,,,,," M. Jaderberg, A. Vedaldi, and ",./refs/download/2/Shufflenet: An extremely efficient convolutional neural network for mobile devices.pdf,Shufflenet: An extremely efficient convolutional neural network for mobile devices
0,,,,,,,," Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Girshick, S. Guadarrama, and ",./refs/download/2/Shufflenet: An extremely efficient convolutional neural network for mobile devices.pdf,Shufflenet: An extremely efficient convolutional neural network for mobile devices
0,,,,,,,," J. Jin, A. Dundar, and ",./refs/download/2/Shufflenet: An extremely efficient convolutional neural network for mobile devices.pdf,Shufflenet: An extremely efficient convolutional neural network for mobile devices
0,,,,,,,," S. Hong, B. Roh, Y. Cheon, and ",./refs/download/2/Shufflenet: An extremely efficient convolutional neural network for mobile devices.pdf,Shufflenet: An extremely efficient convolutional neural network for mobile devices
0,,,,,,,," A. Krizhevsky, I. Sutskever, and ",./refs/download/2/Shufflenet: An extremely efficient convolutional neural network for mobile devices.pdf,Shufflenet: An extremely efficient convolutional neural network for mobile devices
0,,,,,,,," V. Lebedev, Y. Ganin, M. Rakhuba, I. Oseledets, and ",./refs/download/2/Shufflenet: An extremely efficient convolutional neural network for mobile devices.pdf,Shufflenet: An extremely efficient convolutional neural network for mobile devices
0,,,,,,,," M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan, P. Dollár, and ",./refs/download/2/Shufflenet: An extremely efficient convolutional neural network for mobile devices.pdf,Shufflenet: An extremely efficient convolutional neural network for mobile devices
0,,,,,,,," J. Long, E. Shelhamer, and ",./refs/download/2/Shufflenet: An extremely efficient convolutional neural network for mobile devices.pdf,Shufflenet: An extremely efficient convolutional neural network for mobile devices
0,,,,,,,," M. Mathieu, M. Henaff, and ",./refs/download/2/Shufflenet: An extremely efficient convolutional neural network for mobile devices.pdf,Shufflenet: An extremely efficient convolutional neural network for mobile devices
0,,,,,,,," P. Ramachandran, B. Zoph, and ",./refs/download/2/Shufflenet: An extremely efficient convolutional neural network for mobile devices.pdf,Shufflenet: An extremely efficient convolutional neural network for mobile devices
0,,,,,,,," M. Rastegari, V. Ordonez, J. Redmon, and ",./refs/download/2/Shufflenet: An extremely efficient convolutional neural network for mobile devices.pdf,Shufflenet: An extremely efficient convolutional neural network for mobile devices
0,,,,,,,," S. Ren, K. He, R. Girshick, and ",./refs/download/2/Shufflenet: An extremely efficient convolutional neural network for mobile devices.pdf,Shufflenet: An extremely efficient convolutional neural network for mobile devices
0,,,,,,,, K. Simonyan and ,./refs/download/2/Shufflenet: An extremely efficient convolutional neural network for mobile devices.pdf,Shufflenet: An extremely efficient convolutional neural network for mobile devices
0,,,,,,,," D. Soudry, I. Hubara, and ",./refs/download/2/Shufflenet: An extremely efficient convolutional neural network for mobile devices.pdf,Shufflenet: An extremely efficient convolutional neural network for mobile devices
0,,,,,,,," C. Szegedy, S. Ioffe, V. Vanhoucke, and ",./refs/download/2/Shufflenet: An extremely efficient convolutional neural network for mobile devices.pdf,Shufflenet: An extremely efficient convolutional neural network for mobile devices
0,,,,,,,," C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke, and ",./refs/download/2/Shufflenet: An extremely efficient convolutional neural network for mobile devices.pdf,Shufflenet: An extremely efficient convolutional neural network for mobile devices
0,,,,,,,," C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, and ",./refs/download/2/Shufflenet: An extremely efficient convolutional neural network for mobile devices.pdf,Shufflenet: An extremely efficient convolutional neural network for mobile devices
0,,,,,,,," N. Vasilache, J. Johnson, M. Mathieu, S. Chintala, S. Piantino, and ",./refs/download/2/Shufflenet: An extremely efficient convolutional neural network for mobile devices.pdf,Shufflenet: An extremely efficient convolutional neural network for mobile devices
0,,,,,,,," O. Vinyals, A. Toshev, S. Bengio, and ",./refs/download/2/Shufflenet: An extremely efficient convolutional neural network for mobile devices.pdf,Shufflenet: An extremely efficient convolutional neural network for mobile devices
0,,,,,,,," M. Wang, B. Liu, and ",./refs/download/2/Shufflenet: An extremely efficient convolutional neural network for mobile devices.pdf,Shufflenet: An extremely efficient convolutional neural network for mobile devices
0,,,,,,,," W. Wen, C. Wu, Y. Wang, Y. Chen, and ",./refs/download/2/Shufflenet: An extremely efficient convolutional neural network for mobile devices.pdf,Shufflenet: An extremely efficient convolutional neural network for mobile devices
0,,,,,,,," J. Wu, C. Leng, Y. Wang, Q. Hu, and ",./refs/download/2/Shufflenet: An extremely efficient convolutional neural network for mobile devices.pdf,Shufflenet: An extremely efficient convolutional neural network for mobile devices
0,,,,,,,," S. Xie, R. Girshick, P. Dollár, Z. Tu, and ",./refs/download/2/Shufflenet: An extremely efficient convolutional neural network for mobile devices.pdf,Shufflenet: An extremely efficient convolutional neural network for mobile devices
0,,,,,,,," B. Xiao, and ",./refs/download/2/Shufflenet: An extremely efficient convolutional neural network for mobile devices.pdf,Shufflenet: An extremely efficient convolutional neural network for mobile devices
0,,,,,,,," X. Zhang, J. Zou, K. He, and ",./refs/download/2/Shufflenet: An extremely efficient convolutional neural network for mobile devices.pdf,Shufflenet: An extremely efficient convolutional neural network for mobile devices
0,,,,,,,," X. Zhang, J. Zou, X. Ming, K. He, and ",./refs/download/2/Shufflenet: An extremely efficient convolutional neural network for mobile devices.pdf,Shufflenet: An extremely efficient convolutional neural network for mobile devices
0,,,,,,,," A. Zhou, A. Yao, Y. Guo, L. Xu, and ",./refs/download/2/Shufflenet: An extremely efficient convolutional neural network for mobile devices.pdf,Shufflenet: An extremely efficient convolutional neural network for mobile devices
0,,,,,,,," S. Zhou, Y. Wu, Z. Ni, X. Zhou, H. Wen, and ",./refs/download/2/Shufflenet: An extremely efficient convolutional neural network for mobile devices.pdf,Shufflenet: An extremely efficient convolutional neural network for mobile devices
0,,,,,,,," B. Zoph, V. Vasudevan, J. Shlens, and ",./refs/download/2/Shufflenet: An extremely efficient convolutional neural network for mobile devices.pdf,Shufflenet: An extremely efficient convolutional neural network for mobile devices
0,"S. Bakkes, C. T. Tan, Y. Pisan",Personalised gaming, JCT,,,2012,,"S. Bakkes, C. T. Tan, and Y. Pisan. Personalised gaming. JCT, 3, 2012.",./refs/download/2/Deep structure inference network for facial action unit recognition.pdf,Deep structure inference network for facial action unit recognition
0,X. Chu,W, Ouyang,,,2016,,"X. Chu, W. Ouyang, X. Wang, et al. Crf-cnn: Modeling structured information in human pose estimation. In Advances in Neural Information Processing Systems, pages 316–324, 2016.",./refs/download/2/Deep structure inference network for facial action unit recognition.pdf,Deep structure inference network for facial action unit recognition
0,"Z. Deng, A. Vahdat, H. Hu, G. Mori",Structure inference machines: Recurrent neural networks for analyzing relations in group activity recognition, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,,,2016,,"Z. Deng, A. Vahdat, H. Hu, and G. Mori. Structure inference machines: Recurrent neural networks for analyzing relations in group activity recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 4772–4781, 2016.",./refs/download/2/Deep structure inference network for facial action unit recognition.pdf,Deep structure inference network for facial action unit recognition
0,"D. DeVault, R. Artstein, G. Benn, T. Dey, E. Fast, A. Gainer, L.-P. Morency",A virtual human interviewer for healthcare decision support, AAMAS,,,2014,,"D. DeVault, R. Artstein, G. Benn, T. Dey, E. Fast, A. Gainer, and L.-P. Morency. A virtual human interviewer for healthcare decision support. AAMAS, 2014.",./refs/download/2/Deep structure inference network for facial action unit recognition.pdf,Deep structure inference network for facial action unit recognition
0,"X. Ding, W.-S. Chu, F. De la Torre, J. F. Cohn, Q. Wang",Facial action unit event detection by cascade of tasks, In Proceedings of the IEEE International Conference on Computer Vision,,,2013,,"X. Ding, W.-S. Chu, F. De la Torre, J. F. Cohn, and Q. Wang. Facial action unit event detection by cascade of tasks. In Proceedings of the IEEE International Conference on Computer Vision, pages 2400– 2407, 2013.",./refs/download/2/Deep structure inference network for facial action unit recognition.pdf,Deep structure inference network for facial action unit recognition
0,"P. Ekman, W. Friesen, J. Hager",Facs manual, a human face,,,2002,,"P. Ekman, W. Friesen, and J. Hager. Facs manual. a human face. 2002.",./refs/download/2/Deep structure inference network for facial action unit recognition.pdf,Deep structure inference network for facial action unit recognition
0,"S. Eleftheriadis, O. Rudovic, M. Pantic",Multiconditional latent variable model for joint facial action unit detection, In Proceedings of the IEEE International Conference on Computer Vision,,,2015,,"S. Eleftheriadis, O. Rudovic, and M. Pantic. Multiconditional latent variable model for joint facial action unit detection. In Proceedings of the IEEE International Conference on Computer Vision, pages 3792– 3800, 2015.",./refs/download/2/Deep structure inference network for facial action unit recognition.pdf,Deep structure inference network for facial action unit recognition
0,"C. Fabian Benitez-Quiroz, Y. Wang, A. M. Martinez",Recognition of action units in the wild with deep nets and a new global-local loss, In The IEEE International Conference on Computer Vision (ICCV),,,2017,,"C. Fabian Benitez-Quiroz, Y. Wang, and A. M. Martinez. Recognition of action units in the wild with deep nets and a new global-local loss. In The IEEE International Conference on Computer Vision (ICCV), Oct 2017.",./refs/download/2/Deep structure inference network for facial action unit recognition.pdf,Deep structure inference network for facial action unit recognition
0,C. Frith,Role of facial expressions in social interactions, Philosophical Transactions of the Royal Society B: Biological Sciences,,,2009,364,"C. Frith. Role of facial expressions in social interactions. Philosophical Transactions of the Royal Society B: Biological Sciences, 364(1535):3453–3458, 2009.",./refs/download/2/Deep structure inference network for facial action unit recognition.pdf,Deep structure inference network for facial action unit recognition
0,"S. Jaiswal and , M. Valstar",Deep learning the dynamic appearance and shape of facial action units, In Applications of Computer Vision (WACV),,,2016,2016,"S. Jaiswal and M. Valstar. Deep learning the dynamic appearance and shape of facial action units. In Applications of Computer Vision (WACV), 2016 IEEE Winter Conference on, pages 1–8. IEEE, 2016.",./refs/download/2/Deep structure inference network for facial action unit recognition.pdf,Deep structure inference network for facial action unit recognition
0,"S. Kaltwang, O. Rudovic, M. Pantic",Continuous pain intensity estimation from facial expressions, ISVC,,,2012,,"S. Kaltwang, O. Rudovic, and M. Pantic. Continuous pain intensity estimation from facial expressions. ISVC, pages 368–377, 2012.",./refs/download/2/Deep structure inference network for facial action unit recognition.pdf,Deep structure inference network for facial action unit recognition
0,"A. Kapoor, W. Burleson, R. W. Picard",Automatic prediction of frustration, IJHCS,,,2007,65,"A. Kapoor, W. Burleson, and R. W. Picard. Automatic prediction of frustration. IJHCS, 65(8):724–736, 2007.",./refs/download/2/Deep structure inference network for facial action unit recognition.pdf,Deep structure inference network for facial action unit recognition
0,"V. Kazemi and , J. Sullivan",One millisecond face alignment with an ensemble of regression trees, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,,,2014,,"V. Kazemi and J. Sullivan. One millisecond face alignment with an ensemble of regression trees. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1867–1874, 2014.",./refs/download/2/Deep structure inference network for facial action unit recognition.pdf,Deep structure inference network for facial action unit recognition
0,"K. Kulkarni, C. A. Corneanu, I. Ofodile, S. Escalera, X. Baro, S. Hyniewska, J. Allik, G. Anbarjafari",Automatic recognition of deceptive facial expressions of emotion, arXiv preprint arXiv:,,,1707,,"K. Kulkarni, C. A. Corneanu, I. Ofodile, S. Escalera, X. Baro, S. Hyniewska, J. Allik, and G. Anbarjafari. Automatic recognition of deceptive facial expressions of emotion. arXiv preprint arXiv:1707.",./refs/download/2/Deep structure inference network for facial action unit recognition.pdf,Deep structure inference network for facial action unit recognition
0,"W. Li, F. Abitahi, Z. Zhu",Action unit detection with region adaptation, multi-labeling learning and optimal temporal fusing,,,1704,,"W. Li, F. Abitahi, and Z. Zhu. Action unit detection with region adaptation, multi-labeling learning and optimal temporal fusing. arXiv preprint arXiv:1704.",./refs/download/2/Deep structure inference network for facial action unit recognition.pdf,Deep structure inference network for facial action unit recognition
0,"P. Lucey, J. F. Cohn, I. Matthews, S. Lucey, S. Sridharan, J. Howlett, K. M. Prkachin",Automatically detecting pain in video through facial action units, SMC-B,,,2011,41,"P. Lucey, J. F. Cohn, I. Matthews, S. Lucey, S. Sridharan, J. Howlett, and K. M. Prkachin. Automatically detecting pain in video through facial action units. SMC-B, 41(3):664–674, 2011.",./refs/download/2/Deep structure inference network for facial action unit recognition.pdf,Deep structure inference network for facial action unit recognition
0,"S. M. Mavadati, M. H. Mahoor, K. Bartlett, P. Trinh, J. F. Cohn",Disfa: A spontaneous facial action intensity database, IEEE Transactions on Affective Computing,,,2013,,"S. M. Mavadati, M. H. Mahoor, K. Bartlett, P. Trinh, and J. F. Cohn. Disfa: A spontaneous facial action intensity database. IEEE Transactions on Affective Computing, 4(2):151–160, 2013.",./refs/download/2/Deep structure inference network for facial action unit recognition.pdf,Deep structure inference network for facial action unit recognition
0,"O. M. Parkhi, A. Vedaldi, A. Zisserman",Deep face recognition, In British Machine Vision Conference,,,2015,,"O. M. Parkhi, A. Vedaldi, and A. Zisserman. Deep face recognition. In British Machine Vision Conference, 2015.",./refs/download/2/Deep structure inference network for facial action unit recognition.pdf,Deep structure inference network for facial action unit recognition
0,"R. R. Selvaraju, M. Cogswell, A. Das, R. Vedantam, D. Parikh, D. Batra",Grad-cam: Visual explanations from deep networks via gradient-based localization, See https://arxiv,,,1610,,"R. R. Selvaraju, M. Cogswell, A. Das, R. Vedantam, D. Parikh, and D. Batra. Grad-cam: Visual explanations from deep networks via gradient-based localization. See https://arxiv. org/abs/1610.",./refs/download/2/Deep structure inference network for facial action unit recognition.pdf,Deep structure inference network for facial action unit recognition
0,"K. Simonyan and , A. Zisserman",Very deep convolutional networks for large-scale image recognition, arXiv preprint arXiv:1409,.1556,,2014,,"K. Simonyan and A. Zisserman. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556, 2014.",./refs/download/2/Deep structure inference network for facial action unit recognition.pdf,Deep structure inference network for facial action unit recognition
0,"Y. Song, D. McDuff, D. Vasisht, A. Kapoor",Exploiting sparsity and co-occurrence structure for action unit recognition, In Automatic Face and Gesture Recognition (FG),,,2015,2015,"Y. Song, D. McDuff, D. Vasisht, and A. Kapoor. Exploiting sparsity and co-occurrence structure for action unit recognition. In Automatic Face and Gesture Recognition (FG), 2015 11th IEEE International Conference and Workshops on, volume 1, pages 1–8. IEEE, 2015.",./refs/download/2/Deep structure inference network for facial action unit recognition.pdf,Deep structure inference network for facial action unit recognition
0,"Y. Taigman, M. Yang, M. Ranzato, L. Wolf",Deepface: Closing the gap to human-level performance in face verification, In Proceedings of the IEEE conference on computer vision and pattern recognition,,,2014,,"Y. Taigman, M. Yang, M. Ranzato, and L. Wolf. Deepface: Closing the gap to human-level performance in face verification. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 1701–1708, 2014.",./refs/download/2/Deep structure inference network for facial action unit recognition.pdf,Deep structure inference network for facial action unit recognition
0,"A. Vinciarelli, M. Pantic, H. Bourlard",Social signal processing: Survey of an emerging domain, IVC,,,2009,27,"A. Vinciarelli, M. Pantic, and H. Bourlard. Social signal processing: Survey of an emerging domain. IVC, 27(12):1743–1759, 2009.",./refs/download/2/Deep structure inference network for facial action unit recognition.pdf,Deep structure inference network for facial action unit recognition
0,R. Walecki,V, Pavlovic,,,1704,,"R. Walecki, V. Pavlovic, B. Schuller, M. Pantic, et al. Deep structured learning for facial action unit intensity estimation. arXiv preprint arXiv:1704.",./refs/download/2/Deep structure inference network for facial action unit recognition.pdf,Deep structure inference network for facial action unit recognition
0,"Z. Wang, Y. Li, S. Wang, Q. Ji",Capturing global semantic relationships for facial action unit recognition, In Proceedings of the IEEE International Conference on Computer Vision,,,2013,,"Z. Wang, Y. Li, S. Wang, and Q. Ji. Capturing global semantic relationships for facial action unit recognition. In Proceedings of the IEEE International Conference on Computer Vision, pages 3304–3311, 2013.",./refs/download/2/Deep structure inference network for facial action unit recognition.pdf,Deep structure inference network for facial action unit recognition
0,"Y. Wu and , Q. Ji",Constrained joint cascade regression framework for simultaneous facial action unit recognition and facial landmark detection, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,,,2016,,"Y. Wu and Q. Ji. Constrained joint cascade regression framework for simultaneous facial action unit recognition and facial landmark detection. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 3400–3408, 2016.",./refs/download/2/Deep structure inference network for facial action unit recognition.pdf,Deep structure inference network for facial action unit recognition
0,"J. Zeng, W.-S. Chu, F. De la Torre, J. F. Cohn, Z. Xiong",Confidence preserving machine for facial action unit detection, In Proceedings of the IEEE International Conference on Computer Vision,,,2015,,"J. Zeng, W.-S. Chu, F. De la Torre, J. F. Cohn, and Z. Xiong. Confidence preserving machine for facial action unit detection. In Proceedings of the IEEE International Conference on Computer Vision, pages 3622– 3630, 2015.",./refs/download/2/Deep structure inference network for facial action unit recognition.pdf,Deep structure inference network for facial action unit recognition
0,"X. Zhang and , M. H. Mahoor",Task-dependent multitask multiple kernel learning for facial action unit detection, Pattern Recognition,,,2016,51,"X. Zhang and M. H. Mahoor. Task-dependent multitask multiple kernel learning for facial action unit detection. Pattern Recognition, 51:187–196, 2016.",./refs/download/2/Deep structure inference network for facial action unit recognition.pdf,Deep structure inference network for facial action unit recognition
0,"X. Zhang, L. Yin, J. F. Cohn, S. Canavan, M. Reale, A. Horowitz, P. Liu, J. M. Girard",Bp4dspontaneous: a high-resolution spontaneous 3d dynamic facial expression database, Image and Vision Computing,,,2014,32,"X. Zhang, L. Yin, J. F. Cohn, S. Canavan, M. Reale, A. Horowitz, P. Liu, and J. M. Girard. Bp4dspontaneous: a high-resolution spontaneous 3d dynamic facial expression database. Image and Vision Computing, 32(10):692–706, 2014.",./refs/download/2/Deep structure inference network for facial action unit recognition.pdf,Deep structure inference network for facial action unit recognition
0,"K. Zhao, W.-S. Chu, F. De la Torre, J. F. Cohn, H. Zhang",Joint patch and multi-label learning for facial action unit detection, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,,,2015,,"K. Zhao, W.-S. Chu, F. De la Torre, J. F. Cohn, and H. Zhang. Joint patch and multi-label learning for facial action unit detection. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2207–2216, 2015.",./refs/download/2/Deep structure inference network for facial action unit recognition.pdf,Deep structure inference network for facial action unit recognition
0,"K. Zhao, W.-S. Chu, H. Zhang",Deep region and multi-label learning for facial action unit detection, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,,,2016,,"K. Zhao, W.-S. Chu, and H. Zhang. Deep region and multi-label learning for facial action unit detection. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 3391–3399, 2016.",./refs/download/2/Deep structure inference network for facial action unit recognition.pdf,Deep structure inference network for facial action unit recognition
0,"S. Zheng, S. Jayasumana, B. Romera-Paredes, V. Vineet, Z. Su, D. Du, C. Huang, P. H. Torr",Conditional random fields as recurrent neural networks, In Proceedings of the IEEE International Conference on Computer Vision,,,2015,,"S. Zheng, S. Jayasumana, B. Romera-Paredes, V. Vineet, Z. Su, D. Du, C. Huang, and P. H. Torr. Conditional random fields as recurrent neural networks. In Proceedings of the IEEE International Conference on Computer Vision, pages 1529–1537, 2015.",./refs/download/2/Deep structure inference network for facial action unit recognition.pdf,Deep structure inference network for facial action unit recognition
0,"L. Zhong, Q. Liu, P. Yang, J. Huang, D. N. Metaxas",Learning multiscale active facial patches for expression analysis, IEEE transactions on cybernetics,,,2015,45,"L. Zhong, Q. Liu, P. Yang, J. Huang, and D. N. Metaxas. Learning multiscale active facial patches for expression analysis. IEEE transactions on cybernetics, 45(8):1499–1510, 2015.",./refs/download/2/Deep structure inference network for facial action unit recognition.pdf,Deep structure inference network for facial action unit recognition
0,,,,,,,, S. McCulloch and ,./refs/download/2/Gaussian error linear units (gelus).pdf,Gaussian error linear units (gelus)
0,,,,,,,," E. Dahl, and ",./refs/download/2/Gaussian error linear units (gelus).pdf,Gaussian error linear units (gelus)
0,,,,,,,," M. Saxe, James L. McClelland, and ",./refs/download/2/Gaussian error linear units (gelus).pdf,Gaussian error linear units (gelus)
0,,,,,,,," E. Hinton, Alex Krizhevsky, Ilya Sutskever, and ",./refs/download/2/Gaussian error linear units (gelus).pdf,Gaussian error linear units (gelus)
0,"M. Aubry, U. Schlickewei, D. Cremers",The wave kernel signature: A quantum mechanical approach to shape analysis, In Computer Vision Workshops (ICCV Workshops),,,1633,2011,"M. Aubry, U. Schlickewei, and D. Cremers. The wave kernel signature: A quantum mechanical approach to shape analysis. In Computer Vision Workshops (ICCV Workshops), 2011 IEEE International Conference on, pages 1626–1633.",./refs/download/2/PointNet++: Deep hierarchical feature learning on point sets in a metric space.pdf,PointNet++: Deep hierarchical feature learning on point sets in a metric space
0,"D. Belton and , D. D. Lichti",Classification and segmentation of terrestrial laser scanner point clouds using local variance information, Iaprs,,,2006,,"D. Belton and D. D. Lichti. Classification and segmentation of terrestrial laser scanner point clouds using local variance information. Iaprs, Xxxvi, 5:44–49, 2006.",./refs/download/2/PointNet++: Deep hierarchical feature learning on point sets in a metric space.pdf,PointNet++: Deep hierarchical feature learning on point sets in a metric space
0,"J. Bruna, W. Zaremba, A. Szlam, Y. LeCun",Spectral networks and locally connected networks on graphs, arXiv preprint arXiv:,,,1312,,"J. Bruna, W. Zaremba, A. Szlam, and Y. LeCun. Spectral networks and locally connected networks on graphs. arXiv preprint arXiv:1312.",./refs/download/2/PointNet++: Deep hierarchical feature learning on point sets in a metric space.pdf,PointNet++: Deep hierarchical feature learning on point sets in a metric space
0,"A. X. Chang, T. Funkhouser, L. Guibas, P. Hanrahan, Q. Huang, Z. Li, S. Savarese, M. Savva, S. Song, H. Su, J. Xiao, L. Yi, F. Yu",ShapeNet: An Information-Rich 3D Model Repository, Technical Report arXiv:,,,1512,,"A. X. Chang, T. Funkhouser, L. Guibas, P. Hanrahan, Q. Huang, Z. Li, S. Savarese, M. Savva, S. Song, H. Su, J. Xiao, L. Yi, and F. Yu. ShapeNet: An Information-Rich 3D Model Repository. Technical Report arXiv:1512.",./refs/download/2/PointNet++: Deep hierarchical feature learning on point sets in a metric space.pdf,PointNet++: Deep hierarchical feature learning on point sets in a metric space
0,"A. Dai, A. X. Chang, M. Savva, M. Halber, T. Funkhouser, M. Nießner",Scannet: Richly-annotated 3d reconstructions of indoor scenes, arXiv preprint arXiv:,,,1702,,"A. Dai, A. X. Chang, M. Savva, M. Halber, T. Funkhouser, and M. Nießner. Scannet: Richly-annotated 3d reconstructions of indoor scenes. arXiv preprint arXiv:1702.",./refs/download/2/PointNet++: Deep hierarchical feature learning on point sets in a metric space.pdf,PointNet++: Deep hierarchical feature learning on point sets in a metric space
0,"J. Demantké, C. Mallet, N. David, B. Vallet",Dimensionality based scale selection in 3d lidar point clouds, The International Archives of the Photogrammetry,,,2011,,"J. Demantké, C. Mallet, N. David, and B. Vallet. Dimensionality based scale selection in 3d lidar point clouds. The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, 38(Part 5):W12, 2011.",./refs/download/2/PointNet++: Deep hierarchical feature learning on point sets in a metric space.pdf,PointNet++: Deep hierarchical feature learning on point sets in a metric space
0,"A. Gressin, C. Mallet, J. Demantké, N. David",Towards 3d lidar point cloud registration improvement using optimal neighborhood knowledge, ISPRS journal of photogrammetry and remote sensing,,,2013,79,"A. Gressin, C. Mallet, J. Demantké, and N. David. Towards 3d lidar point cloud registration improvement using optimal neighborhood knowledge. ISPRS journal of photogrammetry and remote sensing, 79:240– 251, 2013.",./refs/download/2/PointNet++: Deep hierarchical feature learning on point sets in a metric space.pdf,PointNet++: Deep hierarchical feature learning on point sets in a metric space
0,"K. He, X. Zhang, S. Ren, J. Sun",Deep residual learning for image recognition, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,,,2016,,"K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 770–778, 2016.",./refs/download/2/PointNet++: Deep hierarchical feature learning on point sets in a metric space.pdf,PointNet++: Deep hierarchical feature learning on point sets in a metric space
0,"D. Kingma and , J. Ba",Adam: A method for stochastic optimization, arXiv preprint arXiv:1412,.6980. [10] A. Krizhevsky,,2012,,"D. Kingma and J. Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980. [10] A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classification with deep convolutional neural networks. In Advances in neural information processing systems, pages 1097–1105, 2012.",./refs/download/2/PointNet++: Deep hierarchical feature learning on point sets in a metric space.pdf,PointNet++: Deep hierarchical feature learning on point sets in a metric space
0,"Y. LeCun, L. Bottou, Y. Bengio, P. Haffner",Gradient-based learning applied to document recognition, Proceedings of the IEEE,,,1998,86,"Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278–2324, 1998.",./refs/download/2/PointNet++: Deep hierarchical feature learning on point sets in a metric space.pdf,PointNet++: Deep hierarchical feature learning on point sets in a metric space
0,"Z. Lian, J. Zhang, S. Choi, H. ElNaghy, J. El-Sana, T. Furuya, A. Giachetti, R. A. Guler, L. Lai, C. Li, H. Li, F. A. Limberger, R. Martin, R. U. Nakanishi, A. P. Neto, L. G. Nonato, R. Ohbuchi, K. Pevzner, D. Pickup, P. Rosin, A. Sharf, L. Sun, X. Sun, S. Tari, G. Unal, R. C. Wilson",Non-rigid 3D Shape Retrieval, In I,. Pratikakis,,2015,,"Z. Lian, J. Zhang, S. Choi, H. ElNaghy, J. El-Sana, T. Furuya, A. Giachetti, R. A. Guler, L. Lai, C. Li, H. Li, F. A. Limberger, R. Martin, R. U. Nakanishi, A. P. Neto, L. G. Nonato, R. Ohbuchi, K. Pevzner, D. Pickup, P. Rosin, A. Sharf, L. Sun, X. Sun, S. Tari, G. Unal, and R. C. Wilson. Non-rigid 3D Shape Retrieval. In I. Pratikakis, M. Spagnuolo, T. Theoharis, L. V. Gool, and R. Veltkamp, editors, Eurographics Workshop on 3D Object Retrieval. The Eurographics Association, 2015.",./refs/download/2/PointNet++: Deep hierarchical feature learning on point sets in a metric space.pdf,PointNet++: Deep hierarchical feature learning on point sets in a metric space
0,"M. Lin, Q. Chen, S. Yan",Network in network, arXiv preprint arXiv:,,,1312,,"M. Lin, Q. Chen, and S. Yan. Network in network. arXiv preprint arXiv:1312.",./refs/download/2/PointNet++: Deep hierarchical feature learning on point sets in a metric space.pdf,PointNet++: Deep hierarchical feature learning on point sets in a metric space
0,"L. Luciano and , A. B. Hamza",Deep learning with geodesic moments for 3d shape classification, Pattern Recognition Letters,,,2017,,"L. Luciano and A. B. Hamza. Deep learning with geodesic moments for 3d shape classification. Pattern Recognition Letters, 2017.",./refs/download/2/PointNet++: Deep hierarchical feature learning on point sets in a metric space.pdf,PointNet++: Deep hierarchical feature learning on point sets in a metric space
0,"J. Masci, D. Boscaini, M. Bronstein, P. Vandergheynst",Geodesic convolutional neural networks on riemannian manifolds, In Proceedings of the IEEE International Conference on Computer Vision Workshops,,,2015,,"J. Masci, D. Boscaini, M. Bronstein, and P. Vandergheynst. Geodesic convolutional neural networks on riemannian manifolds. In Proceedings of the IEEE International Conference on Computer Vision Workshops, pages 37–45, 2015.",./refs/download/2/PointNet++: Deep hierarchical feature learning on point sets in a metric space.pdf,PointNet++: Deep hierarchical feature learning on point sets in a metric space
0,M. Meyer,M, Desbrun,,,2002,,"M. Meyer, M. Desbrun, P. Schröder, A. H. Barr, et al. Discrete differential-geometry operators for triangulated 2-manifolds. Visualization and mathematics, 3(2):52–58, 2002.",./refs/download/2/PointNet++: Deep hierarchical feature learning on point sets in a metric space.pdf,PointNet++: Deep hierarchical feature learning on point sets in a metric space
0,"N. J. MITRA, A. NGUYEN, L. GUIBAS",Estimating surface normals in noisy point cloud data, International Journal of Computational Geometry & Applications,,,2004,14,"N. J. MITRA, A. NGUYEN, and L. GUIBAS. Estimating surface normals in noisy point cloud data. International Journal of Computational Geometry & Applications, 14(04n05):261–276, 2004.",./refs/download/2/PointNet++: Deep hierarchical feature learning on point sets in a metric space.pdf,PointNet++: Deep hierarchical feature learning on point sets in a metric space
0,I. Occipital,Structure sensor-3d scanning, augmented reality,,,2016,,"I. Occipital. Structure sensor-3d scanning, augmented reality, and more for mobile devices, 2016.",./refs/download/2/PointNet++: Deep hierarchical feature learning on point sets in a metric space.pdf,PointNet++: Deep hierarchical feature learning on point sets in a metric space
0,"M. Pauly, L. P. Kobbelt, M. Gross",Point-based multiscale surface representation, ACM Transactions on Graphics (TOG),,,2006,25,"M. Pauly, L. P. Kobbelt, and M. Gross. Point-based multiscale surface representation. ACM Transactions on Graphics (TOG), 25(2):177–193, 2006.",./refs/download/2/PointNet++: Deep hierarchical feature learning on point sets in a metric space.pdf,PointNet++: Deep hierarchical feature learning on point sets in a metric space
0,"C. R. Qi, H. Su, K. Mo, L. J. Guibas",Pointnet: Deep learning on point sets for 3d classification and segmentation, arXiv preprint arXiv:,,,1612,,"C. R. Qi, H. Su, K. Mo, and L. J. Guibas. Pointnet: Deep learning on point sets for 3d classification and segmentation. arXiv preprint arXiv:1612.",./refs/download/2/PointNet++: Deep hierarchical feature learning on point sets in a metric space.pdf,PointNet++: Deep hierarchical feature learning on point sets in a metric space
0,"C. R. Qi, H. Su, M. Nießner, A. Dai, M. Yan, L. Guibas",Volumetric and multi-view cnns for object classification on 3d data, In Proc,. Computer Vision and Pattern Recognition (CVPR),,2016,,"C. R. Qi, H. Su, M. Nießner, A. Dai, M. Yan, and L. Guibas. Volumetric and multi-view cnns for object classification on 3d data. In Proc. Computer Vision and Pattern Recognition (CVPR), IEEE, 2016.",./refs/download/2/PointNet++: Deep hierarchical feature learning on point sets in a metric space.pdf,PointNet++: Deep hierarchical feature learning on point sets in a metric space
0,"G. Riegler, A. O. Ulusoys, A. Geiger",Octnet: Learning deep 3d representations at high resolutions, arXiv preprint arXiv:,,,1611,,"G. Riegler, A. O. Ulusoys, and A. Geiger. Octnet: Learning deep 3d representations at high resolutions. arXiv preprint arXiv:1611.",./refs/download/2/PointNet++: Deep hierarchical feature learning on point sets in a metric space.pdf,PointNet++: Deep hierarchical feature learning on point sets in a metric space
0,"R. M. Rustamov, Y. Lipman, T. Funkhouser",Interior distance using barycentric coordinates, In Computer Graphics Forum,,,1288,,"R. M. Rustamov, Y. Lipman, and T. Funkhouser. Interior distance using barycentric coordinates. In Computer Graphics Forum, volume 28, pages 1279–1288.",./refs/download/2/PointNet++: Deep hierarchical feature learning on point sets in a metric space.pdf,PointNet++: Deep hierarchical feature learning on point sets in a metric space
0,"P. Y. Simard, D. Steinkraus, J. C. Platt",Best practices for convolutional neural networks applied to visual document analysis, In ICDAR,,,2003,,"P. Y. Simard, D. Steinkraus, and J. C. Platt. Best practices for convolutional neural networks applied to visual document analysis. In ICDAR, volume 3, pages 958–962, 2003.",./refs/download/2/PointNet++: Deep hierarchical feature learning on point sets in a metric space.pdf,PointNet++: Deep hierarchical feature learning on point sets in a metric space
0,"K. Simonyan and , A. Zisserman",Very deep convolutional networks for large-scale image recognition, arXiv preprint arXiv:1409,.1556,,2014,,"K. Simonyan and A. Zisserman. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556, 2014.",./refs/download/2/PointNet++: Deep hierarchical feature learning on point sets in a metric space.pdf,PointNet++: Deep hierarchical feature learning on point sets in a metric space
0,"H. Su, S. Maji, E. Kalogerakis, E. G. Learned-Miller",Multi-view convolutional neural networks for 3d shape recognition, In Proc,. ICCV,,2015,,"H. Su, S. Maji, E. Kalogerakis, and E. G. Learned-Miller. Multi-view convolutional neural networks for 3d shape recognition. In Proc. ICCV, to appear, 2015.",./refs/download/2/PointNet++: Deep hierarchical feature learning on point sets in a metric space.pdf,PointNet++: Deep hierarchical feature learning on point sets in a metric space
0,"J. Sun, M. Ovsjanikov, L. Guibas",A concise and provably informative multi-scale signature based on heat diffusion, In Computer graphics forum,,,1392,,"J. Sun, M. Ovsjanikov, and L. Guibas. A concise and provably informative multi-scale signature based on heat diffusion. In Computer graphics forum, volume 28, pages 1383–1392.",./refs/download/2/PointNet++: Deep hierarchical feature learning on point sets in a metric space.pdf,PointNet++: Deep hierarchical feature learning on point sets in a metric space
0,"O. Vinyals, S. Bengio, M. Kudlur",Order matters: Sequence to sequence for sets, arXiv preprint arXiv:,,,1511,,"O. Vinyals, S. Bengio, and M. Kudlur. Order matters: Sequence to sequence for sets. arXiv preprint arXiv:1511.",./refs/download/2/PointNet++: Deep hierarchical feature learning on point sets in a metric space.pdf,PointNet++: Deep hierarchical feature learning on point sets in a metric space
0,"M. Weinmann, B. Jutzi, S. Hinz, C. Mallet",Semantic point cloud interpretation based on optimal neighborhoods, relevant features and efficient classifiers,. ISPRS Journal of Photogrammetry and Remote Sensing,,2015,105,"M. Weinmann, B. Jutzi, S. Hinz, and C. Mallet. Semantic point cloud interpretation based on optimal neighborhoods, relevant features and efficient classifiers. ISPRS Journal of Photogrammetry and Remote Sensing, 105:286–304, 2015.",./refs/download/2/PointNet++: Deep hierarchical feature learning on point sets in a metric space.pdf,PointNet++: Deep hierarchical feature learning on point sets in a metric space
0,"Z. Wu, S. Song, A. Khosla, F. Yu, L. Zhang, X. Tang, J. Xiao",3d shapenets: A deep representation for volumetric shapes, In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,,,2015,,"Z. Wu, S. Song, A. Khosla, F. Yu, L. Zhang, X. Tang, and J. Xiao. 3d shapenets: A deep representation for volumetric shapes. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1912–1920, 2015.",./refs/download/2/PointNet++: Deep hierarchical feature learning on point sets in a metric space.pdf,PointNet++: Deep hierarchical feature learning on point sets in a metric space
0,"L. Yi, V. G. Kim, D. Ceylan, I.-C. Shen, M. Yan, H. Su, C. Lu, Q. Huang, A. Sheffer, L. Guibas",A scalable active framework for region annotation in 3d shape collections, SIGGRAPH Asia,,,2016,,"L. Yi, V. G. Kim, D. Ceylan, I.-C. Shen, M. Yan, H. Su, C. Lu, Q. Huang, A. Sheffer, and L. Guibas. A scalable active framework for region annotation in 3d shape collections. SIGGRAPH Asia, 2016.",./refs/download/2/PointNet++: Deep hierarchical feature learning on point sets in a metric space.pdf,PointNet++: Deep hierarchical feature learning on point sets in a metric space
0,"L. Yi, H. Su, X. Guo, L. Guibas",Syncspeccnn: Synchronized spectral cnn for 3d shape segmentation, arXiv preprint arXiv:,,,1612,,"L. Yi, H. Su, X. Guo, and L. Guibas. Syncspeccnn: Synchronized spectral cnn for 3d shape segmentation. arXiv preprint arXiv:1612.",./refs/download/2/PointNet++: Deep hierarchical feature learning on point sets in a metric space.pdf,PointNet++: Deep hierarchical feature learning on point sets in a metric space
