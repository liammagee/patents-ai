<html>
<head>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/vis/4.16.1/vis.css" type="text/css" />
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/vis/4.16.1/vis-network.min.js"> </script>
<center>
<h1></h1>
</center>

<!-- <link rel="stylesheet" href="../node_modules/vis/dist/vis.min.css" type="text/css" />
<script type="text/javascript" src="../node_modules/vis/dist/vis.js"> </script>-->

<style type="text/css">

        #mynetwork {
            width: 100%;
            height: 750px;
            background-color: #222222;
            border: 1px solid lightgray;
            position: relative;
            float: left;
        }

        
        #loadingBar {
            position:absolute;
            top:0px;
            left:0px;
            width: 100%;
            height: 750px;
            background-color:rgba(200,200,200,0.8);
            -webkit-transition: all 0.5s ease;
            -moz-transition: all 0.5s ease;
            -ms-transition: all 0.5s ease;
            -o-transition: all 0.5s ease;
            transition: all 0.5s ease;
            opacity:1;
        }

        #bar {
            position:absolute;
            top:0px;
            left:0px;
            width:20px;
            height:20px;
            margin:auto auto auto auto;
            border-radius:11px;
            border:2px solid rgba(30,30,30,0.05);
            background: rgb(0, 173, 246); /* Old browsers */
            box-shadow: 2px 0px 4px rgba(0,0,0,0.4);
        }

        #border {
            position:absolute;
            top:10px;
            left:10px;
            width:500px;
            height:23px;
            margin:auto auto auto auto;
            box-shadow: 0px 0px 4px rgba(0,0,0,0.2);
            border-radius:10px;
        }

        #text {
            position:absolute;
            top:8px;
            left:530px;
            width:30px;
            height:50px;
            margin:auto auto auto auto;
            font-size:22px;
            color: #000000;
        }

        div.outerBorder {
            position:relative;
            top:400px;
            width:600px;
            height:44px;
            margin:auto auto auto auto;
            border:8px solid rgba(0,0,0,0.1);
            background: rgb(252,252,252); /* Old browsers */
            background: -moz-linear-gradient(top,  rgba(252,252,252,1) 0%, rgba(237,237,237,1) 100%); /* FF3.6+ */
            background: -webkit-gradient(linear, left top, left bottom, color-stop(0%,rgba(252,252,252,1)), color-stop(100%,rgba(237,237,237,1))); /* Chrome,Safari4+ */
            background: -webkit-linear-gradient(top,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* Chrome10+,Safari5.1+ */
            background: -o-linear-gradient(top,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* Opera 11.10+ */
            background: -ms-linear-gradient(top,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* IE10+ */
            background: linear-gradient(to bottom,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* W3C */
            filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#fcfcfc', endColorstr='#ededed',GradientType=0 ); /* IE6-9 */
            border-radius:72px;
            box-shadow: 0px 0px 10px rgba(0,0,0,0.2);
        }
        

        

        
</style>

</head>

<body>
<div id = "mynetwork"></div>

<div id="loadingBar">
    <div class="outerBorder">
        <div id="text">0%</div>
        <div id="border">
            <div id="bar"></div>
        </div>
    </div>
</div>


<script type="text/javascript">

    // initialize global variables.
    var edges;
    var nodes;
    var network; 
    var container;
    var options, data;

    
    // This method is responsible for drawing the graph, returns the drawn network
    function drawGraph() {
        var container = document.getElementById('mynetwork');
        
        

        // parsing and collecting nodes and edges from the python
        nodes = new vis.DataSet([{"font": {"color": "white"}, "id": "PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database", "label": "PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "", "label": "", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deepfashion: Powering robust clothes recognition and retrieval with   rich annotations", "label": "Deepfashion: Powering robust clothes recognition and retrieval with   rich annotations", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Benchmark Datasets for Fault Detection and Classification in   Sensor Data", "label": "Benchmark Datasets for Fault Detection and Classification in   Sensor Data", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Partnet: A large-scale benchmark for fine grained  and  hierarchical  part-level  3d  object  understanding", "label": "Partnet: A large-scale benchmark for fine grained  and  hierarchical  part-level  3d  object  understanding", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fashionista: A fashion-aware graphical system for exploring visually similar items", "label": "Fashionista: A fashion-aware graphical system for exploring visually similar items", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Going   deeper with convolutions", "label": "Going   deeper with convolutions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Hashnet: Deep learning to hash by continuation", "label": "Hashnet: Deep learning to hash by continuation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A comparison of extrinsic clustering evaluation metrics based on   formal constraints", "label": "A comparison of extrinsic clustering evaluation metrics based on   formal constraints", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Adaptive structure discovery for multimedia analysis   using multiple features", "label": "Adaptive structure discovery for multimedia analysis   using multiple features", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Image-based recommendations on styles and substitutes", "label": "Image-based recommendations on styles and substitutes", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Ups and downs: Modeling the  visual evolution of fashion trends with one-class collaborative \ufb01ltering", "label": "Ups and downs: Modeling the  visual evolution of fashion trends with one-class collaborative \ufb01ltering", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "VBPR: visual bayesian  personalized ranking from implicit feedback", "label": "VBPR: visual bayesian  personalized ranking from implicit feedback", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Lotusx: a  position-aware xml graphical search system with auto-completion", "label": "Lotusx: a  position-aware xml graphical search system with auto-completion", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": " \u201cImagenet classi\ufb01cation with deep convolutional neural networks", "label": " \u201cImagenet classi\ufb01cation with deep convolutional neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Y", "label": "Y", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Accelerating t-SNE using  tree-based algorithms", "label": "Accelerating t-SNE using  tree-based algorithms", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Numerical continuation methods: an introduction", "label": "Numerical continuation methods: an introduction", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Representation learning: A review and new perspectives", "label": "Representation learning: A review and new perspectives", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": " [4] T", "label": " [4] T", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Binarynet: Training deep neural networks with weights and activations constrained to +1 or -1", "label": "Binarynet: Training deep neural networks with weights and activations constrained to +1 or -1", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Maximum likelihood in cost-sensitive learning: Model speci\ufb01cation", "label": "Maximum likelihood in cost-sensitive learning: Model speci\ufb01cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Decaf: A deep convolutional activation feature for generic visual recognition", "label": "Decaf: A deep convolutional activation feature for generic visual recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep hashing for compact binary codes learning", "label": "Deep hashing for compact binary codes learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fast search in hamming space with multi-index hashing", "label": "Fast search in hamming space with multi-index hashing", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "P", "label": "P", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "S", "label": "S", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": " procrustean approach to learning binary codes", "label": " procrustean approach to learning binary codes", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep residual  learning for image recognition", "label": "Deep residual  learning for image recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A fast learning algorithm for deep belief nets", "label": "A fast learning algorithm for deep belief nets", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "label": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Product quanIEEE Transactization for nearest neighbor search", "label": "Product quanIEEE Transactization for nearest neighbor search", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Caffe: Convolutional architecture for fast feature embedding", "label": "Caffe: Convolutional architecture for fast feature embedding", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": " Imagenet classi\ufb01cation with deep convolutional neural networks", "label": " Imagenet classi\ufb01cation with deep convolutional neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning to hash with binary In NIPS", "label": "Learning to hash with binary In NIPS", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Simultaneous feature learning and hash coding with deep neural networks", "label": "Simultaneous feature learning and hash coding with deep neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Contentbased multimedia information retrieval: State of the art and challenges", "label": "Contentbased multimedia information retrieval: State of the art and challenges", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep supervised hashing for fast image retrieval", "label": "Deep supervised hashing for fast image retrieval", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "In CVPR", "label": "In CVPR", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Hashing  with graphs", "label": "Hashing  with graphs", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Hash bit selection: a uni\ufb01ed solution for selection problems in hashing", "label": "Hash bit selection: a uni\ufb01ed solution for selection problems in hashing", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Partial hash update via hamming subspace learning", "label": "Partial hash update via hamming subspace learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Recti\ufb01ed linear units improve restricted boltzmann machines", "label": "Recti\ufb01ed linear units improve restricted boltzmann machines", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Minimal loss hashing for compact binary codes", "label": "Minimal loss hashing for compact binary codes", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "In NIPS", "label": "In NIPS", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": " J", "label": " J", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning a nonlinear embedding by preserving class neighbourhood structure", "label": "Learning a nonlinear embedding by preserving class neighbourhood structure", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Supervised discrete hashing", "label": "Supervised discrete hashing", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Content-based image retrieval at the end of the early years", "label": "Content-based image retrieval at the end of the early years", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Dropout: A simple way to prevent neural networks from over\ufb01tting", "label": "Dropout: A simple way to prevent neural networks from over\ufb01tting", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Semi-supervised hashing for large-scale search", "label": "Semi-supervised hashing for large-scale search", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Hashing for  similarity search: A survey", "label": "Hashing for  similarity search: A survey", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Spectral hash ing", "label": "Spectral hash ing", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Supervised hashing for image retrieval via image representation learning", "label": "Supervised hashing for image retrieval via image representation learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Circulant binary embedding", "label": "Circulant binary embedding", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Supervised In SIGIR", "label": "Supervised In SIGIR", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep semantic ranking based hashing for multi-label image retrieval", "label": "Deep semantic ranking based hashing for multi-label image retrieval", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep hashing network for ef\ufb01cient similarity retrieval", "label": "Deep hashing network for ef\ufb01cient similarity retrieval", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fashion-gen: The generative fashion dataset and challenge", "label": "Fashion-gen: The generative fashion dataset and challenge", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A note on the inception score", "label": "A note on the inception score", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Viton: An image-based virtual try-on network", "label": "Viton: An image-based virtual try-on network", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Stacked generative adversarial networks", "label": "Stacked generative adversarial networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Image-toimage translation with conditional adversarial networks", "label": "Image-toimage translation with conditional adversarial networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Getting the look: clothing recognition and segmentation for automatic product suggestions in everyday photos", "label": "Getting the look: clothing recognition and segmentation for automatic product suggestions in everyday photos", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Progressive growing of gans for improved quality, stability, and variation", "label": "Progressive growing of gans for improved quality, stability, and variation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Where to buy it: Matching street clothing photos in online shops", "label": "Where to buy it: Matching street clothing photos in online shops", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Hierarchical adversarially learned inference", "label": "Hierarchical adversarially learned inference", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": ", et al", "label": ", et al", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Apparel classi\ufb01cation with style", "label": "Apparel classi\ufb01cation with style", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Clothes co-parsing via joint image segmentation and labeling with application to clothing retrieval", "label": "Clothes co-parsing via joint image segmentation and labeling with application to clothing retrieval", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Describing clothing by semantic attributes", "label": "Describing clothing by semantic attributes", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep domain adaptation for describing people based on \ufb01ne-grained clothing attributes", "label": "Deep domain adaptation for describing people based on \ufb01ne-grained clothing attributes", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Stochastic video generation with a learned prior", "label": "Stochastic video generation with a learned prior", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "et al", "label": "et al", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Microsoft coco: Common objects in context", "label": "Microsoft coco: Common objects in context", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Street-to-shop: Cross-scenario clothing retrieval via parts In Computer Vision and alignment and auxiliary set", "label": "Street-to-shop: Cross-scenario clothing retrieval via parts In Computer Vision and alignment and auxiliary set", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep learning face attributes in the wild", "label": "Deep learning face attributes in the wild", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": ", and Tang, X", "label": ", and Tang, X", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "label": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Unpaired image-to-image translation using cycle-consistent adversarial networks", "label": "Unpaired image-to-image translation using cycle-consistent adversarial networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Generative adversarial text to image synthesis", "label": "Generative adversarial text to image synthesis", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Improved techniques for training In Advances in Neural Information Processing gans", "label": "Improved techniques for training In Advances in Neural Information Processing gans", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Bidirectional recurrent neural networks", "label": "Bidirectional recurrent neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Neuroaesthetics in fashion: Modeling the perception of fashionability", "label": "Neuroaesthetics in fashion: Modeling the perception of fashionability", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Amortised map inference for image superresolution", "label": "Amortised map inference for image superresolution", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": " Unsupervised cross-domain image generation", "label": " Unsupervised cross-domain image generation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Visualizing data using t-SNE", "label": "Visualizing data using t-SNE", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Attention is all you need", "label": "Attention is all you need", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning visual clothing style with heterogeneous dyadic co-occurrences", "label": "Learning visual clothing style with heterogeneous dyadic co-occurrences", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Central similarity quantization for efficient image and video retrieval", "label": "Central similarity quantization for efficient image and video retrieval", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding", "label": "Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Mesh segmentation-a comparative study", "label": "Mesh segmentation-a comparative study", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A framework for the objective evaluation of segmentation algorithms using a ground-truth of human segmented 3Dmodels", "label": "A framework for the objective evaluation of segmentation algorithms using a ground-truth of human segmented 3Dmodels", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "T", "label": "T", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Linking WordNet to 3D shapes", "label": "Linking WordNet to 3D shapes", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A benchmark for 3D mesh segmentation", "label": "A benchmark for 3D mesh segmentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "3D semantic segmentation with submanifold sparse convolutional networks", "label": "3D semantic segmentation with submanifold sparse convolutional networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Parts of recognition", "label": "Parts of recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Co-segmentation of 3D shapes via subspace clustering", "label": "Co-segmentation of 3D shapes via subspace clustering", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning to predict part mobility from a single static snapshot", "label": "Learning to predict part mobility from a single static snapshot", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning how objects function via co-analysis of interactions", "label": "Learning how objects function via co-analysis of interactions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Predictive and generative neural networks for object functionality", "label": "Predictive and generative neural networks for object functionality", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Robust watertight manifold surface generation method for shapenet models", "label": "Robust watertight manifold surface generation method for shapenet models", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Exploring shape variations by 3d-model decomposition and partIn Computer Graphics Forum", "label": "Exploring shape variations by 3d-model decomposition and partIn Computer Graphics Forum", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning 3D mesh segmentation and labeling", "label": "Learning 3D mesh segmentation and labeling", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Shape2pose: Human-centric shape analysis", "label": "Shape2pose: Human-centric shape analysis", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models", "label": "Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Ai2-thor: An interactive 3d environment for visual ai", "label": "Ai2-thor: An interactive 3d environment for visual ai", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Parameter learning and convergent inference for dense random \ufb01elds", "label": "Parameter learning and convergent inference for dense random \ufb01elds", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The hungarian method for the assignment problem", "label": "The hungarian method for the assignment problem", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "PointGrid: A deep network for 3D shape understanding", "label": "PointGrid: A deep network for 3D shape understanding", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "SO-Net: Self-organizing network for point cloud analysis", "label": "SO-Net: Self-organizing network for point cloud analysis", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Grass: Generative recursive autoencoders for shape structures", "label": "Grass: Generative recursive autoencoders for shape structures", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "PointCNN: Convolution on X -transformed points", "label": "PointCNN: Convolution on X -transformed points", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Physical primitive decomposition", "label": "Physical primitive decomposition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Exploration of continuous variability in collections of 3d shapes", "label": "Exploration of continuous variability in collections of 3d shapes", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Virtualhome: Simulating household activities via programs", "label": "Virtualhome: Simulating household activities via programs", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "PointNet: Deep learning on point sets for 3D classi\ufb01cation and segmentation", "label": "PointNet: Deep learning on point sets for 3D classi\ufb01cation and segmentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "PointNet++: Deep hierarchical feature learning on point sets in a metric space", "label": "PointNet++: Deep hierarchical feature learning on point sets in a metric space", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "label": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions", "label": "Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation", "label": "SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning to group and label \ufb01ne-grained shape components", "label": "Learning to group and label \ufb01ne-grained shape components", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Active co-analysis of a set of shapes", "label": "Active co-analysis of a set of shapes", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Dynamic graph cnn for learning on point clouds", "label": "Dynamic graph cnn for learning on point clouds", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "VoxSegNet: Volumetric CNNs for semantic part segmentation of 3D shapes", "label": "VoxSegNet: Volumetric CNNs for semantic part segmentation of 3D shapes", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Structure-aware generative network for 3d-shape modeling", "label": "Structure-aware generative network for 3d-shape modeling", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "SpiderCNN: Deep learning on point sets with parameterized convolutional \ufb01lters", "label": "SpiderCNN: Deep learning on point sets with parameterized convolutional \ufb01lters", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Chalet: Cornell house agent learning environment", "label": "Chalet: Cornell house agent learning environment", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning hierarchical shape segmentation and labeling from online repositories", "label": "Learning hierarchical shape segmentation and labeling from online repositories", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "V", "label": "V", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation", "label": "SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Visual semantic planning using deep successor representations", "label": "Visual semantic planning using deep successor representations", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Efficientnet: Rethinking model scaling for convolutional neural networks", "label": "Efficientnet: Rethinking model scaling for convolutional neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Birdsnap: Large-scale \ufb01ne-grained visual categorization of birds", "label": "Birdsnap: Large-scale \ufb01ne-grained visual categorization of birds", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Food-101\u2013 mining discriminative components with random forests", "label": "Food-101\u2013 mining discriminative components with random forests", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Proxylessnas: Direct neural architecture search on target task and hardware", "label": "Proxylessnas: Direct neural architecture search on target task and hardware", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Xception: Deep learning with depthwise separa ble convolutions", "label": "Xception: Deep learning with depthwise separa ble convolutions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Autoaugment: Learning augmentation policies from data", "label": "Autoaugment: Learning augmentation policies from data", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Sigmoid-weighted linear units for neural network function approximation in reinforcement learning", "label": "Sigmoid-weighted linear units for neural network function approximation in reinforcement learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Squeezenext: Hardware-aware neural network design", "label": "Squeezenext: Hardware-aware neural network design", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding", "label": "Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep residual learning for image recognition", "label": "Deep residual learning for image recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Mask  r-cnn", "label": "Mask  r-cnn", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Amc: Automl for model compression and acceleration on mobile devices", "label": "Amc: Automl for model compression and acceleration on mobile devices", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Gaussian error linear units  (gelus)", "label": "Gaussian error linear units  (gelus)", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Mobilenets: Ef\ufb01cient convolutional neural networks for mobile vision applications", "label": "Mobilenets: Ef\ufb01cient convolutional neural networks for mobile vision applications", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Squeeze-and-excitation net works", "label": "Squeeze-and-excitation net works", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep networks with stochastic depth", "label": "Deep networks with stochastic depth", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Densely connected convolutional networks", "label": "Densely connected convolutional networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Gpipe: Ef\ufb01cient training of giant neural networks using pipeline parallelism", "label": "Gpipe: Ef\ufb01cient training of giant neural networks using pipeline parallelism", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": ", and Keutzer, K", "label": ", and Keutzer, K", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "On the expressive power of deep neural networks", "label": "On the expressive power of deep neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Collecting a large-scale dataset of \ufb01ne-grained cars", "label": "Collecting a large-scale dataset of \ufb01ne-grained cars", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning multiple layers of  features from tiny images", "label": "Learning multiple layers of  features from tiny images", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Imagenet classi\ufb01cation with deep convolutional neural networks", "label": "Imagenet classi\ufb01cation with deep convolutional neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Searching for activation functions", "label": "Searching for activation functions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Regularized evolution for image classi\ufb01er architecture search", "label": "Regularized evolution for image classi\ufb01er architecture search", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Resnet with one-neuron hidden layers is a universal approximator", "label": "Resnet with one-neuron hidden layers is a universal approximator", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Mobilenetv2: Inverted residuals and linear bottlenecks", "label": "Mobilenetv2: Inverted residuals and linear bottlenecks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Feature pyramid networks for object detection", "label": "Feature pyramid networks for object detection", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Progressive neural architecture search", "label": "Progressive neural architecture search", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The expressive power of neural networks: A view from the width", "label": "The expressive power of neural networks: A view from the width", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Shuf\ufb02enet v2: Practical guidelines for ef\ufb01cient cnn architecture design", "label": "Shuf\ufb02enet v2: Practical guidelines for ef\ufb01cient cnn architecture design", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Exploring the limits of weakly supervised pretraining", "label": "Exploring the limits of weakly supervised pretraining", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "On the expressive power of overlapping architectures of deep learning", "label": "On the expressive power of overlapping architectures of deep learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Dropout: a simple way to prevent neural networks from over\ufb01tting", "label": "Dropout: a simple way to prevent neural networks from over\ufb01tting", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Going deeper with convolutions", "label": "Going deeper with convolutions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Rethinking the inception architecture for computer vision", "label": "Rethinking the inception architecture for computer vision", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Inception-v4, inception-resnet and the impact of residual connections on learning", "label": "Inception-v4, inception-resnet and the impact of residual connections on learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fine-grained visual classi\ufb01cation of aircraft", "label": "Fine-grained visual classi\ufb01cation of aircraft", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "MnasNet: Platform-aware neural architecture search for mobile", "label": "MnasNet: Platform-aware neural architecture search for mobile", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Domain adaptive transfer learning with specialist models", "label": "Domain adaptive transfer learning with specialist models", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Aggregated residual transformations for deep neural networks", "label": "Aggregated residual transformations for deep neural networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Automated \ufb02ower classi\ufb01cation over a large number of classes", "label": "Automated \ufb02ower classi\ufb01cation over a large number of classes", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Netadapt: Platform-aware neural network adaptation for mobile applications", "label": "Netadapt: Platform-aware neural network adaptation for mobile applications", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": " Cats and dogs", "label": " Cats and dogs", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Wide residual networks", "label": "Wide residual networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Polynet: A pursuit of structural diversity in very deep networks", "label": "Polynet: A pursuit of structural diversity in very deep networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Shuf\ufb02enet: An extremely ef\ufb01cient convolutional neural network for mobile devices", "label": "Shuf\ufb02enet: An extremely ef\ufb01cient convolutional neural network for mobile devices", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning deep features for discriminative localization", "label": "Learning deep features for discriminative localization", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Neural architecture search with  reinforcement learning", "label": "Neural architecture search with  reinforcement learning", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning transferable architectures for scalable image recognition", "label": "Learning transferable architectures for scalable image recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A compact embedding for facial expression similarity", "label": "A compact embedding for facial expression similarity", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Emotionet: An accurate", "label": "Emotionet: An accurate", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Large scale online learning of image similarity through ranking", "label": "Large scale online learning of image similarity through ranking", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep structure inference network for facial action unit recognition", "label": "Deep structure inference network for facial action unit recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Self-report captures 27 distinct categories of emotion bridged by continuous gradients", "label": "Self-report captures 27 distinct categories of emotion bridged by continuous gradients", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Clarifying the conceptualization", "label": "Clarifying the conceptualization", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "From individual to group-level emotion recognition: Emotiw 5", "label": "From individual to group-level emotion recognition: Emotiw 5", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "R", "label": "R", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "O", "label": "O", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Facial Action  Coding System Manual", "label": "Facial Action  Coding System Manual", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Candid portrait ACM Transactions on Graphics", "label": "Candid portrait ACM Transactions on Graphics", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep metric  learning with hierarchical triplet loss", "label": "Deep metric  learning with hierarchical triplet loss", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Understanding the dif\ufb01culty of In AISTATS", "label": "Understanding the dif\ufb01culty of In AISTATS", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Challenges in representation learning: A report on three machine learning contests", "label": "Challenges in representation learning: A report on three machine learning contests", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "I", "label": "I", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "MS-Celeb-1M: A dataset and benchmark for large scale face recognition", "label": "MS-Celeb-1M: A dataset and benchmark for large scale face recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Triplet-center  loss for multi-view 3D object retrieval", "label": "Triplet-center  loss for multi-view 3D object retrieval", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "In defense of the triplet loss for person re-identi\ufb01cation", "label": "In defense of the triplet loss for person re-identi\ufb01cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The MegaFace benchmark: 1 million faces for recognition at scale", "label": "The MegaFace benchmark: 1 million faces for recognition at scale", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Adam: A method for stochastic  optimization", "label": "Adam: A method for stochastic  optimization", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "DEAP: A database for emotion analysis using physiological signals", "label": "DEAP: A database for emotion analysis using physiological signals", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Self-supervised In  learning of a facial attribute embedding from video", "label": "Self-supervised In  learning of a facial attribute embedding from video", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep affect prediction in-the-wild: Aff-wild database and challenge", "label": "Deep affect prediction in-the-wild: Aff-wild database and challenge", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "AFEW-VA database for valence and arousal estimation inthe-wild", "label": "AFEW-VA database for valence and arousal estimation inthe-wild", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Convolutional deep belief networks on  CIFAR-10", "label": "Convolutional deep belief networks on  CIFAR-10", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep facial expression recognition: A  survey", "label": "Deep facial expression recognition: A  survey", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Reliable crowdsourcing and deep locality-preserving learning for unconstrained facial expression recognition", "label": "Reliable crowdsourcing and deep locality-preserving learning for unconstrained facial expression recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep relative distance learning: Tell the difference between similar vehicles", "label": "Deep relative distance learning: Tell the difference between similar vehicles", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep learning face  attributes in the wild", "label": "Deep learning face  attributes in the wild", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The extended Cohn-Kanade dataset (CK+): A complete dataset for action unit and emotionspeci\ufb01ed expression", "label": "The extended Cohn-Kanade dataset (CK+): A complete dataset for action unit and emotionspeci\ufb01ed expression", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Automatic analysis of facial actions: A survey", "label": "Automatic analysis of facial actions: A survey", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Facial expression recognition from near-infrared videos", "label": "Facial expression recognition from near-infrared videos", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fast training of triplet-based deep binary embedding networks", "label": "Fast training of triplet-based deep binary embedding networks", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Affectiva-MIT facial expression dataset (AM-FED): Naturalistic and spontaneous facial expressions collected in-the-wild", "label": "Affectiva-MIT facial expression dataset (AM-FED): Naturalistic and spontaneous facial expressions collected in-the-wild", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Basic dimensions for a general psychological theory: Implications for personality", "label": "Basic dimensions for a general psychological theory: Implications for personality", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "LSTMbased facial performance capture using embedding between expressions", "label": "LSTMbased facial performance capture using embedding between expressions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "AffectNet: A database for facial expression", "label": "AffectNet: A database for facial expression", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Facial expression recognition from world wild web", "label": "Facial expression recognition from world wild web", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Level playing  \ufb01eld for million scale face recognition", "label": "Level playing  \ufb01eld for million scale face recognition", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "WebIn ICME", "label": "WebIn ICME", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Introducing the RECOLA multimodal corpus of remote collaborative and affective interactions", "label": "Introducing the RECOLA multimodal corpus of remote collaborative and affective interactions", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A circumplex model of affect", "label": "A circumplex model of affect", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "FaceNet: A In  uni\ufb01ed embedding for face recognition and clustering", "label": "FaceNet: A In  uni\ufb01ed embedding for face recognition and clustering", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep adaptive attention for joint facial action unit detection and face alignment", "label": "Deep adaptive attention for joint facial action unit detection and face alignment", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep metric learning via lifted structured feature embedding", "label": "Deep metric learning via lifted structured feature embedding", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "DeepFace: Closing the gap to human-level performance in face veri\ufb01cation", "label": "DeepFace: Closing the gap to human-level performance in face veri\ufb01cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning \ufb01ne-grained image similarity with deep ranking", "label": "Learning \ufb01ne-grained image similarity with deep ranking", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Deep metric  learning with angular loss", "label": "Deep metric  learning with angular loss", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Distance metric learning for large margin nearest neighbor classi\ufb01cation", "label": "Distance metric learning for large margin nearest neighbor classi\ufb01cation", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "From facial expression recognition to interpersonal relation prediction", "label": "From facial expression recognition to interpersonal relation prediction", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms", "label": "Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Meier, and J", "label": "Meier, and J", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Tapson, and A", "label": "Tapson, and A", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Li, and L", "label": "Li, and L", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Bengio, and P", "label": "Bengio, and P", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Cun, and R", "label": "Cun, and R", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Imagenet: A large-scale hierarchical image database", "label": "Imagenet: A large-scale hierarchical image database", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "ImageNet:  A Large-Scale Hierarchical Image Database", "label": "ImageNet:  A Large-Scale Hierarchical Image Database", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "WordNet: An Electronic Lexical Database", "label": "WordNet: An Electronic Lexical Database", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Introduction to MPEG-7: Multimedia New York", "label": "Introduction to MPEG-7: Multimedia New York", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Color and texture descriptors", "label": "Color and texture descriptors", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Mpeg-7 visual motion descriptors", "label": "Mpeg-7 visual motion descriptors", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Ef\ufb01cient use of mpeg-7 edge  histogram descriptor", "label": "Ef\ufb01cient use of mpeg-7 edge  histogram descriptor", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Partnet: A large-scale benchmark for fine-  grained  and  hierarchical  part-level  3d  object  understanding", "label": "Partnet: A large-scale benchmark for fine-  grained  and  hierarchical  part-level  3d  object  understanding", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Shapenet: An information-rich 3d model repository", "label": "Shapenet: An information-rich 3d model repository", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The protein data bank", "label": "The protein data bank", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Schelling points on 3D surface meshes", "label": "Schelling points on 3D surface meshes", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "ImageNet: A large-scale hierarchical image database", "label": "ImageNet: A large-scale hierarchical image database", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Example-based synthesis of 3D object arrangements", "label": "Example-based synthesis of 3D object arrangements", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Fine-grained semi-supervised labeling of large shape collections", "label": "Fine-grained semi-supervised labeling of large shape collections", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Developing an engineering shape benchmark for CAD models", "label": "Developing an engineering shape benchmark for CAD models", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A probabilistic model for component-based shape synthesis", "label": "A probabilistic model for component-based shape synthesis", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Mobius transformations for global intrinsic symmetry analysis", "label": "Mobius transformations for global intrinsic symmetry analysis", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Learning part-based templates from large collections of 3D shapes", "label": "Learning part-based templates from large collections of 3D shapes", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Exploring collections of 3D models using fuzzy correspondences", "label": "Exploring collections of 3D models using fuzzy correspondences", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "3D object representations for \ufb01ne-grained categorization", "label": "3D object representations for \ufb01ne-grained categorization", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "PDBsum: A web-based database of summaries and analyses of all PDB structures", "label": "PDBsum: A web-based database of summaries and analyses of all PDB structures", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Creating consistent scene graphs using a probabilistic grammar", "label": "Creating consistent scene graphs using a probabilistic grammar", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Building a large annotated corpus of english: The Penn Treebank", "label": "Building a large annotated corpus of english: The Penn Treebank", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Symmetry in 3D geometry: Extraction and applications", "label": "Symmetry in 3D geometry: Extraction and applications", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Simpli\ufb01cation and repair of polygonal models using volumetric techniques", "label": "Simpli\ufb01cation and repair of polygonal models using volumetric techniques", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Building a database  of 3D scenes from user annotations", "label": "Building a database  of 3D scenes from user annotations", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "The Princeton shape benchmark", "label": "The Princeton shape benchmark", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Sliding shapes for 3D ob ject detection in depth images", "label": "Sliding shapes for 3D ob ject detection in depth images", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "A large-scale shape benchmark for 3D object retrieval: Toyohashi shape benchmark", "label": "A large-scale shape benchmark for 3D object retrieval: Toyohashi shape benchmark", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "LabelMe: Online image annotation and applications", "label": "LabelMe: Online image annotation and applications", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "3D ShapeNets: A Deep Representation for Volumetric Shapes", "label": "3D ShapeNets: A Deep Representation for Volumetric Shapes", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Beyond PASCAL: A benchmark for 3D object detection in the wild", "label": "Beyond PASCAL: A benchmark for 3D object detection in the wild", "shape": "dot", "size": 10}, {"font": {"color": "white"}, "id": "Retrieving articulated 3-D models using medial surfaces and their graph spectra", "label": "Retrieving articulated 3-D models using medial surfaces and their graph spectra", "shape": "dot", "size": 10}]);
        edges = new vis.DataSet([{"from": "PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database", "to": "", "weight": 1}, {"from": "PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database", "to": "Deepfashion: Powering robust clothes recognition and retrieval with   rich annotations", "weight": 1}, {"from": "PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database", "to": "Benchmark Datasets for Fault Detection and Classification in   Sensor Data", "weight": 1}, {"from": "PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database", "to": "Partnet: A large-scale benchmark for fine grained  and  hierarchical  part-level  3d  object  understanding", "weight": 1}, {"from": "PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database", "to": "Fashionista: A fashion-aware graphical system for exploring visually similar items", "weight": 1}, {"from": "PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database", "to": "Going   deeper with convolutions", "weight": 1}, {"from": "PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database", "to": "Hashnet: Deep learning to hash by continuation", "weight": 1}, {"from": "PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database", "to": "A comparison of extrinsic clustering evaluation metrics based on   formal constraints", "weight": 1}, {"from": "PatentNet: A Large-Scale Incomplete Multiview, Multimodal, Multilabel Industrial Goods Image Database", "to": "Adaptive structure discovery for multimedia analysis   using multiple features", "weight": 1}, {"from": "Fashionista: A fashion-aware graphical system for exploring visually similar items", "to": "Image-based recommendations on styles and substitutes", "weight": 1}, {"from": "Fashionista: A fashion-aware graphical system for exploring visually similar items", "to": "Ups and downs: Modeling the  visual evolution of fashion trends with one-class collaborative \ufb01ltering", "weight": 1}, {"from": "Fashionista: A fashion-aware graphical system for exploring visually similar items", "to": "VBPR: visual bayesian  personalized ranking from implicit feedback", "weight": 1}, {"from": "Fashionista: A fashion-aware graphical system for exploring visually similar items", "to": "Lotusx: a  position-aware xml graphical search system with auto-completion", "weight": 1}, {"from": "Fashionista: A fashion-aware graphical system for exploring visually similar items", "to": " \u201cImagenet classi\ufb01cation with deep convolutional neural networks", "weight": 1}, {"from": "Fashionista: A fashion-aware graphical system for exploring visually similar items", "to": "Y", "weight": 1}, {"from": "Fashionista: A fashion-aware graphical system for exploring visually similar items", "to": "Accelerating t-SNE using  tree-based algorithms", "weight": 1}, {"from": "Hashnet: Deep learning to hash by continuation", "to": "Numerical continuation methods: an introduction", "weight": 1}, {"from": "Hashnet: Deep learning to hash by continuation", "to": "Representation learning: A review and new perspectives", "weight": 1}, {"from": "Hashnet: Deep learning to hash by continuation", "to": " [4] T", "weight": 1}, {"from": "Hashnet: Deep learning to hash by continuation", "to": "Binarynet: Training deep neural networks with weights and activations constrained to +1 or -1", "weight": 1}, {"from": "Hashnet: Deep learning to hash by continuation", "to": "Maximum likelihood in cost-sensitive learning: Model speci\ufb01cation", "weight": 1}, {"from": "Hashnet: Deep learning to hash by continuation", "to": "Decaf: A deep convolutional activation feature for generic visual recognition", "weight": 1}, {"from": "Hashnet: Deep learning to hash by continuation", "to": "Deep hashing for compact binary codes learning", "weight": 1}, {"from": "Hashnet: Deep learning to hash by continuation", "to": "Fast search in hamming space with multi-index hashing", "weight": 1}, {"from": "Hashnet: Deep learning to hash by continuation", "to": "P", "weight": 1}, {"from": "Hashnet: Deep learning to hash by continuation", "to": "S", "weight": 1}, {"from": "Hashnet: Deep learning to hash by continuation", "to": " procrustean approach to learning binary codes", "weight": 1}, {"from": "Hashnet: Deep learning to hash by continuation", "to": "Deep residual  learning for image recognition", "weight": 1}, {"from": "Hashnet: Deep learning to hash by continuation", "to": "A fast learning algorithm for deep belief nets", "weight": 1}, {"from": "Hashnet: Deep learning to hash by continuation", "to": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "weight": 1}, {"from": "Hashnet: Deep learning to hash by continuation", "to": "Product quanIEEE Transactization for nearest neighbor search", "weight": 1}, {"from": "Hashnet: Deep learning to hash by continuation", "to": "Caffe: Convolutional architecture for fast feature embedding", "weight": 1}, {"from": "Hashnet: Deep learning to hash by continuation", "to": " Imagenet classi\ufb01cation with deep convolutional neural networks", "weight": 1}, {"from": "Hashnet: Deep learning to hash by continuation", "to": "Learning to hash with binary In NIPS", "weight": 1}, {"from": "Hashnet: Deep learning to hash by continuation", "to": "Simultaneous feature learning and hash coding with deep neural networks", "weight": 1}, {"from": "Hashnet: Deep learning to hash by continuation", "to": "Contentbased multimedia information retrieval: State of the art and challenges", "weight": 1}, {"from": "Hashnet: Deep learning to hash by continuation", "to": "Deep supervised hashing for fast image retrieval", "weight": 1}, {"from": "Hashnet: Deep learning to hash by continuation", "to": "In CVPR", "weight": 1}, {"from": "Hashnet: Deep learning to hash by continuation", "to": "Hashing  with graphs", "weight": 1}, {"from": "Hashnet: Deep learning to hash by continuation", "to": "Hash bit selection: a uni\ufb01ed solution for selection problems in hashing", "weight": 1}, {"from": "Hashnet: Deep learning to hash by continuation", "to": "Partial hash update via hamming subspace learning", "weight": 1}, {"from": "Hashnet: Deep learning to hash by continuation", "to": "Recti\ufb01ed linear units improve restricted boltzmann machines", "weight": 1}, {"from": "Hashnet: Deep learning to hash by continuation", "to": "Minimal loss hashing for compact binary codes", "weight": 1}, {"from": "Hashnet: Deep learning to hash by continuation", "to": "In NIPS", "weight": 1}, {"from": "Hashnet: Deep learning to hash by continuation", "to": " J", "weight": 1}, {"from": "Hashnet: Deep learning to hash by continuation", "to": "Learning a nonlinear embedding by preserving class neighbourhood structure", "weight": 1}, {"from": "Hashnet: Deep learning to hash by continuation", "to": "Supervised discrete hashing", "weight": 1}, {"from": "Hashnet: Deep learning to hash by continuation", "to": "Content-based image retrieval at the end of the early years", "weight": 1}, {"from": "Hashnet: Deep learning to hash by continuation", "to": "Dropout: A simple way to prevent neural networks from over\ufb01tting", "weight": 1}, {"from": "Hashnet: Deep learning to hash by continuation", "to": "Semi-supervised hashing for large-scale search", "weight": 1}, {"from": "Hashnet: Deep learning to hash by continuation", "to": "Hashing for  similarity search: A survey", "weight": 1}, {"from": "Hashnet: Deep learning to hash by continuation", "to": "Spectral hash ing", "weight": 1}, {"from": "Hashnet: Deep learning to hash by continuation", "to": "Supervised hashing for image retrieval via image representation learning", "weight": 1}, {"from": "Hashnet: Deep learning to hash by continuation", "to": "Circulant binary embedding", "weight": 1}, {"from": "Hashnet: Deep learning to hash by continuation", "to": "Supervised In SIGIR", "weight": 1}, {"from": "Hashnet: Deep learning to hash by continuation", "to": "Deep semantic ranking based hashing for multi-label image retrieval", "weight": 1}, {"from": "Hashnet: Deep learning to hash by continuation", "to": "Deep hashing network for ef\ufb01cient similarity retrieval", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "A note on the inception score", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Viton: An image-based virtual try-on network", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Stacked generative adversarial networks", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Image-toimage translation with conditional adversarial networks", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Getting the look: clothing recognition and segmentation for automatic product suggestions in everyday photos", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Progressive growing of gans for improved quality, stability, and variation", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Where to buy it: Matching street clothing photos in online shops", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Hierarchical adversarially learned inference", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": ", et al", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Apparel classi\ufb01cation with style", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Clothes co-parsing via joint image segmentation and labeling with application to clothing retrieval", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Describing clothing by semantic attributes", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Deep domain adaptation for describing people based on \ufb01ne-grained clothing attributes", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Stochastic video generation with a learned prior", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "et al", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Microsoft coco: Common objects in context", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Street-to-shop: Cross-scenario clothing retrieval via parts In Computer Vision and alignment and auxiliary set", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Deep learning face attributes in the wild", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": ", and Tang, X", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Stackgan: Text to photo-realistic image synthesis with stacked generative adversarial networks", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Unpaired image-to-image translation using cycle-consistent adversarial networks", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Generative adversarial text to image synthesis", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Improved techniques for training In Advances in Neural Information Processing gans", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Bidirectional recurrent neural networks", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Neuroaesthetics in fashion: Modeling the perception of fashionability", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Amortised map inference for image superresolution", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": " Unsupervised cross-domain image generation", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Visualizing data using t-SNE", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Attention is all you need", "weight": 1}, {"from": "Fashion-gen: The generative fashion dataset and challenge", "to": "Learning visual clothing style with heterogeneous dyadic co-occurrences", "weight": 1}, {"from": "Central similarity quantization for efficient image and video retrieval", "to": "", "weight": 1}, {"from": "Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding", "to": "Mesh segmentation-a comparative study", "weight": 1}, {"from": "Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding", "to": "A framework for the objective evaluation of segmentation algorithms using a ground-truth of human segmented 3Dmodels", "weight": 1}, {"from": "Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding", "to": "T", "weight": 1}, {"from": "Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding", "to": "Linking WordNet to 3D shapes", "weight": 1}, {"from": "Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding", "to": "A benchmark for 3D mesh segmentation", "weight": 1}, {"from": "Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding", "to": "3D semantic segmentation with submanifold sparse convolutional networks", "weight": 1}, {"from": "Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding", "to": "Parts of recognition", "weight": 1}, {"from": "Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding", "to": "Co-segmentation of 3D shapes via subspace clustering", "weight": 1}, {"from": "Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding", "to": "Learning to predict part mobility from a single static snapshot", "weight": 1}, {"from": "Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding", "to": "Learning how objects function via co-analysis of interactions", "weight": 1}, {"from": "Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding", "to": "Predictive and generative neural networks for object functionality", "weight": 1}, {"from": "Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding", "to": "Robust watertight manifold surface generation method for shapenet models", "weight": 1}, {"from": "Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding", "to": "Exploring shape variations by 3d-model decomposition and partIn Computer Graphics Forum", "weight": 1}, {"from": "Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding", "to": "Learning 3D mesh segmentation and labeling", "weight": 1}, {"from": "Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding", "to": "Shape2pose: Human-centric shape analysis", "weight": 1}, {"from": "Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding", "to": "Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models", "weight": 1}, {"from": "Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding", "to": "Ai2-thor: An interactive 3d environment for visual ai", "weight": 1}, {"from": "Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding", "to": "Parameter learning and convergent inference for dense random \ufb01elds", "weight": 1}, {"from": "Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding", "to": "The hungarian method for the assignment problem", "weight": 1}, {"from": "Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding", "to": "PointGrid: A deep network for 3D shape understanding", "weight": 1}, {"from": "Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding", "to": "SO-Net: Self-organizing network for point cloud analysis", "weight": 1}, {"from": "Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding", "to": "Grass: Generative recursive autoencoders for shape structures", "weight": 1}, {"from": "Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding", "to": "PointCNN: Convolution on X -transformed points", "weight": 1}, {"from": "Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding", "to": "Physical primitive decomposition", "weight": 1}, {"from": "Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding", "to": "Exploration of continuous variability in collections of 3d shapes", "weight": 1}, {"from": "Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding", "to": "Virtualhome: Simulating household activities via programs", "weight": 1}, {"from": "Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding", "to": "PointNet: Deep learning on point sets for 3D classi\ufb01cation and segmentation", "weight": 1}, {"from": "Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding", "to": "PointNet++: Deep hierarchical feature learning on point sets in a metric space", "weight": 1}, {"from": "Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding", "to": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "weight": 1}, {"from": "Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding", "to": "Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions", "weight": 1}, {"from": "Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding", "to": "SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation", "weight": 1}, {"from": "Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding", "to": "Learning to group and label \ufb01ne-grained shape components", "weight": 1}, {"from": "Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding", "to": "Active co-analysis of a set of shapes", "weight": 1}, {"from": "Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding", "to": "Dynamic graph cnn for learning on point clouds", "weight": 1}, {"from": "Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding", "to": "VoxSegNet: Volumetric CNNs for semantic part segmentation of 3D shapes", "weight": 1}, {"from": "Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding", "to": "Structure-aware generative network for 3d-shape modeling", "weight": 1}, {"from": "Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding", "to": "SpiderCNN: Deep learning on point sets with parameterized convolutional \ufb01lters", "weight": 1}, {"from": "Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding", "to": "Chalet: Cornell house agent learning environment", "weight": 1}, {"from": "Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding", "to": "Learning hierarchical shape segmentation and labeling from online repositories", "weight": 1}, {"from": "Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding", "to": "V", "weight": 1}, {"from": "Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding", "to": "SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation", "weight": 1}, {"from": "Partnet: A large-scale benchmark for finegrained and hierarchical part-level 3d object understanding", "to": "Visual semantic planning using deep successor representations", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Birdsnap: Large-scale \ufb01ne-grained visual categorization of birds", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Food-101\u2013 mining discriminative components with random forests", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Proxylessnas: Direct neural architecture search on target task and hardware", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Xception: Deep learning with depthwise separa ble convolutions", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Autoaugment: Learning augmentation policies from data", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Sigmoid-weighted linear units for neural network function approximation in reinforcement learning", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Squeezenext: Hardware-aware neural network design", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Deep residual learning for image recognition", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Mask  r-cnn", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Amc: Automl for model compression and acceleration on mobile devices", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Gaussian error linear units  (gelus)", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Mobilenets: Ef\ufb01cient convolutional neural networks for mobile vision applications", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Squeeze-and-excitation net works", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Deep networks with stochastic depth", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Densely connected convolutional networks", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Gpipe: Ef\ufb01cient training of giant neural networks using pipeline parallelism", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": ", and Keutzer, K", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "On the expressive power of deep neural networks", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "V", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Collecting a large-scale dataset of \ufb01ne-grained cars", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Learning multiple layers of  features from tiny images", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Imagenet classi\ufb01cation with deep convolutional neural networks", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Searching for activation functions", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Regularized evolution for image classi\ufb01er architecture search", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": ", et al", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Resnet with one-neuron hidden layers is a universal approximator", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Mobilenetv2: Inverted residuals and linear bottlenecks", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Feature pyramid networks for object detection", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Progressive neural architecture search", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "The expressive power of neural networks: A view from the width", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Shuf\ufb02enet v2: Practical guidelines for ef\ufb01cient cnn architecture design", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Exploring the limits of weakly supervised pretraining", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "On the expressive power of overlapping architectures of deep learning", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Dropout: a simple way to prevent neural networks from over\ufb01tting", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Going deeper with convolutions", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Rethinking the inception architecture for computer vision", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Inception-v4, inception-resnet and the impact of residual connections on learning", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Fine-grained visual classi\ufb01cation of aircraft", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "MnasNet: Platform-aware neural architecture search for mobile", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Domain adaptive transfer learning with specialist models", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Aggregated residual transformations for deep neural networks", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Automated \ufb02ower classi\ufb01cation over a large number of classes", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Netadapt: Platform-aware neural network adaptation for mobile applications", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": " Cats and dogs", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Wide residual networks", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Polynet: A pursuit of structural diversity in very deep networks", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Shuf\ufb02enet: An extremely ef\ufb01cient convolutional neural network for mobile devices", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Learning deep features for discriminative localization", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Neural architecture search with  reinforcement learning", "weight": 1}, {"from": "Efficientnet: Rethinking model scaling for convolutional neural networks", "to": "Learning transferable architectures for scalable image recognition", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Emotionet: An accurate", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Large scale online learning of image similarity through ranking", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Deep structure inference network for facial action unit recognition", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Self-report captures 27 distinct categories of emotion bridged by continuous gradients", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Clarifying the conceptualization", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "From individual to group-level emotion recognition: Emotiw 5", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "R", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "O", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Facial Action  Coding System Manual", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Candid portrait ACM Transactions on Graphics", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Deep metric  learning with hierarchical triplet loss", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Understanding the dif\ufb01culty of In AISTATS", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Challenges in representation learning: A report on three machine learning contests", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "I", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "MS-Celeb-1M: A dataset and benchmark for large scale face recognition", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Triplet-center  loss for multi-view 3D object retrieval", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "In defense of the triplet loss for person re-identi\ufb01cation", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Densely connected convolutional networks", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Batch normalization: Accelerating deep network training by reducing internal covariate shift", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "The MegaFace benchmark: 1 million faces for recognition at scale", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Adam: A method for stochastic  optimization", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "DEAP: A database for emotion analysis using physiological signals", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Self-supervised In  learning of a facial attribute embedding from video", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Deep affect prediction in-the-wild: Aff-wild database and challenge", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "AFEW-VA database for valence and arousal estimation inthe-wild", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Convolutional deep belief networks on  CIFAR-10", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Deep facial expression recognition: A  survey", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Reliable crowdsourcing and deep locality-preserving learning for unconstrained facial expression recognition", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Deep relative distance learning: Tell the difference between similar vehicles", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Deep learning face  attributes in the wild", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "The extended Cohn-Kanade dataset (CK+): A complete dataset for action unit and emotionspeci\ufb01ed expression", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Automatic analysis of facial actions: A survey", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Facial expression recognition from near-infrared videos", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Fast training of triplet-based deep binary embedding networks", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Affectiva-MIT facial expression dataset (AM-FED): Naturalistic and spontaneous facial expressions collected in-the-wild", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Basic dimensions for a general psychological theory: Implications for personality", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "LSTMbased facial performance capture using embedding between expressions", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "AffectNet: A database for facial expression", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Facial expression recognition from world wild web", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Level playing  \ufb01eld for million scale face recognition", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "WebIn ICME", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Introducing the RECOLA multimodal corpus of remote collaborative and affective interactions", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "A circumplex model of affect", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "FaceNet: A In  uni\ufb01ed embedding for face recognition and clustering", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Deep adaptive attention for joint facial action unit detection and face alignment", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Deep metric learning via lifted structured feature embedding", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "DeepFace: Closing the gap to human-level performance in face veri\ufb01cation", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Learning \ufb01ne-grained image similarity with deep ranking", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Deep metric  learning with angular loss", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "Distance metric learning for large margin nearest neighbor classi\ufb01cation", "weight": 1}, {"from": "A compact embedding for facial expression similarity", "to": "From facial expression recognition to interpersonal relation prediction", "weight": 1}, {"from": "Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms", "to": "Meier, and J", "weight": 1}, {"from": "Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms", "to": "Tapson, and A", "weight": 1}, {"from": "Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms", "to": "Li, and L", "weight": 1}, {"from": "Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms", "to": "Bengio, and P", "weight": 1}, {"from": "Fashion-mnist: a novel image dataset for benchmarking machine learning algorithms", "to": "Cun, and R", "weight": 1}, {"from": "Imagenet: A large-scale hierarchical image database", "to": "ImageNet:  A Large-Scale Hierarchical Image Database", "weight": 1}, {"from": "Imagenet: A large-scale hierarchical image database", "to": "WordNet: An Electronic Lexical Database", "weight": 1}, {"from": "Imagenet: A large-scale hierarchical image database", "to": "Introduction to MPEG-7: Multimedia New York", "weight": 1}, {"from": "Imagenet: A large-scale hierarchical image database", "to": "Color and texture descriptors", "weight": 1}, {"from": "Imagenet: A large-scale hierarchical image database", "to": "Mpeg-7 visual motion descriptors", "weight": 1}, {"from": "Imagenet: A large-scale hierarchical image database", "to": "Ef\ufb01cient use of mpeg-7 edge  histogram descriptor", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-  grained  and  hierarchical  part-level  3d  object  understanding", "to": "Mesh segmentation-a comparative study", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-  grained  and  hierarchical  part-level  3d  object  understanding", "to": "A framework for the objective evaluation of segmentation algorithms using a ground-truth of human segmented 3Dmodels", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-  grained  and  hierarchical  part-level  3d  object  understanding", "to": "T", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-  grained  and  hierarchical  part-level  3d  object  understanding", "to": "Linking WordNet to 3D shapes", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-  grained  and  hierarchical  part-level  3d  object  understanding", "to": "A benchmark for 3D mesh segmentation", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-  grained  and  hierarchical  part-level  3d  object  understanding", "to": "3D semantic segmentation with submanifold sparse convolutional networks", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-  grained  and  hierarchical  part-level  3d  object  understanding", "to": "Parts of recognition", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-  grained  and  hierarchical  part-level  3d  object  understanding", "to": "Co-segmentation of 3D shapes via subspace clustering", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-  grained  and  hierarchical  part-level  3d  object  understanding", "to": "Learning to predict part mobility from a single static snapshot", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-  grained  and  hierarchical  part-level  3d  object  understanding", "to": "Learning how objects function via co-analysis of interactions", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-  grained  and  hierarchical  part-level  3d  object  understanding", "to": "Predictive and generative neural networks for object functionality", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-  grained  and  hierarchical  part-level  3d  object  understanding", "to": "Robust watertight manifold surface generation method for shapenet models", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-  grained  and  hierarchical  part-level  3d  object  understanding", "to": "Exploring shape variations by 3d-model decomposition and partIn Computer Graphics Forum", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-  grained  and  hierarchical  part-level  3d  object  understanding", "to": "Learning 3D mesh segmentation and labeling", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-  grained  and  hierarchical  part-level  3d  object  understanding", "to": "Shape2pose: Human-centric shape analysis", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-  grained  and  hierarchical  part-level  3d  object  understanding", "to": "Escape from cells: Deep kdnetworks for the recognition of 3D point cloud models", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-  grained  and  hierarchical  part-level  3d  object  understanding", "to": "Ai2-thor: An interactive 3d environment for visual ai", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-  grained  and  hierarchical  part-level  3d  object  understanding", "to": "Parameter learning and convergent inference for dense random \ufb01elds", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-  grained  and  hierarchical  part-level  3d  object  understanding", "to": "The hungarian method for the assignment problem", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-  grained  and  hierarchical  part-level  3d  object  understanding", "to": "PointGrid: A deep network for 3D shape understanding", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-  grained  and  hierarchical  part-level  3d  object  understanding", "to": "SO-Net: Self-organizing network for point cloud analysis", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-  grained  and  hierarchical  part-level  3d  object  understanding", "to": "Grass: Generative recursive autoencoders for shape structures", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-  grained  and  hierarchical  part-level  3d  object  understanding", "to": "PointCNN: Convolution on X -transformed points", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-  grained  and  hierarchical  part-level  3d  object  understanding", "to": "Physical primitive decomposition", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-  grained  and  hierarchical  part-level  3d  object  understanding", "to": "Exploration of continuous variability in collections of 3d shapes", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-  grained  and  hierarchical  part-level  3d  object  understanding", "to": "Virtualhome: Simulating household activities via programs", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-  grained  and  hierarchical  part-level  3d  object  understanding", "to": "PointNet: Deep learning on point sets for 3D classi\ufb01cation and segmentation", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-  grained  and  hierarchical  part-level  3d  object  understanding", "to": "PointNet++: Deep hierarchical feature learning on point sets in a metric space", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-  grained  and  hierarchical  part-level  3d  object  understanding", "to": "SplatNet: Sparse lattice networks for In Proceedings of the IEEE Conpoint cloud processing", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-  grained  and  hierarchical  part-level  3d  object  understanding", "to": "Deep functional dictionaries: Learning consistent semantic structures on 3D models from functions", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-  grained  and  hierarchical  part-level  3d  object  understanding", "to": "SGPN: Similarity group proposal network for 3D point cloud instance In Proceedings of the IEEE Conference on segmentation", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-  grained  and  hierarchical  part-level  3d  object  understanding", "to": "Learning to group and label \ufb01ne-grained shape components", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-  grained  and  hierarchical  part-level  3d  object  understanding", "to": "Active co-analysis of a set of shapes", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-  grained  and  hierarchical  part-level  3d  object  understanding", "to": "Dynamic graph cnn for learning on point clouds", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-  grained  and  hierarchical  part-level  3d  object  understanding", "to": "VoxSegNet: Volumetric CNNs for semantic part segmentation of 3D shapes", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-  grained  and  hierarchical  part-level  3d  object  understanding", "to": "Structure-aware generative network for 3d-shape modeling", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-  grained  and  hierarchical  part-level  3d  object  understanding", "to": "SpiderCNN: Deep learning on point sets with parameterized convolutional \ufb01lters", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-  grained  and  hierarchical  part-level  3d  object  understanding", "to": "Chalet: Cornell house agent learning environment", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-  grained  and  hierarchical  part-level  3d  object  understanding", "to": "Learning hierarchical shape segmentation and labeling from online repositories", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-  grained  and  hierarchical  part-level  3d  object  understanding", "to": "V", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-  grained  and  hierarchical  part-level  3d  object  understanding", "to": "SyncSpecCNN: Synchronized spectral CNN for 3D shape segmentation", "weight": 1}, {"from": "Partnet: A large-scale benchmark for fine-  grained  and  hierarchical  part-level  3d  object  understanding", "to": "Visual semantic planning using deep successor representations", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "The protein data bank", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "A benchmark for 3D mesh segmentation", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "Schelling points on 3D surface meshes", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "ImageNet: A large-scale hierarchical image database", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "Example-based synthesis of 3D object arrangements", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "Fine-grained semi-supervised labeling of large shape collections", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "Developing an engineering shape benchmark for CAD models", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "A probabilistic model for component-based shape synthesis", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "Mobius transformations for global intrinsic symmetry analysis", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "Learning part-based templates from large collections of 3D shapes", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "Exploring collections of 3D models using fuzzy correspondences", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "3D object representations for \ufb01ne-grained categorization", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "PDBsum: A web-based database of summaries and analyses of all PDB structures", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "Creating consistent scene graphs using a probabilistic grammar", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "Building a large annotated corpus of english: The Penn Treebank", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "Symmetry in 3D geometry: Extraction and applications", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "Simpli\ufb01cation and repair of polygonal models using volumetric techniques", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "Building a database  of 3D scenes from user annotations", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "The Princeton shape benchmark", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "Sliding shapes for 3D ob ject detection in depth images", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "A large-scale shape benchmark for 3D object retrieval: Toyohashi shape benchmark", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "LabelMe: Online image annotation and applications", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "3D ShapeNets: A Deep Representation for Volumetric Shapes", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "Beyond PASCAL: A benchmark for 3D object detection in the wild", "weight": 1}, {"from": "Shapenet: An information-rich 3d model repository", "to": "Retrieving articulated 3-D models using medial surfaces and their graph spectra", "weight": 1}]);

        // adding nodes and edges to the graph
        data = {nodes: nodes, edges: edges};

        var options = {
    "configure": {
        "enabled": false
    },
    "edges": {
        "color": {
            "inherit": true
        },
        "smooth": {
            "enabled": false,
            "type": "continuous"
        }
    },
    "interaction": {
        "dragNodes": true,
        "hideEdgesOnDrag": false,
        "hideNodesOnDrag": false
    },
    "physics": {
        "enabled": true,
        "stabilization": {
            "enabled": true,
            "fit": true,
            "iterations": 1000,
            "onlyDynamicEdges": false,
            "updateInterval": 50
        }
    }
};
        
        

        

        network = new vis.Network(container, data, options);
	 
        


        
        network.on("stabilizationProgress", function(params) {
      		document.getElementById('loadingBar').removeAttribute("style");
	        var maxWidth = 496;
	        var minWidth = 20;
	        var widthFactor = params.iterations/params.total;
	        var width = Math.max(minWidth,maxWidth * widthFactor);

	        document.getElementById('bar').style.width = width + 'px';
	        document.getElementById('text').innerHTML = Math.round(widthFactor*100) + '%';
	    });
	    network.once("stabilizationIterationsDone", function() {
	        document.getElementById('text').innerHTML = '100%';
	        document.getElementById('bar').style.width = '496px';
	        document.getElementById('loadingBar').style.opacity = 0;
	        // really clean the dom element
	        setTimeout(function () {document.getElementById('loadingBar').style.display = 'none';}, 500);
	    });
        

        return network;

    }

    drawGraph();

</script>
</body>
</html>